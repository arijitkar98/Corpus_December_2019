16 performance 2817 power wall 4018 sea change switch uniprocessors multiprocessors 4319 real stuff benchmarking intel core i7 46110 fallacies pitfalls 49111 concluding remarks 52112 historical perspective reading 54113 exercises 54 11 introductionwelcome book delighted opportunity convey excitement world computer system dry dreary eld progress glacial new ideas atrophy neglect computers product incredibly vibrant information technology industry aspects responsible almost 10 gross national product united states whose economy become dependent part rapid improvements information technology promised moores law unusual industry embraces innovation breathtaking rate last 30 years number new computers whose introduction appeared revolutionize computing industry revolutions cut short someone else built even better computer race innovate led unprecedented progress since inception electronic computing late 1940s transportation industry kept pace computer industry example today could travel new york london second penny take moment contemplate improvement would change societyliving tahiti working san francisco going moscow evening bolshoi balletand appreciate implications change 4 chapter 1 computer abstractions technology computers led third revolution civilization information revolution taking place alongside agricultural industrial revolutions e resulting multiplication humankinds intellectual strength reach naturally ected everyday lives profoundly changed ways search new knowledge carried ou ere new vein scien c investigation computational scientists joining theoretical experimental scientists exploration new frontiers astronomy biology chemistry physics among others e computer revolution continues time cost computing improves another factor 10 opportunities computers multiply applications economically infeasible suddenly beco practical recent past following applications computer ction computers automobiles microprocessors improved dramatically price performance early 1980s computer control cars ludicrous today computers reduce pollution improve f ciency via engine controls increase safety blind spot warnings lane departure warnings moving object detection ation protect occupants crash cell phones would dreamed advances computer systems would lead half planet mobile phones allowing persontoperson communication almost anyone anywhere world human genome project e cost computer equipment map analyze human dna sequences hundreds mil lions dollars unlikely anyone would considered project computer costs 10 100 times higher would 15 25 years earlier moreover costs continue drop soon able acquire genome allowing medical care tailored world wide web existence time th rst edition book web transformed society many web replaced libraries newspapers search engines content web grew size value nding relevant information became increasingly important today many people rely search engines large part lives would hardship go without clearly advances technology ect almost every aspect society hardware advances allowed programmers create wonderfully useful ware explains computers omnipresent todays science ction suggests tomorrows killer applications already way glasses augment reality cashless society cars drive 11 introduction 5classes computing applications characteristicsalthough common set hardware technologies see sections 14 15 used computers ranging smart home appliances cell phones largest supercomputers thes erent applications hav erent design requirements employ core hardware techno erent ways broadly speaking computers used thre erent classes applications personal computers pcs possibly best known form computing readers book likely used extensively personal computers emphasize delivery good performance single users low cost usually execute thirdparty ware class computing drove evolution many computing technologies 35 years old servers modern form much larger computers usually accessed via network servers oriented carrying large workloads may consist either single complex applicationsusually scien c engineering applicationor handling many small jobs would occur building large web server ese applications usually based ware another source database simulation system en mo ed customized particular function servers built basic technology desktop computers provide greater computing storage inputoutput capacity general servers also place greater emphasis dependability since crash usually mo costly would single user pc servers span widest range cost capability low end server may little desktop computer without screen keyboard cost thousand dollar ese lowend servers typically used fo le storage small business applications simple web serving see section 610 extreme supercomputers present consist tens thousands processors many terabytes memory cost tens hundreds millions dollars supercomputers usually used highend scien c engineering calculations weather forecasting oil exploration protein structure determination largescale problems although supercomputers represent peak computing capability represent relatively small fraction servers relatively small fraction overall computer market terms total revenue embedded computers largest class computers span widest range applications performance embedded computers include microprocessors found car computers television set networks processors control modern airplane cargo ship embedded computing systems designed run one application one set related applications normally integrated hardware delivered single system thus despite large number embedded computers users never really see using computer personal computer pc computer designed use individual usually incorporating graphics display keyboard mouse server computer used running larger programs multiple users en simultaneously typically accessed via network supercomputer class computers highest performance cost co gured servers typically cost tens hundreds millions dollars terabyte tb originally 1099511627776 240 bytes although communications secondary storage systems developers started using term mean 1000000000000 1012 bytes reduce confusion use term tebibyte tib 240 byt ning terabyte tb mean 10 12 bytes figure 11 shows full range decimal binary values names embedded computer computer inside another device used running one predetermined application collection ware 6 chapter 1 computer abstractions technology embedded applications en unique application requirements combine minimum performance stringent limitations cost power example consider music player processor need fast necessary handle limited function beyond minimizing cost power important objectives despite low cost embedded computers en lower tolerance failure since results vary upsetting new television crashes devastating might occur computer plane cargo ship crashes consumeroriented embedded applications digital home appliance dependability achieved primarily simplicity emphasis one function perfectly possible large embedded systems techniques redundancy server world en employed although book focuses generalpurpose computers concepts apply directly slight mo cations embedded computers elaboration elaborations short sections used throughout text provide detail particular subject may interest disinterested readers may skip elaboration since subsequent material never depend contents elaborationmany embedded processors designed using processor cores version processor written hardware description language verilog vhdl see c hardware processor core fabrication single chipwelcome postpc era e continuing march technology brings generational changes computer hardware shake entire information technology industry since last edition book undergone change cant past switch starting 30 years ago personal computers replacing figure 11 2x vs 10y bytes ambiguity resolved adding binary notation common size terms last column note much larger binary term corresponding decimal term compounded head char ese pr xes work bits well bytes gigabit gb 109 bits gibibits gib 2 30 bits decimal term abbreviation value binary term abbreviation value largerkilobyte kb103kibibyte kib2102megabytemb10 6mebibytemib 2205gigabyte gb109gibibyte gib2307terabyte tb1012tebibyte tib24010petabytepb10 15pebibytepib 25013exabyteeb10 18exbibyteeib 26015zettabytezb10 21zebibytezib 27018yottabyteyb10 24yobibyteyib 28021 11 introduction 70200400 60080010001200 1400200720082009201020112012 tablet smart phone sales millionspc including tabletcell phone including smart phonefigure 12 number manufactured per year tablets smart phones reﬂ ect postpc era versus personal computers traditional cell phones smart phones represent recent growth cell phone industry passed pcs 2011 tablets fastest growing category nearly doubling 2011 2012 recent pcs traditional cell phone categories relatively declining pc personal mobile device pmd pmds battery operated wireless connectivity internet typically cost hundreds dollars like pcs users download ware apps run unlike pcs longer keyboard mouse likely rely touchsensitive screen even speech input todays pmd smart phone tablet computer tomorrow may include electronic glasses figure 12 shows rapid growth time tablets smart phones versus pcs traditional cell phones taking traditional server cloud computing relies upon giant datacenters known warehouse scale computers wscs companies like amazon google build wscs containing 100000 servers let companies rent portions provide ware services pmds without build wscs indeed ware service saas deployed via cloud revolutionizing ware industry pmds wscs revolutionizing hardware industry todays ware developers en portion application runs pmd portion runs cloud learn book successful programmers always concerned performance programs getting results user quickly critical creating successful ware 1960s 1970s primary constraint computer performance size computers memory us programmers en followed simple credo minimize memory space make programs fast personal mobile devices pmds small wireless devices connect internet rely batteries power ware installed downloading apps conventional examples smart phones tablets cloud computing refers large collections servers provide services internet providers rent dynamically varying numbers servers utility ware service saas delivers ware data service internet usually via thin program browser runs local client devices instead binary code must installed runs wholly device examples include web search social networking 8 chapter 1 computer abstractions technology last decade advances computer design memory technology greatly reduced importance small memory size applications embedded computing systems programmers interested performance need understand issues replaced simple memory model 1960s parallel nature processors hierarchical nature memories moreover explain section 17 todays programmers need worry energ ciency programs running either pmd cloud also requires understanding code programmers seek build competitive versions ware therefore need increase knowledge computer organization honored opportunity explain whats inside revolutionary machine unraveling ware program hardware covers computer time complete book believe able answer following questions programs written highlevel language c java translated language hardware hardware execute resulting program comprehending concepts forms basis understanding aspects hardware ware ect program performance interface ware hardware ware instruct hardware perform needed function ese concepts vital understanding write many kinds ware determines performance program programmer improve performance see depends original program ware translation program computers language th ectiveness hardware executing program techniques used hardware designers improve performance book introduce basic concepts modern comput e interested nd much material topic advanced book computer architecture quantitative approach techniques used hardware designers improve energy ciency programmer help hinder energ ciency reasons consequences recent switch sequential processing parallel processin book gives motivation describes current hardware mechanisms support parallelism surveys new generation multicore microprocessors see chapter 6 since th rst commercial computer 1951 great ideas computer architects come lay foundation modern computing multicore microprocessor microprocessor containing multiple processors cores single integrated circuit 11 introduction 9without understanding answers questions improving performance program modern computer evaluating features might make one computer better another particular application complex process trial error rather scien c procedure driven insight analysis rst chapter lays foundation rest book introduces basic ideas nitions places major components ware hardware perspective shows evaluate performance energy introduces integrated circuits technology fuels computer revolution explains th multicores chapter later ones likely see many new words words may heard sure mean dont panic yes lot special terminology used describing modern computers terminology actually helps since enables us describe precisely function capability addition computer designers including authors love using acronyms easy understand know letters stand help remember locate terms included highlighted nition every term margins th rst time appears er short time working terminology uent friends impressed correctly use acronyms bios cpu dimm dram pcie sata many others reinforce ware hardware systems used run program ect performance use special section understanding program performance throughout book summarize important insights program performance e rst one appears e performance program depends combination th ectiveness algorithms used program ware systems used create translate program machine instructions th ectiveness computer executing instructions may include inputoutput io operations table summarizes hardware ware ect performance hardware software componenthow component affects performance topic covered algorithmdetermines number sourcelevel statements number io operations executedother booksprogramming language compiler architecture determines number computer instructions sourcelevel statement chapters 2 3 processor memory systemdetermines fast instructions executedchapters 4 5 6 io system hardware operating systemdetermines fast io operations may executedchapters 4 5 6 acronym word constructed taking initial letters string words example ram acronym random access memory cpu acronym central processing unit understanding program performance 10 chapter 1 computer abstractions technology demonstrate impact ideas book improve performance c program multiplies matrix times vector sequence chapters step leverages understanding underlying hardware really works modern microprocessor improve performance factor 200 category data level parallelism chapter 3 use subword parallelism via c intrinsics increase performance factor 38 category instruction level parallelism chapter 4 use loop unrolling exploit multiple instruction issue outoforder execution hardware increase performance another factor 23 category memory hierarchy optimization chapter 5 use cache blocking increase performance large matrices another factor 25 category thread level parallelism chapter 6 use parallel loops openmp exploit multicore hardware increase performance another factor 14 check sections designed help readers assess whether comprehend major concepts introduced chapter understand implications concepts check questions simple answers others discussion among group answers sp c questions found end chapter check questions appear end section making easy skip sure understand material e number embedded processors sold every year greatly outnumbers number pc even postpc processors co rm deny insight based experience try count number embedded processors home compare number conventional computers home 2 mentioned earlier ware hardware ect performance program think examples following right place look performance bottleneck e algorithm chosen e programming language compiler e operating system e processor e io system devices check 12 eight great ideas computer architecture 11 12 eight great ideas computer architecturewe introduce eight great ideas computer architects invented last 60 years comput ese ideas powerful lasted long er th rst computer used newer architects demonstrating admiration imitating predecessor ese great ideas themes weave subsequent chapters examples arise point th uence section introduce icons highlighted terms represent great ideas use identify nearly 100 sections book feature use great ideas design moores law e one constant computer designers rapid change driven largely moores law states integrated circuit resources double every 1824 months moores law resulted 1965 prediction growth ic capacity made gordon moore one founders intel computer designs take years resources available per chip easily double quadruple start nish project like skeet shooter computer architects must anticipate technology th nishes rather design starts use right moores law graph represent designing rapid change use abstraction simplify designboth computer architects programmers invent techniques make productive otherwise design time would lengthen dramatically resources grew moores law major productivity technique hardware ware use abstractions represent design erent levels representation lowerlevel details hidden er simpler model higher levels well use abstract painting icon represent second great idea make common case fast making common case fast tend enhance performance better optimizing rare case ironically common case en simpler rare case hence en easier enhance common sense advice implies know common case possible careful experimentation measurement see section 16 use sports car icon making common case fast common trip one two passengers surely easier make fast sports car fast minivan 12 chapter 1 computer abstractions technology performance via parallelism since dawn computing computer architects ered designs get performance performing operations parallel well see many examples parallelism book use multiple jet engines plane icon parallel performance performance via pipelining particular pattern parallelism prevalent computer architecture merits name pipelining example befor engines bucket brigade would respond many cowboy movies show response dastardly act villa e townsfolk form human chain carry water source could much quickly move buckets chain instead individuals running back forth pipeline icon sequence pipes section representing one stage pipeline performance via prediction following saying better ask forgiveness ask permission th nal great idea prediction cases faster average guess start working rather wait know sure assuming mechanism recover misprediction expensive prediction relatively accurate use fortunetellers crystal ball prediction icon hierarchy memories programmers want memory fast large cheap memory speed en shapes performance capacity limits size problems solved cost memory today en majority computer cost architects found address co icting demands hierarchy memories fastest smallest expensive memory per bit top hierarchy slowest largest cheapest per bit bottom shall see chapter 5 caches give programmer illusion main memory nearly fast top hierarchy nearly big cheap bottom hierarchy use layered triangle icon represent memory hierarchy e shape indicates speed cost size closer top faster expensive per bit memory wider base layer bigger memory dependability via redundancycomputers need fast need dependable since physical device fail make systems dependable including redundant components take failure occurs help detect failures use tractortrailer icon since dual tires side rear axels allow truck continue driving even one tire fails presumably truck driver heads immediately repair facility th tire xed thereby restoring redundancy 13 program 13 13 program typical application word processor large database system may consist millions lines code rely sophisticated ware libraries implement complex functions support application see hardware computer execute extremely simple lowlevel instructions go complex application simple instructions involves several layers ware interpret translate highlevel operations simple computer instructions example great idea abstraction figure 13 shows layers ware organized primarily hierarchical fashion applications outermost ring variety systems ware sitting hardware applications ware ere many types systems ware two types systems ware central every computer system today operating system compiler operating system interfaces users program hardware provides variety services supervisory functions among important functions handling basic input output operations allocating storage memory providing protected sharing computer among multiple applications using simultaneously examples operating systems use today linux ios windows paris simply stared spoke french never succeed making idiots understand language mark twain e innocents abroad 1869systems ware ware provides services commonly useful including operating systems compilers loaders assemblers operating system supervising program manages resources computer b programs run computer applications software systems software hardware figure 13 simpliﬁ ed view hardware software hierarchical layers shown concentric circles hardware center applications software outermost complex applications en multiple layers application ware well example database system may run top systems ware hosting application turn runs top database 14 chapter 1 computer abstractions technology compilers perform another vital function translation program written highlevel language c c java visual basic instructions hardware execute given sophistication modern programming languages simplicity instructions executed hardware translation highlevel language program hardware instructions complex give brief overview process go depth chapter 2 appendix highlevel language language hardware actually speak electronic hardware need send electr e easiest signals computers understand computer alphabet two letters 26 letters english alphabet limit much written two letters computer alphabet limit computers e two symbols two letters numbers 0 1 commonly think computer language numbers base 2 binary numbers refer letter binary digit bit computers slaves commands called instructions instructions collections bits computer understands obeys thought numbers example bits 1000110010100000tell one computer add two numbers chapter 2 explains use numbers instructions data dont want steal chapters thunder using numbers instructions data foundation computing e rst programmers communicated computers binary numbers tedious quickly invented new notations closer way humans think rst notations translated binary hand process still tiresome using computer help program computer pioneers invented programs translate symbolic notation binary e rst programs named assembler program translates symbolic version instruction binary version example programmer would write add aband assembler would translate notation 1000110010100000 instruction tells computer add two numbers b e name coined symbolic language still used today assembly language contrast binary language machine understands machine language although tremendous improvement assembly language still far notations scientist might like use simulat ow accountant might use balance books assembly language requires programmer write one line every instruction computer follow forcing programmer think like computer compiler program translates highlevel language statements assembly language statements binary digit also called bit one two numbers base 2 0 1 components information instruction command computer hardware understands obeys assembler program translates symbolic version instructions binary version assembly language symbolic representation machine instructions machine language binary representation machine instructions e recognition program could written translate powerful language computer instructions one great breakthroughs early days computing programmers today owe productivityand sanityto creation highlevel programming languages compilers translate programs languages instructions figure 14 shows relationships among programs languages examples power abstraction highlevel programming language portable language c c java visual basic composed words algebraic notation translated compiler assembly language figure 14 c program compiled assembly language assembled binary machine language although translation highlevel language binary machine language shown two steps compilers cut middleman produce binary machine language directly ese languages program examined detail chapter 2 13 program 15swapint v int kint temp temp vk vk vk1 vk1 temp swap multi 2 54 add 2 42 lw 15 02 lw 16 42 sw 16 02 sw 15 42 jr 3100000000101000100000000100011000 00000000100000100001000000100001 10001101111000100000000000000000 10001110000100100000000000000100 10101110000100100000000000000000 10101101111000100000000000000100 00000011111000000000000000001000assembler compilerbinary machine language program mips assembly language program mips highlevel language program c 16 chapter 1 computer abstractions technology compiler enables programmer write highlevel language expression b e compiler would compile assembly language statement add abas shown assembler would translate statement binary instructions tell computer add two numbers bhighlevel programming languages er several important b ts first allow programmer think natural language using english words algebraic notation resulting programs look much like text like tables cryptic symbols see figure 14 moreover allow languages designed according intended use hence fortran designed scien c computation cobol business data processing lisp symbol manipulation ere also domainspe c languages even narrower groups users interested simulation uids example e second advantage programming languages improved programmer productivity one areas widespread agreement ware development takes less time develop programs written languages require fewer lines express idea conciseness clear advantage high level languages assembly language e nal advantage programming languages allow programs independent computer developed since compilers assemblers translate highlevel language programs binary instructions computer ese three advantages strong today little programming done assembly language 14 covers looked program uncover underlying ware lets open covers computer learn underlying hardware e underlying hardware computer performs basic functions inputting data outputting data processing data storing data functions performed primary topic book subsequent chapters deal erent parts four tasks come important point book point important hope remember forever emphasize identifying big picture item dozen big pictures book th rst components computer perform tasks inputting outputting processing storing data two key components computers input devices microphone output devices speaker names suggest input feeds input device mechanism computer fed information keyboard output device mechanism conveys result computation user display another computer 14 covers 17figure 15 organization computer showing ﬁ classic components e processor gets instructions data memory input writes data memory output reads data memory control sends signals determine operations datapath memory input output e classic components computer input output memory datapath control last two sometimes combined called processor figure 15 shows standard organization computer organization independent hardware technology place every piece every computer past present one thes categories help keep perspective th components computer shown front page following chapters portion interest chapter highlighted bigpicturecomputer output result computation sent user devices wireless networks provide input output computer chapters 5 6 describe inputoutput io devices detail lets take introductory tour computer hardware starting external io devices 18 chapter 1 computer abstractions technology looking glass e fascinating io device probably graphics display personal mobile devices use liquid crystal displays lcds get thin lowpower display e lcd source light instead controls transmission light typical lcd includes rodshaped molecules liquid form twisting helix bends light entering display either light source behind display less en r ected ligh e rods straighten current applied longer bend light since liquid crystal material two screens polarized 90 degrees light pass unless bent today lcd displays use active matrix tiny transistor switch pixel precisely control current make sharper images redgreenblue mask associated dot display determines intensity three color components th nal image color active matrix lcd three transistor switches point e image composed matrix picture elements pixels represented matrix bits called bit map depending size screen resolution display matrix typical tablet ranges size 1024 768 2048 1536 color display might use 8 bits three colors red blue green 24 bits per pixel permitting millions erent colors displayed e computer hardware support graphics consists mainly raster refresh er frame bu er store bit map e image represented onscreen stored frame bu er bit pattern per pixel read graphics display refresh rate figure 16 shows frame b er simp ed design 4 bits per pixel e goal bit map faithfully represent scre e challenges graphics systems arise human eye good detecting even subtle changes screen liquid crystal display display technology using thin layer liquid polymers used transmit block light according whether charge applied pixel e smallest individual picture element screens composed hundreds thousands millions pixels organized matrix x0x1y0frame buffer raster scan crt display 00111101y1x0x1y0y1figure 16 coordinate frame buffer left determines shade corresponding coordinate raster scan crt display right pixel x 0 y0 contains bit pattern 0011 lighter shade screen bit pattern 1101 pixel x 1 y1active matrix display liquid crystal display using transistor control transmission light individual pixel rough computer displays landed airplane deck moving carrier observed nuclear particle hit potential rocket nearly speed light watched computer reveal innermost workings ivan sutherland father computer graphics scienti c american 1984 14 covers 19touchscreen pcs also use lcd displays tablets smartphones postpc era replaced keyboard mouse touch sensitive displays wonderful user interface advantage users pointing directly interested rather indirectly mouse variety ways implement touch screen many tablets today use capacitive sensing since people electrical conductors insulator like glass covered transparent conductor touching distorts electrostatic eld screen results change capacitance technology allow multiple touches simultaneously allows gestures lead attractive user interfaces opening boxfigure 17 shows contents apple ipad 2 tablet computer unsurprisingly th classic components computer io dominates reading device e list io devices includes capacitive multitouch lcd display front facing camera rear facing camera microphone headphone jack speakers accelerometer gyroscope wifi network bluetooth networ e datapath control memory tiny portion components e small rectangles figure 18 contain devices drive advancing technology called integrated circuits nicknamed chips e a5 package seen middle figure 18 contains two arm processors operate clock rate 1 gh e processor active part computer following instructions program letter adds numbers tests numbers signals io devices activate occasionally people call processor cpu bureaucraticsounding central processor unit descending even lower hardware figure 19 reveals details microprocessor e processor logically comprises two main components datapath control respective brawn brain processor e datapath performs arithmetic operations control tells datapath memory io devices according wishes instructions program chapter 4 explains datapath control higherperformance design e a5 package figure 18 also includes two memory chips 2 gibibits capacity thereby supplying 512 mib e memory programs kept running also contains data needed running program e memory built dram chips dram stands dynamic random access memory multiple drams used together contain instructions data program contrast sequential access memories magnetic tapes ram portion term dram means memory accesses take basically amount time matter portion memory read descending depths component hardware reveals insights computer inside processor another type memorycache memory integrated circuit also called chip device combining dozens millions transistors central processor unit cpu also called processor e active part computer contains datapath control adds numbers tests numbers signals io devices activate datapath e component processor performs arithmetic operations control e component processor commands datapath memory io devices according instructions program memory e storage area programs kept running contains data needed running programs dynamic random access memory dram memory built integrated circuit provides random access location access times 50 nanoseconds cost per gigabyte 2012 5 10 20 chapter 1 computer abstractions technology figure 17 components apple ipad 2 a1395 e metal back ipad reversed apple logo middle center top capacitive multitouch screen lcd display far right 38 v 25 watthour polymer battery consists three liion cell cases ers 10 hours battery life fa metal frame attaches lcd back ipad e small components surrounding metal back center think computer en lshaped compactly inside case next battery figure 18 shows closeup lshaped board low metal case logic printed circuit board contains processor memory e tiny rectangle logic board contains chip provides wireless communication wifi bluetooth fm tuner ts small slot low corner logic board near upp corner case another lshaped component frontfacing camera assembly includes camera headphone jack microphone near right upper corner case board containing volume control silentscreen rotation lock button along gyroscope accelerometer ese last two chips combine allow ipad recognize 6axis motio e tiny rectangle next rearfacing camera near bottom right case lshaped speaker assembly e cable bottom connector logic board cameravolume control board e board cable speaker assembly controller capacitive touchscreen courtesy ifixit www xitcom figure 18 e logic board apple ipad 2 figure 17 e photo highligh integrated circuits e large integrated circuit middle apple a5 chip contains dual arm processor cores run 1 ghz well 512 mb main memory inside package figure 19 shows photograph processor chip inside a5 package e similar sized chip th 32 ash memory chip nonvolatile storage ere empty space two chips seco ash chip installed double storage capacity ipad e chips right a5 include power controller io controller chips courtesy ifixit www xitcom 14 covers 21figure 19 e processor integrated circuit inside a5 package e size chip 121 101 mm manufactured originally 45nm process see section 15 two identical arm processors cores th chip powervr graphical processor unit gpu four datapaths upp quadrant th bottom side arm cores interfaces main memory dram courtesy chipworks wwwchipworkscom cache memory consists small fast memory acts bu er dram memory e nontec nition cache safe place hiding things cache built usin erent memory technology static random access memory sram sram faster less dense hence expensive dram see chapter 5 sram dram two layers memory hierarchy cache memory small fast memory acts bu er slower larger memory static random access memory sram also memory built integrated circuit faster less dense dram 22 chapter 1 computer abstractions technology mentioned one great ideas improve design abstraction one important abstractions interface hardware lowestlevel ware importance given special name instruction set architecture simply architecture computer e instruction set architecture includes anything programmers need know make binary machine language program work correctly including instructions io devices typically operating system encapsulate details io allocating memory lowlevel system functions application programmers need worry detai e combination basic instruction set operating system interface provided application programmers called application binary interface abian instruction set architecture allows computer designers talk functions independently hardware performs example talk functions digital clock keeping time displaying time setting alarm independently clock hardware quartz crystal led displays plastic buttons computer designers distinguish architecture implementation architecture along lines implementation hardware obeys architecture abstractio ese ideas bring us another big picture instruction set architecture also called architecture abstract interface hardware lowestlevel ware encompasses information necessary write machine language program run correctly including instructions registers memory access io application binary interface abi e user portion instruction set plus operating system interfaces used application programmers nes standard binary portability across computers implementation hardware obeys architecture abstraction hardware ware consist hierarchical layers using abstraction lower layer hiding details level one key interface levels abstraction instruction set architecture interface hardware lowlevel ware abstract interface enables many implementations varying cost performance run identical ware bigpicturea safe place data us far seen input data compute using data display data lose power computer however everything would lost memory inside computer volatile loses power forgets contrast dvd disk doesnt forget movie turn power dvd player thus nonvolatile memory technology volatile memory storage dram retains data receiving power nonvolatile memory form memory retains data even absence power source used store programs runs dvd disk nonvolatile 14 covers 23to distinguish volatile memory used hold data programs running nonvolatile memory used store data programs runs term main memory primary memory used former secondary memory latter secondary memory forms next lower layer memory hierarchy drams dominated main memory since 1975 magnetic disks dominated secondary memory starting even earlier size form factor personal mobile devices use ash memory nonvolatile semiconductor memory instead disks figure 18 shows chip containing th ash memory ipad 2 slower dram much cheaper dram addition nonvolatile although costing per bit disks smaller comes much smaller capacities rugged pow cient disks hence ash memory standard secondary memory pmds alas unlike disks dr ash memory bits wear er 100000 1000000 writ us le systems must keep track number writes strategy avoid wearing storage moving popular data chapter 5 describes disks ash memory detail communicating computers weve explained input compute display save data still one missing item found todays computers computer networks processor shown figure 15 connected memory io devices networks interconnect whole computers allowing computer users extend power computing including communication networks become popular backbone current computer systems new personal mobile device server without network interface would ridiculed networked computers several major advantages communication information exchanged computers high speeds resource sharing rather computer io devices computers network share io devices nonlocal access connecting computers long distances users need near computer using networks vary length performance cost communication increasing according speed communication distance information travels perhaps popular type network ethernet kilometer long transfer 40 gigabits per second length speed make ethernet useful connect computers sa oor building main memory also called primary memory memory used hold programs running typically consists dram todays computers secondary memory nonvolatile memory used store programs data runs typically consists ash memory pmds magnetic disks servers magnetic disk also called hard disk form nonvolatile secondary memory composed rotating platters coated magnetic recording material rotating mechanical devices access times 5 20 milliseconds cost per gigabyte 2012 005 010 ash memory nonvolatile semi conductor memory cheaper slower dram expensive per bit faster magnetic disks access times 5 50 microseconds cost per gigabyte 2012 075 100 24 chapter 1 computer abstractions technology hence example generically called local area network local area networks interconnected switches also provide routing services security wide area networks cross continents backbone internet supports web ey typically based opt bers leased telecommunication companies networks changed face computing last 30 years becoming much ubiquitous making dramatic increases performance 1970s individuals access electronic mail internet web exist physically mailing gnetic tapes primary way transfer large amounts data two locations local area networks almost nonexistent existing wide area networks limited capacity restricted access networking technology improved became much cheaper much higher capacity example th rst standardized local area network technology developed 30 years ago version ethernet maximum capacity also called bandwidth 10 million bits per second typically shared tens hundred computers today local area network technology ers capacity 1 40 gigabits per second usually shared computers optical communications technology allowed similar growth capacity wide area networks hundreds kilobits gigabits hundreds computers connected worldwide network millions computers connected combination dramatic rise deployment networking combined increases capacity made network technology central information revolution last 30 years last decade another innovation networking reshaping way computers communicate wireless technology widespread enabled p e ability make radio lowcost semiconductor technology cmos used memory microprocessors enab cant improvement price leading explosion deployment currently available wireless technologies called ieee standard name 80211 allow transmission rates 1 nearly 100 million bits per second wireless technology quite bit erent wirebased networks since users immediate area share airwaves semiconductor dram memory ash memory disk storag er cantly technology list volatility approximate relative access time approximate relative cost compared dram 15 technologies building processors processors memory improved incredible rate computer designers long embraced latest electronic technology try win race design better computer figure 110 shows technologies local area network lan network designed carry data within geographically co ned area typically within single building wide area network wan network extended hundreds kilometers span continent check figure 110 relative performance per unit cost technologies used computers time source computer museum boston 2013 extrapolated authors see section 112 1000000 10000000197619781980198219841986year introduction 1988199019921994199619982000 200220042006200820102012 kibibit capacity16k64k256k1m4m16m64m128m256m512m1g2g4g10000010000100010010figure 111 growth capacity per dram chip time e yaxis measured kibibits 2 10 bi e dram industry quadrupled capacity almost every three years 60 increase per year 20 years recent years rate slowed somewhat closer doubling every two years three years 15 technologies building processory 25been used time estimate relative performance per unit cost technology since technology shapes computers able quickly evolve believe computer professionals familiar basics integrated circuits transistor simply ono switch controlled electricity e integrated circuit ic combined dozens hundreds transistors single chip gordon moore predicted continuous doubling resources predicting growth rate number transistors per chip describe tremendous increase number transistors hundreds millions adjective large scale added term creating abbreviation vlsi largescale integrated circuit rate increasing integration remarkably stable figure 111 shows growth dram capacity since 1977 decades industry consistently quadrupled capacity every 3 years resulting increase excess 16000 times understand manufacture integrated circuits start beginning e manufacture chip begins silicon substance found sand silicon conduct electricity well called semiconductor special chemical process possible add materials silicon allow tiny areas transform one three devices excellent conductors electricity using either microscopic copper aluminum wire transistor ono switch controlled electric signal largescale integrated vlsi circuit device containing hundreds thousands millions transistors silicon natural element semiconductor semiconductor substance conduct electricity well yeartechnology used computersrelative performanceunit cost 1951vacuum tube 11965351975integrated circuitvery largescale integrated circuit ultra largescale integrated circuittransistor 900199524000002013250000000000 26 chapter 1 computer abstractions technology excellent insulators electricity like plastic sheathing glass areas conduct insulate special conditions switch transistors fall last category vlsi circuit billions combinations conductors insulators switches manufactured single small package e manufacturing process integrated circuits critical cost chips hence important computer designers figure 112 shows process e process starts silicon crystal ingot looks like giant sausage today ingots 812 inches diameter 1224 inches long ingot nely sliced wafers 01 inches thic ese wafers go series processing steps patterns chemicals placed wafer creating transistors conductors insulators discussed earlier todays integrated circuits contain one layer transistors may two eight levels metal conductor separated layers insulators silicon crystal ingot rod composed silicon crystal 8 12 inches diameter 12 24 inches long wafer slice silicon ingot 01 inches thick used create chips slicerdicer20 40processing stepsbond die topackagesilicon ingotwafertesterparttestership tocustomerstested diestestedwaferblankwaferspackaged diespatterned waferstested packaged diesfigure 112 chip manufacturing process er sliced silicon ingot blank wafers put 20 40 steps create patterned wafers see figure 113 ese patterned wafers tested wafer tester map good parts made en wafers diced dies see figure 19 gure one wafer produced 20 dies 17 passed testing x means die bad e yield good dies case 1720 ese good dies bonded packages tested one time shipping packaged parts customers one bad packaged part found nal test single microscop aw wafer one dozens patterning steps result area wafer failin ese defects called make virtually impossible manufacture perfect wafer e simplest way cope imperfection place many independent components single wafer e patterned wafer chopped diced components defect microscopic aw wafer patterning steps result failure die containing defect figure 113 12inch 300 mm wafer intel core i7 courtesy intel e number dies 300 mm 12 inch wafer 100 yield 280 207 105 e several dozen partially rounded chips boundaries wafer useless included easier create masks used pattern silico die uses 32nanometer technology means smallest features approximately 32 nm size although typically somewhat smaller actual feature size refers size transistors drawn versus th nal manufactured size 16 performance 27called dies informally known chips figure 113 shows photograph wafer containing microprocessors diced earlier figure 19 shows individual microprocessor die dicing enables discard dies unlucky enough contain th aws rather whole wafer concept quan ed yield process whic ned percentage good dies total number dies wafer e cost integrated circuit rises quickly die size increases due lower yield smaller number dies tha wafer reduce cost using next generation process sh rinks large die uses smaller sizes transistors wir improves yield die count per wafer 32nanometer nm process typical 2012 means essentially smallest feature size die 32 nm die e individual rectangular sections cut wafer informally known chipsyield e percentage good dies total number dies wafer 28 chapter 1 computer abstractions technology youve found good dies connected inputoutput pins package using process called bonding ese packaged parts test nal time since mistakes occur packaging shipped customers elaboration cost integrated circuit expressed three simple equationscost per die cost per wafer dies per waferyield dies per waf fer wafer area die areayield defects per areadie 11a a2 2 rst equation straightforward derive second approximation since subtract area near border round wafer accommodate rectangular dies see figure 113 nal equation based empirical observations yields integrated circuit factories exponent related number critical processing stepshence depending defect rate size die wafer costs generally linear die areaa key factor determining cost integrated circuit volume following reasons chip made high volume cost less 1 high volumes manufacturing process tuned particular design increasing yield 2 less work design highvolume part lowvolume part e masks used make chip expensive cost per chip lower higher volumes 4 engineering development costs high largely independent volume thus development cost per die lower highvolume parts 5 highvolume parts usually smaller die sizes lowvolume parts therefore higher yield per wafer 16 performance assessing performance computers quite challenging e scale intricacy modern ware systems together wide range performance improvement techniques employed hardware designers made performance assessment much cult trying choose amon erent computers performance important attribute accurately measuring comparin erent computers critical check airplanepassenger capacitycruising range milescruising speed mphpassenger throughput mphboeing 777375 46300610228750boeing 74747013214641500610286700bacsud concorde40001350178200douglas dc85087200544 79424passengers mphfigure 114 capacity range speed number commercial airplanes e last column shows rate airplane transports passengers capacity times cruising speed ignoring range takeo landing times 16 performance 29purchasers therefore designer e people selling computers know well en salespeople would like see computer best possible light whether light accurately ects needs purchasers application hence understanding best measure performance limitations performance measurements important selecting computer e rest section describ erent ways performance determined describe metrics measuring performance viewpoint computer user designer also look metrics related present classical processor performance equation use throughout text deﬁ ning performance say one computer better performance another mean although question might seem simple analogy passenger airplanes shows subtle question performance figure 114 lists typical passenger airplanes together cruising speed range capacity wanted know planes table best performance would rst need ne performance example considering erent measures performance see plane highest cruising speed concorde retired service 2003 plane longest range dc8 plane largest capacity 747 lets suppose ne performance terms speed still leaves two possib nitions co ne fastest plane one highest cruising speed taking single passenger one point another least time interested transporting 450 passengers one point another however 747 would clearly fastest last column th gure shows similarly ca ne computer performance sev erent ways running program tw erent desktop computers youd say faster one desktop computer gets job rst running datacenter several servers running jobs submitted many users youd say faster computer one completed jobs day individual computer user interested reducing response time time start completion taskalso referred response time also called execution time e total time required computer complete task including disk accesses memory accesses io activities operating system overhead cpu execution time 30 chapter 1 computer abstractions technology execution time datacenter managers en interested increasing throughput bandwidth total amount work done given time hence cases w erent performance metrics erent sets applications benchmark personal mobile devices focused response time versus servers focused throughput throughput response time following changes computer system increase throughput decrease response time 1 replacing processor computer faster version 2 adding additional processors system uses multiple processors separate tasksfor example searching web decreasing response time almost always improves throughput hence case 1 response time throughput improved case 2 one task gets work done faster throughput increases however demand processing second case almost large throughput system might force requests queue case increasing throughput could also improve response time since would reduce waiting time queue us many real computer systems changing either execution time throughput en ects discussing performance computers primarily concerned response time th rst chapters maximize performance want minimize response time execution time ta us relate performance execution time computer x performance execution time xx1 means two computers x performance x greater performance performanceperformance execution timeexecution time xyxy11eexecution timeexecution time yx execution time longer x x faster throughput also called bandwidth another measure performance number tasks completed per unit time exampleanswer discussing computer design en want relate performance two erent computers quantitatively use phrase x n times faster yor equivalently x n times fast yto mean performance performance xynif x n times fast execution time n times long x performance performance execution time execution time xyyxnrelative performance computer runs program 10 seconds computer b runs program 15 seconds much faster b know n times fast b ifperformance performance execution time execution time abban us performance ratio 151015and therefore 15 times fast b example could also say computer b 15 times slower computer since performance performance ab15means performance performance ab15exampleanswer 16 performance 31 32 chapter 1 computer abstractions technology simplicity normally use terminology fast try compare computers quantitatively performance execution time reciprocals increasing performance requires decreasing execution time avoid potential confusion terms increasing decreasing usually say improve performance improve execution time mean increase performance decrease execution time measuring performance time measure computer performance computer performs amount work least time fastest program execution time measured seconds per program however time b erent ways depending coun e straightforwar nition time called wall clock time response time elapsed time ese terms mean total time complete task including disk accesses memory accesses inputoutput io activities operating system overheadeverything computers en shared however processor may work several programs simultaneously cases system may try optimize throughput rather attempt minimize elapsed time one program hence en want distinguish elapsed time time processor working behalf cpu execution time simply cpu time recognizes distinction time cpu spends computing task include time spent waiting io running programs remember though response time experienced user elapsed time program cpu time cpu time divided cpu time spent program called user cpu time cpu time spent operating system performing tasks behalf program called system cpu time erentiating system us cult accurately en hard assign responsibility operating system activities one user program rather another functionality erences among operating systems consistency maintain distinction performance based elapsed time based cpu execution time use term system performance refer elapsed time unloaded system cpu performance refer user cpu time focus cpu performance chapter although discussions summarize performance applied either elapsed time cpu time measurements erent applications sensitive erent aspects performance computer system many applications especially running servers depend much io performance turn relies hardware ware total elapsed time measured wall clock measurement interest cpu execution time also called cpu time e actual time cpu spends computing sp c task user cpu time e cpu time spent program system cpu time e cpu time spent operating system performing tasks behalf program understanding program performance application environments user may care throughput response time complex combination two eg maximum throughput worstcase response time improve performance program one must clea nition performance metric matters proceed look performance bottlenecks measuring program execution looking likely bottlenecks following chapters describe search bottlenecks improve performance various parts system although computer users care time examine details computer convenient think performance metrics particular computer designers may want think computer using measure relates fast hardware perform basic functions almost computers constructed using clock determines events take place hardware ese discrete time intervals called clock cycles ticks clock ticks clock periods clocks cycles designers refer length clock period time complete clock cycle eg 250 picoseconds 250 ps clock rate eg 4 gigahertz 4 ghz inverse clock period next subsection formalize relationship clock cycles hardware designer seconds computer user 1 suppose know application uses personal mobile devices cloud limited network performance following changes state whether throughput improves response time throughput improve neither improves extra network channel added pmd cloud increasing total network throughput reducing delay obtain network access since two channels b e networking ware improved thereby reducing network communication delay increasing throughput c memory added computer 2 computer cs performance 4 times fast performance computer b runs given application 28 seconds long computer c take run application cpu performance factors users designers en examine performance usin erent metrics could relate thes erent metrics could determine th ect design change performance experienced user since co ning cpu performance point bottomline performance measure cpu clock cycle also called tick clock tick clock period clock cycle e time one clock period usually processor clock runs constant rate clock period e length clock cycle check 16 performance 33 34 chapter 1 computer abstractions technology execution time simple formula relates basic metrics clock cycles clock cycle time cpu time cpu execution time programcpu clock cycles progrram clock cycle time alternatively clock rate clock cycle time inverses cpu execution time programcpu clock cycles pro g gramclock rate formula makes clear hardware designer improve performance reducing number clock cycles required program length clock cycle see later chapters designer en faces tradeo number clock cycles needed program length cycle many techniques decrease number clock cycles may also increase clock cycle time improving performance favorite program runs 10 seconds computer 2 ghz clock trying help computer designer build computer b run program 6 seco e designer determined substantial increase clock rate possible increase ect rest cpu design causing computer b require 12 times many clock cycles computer program clock rate tell designer target let rst nd number clock cycles required program cpu time cpu clock cycles clock rate seconds cpu clock aaa10 cycles cyclessecond cpu clock cycles seconds aa210 1021 9002010 99cyclessecond cyclesexampleanswer cpu time b found using equation cpu time cpu clock cyclesclock rate seconds bab1261220 10122010 699 cyclesclock rateclock rate cycles secobbn nds cyclessecond cyclessecond ghz022010410 499to run program 6 seconds b must twice clock rate instruction performance e performance equations include reference number instructions needed program however since compiler clearly generated instructions execute computer execute instructions run program execution time must depend number instructions program one way think execution time equals number instructions executed multiplied average time per instructio erefore number clock cycles required program written cpu clock cyclesinstructions program average clock ccyclesper instruction e term clock cycles per instruction average number clock cycles instruction takes execute en abbreviated cpi erent instructions may tak erent amounts time depending cpi average instructions executed program cpi provides one way comparing tw erent implementations instruction set architecture since number instructions executed program course using performance equation suppose two implementations instruction set architecture computer clock cycle time 250 ps cpi 20 program computer b clock cycle time 500 ps cpi 12 program computer faster program much clock cycles per instruction cpi average number clock cycles per instruction program program fragment example 16 performance 35 36 chapter 1 computer abstractions technology know computer executes number instructions program lets call number fir nd number processor clock cycles computer cpu clock cycles cpu clock cycles abii2012now compute cpu time computer cpu timecpu clock cyclesclock cycle time psaai20250 5500i pslikewise b cpu time ps ps bii12500600 clearly computer faster e amount faster given ratio execution times cpu performancecpu performanceexecution time execution abbttime pspsa600 50012i iwe conclude computer 12 times fast computer b program classic cpu performance equation write basic performance equation terms instruction count number instructions executed program cpi clock cycle time cpu timeinstruction countcpiclock cycle time since clock rate inverse clock cycle time cpu time instruction countcpi clock rate ese formulas particularly useful separate three key factors ect performance use formulas compare tw erent implementations evaluate design alternative know impact three parameters answerinstruction count e number instructions executed program comparing code segmentsa compiler designer trying decide two code sequences particular computer e hardware designers supplied following facts cpi instruction class abccpi123for particular highlevel language statement compiler writer considering two code sequences require following instruction counts instruction counts instruction class code sequenceabc12122411which code sequence executes instructions faster cpi sequence sequence 1 executes 2 1 2 5 instructions sequence 2 executes 4 1 1 6 instruction erefore sequence 1 executes fewer instructions use equation cpu clock cycles based instruction count cpi nd total number clock cycles sequence cpu clock cyclescpic iiin1 yields cpu clock cycles cycles121122322610 cpu clock cycles cycles24112134239 code sequence 2 faster even though executes one extra instruction since code sequence 2 takes fewer overall clock cycles instructions must low e cpi values computed cpi cpu clock cycles instruction count cpi cpu clock cycles 111 12210520instruction count cpi cpu clock cycles instruct iion count 29615exampleanswer 16 performance 37 38 chapter 1 computer abstractions technology figure 115 shows basic measurements erent levels computer measured case see factors combined yield execution time measured seconds per program timesecondsprogram instructions programclock cycles instr uuctionseconds clock cycle always bear mind complete reliable measure computer performance time example changing instruction set lower instruction count may lead organization slower clock cycle time higher cpi sets improvement instruction count similarly cpi depends type instructions executed code executes fewest number instructions may fastest bigpicturecomponents performance units measure cpu execution time programseconds programinstruction count instructions executed program clock cycles per instruction cpi average number clock cycles per instruction clock cycle time seconds per clock cyclefigure 115 basic components performance measured determine value factors performance equation measure cpu execution time running program clock cycle time usually published part documentation computer e instruction count cpi mor cult obtain course know clock rate cpu execution time need one instruction count cpi determine measure instruction count using ware tools pro le execution using simulator architecture alternatively use hardware counters included processors record variety measurements including number inst ructions executed average cpi en sources performance loss since instruction count depends architecture exact implementation measure instruction count without knowing details implementatio e cpi however depends wide variety design details computer including memory system processor structure see chapter 4 chapter 5 well mix instruction types executed application us cpi varies application well among implementations instruction set e example shows danger using one factor instruction count assess performance comparing two computers must look three components combine form execution time factors identical like clock rate example performance determined comparing nonidentical factors since cpi varies instruction mix instruction count cpi must compared even clock rates identical several exercises end chapter ask evaluate series computer compiler enhancements ect clock rate cpi instruction count section 110 well examine common performance measurement incorporate terms thus misleading e performance program depends algorithm language compiler architecture actual hardware e following table summarizes components ect factors cpu performance equation hardware software componentaffects whathow algorithminstruction count possibly cpithe algorithm determines number source program instructions executed hence number processor instructions executed algorithm may also affect cpi favoring slower faster instructions example algorithm uses divides tend higher cpi programming languageinstruction count cpithe programming language certainly affects instruction count since statements language translated processor instructions determine instruction count language may also affect cpi features example language heavy support data abstraction eg java require indirect calls use higher cpi instructions compilerinstruction count cpi ciency compiler affects instruction count average cycles per instruction since compiler determines translation source language instructions computer instructions compilers role complex affect cpi complex ways instruction set architectureinstruction count clock rate cpi instruction set architecture affects three aspects cpu performance since affects instructions needed function cost cycles instruction overall clock rate processor elaboration although might expect minimum cpi 10 well see chapter 4 processors fetch execute multiple instructions per clock cycle ect approach designers invert cpi talk ipc instructions per clock cycle processor executes average 2 instructions per clock cycle ipc 2 hence cpi 05instruction mix measure dynamic frequency instructions across one many programs understanding program performance 17 power wall 39 40 chapter 1 computer abstractions technology 26673300340012516200020066253600753958777291101494133103110100100010000802861982803861985804861989pentium1993pentiumpro 1997pentium 4willamette2001pentium 4prescott2004core 2kentsfield2007clock rate mhz02040 60 80100 120power wattsclock ratepowercore i5clarkdale 2010core i5ivy bridge2012figure 116 clock rate power intel x86 microprocessors eight generations 25 years e pentium 4 made dramatic jump clock rate power less performance e prescott thermal problems led abandonment pentium 4 line e core 2 line reverts simpler pipeline lower clock rates multiple processors per chip e core i5 pipelines follow footsteps elaboration xed save energy temporarily boost performance todays processors vary clock rates would need use average clock rate program example intel core i7 temporarily increase clock rate 10 chip gets warm intel calls turbo mode given application written java runs 15 seconds desktop processor new java compiler released requires 06 many instructions old compiler unfortunately increases cpi 11 fast expect application run using new compiler pick right answer three choices 1506 1182 sec b 15 06 11 99 sec c 1511 06275 sec 17 power wall figure 116 shows increase clock rate power eight generations intel microprocessors 30 years clock rate power increased rapidly decades th attened recently e reason grew together correlated reason recent slowing run practical power limit cooling commodity microprocessors check although power provides limit cool postpc era really critical resource energy battery life trump performance personal mobile device architects warehouse scale computers try reduce costs powering cooling 100000 servers costs high scale measuring time seconds safer measure program performance rate like mips see section 110 energy metric joules better measure power rate like watts joulessecond e dominant technology integrated circuits called cmos complementary metal oxide semiconductor cmos primary source energy consumption socalled dynamic energythat energy consumed transistors switch states 0 1 vice vers e dynamic energy depends capacitive loading transistor voltage applied energycapacitiveloadvoltage 2 equation energy pulse logic transition 0 1 0 1 0 e energy single transition energycapacitiveloadvoltage 122 e power required per transistor product energy transition frequency transitions powercapacitiveloadvoltagefrequencyswitche d122 frequency switched function clock rate e capacitive load per transistor function number transistors connected output called fanout technology determines capacitance wires transistors regard figure 116 could clock rates grow factor 1000 power grew factor 30 energy thus power reduced lowering voltage occurred new generation technology power function voltage squared typically voltage reduced 15 per generation 20 years voltages gone 5 v 1 v increase power 30 times relative power suppose developed new simpler processor 85 capacitive load complex older processor assume adjustable voltage reduce voltage 15 compared processor b results 15 shrink frequency impact dynamic power example 17 power wall 41 42 chapter 1 computer abstractions technology powerpowercapacitive loadvoltage fnewold 085 085 2r requency switched capacitive loadvoltagefrequency 085 2 switched us power ratio 085052 4hence new processor uses half power old processor e problem today lowering voltage appears make transistors leaky like water faucets completely shut even today 40 power consumption server chips due leakage transistors started leaking whole process could become unwieldy try address power problem designers already attached large devices increase cooling turn parts chip used given clock cycle although many expensive ways cool chips thereby raise power say 300 watts techniques generally expensive personal computers even servers mention personal mobile devices since computer designers slammed power wall needed new way forward ey chos erent path way designed microprocessors th rst 30 years elaboration although dynamic energy primary source energy consumption cmos static energy consumption occurs leakage cur ows even transistor servers leakage typically responsible 40 energy consumption thus increasing number transistors increases power dissipation even transistors always variety design techniques technology innovations deployed control leakage hard lower voltage elaboration power challenge integrated circuits two reasons first power must brought distributed around chip modern microprocessors use hundreds pins power ground similarly multiple levels chip interconnect used solely power ground distribution portions chip second power dissipated heat must removed server chips burn 100 watts cooling chip surrounding system major expense warehouse scale computers see chapter 6 answer 18 sea change switch uniprocessors multiprocessors 43 18 sea change switch uniprocessors multiprocessors e power limit forced dramatic change design microprocessors figure 117 shows improvement response time programs desktop microprocessors time since 2002 rate slowed factor 15 per year factor 12 per year rather continuing decrease response time single program running single processor 2006 desktop server companies shipping microprocessors multiple processors per chip b en throughput response time reduce confusion words processor microprocessor companies refer processors cores microprocessors generically called multicore microprocessors hence quadcore microprocessor chip contains four processors four cores past programmers could rely innovations hardware architecture compilers double performance programs every 18 months without change line code today programmers g cant improvement response time need rewrite programs take advantage multiple processors moreover get historic running faster new microprocessors programmers continue improve performance code number cores increases reinforce ware hardware systems work hand hand use special section hardwareso ware interface throughout book th rst one appearing ese elements summarize important insights critical interface parallelism always critical performance computing en hidden chapter 4 explain pipelining elegant technique runs programs faster overlapping execution instruction one example instructionlevel parallelism parallel nature hardware abstracted away programmer compiler think hardware executing instructions sequentially forcing programmers aware parallel hardware explicitly rewrite programs parallel third rail computer architecture companies past depended change behavior failed see section 615 historical perspective startling whole industry bet future programmer nally successfully switch explicitly parallel programming ware like music written solo performer current generation chips getting little experience duets quartets small ensembles scoring work large orchestra chorus di erent kind challenge brian hayes computing parallel universe 2007hardware software interface 44 chapter 1 computer abstractions technology 15913182451801171832804816499931267177930164195604366817108118651438719484218712412911010010001000010000019781980198219841986198819901992199419961998200020022004200620082010 20142012performance vs vax1178025year 52year 22year ibm powerstation 100 150 mhz digital alphastation 4266 266 mhzdigital alphastation 5300 300 mhzdigital alphastation 5500 500 mhz alphaserver 4000 5600 600 mhz 21164 digital alphaserver 8400 6575 575 mhz 21264 professional workstation xp1000 667 mhz 21264a intel vc820 motherboard 10 ghz pentium iii processor ibm power4 13 ghz intel xeon ee 32 ghz amd athlon 26 ghz intel core 2 extreme 2 cores 29 ghz intel core duo extreme 2 cores 30 ghz intel core i7 extreme 4 cores 32 ghz boost 35 ghz intel xeon 4 cores 33 ghz boost 36 ghz intel xeon 6 cores 33 ghz boost 36 ghz intel d850emvr motherboard 306 ghz pentium 4 processor hyperthreading technology 15 vax11785 amd athlon 64 28 ghzdigital 3000 axp500 150 mhzhp 9000750 66 mhzibm rs6000540 30 mhzmips m2000 25 mhz mips m120 167 mhzsun4260 167 mhzvax 8700 22 mhz ax11780 5 mhz intel core i7 4 cores 34 ghz boost 38 ghz31999intel xeon 4 cores 36 ghz boost 40 34967figure 117 growth processor performance since mid1980s chart plots performance relative vax 11780 measured specint benchmarks see section 110 prior mid1980s processor performance growth largely tech nology driven averaged 25 per year e increase growth 52 since attributable advanced architectural organizational ide e higher annual performance improvement 52 since mid1980s meant performance factor seven higher 2002 would stayed 25 since 2002 limits power available instructionlevel paral lelism long memory latency slowed uniprocessor performance recently 22 per year hard programmers write explicitly parallel programs e rst reason parallel programming b nition performance programming increases th culty programming program need correct solve important problem provide useful interface people programs invoke program must also fast otherwise dont need performance write sequential program e second reason fast parallel hardware means programmer must divide application processor roughly amount time overhead scheduling coordination doesnt fritter away potential performance b ts parallelism analogy suppose task write newspaper story eight reporters working story could potentially write story eight times faster achieve increased speed one would need break task reporter something time us must schedule subtasks anything went wrong one reporter took longer seven others bene ts eight writers would diminished us must balance 18 sea change switch uniprocessors multiprocessors 45load evenly get desired speedup another danger would reporters spend lot time talking write sections would also fall short one part story conclusion couldnt written parts completed us care must taken reduce communication synchronization overhead analogy parallel programming challenges include scheduling load balancing time synchronization overhead communication parties might guess challenge er reporters newspaper story processors parallel programming ect sea change industry th chapters edition book section implications parallel revolution chapter chapter 2 section 211 parallelism instructions synchronization usually independent parallel tasks need coor dinate times say completed wo chapter explains instructions used multicore processors synchronize tasks chapter 3 section 36 parallelism computer arithmetic subword parallelism perhaps simplest form parallelism build involves computing elements parallel multiplying two vectors subword parallelism takes advantage resources supplied moores law provider wider arithmetic units operate many operands simultaneously chapter 4 section 410 parallelism via instructions given th culty explicitly parallel programming tremendo ort invested 1990s hardware compiler uncover implicit parallelism initially via pipelining chapter describes aggressive techniques including fetching executing multiple instructions simultaneously guessing outcomes decisions executing instructions speculatively using prediction chapter 5 section 510 parallelism memory hierarchies cache coherence one way lower cost communication processors use address space processor read write data given processors today use caches keep temporary copy data faster memory near processor easy imagine parallel programming would even cult caches associated processor inconsistent values shared dat chapter describes mechanisms keep data caches consistent chapter 5 section 511 parallelism memory hierarchy redundant arrays inexpensive disks section describes using many disks conjunction er much higher throughput original inspiration redundant arrays inexpensive disks e real popularity raid proved much greater dependability ered including modest number redundan e section explains erences performance cost dependability th erent raid levels 46 chapter 1 computer abstractions technology addition sections full chapter parallel processing chapter 6 goes detail challenges parallel programming presents two contrasting approaches communication shared addressing explicit message passing describes restricted model parallelism easier program discusses th culty benchmarking parallel processors introduces new simple performance model multicore microprocessors nally describes evaluates four examples multicore microprocessors using model mentioned chapters 3 6 use matrix vector multiply running example show type parallelism ca cantly increase performance appendix c describes increasingly popular hardware component included desktop computers graphics processing unit gpu invented accelerate graphics gpus becoming programming platforms right might expect given times gpus rely parallelism appendix c describes nvidia gpu highlights parts parallel programming environment 19 real stuff benchmarking intel core i7each chapter section entitled real st ties concepts book computer may use every day ese sections cover technology underlying modern computers th rst real st section look integrated circuits manufactured performance power measured intel core i7 example spec cpu benchmark computer user runs programs day day would perfect candidate evaluate new computer e set programs run would form workload evaluate two computer systems user would simply compare execution time workload two computers users however situation instead must rely methods measure performance candidate computer hoping methods r ect well computer perform users workload alternative usually followed evaluating computer using set benchmarks programs sp cally chosen measure performance e benchmarks form workload user hopes predict performance actual workload noted make common case fast yo rst need know accurately case common benchmarks play critical role computer architecture spec system performance evaluation cooperative ort funded supported number computer vendors create standard sets benchmarks modern computer systems 1989 spec originally created benchmark thought computers would universally applicable idea like book didnt think would develop fast didnt envision wed able get many parts chip nally go e transistor came along unexpectedly happened much faster expected j presper eckert coinventor eniac speaking 1991 workload set programs run computer either actual collection applications run user constructed real programs approximate mix typical workload sp es programs relative frequencies benchmark program selected use comparing computer performance set focusing processor performance called spec89 evolved throug generation e latest spec cpu2006 consists set 12 integer benchmarks cint2006 oatingpoint benchmarks cfp2006 e integer benchmarks vary part c compiler chess program quantum computer simulatio e oatingpoint benchmarks include structured grid codes fo nite element modeling particle method codes molecular dynamics sparse linear algebra codes fo uid dynamics figure 118 describes spec integer benchmarks execution time intel core i7 shows factors explain execution time instruction count cpi clock cycle time note cpi varies factor 5 simplify marketing computers spec decided report single number summarize 12 integer benchmarks dividing execution time reference processor execution time measured computer normalizes execution time measurements normalization yields measure called specratio advantage bigger numeric results indicate faster performance specratio inverse execution time cint2006 cfp2006 summary measurement obtained taking geometric mean specratios elaboration comparing two computers using specratios use geometric mean gives relative answer matter computer used normalize results averaged normalized execution time values arithmetic mean results would vary depending computer choose reference 19 real stuff benchmarking intel core i7 47figure 118 specintc2006 benchmarks running 266 ghz intel core i7 920 equation page 35 explains execution time product three factors table instruction count billions clocks per instruction cpi clock cycle time nanoseconds specratio simply reference time supplied spec divided measured execution time e single number quoted specintc2006 geometric mean specratios descriptionname instructioncount x 109cpiclock cycle timeseconds x 10œ9executiontime secondsreference time secondsspecratio interpreted string processing perl 2252 060 0376 508 9770 192 blocksorting bzip2 2390 070 0376 629 9650 154 compressiongnu c compiler gcc 794 120 0376 358 8050 225 combinatorial optimization mcf 221 266 0376 221 9120 412 go game ai go 1274 110 0376 527 10490 199 search gene sequence hmmer 2616 060 0376 590 9330 158 chess game ai sjeng 1948 080 0376 586 12100 207 quantum computer libquantum 659 044 0376 109 20720 1900 simulation video compression h264avc 3793 050 0376 713 22130 310 discrete event omnetpp 367 210 0376 290 6250 215 simulation librarygamespath finding astar 1250 100 0376 470 7020 149 xml parsing xalancbmk 1045 070 0376 275 6900 251 geometric mean œ œ œ œ œ 257 œ 48 chapter 1 computer abstractions technology formula geometric mean execution time ratio iinn1where execution time ratioi execution time normalized reference computer ith program total n workload aaaa inin means product 121spec power benchmark given increasing importance energy power spec added benchmark measure power reports power consumption servers erent workload levels divided 10 increments period time figure 119 shows results server using intel nehalem processors similar figure 119 specpower_ssj2008 running dual socket 266 ghz intel xeon x5650 16 gb dram one 100 gb ssd disk target load performance ssj_opsaverage power watts 100 865618 258 90 786688 242 80 698051 224 70 607826 204 60 521391 185 50 436757 170 40 345919 157 30 262071 146 20 176061 135 10 86784 121 0 0 80 overall sum 4787166 1922 ssj_ops power 2490specpower started another spec benchmark java business applications specjbb2005 exercises processors caches main memory well java virtual machine compiler garbage collector pieces operating system performance measured throughput units business operations per second simplify marketing computers spec 110 fallacies pitfalls 49boils numbers single number called overall ssj_ops per watt e formula single summarizing metric overall ssj_ops per wattssj_ops power iii010 ii 010 ssj_ops performance 10 increment power power consumed performance level fallacies pitfalls e purpose section fallacies pitfalls found every chapter explain commonly held misconceptions might encounter call fallacies discussing fallacy try give counterexample also discuss pitfalls easily made mistak en pitfalls generalizations principles true limited cont e purpose sections help avoid making mistakes computers may design use costperformance fallacies pitfalls ensnared many computer architect including us accordingly sectio ers shortage relevant examples start pitfall traps many designers reveals important relationship computer design pitfall expecting improvement one aspect computer increase overall performance amount proportional size improvement e great idea making common case fast demoralizing corollary plagued designers hardware ware reminds us opportunity improvement ected much time event consumes simple design problem illustrates well suppose program runs 100 seconds computer multiply operations responsible 80 seconds time much improve speed multiplication want program r times faster e execution time program er making improvement given following simple equation known amdahls law execution time mprovement execution tiyy improvement amount improvement execution time unaec ttedfor problem execution time mprovement seconds secon 8010080 ndds science must begin myths criticism myths sir karl popper e philosophy science 1957amdahls law rule stating performance enhancement possible given improvement limited amount improved feature used quantitative version law diminishing returns 110 50 chapter 1 computer abstractions technology since want performance times faster new execution time 20 seconds giving 208020080 seconds seconds seconds seconds nn amount enhancemultiply achiev vefold increase performance multiply accounts 80 workload e performance enhancement possible given improvement limited amount improved feature used everyday life concept also yields call law diminishing returns use amdahls law estimate performance improvements know time consumed function potential speedup amdahls law together cpu performance equation handy tool evaluating potential enhancements amdahls law explored detail exercises amdahls law also used argue practical limits number parallel processors examine argument fallacies pitfalls section chapter 6 fallacy computers low utilization use little power pow ciency matters low utilizations server workloads vary utilization servers googles warehouse scale computer example 10 50 time 100 less 1 time even giv years learn run specpower benchmark well specially co gured computer best results 2012 still uses 33 peak power 10 load systems th eld co gured specpower benchmark surely worse since servers workloads vary use large fraction peak power luiz barroso urs hölzle 2007 argue redesign hardware achieve energyproportional computing future servers used say 10 peak power 10 workload could reduce electricity bill datacenters become good corporate citizens era increasing concern co 2 emissions fallacy designing performance designing energy e ciency unrelated goals since energy power time en case hardware ware optimizations take less time save energy overall even optimization takes bit energy used one reason rest computer consuming energy program running even optimized portion uses little energy reduced time save energy whole system pitfall using subset performance equation performance metric already warned danger predicting performance based simply one clock rate instruction count cpi another common mistake 110 fallacies pitfalls 51is use two three factors compare performance although using two three factors may valid limited context concept also easily misused indeed nearly proposed alternatives use time performance metric led eventually misleading claims distorted results incorrect interpretations one alternative time mips million instructions per second given program mips simply mipsinstruction count execution time 106since mips instruction execution rate mips sp es performance inversely execution time faster computers higher mips rating e good news mips easy understand faster computers mean bigger mips matches intuition ere three problems using mips measure comparing computers first mips sp es instruction execution rate take account capabilities instructions compare computers erent instruction sets using mips since instruction counts certainl er second mips varies programs computer thus computer single mips rating example substituting execution time see relationship mips clock rate cpi mipsinstruction count instruction countcpi clock rate106cclock ratecpi 106 e cpi varied factor 5 spec cpu2006 intel core i7 computer figure 118 mips well finally importantly new program executes instructions instruction faster mips vary independently performance consider following performance measurements program measurementcomputer acomputer b instruction count10 billion 8 billionclock rate4 ghz 4 ghzcpi1011a computer higher mips rating b computer faster million instructions per second mips measurement program execution speed based number millions instructions mips computed instruction count divided product execution time 10 6check 52 chapter 1 computer abstractions technology 111 concluding remarks although di cult predict exactly level costperformance computers future safe bet much better today participate advances computer designers programmers must understand wider variety issues hardware ware designers construct computer systems hierarchical layers lower layer hiding details level great idea abstraction fundamental understanding todays computer systems mean designers limit knowing single abstraction perhaps important example abstraction interface hardware lowlevel ware called instruction set architecture maintaining instruction set architecture constant enables many implementations architecturepresumably varying cost performanceto run identical ware downside architecture may preclude introducing innovations require interface change ere reliable method determining reporting performance using execution time real programs metr execution time related important measurements make following equation seconds program instructions program clock cycles instruction seconds clock cycle use equation constituent factors many times remember though individually factors determine performance product equals execution time reliable measure performance execution time valid unimpeachable measure performance many metrics proposed found wanting sometimes metrics ar awed start ecting execution time times metric valid limited context extended used beyond context without additional clari cation needed make valid bigpicturewhere eniac equipped 18000 vacuum tubes weighs 30 tons computers future may 1000 vacuum tubes perhaps weigh 1½ tons popular mechanics march 1949 111 concluding remarks 53 e key hardware technology modern processors silicon equal importance understanding integrated circuit technology understanding expected rates technological change predicted moores law silicon fuels rapid advance hardware new ideas organization computers improved priceperformance two key ideas exploiting parallelism program typically today via multiple processors exploiting locality accesses memory hierarchy typically via caches energy ciency replaced die area critical resource microprocessor design conserving power trying increase performance forced hardware industry switch multicore microprocessors thereby forcing ware industry switch programming parallel hardware parallelism required performance computer designs always measured cost performance well important factors energy dependability cost ownership scalability although chapter focused cost performance energy best designs strike appropriate balance given market among factors road map bookat bottom abstractions th classic components computer datapath control memory input output refer figure 15 ese components also serve framework rest chapters book datapath chapter 3 chapter 4 chapter 6 appendix c control chapter 4 chapter 6 appendix c memory chapter 5 input chapters 5 6 output chapters 5 6 mentioned chapter 4 describes processors exploit implicit parallelism chapter 6 describes explicitly parallel multicore microprocessors heart parallel revolution appendix c describes highly parallel graphics processor chip chapter 5 describes memory hierarchy exploits locality chapter 2 describes instruction setsthe interface compilers computerand emphasizes role compilers programming languages using features instruction set appendix provides reference instruction set chapter 2 chapter 3 describes computers handle arithmetic data appendix b introduces logic design 54 chapter 1 computer abstractions technology 112 historical perspective readingfor chapter text section devoted historical perspective found online site accompanies book may trace development idea series computers describe important projects provide references case interested probing e historical perspective chapter provides background key ideas presented opening chapter purpose give human story behind technological advances place achievements historical context understanding past may better able understand forces shape computing future historical perspective section online ends suggestions reading also collected separately online section reading e rest section 112 found online 113 exercises e relative time ratings exercises shown square brackets er exercise number average exercise rated 10 take twice long one rated 5 sections text read attempting exercise given angled brackets example 14 means read section 14 covers help solve exercise 11 2 11 aside smart cell phones used billion people list describe four types computers 12 e eight great ideas computer architecture similar ideas ot elds match eight ideas computer architecture design moores law use abstraction simplify design make common case fast performance via parallelism performance via pipelining performance via prediction hierarchy memories dependability via redundancy following ideas ot eldsa assembly lines automobile manufacturing b suspension bridge cables c aircra marine navigation systems incorporate wind information express elevators buildings acti eld science like immense anthill individual almost vanishes mass minds tumbling carrying information place place passing around speed light le omas natural science e lives cell 1974 113 exercises 55e library reserve desk f increasing gate area cmos transistor decrease switching time g adding electromagnetic aircra catapults electricallypowered opposed current steampowered models allowed increased power generation ered new reactor technology h building selfdriving cars whose control systems partially rely existing sensor systems already installed base vehicle lane departure systems smart cruise control systems 13 2 13 describe steps transform program written highlevel language c representation directly executed computer processor 14 2 14 assume color display using 8 bits primary colors red green blue per pixel frame size 1280 1024a minimum size bytes frame b er store frame b long would take minimum frame sent 100 mbits network 15 4 16 consider thre erent processors p1 p2 p3 executing instruction set p1 3 ghz clock rate cpi 15 p2 25 ghz clock rate cpi 10 p3 40 ghz clock rate cpi 22 processor highest performance expressed instructions per second b processors execute program 10 seco nd number cycles number instructions c trying reduce execution time 30 leads increase 20 cpi clock rate get time reduction 16 20 16 consider tw erent implementations instruction set architecture e instructions divided four classes according cpi class b c p1 clock rate 25 ghz cpis 1 2 3 3 p2 clock rate 3 ghz cpis 2 2 2 2 given program dynamic instruct ion count 10e6 instructions divided classes follows 10 class 20 class b 50 class c 20 class implementation faster global cpi implementation b find clock cycles required cases 56 chapter 1 computer abstractions technology 17 15 16 compilers profound impact performance application assume program compiler results dynamic instruction count 10e9 execution time 11 compiler b results dynamic instruction count 12e9 execution time 15 find average cpi program given processor clock cycle time 1 ns b assume compiled programs run tw erent processors execution times two processors much faster clock processor running compiler code versus clock processor running compiler bs code c new compiler developed uses 60e8 instructions average cpi 11 speedup using new compiler versus using compiler b original processor 18 e pentium 4 prescott processor released 2004 clock rate 36 ghz voltage 125 v assume average consumed 10 w static power 90 w dynamic power e core i5 ivy bridge released 2012 clock rate 34 ghz voltage 09 v assume average consumed 30 w static power 40 w dynamic power 181 5 17 processo nd average capacitive loads 182 5 17 find percentage total dissipated power comprised static power ratio static power dynamic power technology 183 15 17 total dissipated power reduced 10 much voltage reduced maintain leakage current note power ned product voltage current 19 assume arithmetic loadstore branch instructions processor cpis 1 12 5 respectively also assume single processor program requires execution 256e9 arithmetic instructions 128e9 loadstore instructions 256 million branch instructions assume processor 2 ghz clock frequency assume program parallelized run multiple cores number arithmetic loadstore instructions per processor divided 07 x p p number processors number branch instructions per processor remains 191 5 17 find total execution time program 1 2 4 8 processors show relative speedup 2 4 8 processor result relative single processor result 113 exercises 57192 10 16 18 cpi arithmetic instructions doubled would impact execution time program 1 2 4 8 processors 193 10 16 18 cpi loadstore instructions reduced order single processor match performance four processors using original cpi values 110 assume 15 cm diameter wafer cost 12 contains 84 dies 0020 defectscm 2 assume 20 cm diameter wafer cost 15 contains 100 dies 0031 defectscm 21101 10 15 find yield wafers 1102 5 15 find cost per die wafers 1103 5 15 number dies per wafer increased 10 defects per area unit increases b nd die area yield 1104 5 15 assume fabrication process improves yield 092 095 find defects per area unit version technology given die area 200 mm 2111 e results spec cpu2006 bzip2 benchmark running amd barcelona instruction count 2389e12 execution time 750 reference time 9650 1111 5 16 19 find cpi clock cycle time 0333 ns 1112 5 19 find specratio 1113 5 16 19 find increase cpu time number instructions benchmark increased 10 without ecting cpi 1114 5 16 19 find increase cpu time number instructions benchmark increased 10 cpi increased 5 1115 5 16 19 find change specratio change 1116 10 16 suppose developing new version amd barcelona processor 4 ghz clock rate added additional instructions instruction set way number instructions reduced b e execution time reduced 700 new specratio 137 find new cpi 1117 cpi value larger obtained 1111 clock rate increased 3 ghz 4 ghz determine whether increase cpi similar clock rate dissimilar 1118 5 16 much cpu time reduced 58 chapter 1 computer abstractions technology 1119 10 16 second benchmark libquantum assume execution time 960 ns cpi 161 clock rate 3 ghz execution time reduced additional 10 without ecting cpi clock rate 4 ghz determine number instructions 11110 10 16 determine clock rate required give 10 reduction cpu time maintaining number instructions cpi unchanged 11111 10 16 determine clock rate cpi reduced 15 cpu time 20 number instructions unchanged 112 section 110 cites pitfall utilization subset performance equation performance metric illustrate consider following two processors p1 clock rate 4 ghz average cpi 09 requires execution 50e9 instructions p2 clock rate 3 ghz average cpi 075 requires execution 10e9 instructions 1121 5 16 110 one usual fallacy consider computer largest clock rate largest performance check true p1 p21122 10 16 110 another fallacy consider processor executing largest number instructions need larger cpu time considering processor p1 executing sequence 10e9 instructions cpi processors p1 p2 change determine number instructions p2 execute time p1 needs execute 10e9 instructions 1123 10 16 110 common fallacy use mips millions instructions per second compare performance tw erent processors consider processor largest mips largest performance check true p1 p2 1124 10 110 another common performa gure mflops millions oatingpoint operations per seco ned mflops fp operations execution time 1e6but th gure problems mips assume 40 instructions executed p1 p2 ar oatingpoint instructions find mflops gures programs 113 another pitfall cited section 110 expecting improve overall performance computer improving one aspect computer consider computer running program requires 250 70 spent executing fp instructions 85 executed ls instructions 40 spent executing branch instructions 1131 5 110 much total time reduced time fp operations reduced 20 113 exercises 591132 5 110 much time int operations reduced total time reduced 20 1133 5 110 total time reduced 20 reducing time branch instructions 114 assume program requires execution 50 106 fp instructions 110 106 int instructions 80 106 ls instructions 16 106 branch instruction e cpi type instruction 1 1 4 2 respectively assume processor 2 ghz clock rate 1141 10 110 much must improve cpi fp instructions want program run two times faster 1142 10 110 much must improve cpi ls instructions want program run two times faster 1143 5 110 much execution time program improved cpi int fp instructions reduced 40 cpi ls branch reduced 30 115 5 18 program adapted run multiple processors multiprocessor system execution time processor comprised computing time overhead time required locked critical sections andor send data one processor another assume program requires 100 execution time one processor run p processors processor requires tp well additional 4 overhead irrespective number processors compute perprocessor execution time 2 4 8 16 32 64 128 processors case list corresponding speedup relative single processor ratio actual speedup versus ideal speedup speedup overhead 11 page 10 discussion questions many answers acceptable 14 page 24 dram memory volatile short access time 50 70 nanoseconds cost per gb 5 10 disk memory nonvolatile access times 100000 400000 times slower dram cost per gb 100 times cheaper dram flash memory nonvolatile access times 100 1000 times slower dram cost per gb 7 10 times cheaper dram 15 page 28 1 3 4 valid reasons answer 5 generally true high volume make extra investment reduce die size say 10 good economic decision doesnt true 16 page 33 1 b latency c neither 7 seconds 16 page 40 b 110 page 51 computer higher mips rating b computer b faster answers check 2i speak spanish god italian women french men german horse charles v holy roman emperor 15001558instructions language computer21 introduction 6222 operations computer hardware 6323 operands computer hardware 6624 signed unsigned numbers 7325 representing instructions computer 8026 logical operations 8727 instructions making decisions 90computer organization design doi 2013 elsevier inc rights reservedhttpdxdoiorg101016b97801240772630000112013 28 supporting procedures computer hardware 9629 communicating people 106210 mips addressing 32bit immediates addresses 111211 parallelism instructions synchronization 121212 translating starting program 123213 c sort example put together 132214 arrays versus pointers 141215 advanced material compiling c interpreting java 145216 real stuff armv7 32bit instructions 145217 real stuff x86 instructions 149218 real stuff armv8 64bit instructions 158219 fallacies pitfalls 159220 concluding remarks 161221 historical perspective reading 163222 exercises 164the five classic components computer 62 chapter 2 instructions language computer 21 introductionto command computers hardware must speak language e words computers language called instructions vocabulary called instruction set chapter see instruction set real computer form written people form read computer introduce instructions topdown fashion starting notation looks like restricted programming language ne stepbystep see real language real computer chapter 3 continues downward descent unveiling hardware arithmetic representation oatingpoint numbers might think languages computers would diverse people reality computer languages quite similar like regional dialects like independent languages hence learn one easy pick others e chosen instruction set comes mips technologies elegant example instruction sets designe since 1980s demonstrate easy pick instruction sets take quick look three popular instruction sets 1 armv7 similar mips 9 billion chips arm processors manufactured 2011 making popular instruction set world e second example intel x86 powers pc cloud postpc era e third example armv8 extends address size armv7 32 bits 64 bits ironically shall see 2013 instruction set closer mips armv7 similarity instruction sets occurs computers constructed hardware technologies based similar underlying principles basic operations computers must provide moreover computer designers common goal nd language makes easy build hardware compiler maximizing performance minimizing cost energy goal time honored following quote written could buy computer true today 1947 easy see formallogical methods exist certain instruction sets abstract adequate control cause execution sequence operations e really decisive considerations present point view selecting instruction set practical nature simplicity equipment demanded instruction set clarity application actually important problems together speed handling probl emsburks goldstine von neumann 1947 instruction set e vocabulary commands understood given architecture 22 operations computer hardware 63 e simplicity equipment valuable consideration todays computers th e goal chapter teach instruction set follows advice showing represented hardware relationship highlevel programming languages primitive one examples c programming language section 215 shows would change objectoriented language like java learning represent instructions also discover secret computing storedprogram concept moreover exercise foreign language skills writing programs language computer running simulator comes book also see impact programming languages compiler optimization performance conclude look historical evolution instruction sets overview computer dialects reveal rst instruction set piece time giving rationale along computer structur topdown stepbystep tutorial weaves components explanations making computers language palatable figure 21 gives sneak preview instruction set covered chapter 22 operations computer hardware every computer must able perform arit e mips assembly language notation add b cinstructs computer add two variables b c put sum notation rigid mips arithmetic instruction performs one operation must always exactly three variables example suppose want place sum four variables b c e variable section deliberately vague variable next section well explain detail e following sequence instructions adds four variables add b c sum b c placed aadd sum b c add e sum b c e us takes three instructions sum four variables e words right sharp symbol line comments human reader computer ignores note unlike programming languages line language contain one storedprogram concept e idea instructions data many types stored memory numbers leading stored program computer ere must certainly instructions performing fundamental arithmetic operations burks goldstine von neumann 1947 64 chapter 2 instructions language computer mips operandsnameexamplecomments32 registers s0œs7 t0œt9 zero a0œa3 v0œv1 gp fp sp ra atfast locations data mips data must registers perform arithmetic register zero always equals 0 register reserved assembler handle large constants 230 memory words memory0 memory4 memory4294967292 accessed data transfer instructions mips uses byte addresses sequential word addresses differ 4 memory holds data structures arrays spilled registers mips assembly languagecategory instructionexample meaningcommentsarithmeticaddadd s1s2s3s1 s2 s3three register operands subtractsub s1s2s3s1 s2 œ s3three register operands add immediateaddi s1s220s1 s2 20used add constantsdata transferload wordlw s120s2s1 memory s2 20word memory register store word sw s120s2memory s2 20 s1word register memory load halflh s120s2s1 memory s2 20halfword memory register load half unsignedlhu s120s2s1 memory s2 20halfword memory register store half sh s120s2memory s2 20 s1halfword register memory load bytelb s120s2s1 memory s2 20byte memory register load byte unsignedlbu s120s2s1 memory s2 20byte memory register store byte sb s120s2memory s2 20 s1byte register memory load linked word s120s2s1 memory s2 20load word 1st half atomic swap store condition word sc s120s2memory s220s1s10 or1store word 2nd half atomic swap load upper immedlui s120s1 20 216loads constant upper 16 bitslogicaland s1s2s3s1 s2 s3three reg operands bitbybit oror s1s2s3s1 s2 s3three reg operands bitbybit nornor s1s2s3s1 s2 s3three reg operands bitbybit immediateandi s1s220s1 s2 20bitbybit reg constant immediateori s1s220s1 s2 20bitbybit reg constant shift left logicalsll s1s210s1 s2 10shift left constantshift right logicalsrl s1s210s1 s2 10shift right constantconditional branchbranch equalbeq s1s225if s1 s2 go pc 4 100equal test pcrelative branch branch equalbne s1s225if s1 s2 go pc 4 100not equal test pcrelative set less thanslt s1s2s3if s2 s3 s1 1 else s1 0compare less beq bneset less unsignedsltu s1s2s3if s2 s3 s1 1 else s1 0compare less unsigned set less immediate slti s1s220if s2 20 s1 1 else s1 0compare less constant set less immediate unsignedsltiu s1s220if s2 20 s1 1 else s1 0compare less constant unsignedunconditional jumpjumpj 2500 go 10000jump target address jump register jr rago rafor switch procedure return jump linkjal 2500ra pc 4 go 10000for procedure call figure 21 mips assembly language revealed chapter information also found column 1 mips reference data card front book 22 operations computer hardware 65instruction anot erence c comments always terminate end line e natural number operands operation like addition three two numbers added together place put sum requiring every instruction exactly three operands less conforms philosophy keeping hardware simple hardware variable number operands complicated hardware fo xed number situation illustrates th rst three underlying principles hardware design design principle 1 simplicity favors regularity show two examples follow relationship programs written higherlevel programming languages programs primitive notation compiling two c assignment statements mips segment c program contains th variables b c e since java evolved c example next work either highlevel programming language b cd e e translation c mips assembly language instructions performed compiler show mips code produced compiler mips instruction operates two source operands places result one destination operand hence two simple statements compile directly two mips assembly language instructions add b csub ecompiling complex c assignment mipsa somewhat complex statement contains th variables f g h jf g h jwhat might c compiler produce exampleanswerexample 66 chapter 2 instructions language computer e compiler must break statement several assembly instructions since one operation performed per mips instructio e rst mips instruction calculates sum g h must place result somewhere compiler creates temporary variable called t0add t0gh temporary variable t0 contains g halthough next operation subtract need calculate sum j subtrac us second instruction places sum j another temporary variable created compiler called t1add t1ij temporary variable t1 contains jfinally subtract instruction subtracts second sum th rst places th erence variable f completing compiled code sub ft0t1 f gets t0 t1 g h jfor given function programming language likely takes lines code put three representations order 1 java 2 c 3 mips assembly language elaboration increase portability java originally envisioned relying software interpreter instruction set interpreter called java bytecodes see section 215 quite different mips instruction set get performance close equivalent c program java systems today typically compile java bytecodes native instruction sets like mips compilation normally done much later c programs java compilers often called time jit compilers section 212 shows jits used later c compilers startup process section 213 shows performance consequences compiling versus interpreting java programs 23 operands computer hardware unlike programs highlevel languages operands arithmetic instructions restricted must limited number special locations built directly hardware called registers registers primitives used hardware design also visible programmer computer completed think registers bricks computer constructio e size register mips architecture 32 bits groups 32 bits occur frequently given name word mips architecture answercheck word e natural unit access computer usually group 32 bits corresponds size register mips architecture 23 operands computer hardware 67one majo erence variables programming language registers limited number registers typically 32 current computers like mips see section 221 history number register us continuing topdown stepwise evolution symbolic representation mips language section added restriction three operands mips arithmetic instructions must chosen one 32 32bit registers e reason limit 32 registers may found second three underlying design principles hardware technology design principle 2 smaller faster large number registers may increase clock cycle time simply takes electronic signals longer must travel farther guidelines smaller faster absolutes 31 registers may faster 32 yet truth behind observations causes computer designers take seriously case designer must balance craving programs registers designers desire keep clock cycle fast another reason using 32 number bits would take instruction format section 25 demonstrates chapter 4 shows central role registers play hardware construction shall see chapter ective use registers critical program performance although could simply write instructions using numbers registers 0 31 mips convention use twocharacter names following dollar sign represent register section 28 explain reasons behind names use s0 s1 registers correspond variables c java programs t0 t1 temporary registers needed compile program mips instructions compiling c assignment using registers compilers job associate program variables registers take instance assignment statement earlier example f g h j e variables f g h j assigned registers s0 s1 s2 s3 s4 respectively compiled mips code example 68 chapter 2 instructions language computer e compiled program similar prior example except replace variables register names mentioned plus two temporary registers t0 t1 correspond temporary variables add t0s1s2 register t0 contains g hadd t1s3s4 register t1 contains j sub s0t0t1 f gets t0 t1 g hi jmemory operands programming languages simple variables contain single data elements examples also complex data structuresarrays structur ese complex data structures contain many data elements registers computer computer represent access large structures recall th components computer introduced chapter 1 repeated pag e processor keep small amount data registers computer memory contains billions data elements hence data structures arrays structures kept memory explained arithmetic operations occur registers mips instructions thus mips must include instructions transfer data memory registers instructions called data transfer instructions access word memory instruction must supply memory address memory large singledimensional array address acting index array starting 0 example figure 22 address third data element 2 value memory 2 10 answerdata transfer instruction command moves data memory registers address value used delineate location sp c data element within memory array processor memory addressdata 1101101000123figure 22 memory addresses contents memory locations elements words addresses would incorrect since mips actually uses byte addressing word representing four bytes figure 23 shows memory addressing sequential word addresses e data transfer instruction copies data memory register traditionally called load e format load instruction name operation followed register loaded constant register used access memory e sum constant portion instruction contents second register forms memory addr e actual mips name instruction lw standing load word compiling assignment operand memory lets assume array 100 words compiler associated variables g h registers s1 s2 lets also assume starting address base address array s3 compile c assignment statement g h a8although single operation assignment statement one operands memory mu rst transfer a8 register e address array element sum base array found register s3 plus number select elemen e data sh ould pl aced temporary register use next instruction based figure 22 rst compiled instruction lw t08s3 temporary reg t0 gets a8well making slight adjustment instruction well use simp ed version e following instruction operate value t0 equals a8 since register e instruction must add h contained s2 a8 contained t0 put sum register corresponding g associated s1add s1s2t0 g h a8 e constant data transfer instruction 8 called set register added form address s3 called base register addition associating variables registers compiler allocates data structures like arrays structures locations memory e compiler place proper starting address data transfer instructions since 8bit bytes useful many programs virtually architectures today address individual byt erefore address word matches address one 4 bytes within word addresses sequential word er 4 example figure 23 shows actual mips addresses words figure 22 byte address third word 8 mips words must start addresses multiples requirement called alignment restriction many architectures chapter 4 suggests alignment leads faster data transfers exampleanswerhardware software interfacealignment restriction requirement data aligned memory natural boundaries 23 operands computer hardware 69 70 chapter 2 instructions language computer computers divide use address th big end byte word address versus use rightmost little end byte mips bigendian camp since order matters access identical data word four bytes need aware endianess appendix shows two options number bytes word byte addressing also ects array index get proper byte address code set added base register s3 must 4 8 32 load address select a8 a84 see related pitfall page 160 section 219 e instruction complementary load traditionally called store copies data register memory e format store similar load name operation followed register stored set select array element nally base register mips address sp ed part constant part contents register e actual mips name sw standing store word addresses loads stores binary numbers see dram main memory comes binary sizes rather tha gebibytes 2 30 tebibytes 2 40 gigabytes 10 9 terabytes 10 12 see figure 11 hardware software interfaceprocessor memory byte addressdata 11011010004812figure 23 actual mips memory addresses contents memory words e changed addresses highlighted contrast figure 22 since mips addresses byte word addresses multiples 4 4 bytes word compiling using load storeassume variable h associated register s2 base address array s3 mips assembly code c assignment statement a12 h a8although single operation c statement two operands memory need even mips instruction e rst two instructions prior example except time use proper set byte addressing load word instruction select a8 add instruction places sum t0lw t032s3 temporary reg t0 gets a8add t0s2t0 temporary reg t0 gets h a8 e nal instruction stores sum a12 using 48 4 12 set register s3 base register sw t048s3 stores h a8 back a12load word store word instructions copy words memory registers mips architecture brands computers use instructions along load store transfer data architecture alternatives intel x86 described section 217 many programs variables computers registers consequently compiler tries keep frequently used variables registers places rest memory using loads stores move variables registers memory e process putting less commonly used variables needed later memory called spilling registers e hardware principle relating size speed suggests memory must slower registers since fewer register indeed case data accesses faster data registers instead memory moreover data useful register mips arithmetic instruction read two registers operate write result mips data transfer instruction reads one operand writes one operand without operating us registers take less time access higher throughput memory making data registers faster access simpler use accessing registers also uses less energy accessing memory achieve highest performance conserve energy instruction set architecture must hav cient number registers compilers must use register ciently exampleanswerhardware software interface 23 operands computer hardware 71 72 chapter 2 instructions language computer constant immediate operandsmany times program use constant operationfor example incrementing index point next element array fact half mips arithmetic instructions constant operand running spec cpu2006 benchmarks using instructions seen far would load constant memory use e constants would placed memory program loaded example add constant 4 register s3 could use code lw t0 addrconstant4s1 t0 constant 4add s3s3t0 s3 s3 t0 t0 4assuming s1 addrconstant4 memory address constant 4 alternative avoids load instruction er versions arithmetic instructions one operand constan quick add instruction one constant operand called add immediate addi add 4 register s3 write addi s3s34 s3 s3 4constant operands occur frequently including constants inside arithmetic instructions operations much faster use less energy constants loaded memory e constant zero another role simplify instruction set ering useful variations example move operation add instruction one operand zero hence mips dedicates register zero hardwired value zero might expect register number 0 using frequency justify inclusions constants another example great idea making common case fast given importance registers rate increase number registers chip time 1 ey increase fast moores law predicts doubling number transistors chip every 18 months 2 slow since programs usually distributed language computer inertia instruction set architecture number registers increases fast new instruction sets become viable elaboration although mips registers book 32 bits wide 64bit version mips instruction set 32 64bit registers keep straight cially called mips32 mips64 chapter use subset mips32 appendix e shows differences mips32 mips64 sections 216 218 show much dramatic difference 32bit address armv7 64bit successor armv8 check 24 signed unsigned numbers 73elaboration mips offset plus base register addressing excellent match structures well arrays since register point beginning structure offset select desired element well see example section 213elaboration register data transfer instructions originally invented hold index array offset used starting address array thus base register also called index register todays memories much larger software model data allocation sophisticated base address array normally passed register since offset shall see elaboration since mips supports negative constants need subtract immediate mips 24 signed unsigned numbers first lets quickly review computer represents numbers humans taught think base 10 numbers may represented base example 123 base 10 1111011 base 2 numbers kept computer hardware series high low electronic signals considered base 2 numbers base 10 numbers called decimal numbers base 2 numbers called binary numbers single digit binary number thus atom computing since information composed binary digits bits fundamental building block one two values thought several alternatives high low true false 1 0 generalizing point number base value ith digit isdibase starts 0 increases right representation leads obvious way number bits word simply use power base bit subscript decimal numbers ten binary numbers two example 1011tworepresents 1 x 23 0 x 2 2 1 x 21 1 x 2 0ten 1 x 8 0 x 4 1 x 2 1 x 1 ten 8 0 2 1 ten 11tenbinary digit also called binary bit one two numbers base 2 0 1 components information 74 chapter 2 instructions language computer number bits 0 1 2 3 right word e drawing shows numbering bits within mips word placement number 1011two 313029282726252423222120191817161514131211109876543210 00000000000000000000000000001011 32 bits widesince words drawn vertically well horizontally rightmost may unclear hence phrase least sig cant bit used refer right bit bit 0 sig cant bit th bit bit 31 e mips word 32 bits long represent 2 32 erent 32bit patterns natural let combinations represent numbers 0 2 32 1 4294967295ten 0000 0000 0000 0000 0000 0000 0000 0000two 0ten0000 0000 0000 0000 0000 0000 0000 0001two 1ten0000 0000 0000 0000 0000 0000 0000 0010two 2ten 1111 1111 1111 1111 1111 1111 1111 1101two 4294967293ten1111 1111 1111 1111 1111 1111 1111 1110two 4294967294ten1111 1111 1111 1111 1111 1111 1111 1111two 4294967295ten 32bit binary numbers represented terms bit value times power 2 xi means ith bit x xxxxx 3123022921202 31302910for reasons shortly see positive numbers called unsigned numbers base 2 natural human beings ngers nd base 10 natural didnt computers use decimal fact th rst commercial computer er decimal arit e problem computer still used signals decimal digit simply represented several binary digits decimal proved cient subsequent computers reverted binary converting base 10 relatively infrequent inputoutput events keep mind binary bit patterns simply representatives numbers numbers really nite number digits almost 0 except rightmost digits dont normally show leading 0s hardware designed add subtract multiply divide binary bit patterns number proper result operations represented rightmost hardware bits ow said occurred least sig cant bit e rightmost bit mips wordmost sig cant bit e bit mips wordhardware software interface programming language operating system program determine ow occurs computer programs calculate positive negative numbers need representation distinguishes positive negative e obvious solution add separate sign conveniently represented single bit name representation sign magnitude alas sign magnitude representation several shortcomings first obvious put sign bit right th early computers tried second adders sign magnitude may need extra step set sign cant know advance proper sign finally separate sign bit means sign magnitude positive negative zero lead problems inattentive programmers result shortcomings sign magnitude representation soon abandoned search attractive alternative question arose would result unsigned numbers tried subtract large number small one e answer would try borrow string leading 0s result would string leading 1s given obvious better alternative th nal solution pick representation made hardware simple leading 0s mean positive leading 1s mean negative convention representing signed binary numbers called twos complement representation 0000 0000 0000 0000 0000 0000 0000 0000two 0ten0000 0000 0000 0000 0000 0000 0000 0001two 1ten0000 0000 0000 0000 0000 0000 0000 0010two 2ten 0111 1111 1111 1111 1111 1111 1111 1101two 2147483645ten0111 1111 1111 1111 1111 1111 1111 1110two 2147483646ten0111 1111 1111 1111 1111 1111 1111 1111two 2147483647ten1000 0000 0000 0000 0000 0000 0000 0000two 2147483648ten1000 0000 0000 0000 0000 0000 0000 0001two 2147483647ten1000 0000 0000 0000 0000 0000 0000 0010two 2147483646ten 1111 1111 1111 1111 1111 1111 1111 1101two 3ten1111 1111 1111 1111 1111 1111 1111 1110two 2ten1111 1111 1111 1111 1111 1111 1111 1111two 1ten e positive half numbers 0 2147483647 ten 231 1 use representation e following bit pattern 1000 0000 two represents negative number 2147483648ten 231 followed declining set negative numbers 2147483647ten 1000 0001two 1ten 1111 1111two twos complement one negative number 2147483648ten corresponding positive number imbalance also worry inattentive programmer sign magnitude problems programmer hardware designer consequently every computer today uses twos complement binary representations signed numbers 24 signed unsigned numbers 75 76 chapter 2 instructions language computer twos complement representation advantage negative numbers 1 th cant bit consequently hardware needs test bit see number positive negative number 0 considered positiv bit en called sign bit recognizing role sign bit represent positive negative 32bit numbers terms bit value times power 2 xxxxx 3123022921202 31302910 e sign bit multiplied 231 rest bits multiplied positive versions respective base values binary decimal conversion decimal value 32bit twos complement number 1111 1111 1111 1111 1111 1111 1111 1100twosubstituting numbers bit values formula 121212120202 222 3130291103130 2292200 21474836482147483644 4 tetnenten well see shortcut simplify conversion negative positive soon operation unsigned numbers ow capacity hardware represent result operation twos complement numbers ow occurs th retained bit binary bit pattern nite number digits th sign bit incorrect 0 th bit pattern number negative 1 number positive signed versus unsigned applies loads well arit e function signed load copy sign repeatedly rest registercalled sign extension purpose place correct representation number within register unsigned loads simpl 0s th data since number represented bit pattern unsigned loading 32bit word 32bit register point moot signed unsigned loads identical mips er tw avors byte loads load byte lb treats byte signed number thus signextends th bits register load byte unsigned lbu works unsigned integers since c programs almost always use bytes represent characters rather consider bytes short signed integers lbu used practically exclusively byte loads exampleanswerhardware software interface unlike numbers discussed memory addresses naturally start 0 continue largest address put another way negative addresses make sens us programs want deal sometimes numbers positive negative sometimes numbers positive programming languages r ect distinction c example names former integers declared int program latter unsigned integers unsigned int c style guides even recommend declaring former signed int keep distinction clear lets examine two useful shortcuts working twos complement number e rst shortcut quick way negate twos complement binary number simply invert every 0 1 every 1 0 add one result shortcut based observation sum number inverted representation must 111 111 two represents 1 since xx1 therefore xx10 xx1 use notation x mean invert every bit x 0 1 vice versa negation shortcut negate 2 ten check result negating 2ten 2ten 0000 0000 0000 0000 0000 0000 0000 0010two negating number inverting bits adding one 1111 1111 1111 1111 1111 1111 1111 1101 two 1 two 1111 1111 1111 1111 1111 1111 1111 1110 two 2 tengoing direction 1111 1111 1111 1111 1111 1111 1111 1110two rst inverted incremented 0000 0000 0000 0000 0000 0000 0000 0001two 1 two 0000 0000 0000 0000 0000 0000 0000 0010two 2 tenhardware software interfaceexampleanswer 24 signed unsigned numbers 77 78 chapter 2 instructions language computer next shortcut tells us convert binary number represented n bits number represented n bits example immediat eld load store branch add set less instructions contains twos complement 16bit number representing 32768ten 215 32767 ten 215 1 add immediate eld 32bit register computer must convert 16 bit number 32bit equivalen e shortcut take th cant bit smaller quantitythe sign bitand replicate new bits larger quantity e old nonsign bits simply copied right portion new word shortcut commonly called sign extension sign extension shortcut convert 16bit binary versions 2 ten 2ten 32bit binary numbers e 16bit binary version number 2 0000 0000 0000 0010two 2tenit converted 32bit number making 16 copies value cant bit 0 placing th hand half word e right half gets old value 0000 0000 0000 0000 0000 0000 0000 0010two 2tenlets negate 16bit version 2 using earlier shortcu us0000 0000 0000 0010twobecomes 1111 1111 1111 1101 two 1two 1111 1111 1111 1110 twocreating 32bit version negative number means copying sign bit 16 times placing th 1111 1111 1111 1111 1111 1111 1111 1110two 2ten trick works positive twos complement numbers really nite number 0s th negative twos complement numbers nite number e binary bit pattern representing number hides leading bits width hardware sign extension simply restores exampleanswer summary e main point section need represent positive negative integers within computer word although pros cons option unanimous choice since 1965 twos complement elaboration signed decimal numbers used represent negative limits size decimal number xed word size binary hexadecimal see figure 24 bit strings encode sign hence normally use binary hexadecimal notation decimal value 64bit twos complement number 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1000two1 4ten 2 8ten 3 16ten 4 18446744073709551609ten elaboration twos complement gets name rule unsigned sum nbit number nbit negative 2n hence negation complement number x 2n x twos complement third alternative representation twos complement sign magnitude called ones complement negative ones complement found inverting bit 0 1 1 0 x relation helps explain name since complement x 2n x 1 also attempt better solution sign magnitude several ear c computers use notation representation similar twos complement except also two 0s 00 00 two positive 0 11 11 two negative 0 negative number 10 000 two represents 2147483647ten positives negatives balanced ones complement adders need extra step subtract number hence twos complement dominates today nal notation look w oating point chapter 3 represent negative value 00 000 two positive value 11 11 two 0 typically value 10 00 two called biased notation since biases number number plus bias non negative representationcheck ones complement notation represents negative value 10 000 two positive value 01 11two leaving equal number negatives positives ending two zeros one positive 00 00 two one negative 11 11 two e term also used mean inversion every bit pattern 0 1 1 0 biased notation notation represents negative value 00 000 two positive value 11 11two 0 typically value 10 00two thereby biasing number number plus bias nonnegative representation 24 signed unsigned numbers 79 80 chapter 2 instructions language computer 25 representing instructions computer ready explain th erence way humans instruct computers way computers see instructions instructions kept computer series high low electronic signals may represented numbers fact piece instruction considered individual number placing numbers side side forms instruction since registers referred instructions must convention map register names numbers mips assembly language registers s0 s7 map onto registers 16 23 registers t0 t7 map onto registers 8 15 hence s0 means register 16 s1 means register 17 s2 means register 18 t0 means register 8 t1 means register 9 well describe convention rest 32 registers following sections translating mips assembly instruction machine instruction lets next step nement mips language example well show real mips language version instruction represented symbolically add t0s1s2 rst combination decimal numbers binary numbers e decimal representation 0171 8803 2each segments instruction called eld e rst last elds containing 0 32 case combination tell mips computer instruction performs additio e seco eld gives number register th rst source operand addition operation 17 s1 thir eld gives source operand addition 18 s2 e fourt eld contains number register receive sum 8 t0 e h eld unused instruction set us instruction adds register s1 register s2 places sum register t0 instruction also represente elds binary numbers opposed decimal 00000010001100100100000000100000 6 bits5 bits5 bits5 bits5 bits6 bits exampleanswer 25 representing instructions computer 81 layout instruction called instruction format see counting number bits mips instruction takes exactly 32 bitsthe size data word keeping design principle simplicity favors regularity mips instructions 32 bits long distinguish assembly language call numeric version instructions machine language sequence instructions machine code would appear would reading writing long tedious strings binary numbers avoid tedium using higher base binary converts easily binary since almost computer data sizes multiples 4 hexadecimal base 16 numbers popular since base 16 power 2 trivially convert replacing group four binary digits single hexadecimal digit vice versa figure 24 converts hexadecimal binary instruction format form representation instruction composed elds binary numbers machine language binary representation used communication within computer system hexadecimal numbers base 16 hexadecimal binary hexadecimal binary hexadecimal binary hexadecimal binary 0hex0000two4hex0100two8hex1000twochex1100two1hex0001two5hex0101two9hex1001twodhex1101two2hex0010two6hex0110twoahex1010twoehex1110two3hex0011two7hex0111twobhex1011twofhex1111twofigure 24 hexadecimalbinary conversion table replace one hexadecimal digit corresponding four binary digits vice versa length binary number multiple 4 go right frequently deal erent number bases avoid confusion subscript decimal numbers ten binary numbers two hexadecimal numbers hex subscript default base 10 way c java use notation 0x nnnn hexadecimal numbers binary hexadecimal back convert following hexadecimal binary numbers base eca8 6420hex0001 0011 0101 0111 1001 1011 1101 1111twoexample 82 chapter 2 instructions language computer using figure 24 answer table lookup one way mips fields elds given names make easier discuss oprsrtrdshamtfunct 6 bits5 bits5 bits5 bits5 bits 6 bitshere meaning name th elds mips instructions op basic operation instruction traditionally called opcode rs e rst register source operand rt e second register source operand rd e register destination operand gets result operation shamt amount section 26 explain instructions term used hence th eld contains zero section funct functio eld en called function code selects sp c variant operation elda problem occurs instruction needs long elds shown example load word instruction must specify two registers constant address use one 5bi elds format constant within load word instruction would limited 2 5 constant used select elements arrays data structures en needs much larger 5bi eld small useful hence co ict desire keep instructions length desire single instruction forma leads us th nal hardware design principle answeropcode e eld denotes operation format instruction eca8 6420 hex 1110 1100 1010 1000 0110 0100 0010 0000 twoand direction 0001 0011 0101 0111 1001 1011 1101 1111 two 1357 9bdfhex design principle 3 good design demands good compromises e compromise chosen mips designers keep instructions length thereby requirin erent kinds instruction formats fo erent kinds instructions example format called rtype register rformat second type instruction format called itype immediate iformat used immediate data transfer instruction e elds iformat oprsrtconstant address6 bits5 bits5 bits16 bits e 16bit address means load word instruction load word within region 215 32768 bytes 213 8192 words address base register rs similarly add immediate limited constants larger 215 see 32 registers would b cult format rs rt elds would need another bit making harder everything one word lets look load word instruction page 71 lw t032s3 temporary reg t0 gets a8here 19 s3 placed r eld 8 t0 placed r eld 32 placed addr eld note meaning rt eld changed instruction load word instruction r eld sp es destination register receives result load although multiple formats complicate hardware reduce complexity keeping formats similar example th rst thre elds rtype itype formats size names length fourth eld itype equal sum lengths last thre elds rtype case wondering formats distinguished values rst eld format assigned distinct set values th rst eld op hardware knows whether treat last half instruction thre elds rtype sing eld itype figure 25 shows numbers used eld mips instructions covered far 25 representing instructions computer 83instructionformatoprsrtrdshamtfunctaddress addr0regregreg032 tennasub subtractr0regregreg034 tennaaddimmediate i8tenregregnananaconstant lw load word i35 tenregregnananaaddress sw store word i43 tenregregnananaaddress figure 25 mips instruction encoding table reg means register number 0 31 address means 16bit address na applicable means th eld appear format note add sub instructions value eld hardware uses funct eld decide variant operation add 32 subtract 34 84 chapter 2 instructions language computer translating mips assembly language machine language take example way programmer writes computer executes t1 base array s2 corresponds h assignment statement a300 h a300is compiled lw t01200t1 temporary reg t0 gets a300add t0s2t0 temporary reg t0 gets h a300 sw t01200t1 stores h a300 back a300what mips machine language code three instructions convenience let rst represent machine language instructions using decimal numbers figure 25 determine three machine language instructions oprs rt rdaddressshamtfunct 359812000188803 243981200 e lw instruction iden ed 35 see figure 25 th rst eld e base register 9 t1 sp ed seco eld rs destination register 8 t0 sp ed thir eld r e set select a300 1200 300 4 found th nal eld address e add instruction follows sp ed 0 th rst eld op 32 th eld func e three register operands 18 8 8 found second third fourt elds correspond s2 t0 t0 e sw instruction iden ed 43 th rst eld e rest nal instruction identical lw instruction since 1200 ten 0000 0100 1011 0000two binary equivalent decimal form exampleanswer1000110100101000 0000 0100 1011 000000000010010010000100000000100000 1010110100101000 0000 0100 1011 0000 note similarity binary representations th rst last instruction e onl erence third bit th highlighted e desire keep instructions size co ict desire many registers possible increase number registers uses least one bit every regist eld instruction format given constraints design princple smaller faster instruction sets today 16 32 general purpose registers hardware software interfacemips machine languagenameformat examplecommentsaddr0181917032 adds1s2s3subr0181917034 subs1s2s3addii81817 100addis1s2100lwi351817 100lws1100s2swi431817 100sws1100s2field size6 bits5 bits5 bits5 bits5 bits6 bitsall mips instructions 32 bits long rformatroprsrtrdshamtfunctarithmetic instruction format iformatioprsrt address data transfer format figure 26 mips architecture revealed section 25 e two mips instruction formats far r e rst 16 bits contain op eld giving base operation rs eld giving one sources rt eld sp es source operand except load word sp es destination register rformat divides last 16 bits rd eld specifying destination register shamt eld section 26 explains funct eld sp es sp c operation rformat instructions iformat combines last 16 bits single address eld 25 representing instructions computer 85figure 26 summarizes portions mips machine language described section shall see chapter 4 similarity binary representations related instructions simp es hardwar ese similarities another example regularity mips architecture 86 chapter 2 instructions language computer todays computers built two key principles 1 instructions represented numbers 2 programs stored memory read written like data ese principles lead storedprogram concept invention let computing genie bottle figure 27 shows power concept sp cally memory contain source code editor program corresponding compiled machine code text compiled program using even compiler generated machine code one consequence instructions numbers programs en shippe les binary number e commercial implication computers inherit readymade ware provided compatible existing instruction set binary compatibility en leads industry align around small number instruction set architectures bigpicturememory accounting program machine codeprocessor editor program machine codec compilermachine codepayroll data book text source code cfor editor program figure 27 storedprogram concept stored programs allow computer performs accounting become blink eye computer helps author write boo e switch happens simply loading memory programs data telling computer begin executing given location memory treating instructions way data greatly simp es memory hardware ware computer systems sp cally memory technology needed data also used programs programs like compilers instance translate code written notation far convenient humans code computer understand 26 logical operations 87what mips instruction represent choose one four options oprsrtrdshamtfunct 08910034 1 sub t0 t1 t22 add t2 t0 t13 sub t2 t1 t04 sub t2 t0 t1 26 logical operations although rst computers operated full words soon became clear useful operate elds bits within word even individual bits examining characters within word stored 8 bits one example operation see section 29 follows operations added programming languages instruction set architectures simplify among things packing unpacking bits word ese instructions called logical operations figure 28 shows logical operations c java mips check contrariwise continued tweedledee might would isnt aint ats logic lewis carroll alices adventures wonderland 1865figure 28 c java logical operators corresponding mips instructions mips implements using one operand zero e rst class operations called ey move bits word th righ lling emptied bits 0s example register s0 contained 0000 0000 0000 0000 0000 0000 0000 1001two 9tenand instruction 4 executed new value would 0000 0000 0000 0000 0000 0000 1001 0000two 144tenlogical operationsc operatorsjava operatorsmips instructions shift left sll shift right srl bitbybit andandi bitbybit orori bitbybit 88 chapter 2 instructions language computer e dual righ e actual name tw instructions called logical sll right logical srl e following instruction performs operation assuming original value register s0 result go register t2sll t2s04 reg t2 reg s0 4 bitswe delayed explaining shamt eld rformat us instructions stands amount hence machine language version instruction oprs rt rdshamtfunct00161040 e encoding sll 0 op func elds rd contains 10 register t2 rt contains 16 register s0 shamt contain e r eld unused thus set 0 logical provides bonus ing bits gives result multiplying 2 ju ing decimal number digits equivalent multiplying 10 example sll 4 gives result multiplying 2 4 e rst bit pattern represents 9 9 16 144 value second bit pattern another useful operation isolat elds capitalize word avoid confusion operation english conjunction bit bybit operation leaves 1 result bits operands 1 example register t2 contains 0000 0000 0000 0000 0000 1101 1100 0000twoand register t1 contains 0000 0000 0000 0000 0011 1100 0000 0000twothen er executing mips instruction t0t1t2 reg t0 reg t1 reg t2the value register t0 would 0000 0000 0000 0000 0000 1100 0000 0000twoas see apply bit pattern set bits force 0s 0 bit pattern bit pattern conjunction traditionally called mask since mask conceals bits logical bit bybit operation two operands calculates 1 1 operands place value one seas 0s dual called bitbybit operation places 1 result either operand bit 1 elaborate registers t1 t2 unchanged preceding example result mips instruction t0t1t2 reg t0 reg t1 reg t2is value register t00000 0000 0000 0000 0011 1101 1100 0000two e nal logical operation contrarian takes one operand places 1 result one operand bit 0 vice versa using prior notation calculates xin keeping threeoperand format designers mips decided include instruction instead one operand zero equivalent 0 0 register t1 unchanged preceding example register t3 value 0 result mips instruction t0t1t3 reg t0 reg t1 reg t3is value register t01111 1111 1111 1111 1100 0011 1111 1111twofigure 28 shows relationship c java operators mips instructions constants useful logical operations well arithmetic operations mips also provides instructions immediate andi immediate ori constants rare since main use invert bits single operand thus mips instruction set architecture immediate version elaboration full mips instruction set also includes exclusive xor sets bit 1 two corresponding bits differ 0 c allows bit ﬁ elds ﬁ elds ned within words allowing objects packed within word match externally enforced interface io device within single word fields unsigned integers short 1 bit c compilers inser elds using logical instructions mips sll srlelaboration logical immediate logical immediate put 0s upper 16 bits form 32bit constant unlike add immediate sign extension operations isolat eld word 1 and2 followed right logical bitby bit operation two operands calculates 1 1 either operand logical bitby bit operation one operand inverts bits replaces every 1 0 every 0 1 logical bitby bit operation two operands calculates two opera calculates 1 0 operands check 26 logical operations 89 90 chapter 2 instructions language computer 27 instructions making decisions distinguishes computer simple calculator ability make decisions based input data values created computation erent instructions execute decision making commonly represented programming languages using statement sometimes combined go statements labels mips assembly language includes two decisionmaking instructions similar statement go e rst instruction beq register1 register2 l1 instruction means go statement labeled l1 value register1 equals value register2 e mnemonic beq stands branch equal e second instruction bne register1 register2 l1it means go statement labeled l1 value register1 equal value register2 e mnemonic bne stands branch equal ese two instructions traditionally called conditional branches compiling ifthenelse conditional branchesin following code segment f g h j variables th variables f j correspond th registers s0 s4 compiled mips code c statement j f g h else f g hfigure 29 sho owchart mips code e rst expression compares equality would seem would want branch registers equal instruction beq general code cient test opposite condition branch code performs subsequent part label else ned use branch registers equal instruction bne e utility automatic computer lies possibility using given sequence instructions repeatedly number times iterated dependent upon results computation choice made depend upon sign number zero reckoned plus machine purposes consequently introduce instruction conditional transfer instruction depending sign given number cause proper one two routines executed burks goldstine von neumann 1947 exampleanswer 27 instructions making decisions 91 e next assignment statement performs single operation operands allocated registers one instruction need go end statemen example introduces another kind branch en called unconditional branch instruction says processor always follows branch distinguish conditional unconditional branches mips name type instruction jump abbreviated j label exit ned j exit go exit e assignment statement else portion statement compiled single instruction need append label else instruction also show label exit er instruction showing end ifthenelse compiled code elsesub s0s1s2 f g h skipped jexitnotice assembler relieves compiler assembly language programmer tedium calculating addresses branches calculating data addresses loads stores see section 212 fghfgœhiji ji j elseexitfigure 29 illustration options statement e box corresponds part statement right box corresponds else part conditional branch instruction requires comparison two values allows subsequent transfer control new address program based outcome comparison 92 chapter 2 instructions language computer compilers frequently create branches labels appear programming language avoiding burden writing explicit labels branches one writing highlevel programming languages reason coding faster level loopsdecisions important choosing two alternativesfound statementsand iterating computationfound loo e assembly instructions building blocks cases compiling loop chere traditional loop c savei ki 1assume k correspond registers s3 s5 base array save s6 mips assembly code corresponding c segment e rst step load savei temporary register load savei temporary register need address add base array save form address must multiply index 4 due byte addressing problem fortunately us logical ing 2 bits multiplies 2 2 4 see page 88 prior section need add label loop branch back instruction end loop loop sll t1s32 temp reg t1 4to get address savei need add t1 base save s6add t1t1s6 t1 address saveinow use address load savei temporary register lw t00t1 temp reg t0 savei e next instruction performs loop test exiting hardware software interfaceexampleanswer e next instruction adds 1 iaddi s3s31 1 e end loop branches back test top loop add exit label er done j loop go loopexitsee exercises optimization sequence sequences instructions end branch fundamental compiling given buzzword basic block sequence instructions without branches except possibly end without branch targets branch labels except possibly beginning one th rst early phases compilation breaking program basic blocks e test equality inequality probably popular test sometimes useful see variable less another variable example loop may want test see index variable less 0 comparisons accomplished mips assembly language instruction compares two registers sets third register 1 th rst less second otherwise set e mips instruction called et less slt example slt t0 s3 s4 t0 1 s3 s4means register t0 set 1 value register s3 less value register s4 otherwise register t0 set 0 constant operands popular comparisons immediate version set less instruction test register s2 less constant 10 write slti t0s210 t0 1 s2 10mips compilers use slt slti beq bne th xed value 0 always available reading register zero create relative conditions equal equal less less equal greater greater equal hardware software interfacebasic block sequence instructions without branches except possibly end without branch targets branch labels except possibly beginning hardware software interface 27 instructions making decisions 93 94 chapter 2 instructions language computer heeding von neumanns warning simplicity equipment mips architecture doesnt include branch less complicated either would stretch clock cycle time would take extra clock cycles per instruction two faster instructions useful comparison instructions must deal dichotomy signed unsigned numbers sometimes bit pattern 1 th cant bit represents negative number course less positive number must 0 th cant bit unsigned integers hand 1 th cant bit represents number larger begins 0 well soon take advantage dual meaning cant bit reduce cost array bounds checking mips ers two versions set less comparison handle alternatives set less slt set less immediate slti work signed integers unsigned integers compared using set less unsigned sltu set less immediate unsigned sltiusigned versus unsigned comparison suppose register s0 binary number 1111 1111 1111 1111 1111 1111 1111 1111twoand register s1 binary number 0000 0000 0000 0000 0000 0000 0000 0001twowhat values registers t0 t1 er two instructions slt t0 s0 s1 signed comparisonsltu t1 s0 s1 unsigned comparison e value register s0 represents 1ten integer 4294967295 ten unsigned integer e value register s1 represents 1 ten either case en register t0 value 1 since 1ten 1ten register t1 value 0 since 4294967295 ten 1ten hardware software interfaceexampleanswer treating signed numbers unsigned gives us low cost way checking 0 x matches index outofbounds check arra e key negative integers twos complement notation look like large numbers unsigned notation th cant bit sign bit former notation large part number latter us unsigned comparison x also checks x negative well x less ybounds check shortcut use shortcut reduce indexoutofbounds check jump indexoutofbounds s1 negative e checking code uses u checks sltu t0s1t2 t00 s1length s10beq t0zeroindexoutofbounds bad goto errorcaseswitch statementmost programming languages case switch statement allows programmer select one many alternatives depending single value e simplest way implement switch via sequence conditional tests turning switch statement chain ifthenelse statements sometimes alternatives may mor ciently encoded table addresses alternative instruction sequences called jump address table jump table program needs index table jump appropriate sequence e jump table array words containing addresses correspond labels code e program loads appropriate entry jump table register needs jump using address register support situations computers like mips include jump register instruction jr meaning unconditional jump address sp ed register en jumps proper address using instruction well see even popular use jr next section exampleanswerjump address table also called jump table table addresses alternative instruction sequences 27 instructions making decisions 95 96 chapter 2 instructions language computer although many statements decisions loops programming languages like c java bedrock statement implements instruction set level conditional branch elaboration heard delayed branches covered chapter 4 dont worry mips assembler makes invisible assembly language programmer c many statements decisions loops mips following explain imbalance 1 decision statements make code easier read understand 2 fewer decision statements simplify task underlying layer responsible execution 3 decision statements mean fewer lines code generally reduces coding time 4 decision statements mean fewer lines code generally results execution fewer operations ii c provide two sets operators two sets operators mips doesnt 1 logical operations implement conditional branches implement e previous statement backwards correspond logical operations map conditional branches ey redundant mean thing simply inherited programming language b predecessor c 28 supporting procedures computer hardware procedure function one tool programmers use structure programs make easier understand allow code reused procedures allow programmer concentrate one portion task time parameters act interface procedure rest program data since pass values return results describe equivalent procedures java section 215 java needs everything computer c needs procedures one way implement abstraction ware hardware software interfacecheck procedure stored subroutine performs sp c task based parameters provided 28 supporting procedures computer hardware 97you think procedure like spy leaves secret plan acquires resources performs task covers tracks returns point origin desired result nothing else perturbed mission complete moreover spy operates need know basis spy cant make assumptions employer similarly execution procedure program must follow six steps 1 put parameters place procedure access 2 transfer control procedure 3 acquire storage resources needed procedure 4 perform desired task 5 put result value place wher e calling program access 6 return control point origin since procedure called several points program mentioned registers fastest place hold data computer want use much possible mips ware follows following convention procedure calling allocating 32 registers a0a3 four argument registers pass parameters v0v1 two value registers return values ra one return address register return point origin addition allocating registers mips assembly language includes instruction procedures jumps address simultaneously saves address following instruction register ra e jumpandlink instruction jal simply written jal procedureaddress e link portion name means address link formed points calling site allow procedure return proper addr link stored register ra register 31 called return address e return address needed procedure could called several parts program support situations computers like mips use jump register instruction jr introduced help case statements meaning unconditional jump address sp ed register jr rajumpandlink instruction instruction jumps address simultaneously saves address following instruction register ra mipsreturn address link calling site allows procedure return proper address mips stored register ra 98 chapter 2 instructions language computer e jump register instruction jumps address stored register rawhich wan us calling program caller puts parameter values a0a3 uses jal x jump procedure x sometimes named callee e callee performs calculations places results v0 v1 returns control caller using jr raimplicit storedprogram idea need register hold address current instruction executed historical reasons register almost always called program counter abbreviated pc mips architecture although sensible name would instruction address register e jal instruction actually saves pc 4 register ra link following instruction set procedure return using registers suppose compiler needs registers procedure four argument two return value registers since must cover tracks er mission complete registers needed caller must restored values contained procedure invoked situation example need spill registers memory mentioned hardwareso ware interface section e ideal data structure spilling registers stack rstout queue stack needs pointer recently allocated address stack show next procedure place registers spilled old register values found e stack pointer adjusted one word register saved restored mips ware reserves register 29 stack pointer giving obvious name sp stacks popular buzzwords transferring data stack placing data onto stack called push removing data stack called pop historical precedent stacks grow higher addresses lower addresses convention means push values onto stack subtracting stack pointer adding stack pointer shrinks stack thereby popping values stack compiling c procedure doesnt call another procedure lets turn example page 65 section 22 c procedure int leaf_example int g int h int int j int f f g h j return f compiled mips assembly code caller e program instigates procedure provides necessary parameter values callee procedure executes series stored instructions based parameters provided caller returns control caller program counter pc e register containing address instruction program executed stack data structure spilling registers organized lastin rstout queue stack pointer value denoting recently allocated address stack shows registers spilled old register values found mips register sppush add element stack pop remove element stack example e parameter variables g h j correspond argument registers a0 a1 a2 a3 f corresponds s0 e compiled program starts label procedure leaf_example e next step save registers used procedure e c assignment statement procedure body identical example page 68 uses two temporary register us need save three registers s0 t0 t1 push old values onto stack creating space three words 12 bytes stack store addi sp sp 12 adjust stack make room 3 itemssw t1 8sp save register t1 use afterwards sw t0 4sp save register t0 use afterwards sw s0 0sp save register s0 use afterwardsfigure 210 shows stack er procedure call e next three statements correspond body procedure follows example page 68 add t0a0a1 register t0 contains g h add t1a2a3 register t1 contains j sub s0t0t1 f t0 t1 g hi jto return value f copy return value register add v0s0zero returns f v0 s0 0before returning restore three old values registers saved popping stack lw s0 0sp restore register s0 callerlw t0 4sp restore register t0 caller lw t1 8sp restore register t1 caller addi spsp12 adjust stack delete 3 items e procedure ends jump register using return address jr ra jump back calling routinein previous example used temporary registers assumed old values must saved restored avoid saving restoring register whose value never used might happen temporary register mips ware separates 18 registers two groups t0t9 temporary registers preserved callee called procedure procedure call s0s7 saved registers must preserved procedure call used callee saves restores answer 28 supporting procedures computer hardware 99 100 chapter 2 instructions language computer simple convention reduces register spilling example since caller expect registers t0 t1 preserved across procedure call drop two stores two loads code still must save restore s0 since callee must assume caller needs value nested proceduresprocedures call others called leaf procedures life would simple procedures leaf procedures arent spy might employ spies part mission turn might use even spies procedures invoke procedures moreover recursive procedures even invoke clones need careful using registers procedures care must also taken invoking nonleaf procedures example suppose main program calls procedure argument 3 placing value 3 register a0 using jal en suppose procedure calls procedure b via jal b argument 7 also placed a0 since nished task yet co ict use register a0 similarly co ict return address register ra since return address b unless take steps prevent problem co ict eliminate procedure ability return caller one solution push registers must preserved onto stack saved register e caller pushes argument registers a0a3 temporary registers t0t9 needed er call e callee pushes return address register ra saved registers s0s7 used callee e stack pointer sp adjusted account number registers placed stack upon return registers restored memory stack pointer readjusted high addresslow address contents register t1contents register t0contents register s0spspspabcfigure 210 values stack pointer stack b c procedure call e stack pointer always points top stack last word stack drawing compiling recursive c procedure showing nested procedure linkinglets tackle recursive procedure calculates factorial int fact int n n 1 return 1 else return n factn 1 mips assembly code e parameter variable n corresponds argument register a0 e compiled program starts label procedure saves two registers stack return address a0fact addi sp sp 8 adjust stack 2 items sw ra 4sp save return address sw a0 0sp save argument n e rst time fact called sw saves address program called fact e next two instructions test whether n less 1 going l1 1slti t0a01 test n 1 beq t0zerol1 n 1 go l1if n less 1 fact returns 1 putting 1 value register adds 1 0 places sum v0 pops two saved values stack jumps return address addi v0zero1 return 1 addi spsp8 pop 2 items stack jr ra return callerbefore popping two items stack could loaded a0 ra since a0 ra dont change n less 1 skip instructions n less 1 argument n decremented fact called decremented value l1 addi a0a01 n 1 argument gets n 1 jal fact call fact n 1exampleanswer 28 supporting procedures computer hardware 101 102 chapter 2 instructions language computer e next instruction fact returns old return address old argument restored along stack pointer lw a0 0sp return jal restore argument nlw ra 4sp restore return address addi sp sp 8 adjust stack pointer pop 2 itemsnext value register v0 gets product old argument a0 current value value register assume multiply instruction available even though covered chapter 3 mul v0a0v0 return n fact n 1finally fact jumps return address jr ra return callera c variable generally location storage interpretation depends type storage class examples include integers characters see section 29 c two storage classes automatic static automatic variables local procedure discarded procedure exits static variables exist across exits entries procedures c variables declared outside procedures considered static variables declared using keyword static e rest automatic simplify access static data mips ware reserves another register called global pointer gpfigure 211 summarizes preserved across procedure call note several schemes preserve stack guaranteeing caller get data back load stack stored onto stac e stack sp preserved simply making sure callee write sp sp hardware software interfaceglobal pointer e register reserved point static area saved registers s0œs7temporary registers t0œt9stack pointer register sp argument registers a0œa3return address register ra return value registers v0œv1stack stack pointerstack stack pointerpreserved preserved figure 211 preserved across procedure call ware relies frame pointer register global point er register discussed following subsections also preserved preserved callee adding exactly amount subtracted registers preserved saving stack used restoring allocating space new data stack e nal complexity stack also used store variables local procedure registers local arrays structur e segment stack containing procedures saved registers local variables called procedure frame activation record figure 212 shows state stack er procedure call mips ware uses frame pointer fp point th rst word frame procedure stack pointer might change procedure references local variable memory might hav erent sets depending procedure making procedure harder understand alternatively frame pointer ers stable base register within procedure local memoryreferences note activation record appears stack whether explicit frame pointer used weve avoiding using fp avoiding changes sp within procedure examples stack adjusted entry exit procedure procedure frame also called activation record e segment stack containing procedures saved registers local variables frame pointer value denoting location saved registers local variables given procedure high addresslow address abcsaved argument registers spspspfpfpfpsaved return address saved saved registers local arrays structures figure 212 illustration stack allocation b c procedure call e frame pointer fp points th rst word frame en saved argument register stack pointer sp points top stac e stack adjusted make room saved registers memoryresident local variables since stack pointer may change program execution easier programmers reference variables via stable frame pointer although could done stack pointer little address arithmetic local variables stack within procedure compiler save time setting restoring frame pointer frame pointer used initialized using address sp call sp restored using fp information also found column 4 mips reference data card front book 28 supporting procedures computer hardware 103 104 chapter 2 instructions language computer allocating space new data heap addition automatic variables local procedures c programmers need space memory static variables dynamic data structures figure 213 shows mips convention allocation memory e stack starts high end memory grows e rst part low end memory reserved followed home mips machine code traditionally called text segment code static data segment place constants static variables although arrays tend b xed length thus good match static data segment data structures like linked lists tend grow shrink lif e segment data structures traditionally called heap placed next memory note allocation allows stack heap grow toward thereby allowing th cient use memory two segments wax wane text segment e segment unix object le contains machine language code routines source le stack dynamic datastatic datatext reserved sp7fff fffchexgp1000 8000hex1000 0000hexpc0040 0000hex0figure 213 mips memory allocation program data ese addresses ware convention part mips architecture e stack pointer initialized 7fff fffchex grows toward data segment end program code text starts 0040 0000hex e static data starts 1000 0000hex dynamic data allocated malloc c new java next grows toward stack area called heap e global pointer gp set address make easy access data initialized 1000 8000hex access 1000 0000hex 1000 ffffhex using positive negative 16bit sets gp information also found column 4 mips reference data card front book c allocates frees space heap explicit functions malloc allocates space heap returns pointer free releases space heap pointer points memory allocation controlled programs c source many common cult bugs forgetting free space leads memory leak eventually uses much memory operating system may crash freeing space early leads dangling pointers cause pointers point things program never intended java uses automatic memory allocation garbage collection avoid bugs figure 214 summarizes register conventions mips assembly lan guage convention another example making common case fast procedures sa ed 4 arguments 2 registers return value 8 saved registers 10 temporary registers without ever going memory nameregister number usagepreserved callzero0the constant value 0na v0œv12œ3values results expression evaluationno a0œa34œ7argumentsno t0œt7on seiraropmet 51œ8 s0œs7sey devas 32œ61 t8œt9on seiraropmeterom 52œ42 gpsey retnioplabolg 82 spsey retniopkcats 92 fpsey retniopemarf 03 rasey sserddanruter 13 figure 214 mips register conventions register 1 called reserved assembler see section 212 registers 2627 called k0k1 reserved operating syst information also found column 2 mips reference data card front book elaboration four parameters mips convention place extra parameters stack frame pointer procedure rst four parameters registers a0 a3 rest memory addressable via frame pointer mentioned caption figure 212 frame pointer convenient references variables stack within procedure offset frame pointer necessary however gnu mips c compiler uses frame pointer c compiler mips treats register 30 another save register s8elaboration recursive procedures implemented iteratively without using recur cantly improve performance removing overhead associated recursive procedure calls example consider procedure used accumulate sumint sum int n int acc n 0 return sumn 1 acc n else return acc consider procedure call sum30 result recursive calls sum23 sum15 sum06 result 6 returned four 28 supporting procedures computer hardware 105 106 chapter 2 instructions language computer times recursive call sum referred tail call example use tail recursion implemented ver ciently assume a0 n a1 accsum slti t0 a0 1 test n 0 bne t0 zero sum_exit go sum_exit n 0 adda1 a1 a0 add n acc addia0 a0 1 subtract 1 n j sum go sumsum_exit addv0 a1 zero return value acc jr ra return callerwhich following statements c java generally true 1 c programmers manage data explicitly automatic java 2 c leads pointer bugs memory leak bugs java 29 communicating people computers invented crunch numbers soon became commercially viable used process text computers today er 8bit bytes represent characters american standard code information interchange ascii representation nearly everyone follows figure 215 summarizes ascii check wow open tab bar great fourth line keyboard poem hatless atlas 1991 give names ascii characters wow open bar ascii valuecharacterascii valuecharacterascii valuecharacterascii valuecharacterascii valuecharacterascii valuecharacter096112p 3349 097a113q 3450 098b114r 355136 099c115s 3652 32 space4806480p 165a81q 266b82r 7c83s 468d84t100d116t 3753569e85u101e117u 3854670f86v102f118v 3955771g87w103g119w 4056872h88x104h120x 4157973i89y105i121y 425874j90z106j122z 435975k91107k123 446076l92108l124 456177m93109m125 466278n94110n126 476379o95_111o127del figure 215 ascii representation characters note upper lowercase letter er exactly 32 observation lead shortcuts checking changing upper lowercase values shown include formatting characters example 8 represents backspace 9 represents tab character 13 carriage return another useful value 0 null value programmin g language c uses mark end string information also found column 3 mips reference data card front book 29 communicating people 107ascii versus binary numbers could represent numbers strings ascii digits instead integers much storage increase number 1 billion represented ascii versus 32bit integer one billion 1000000000 would take 10 ascii digits 8 bits long us storage expansion would 10 832 25 beyond expansion storage hardware add subtract multiply divide decimal number cult would consume energy suc culties explain computing professionals raised believe binary natural occasional decimal computer bizarre series instructions extract byte word load word store word ar cient transferring bytes well words popularity text programs however mips provides instructions move bytes load byte lb loads byte memory placing rightmost 8 bits register store byte sb takes byte rightmost 8 bits register writes memory us copy byte sequence lb t00sp read byte sourcesb t00gp write byte destinationcharacters normally combined strings variable number character ere three choices representing string 1 th rst position string reserved give length string 2 accompanying variable length string structure 3 last position string indicated character used mark end string c uses third choice terminating string byte whose value 0 named n us string cal represented c following 4 bytes shown decimal numbers 67 97 108 0 shall see java uses th rst option exampleanswer 108 chapter 2 instructions language computer compiling string copy procedure showing use c strings e procedure strcpy copies string string x using null byte termination convention c void strcpy char x char int 0 xi yi 0 copy test byte 1 mips assembly code basic mips assembly code segment assume base addresses arrays x found a0 a1 s0 strcpy adjusts stack pointer saves saved register s0 stack strcpy addi spsp4 adjust stack 1 item sw s0 0sp save s0 initialize 0 next instruction sets s0 0 adding 0 0 placing sum s0 add s0zerozero 0 0 beginning loop e address yi rst formed adding yl1 add t1s0a1 address yi t1 note dont multiply 4 since array bytes words prior examples load character yi use load byte unsigned puts character t2 lbu t2 0t1 t2 yi similar address calculation puts address xi t3 character t2 stored address exampleanswer add t3s0a0 address xi t3 sb t2 0t3 xi yi next exit loop charact exit last character string beq t2zerol2 yi 0 go l2 increment loop back addi s0 s01 1 j l1 go l1if dont loop back last character string restore s0 stack pointer return l2 lw s0 0sp yi 0 end string restore old s0 addi spsp4 pop 1 word stack jr ra return string copies usually use pointers instead arrays c avoid operations code see section 214 explanation arrays versus pointers since procedure strcpy leaf procedure compiler could allocate temporary register avoid saving restoring s0 hence instead thinking registers temporaries think registers callee use whenever convenient compiler nds leaf procedure exhausts temporary registers using registers must save characters strings java unicode universal encoding alphabets human languages figure 216 gives list unicode alphabets almost many alphabets unicode useful symbols ascii inclusive java uses unicode characters default uses 16 bits represent character 29 communicating people 109 110 chapter 2 instructions language computer latinmalayalamtagbanwa general punctuationgreeksinhalakhmerspacing modier letters cyrillicthaimongoliancurrency symbols armenianlaolimbucombining diacritical marks hebrewtibetantai lecombining marks symbols arabicmyanmarkangxi radicalssuperscripts subscripts syriacgeorgianhiragananumber forms thaanahangul jamokatakanamathematical operators devanagariethiopicbopomofomathematical alphanumeric symbols bengalicherokeekanbunbraille patterns gurmukhiunied canadian aboriginal syllabicshavianoptical character recognition gujaratioghamosmanyabyzantine musical symbols oriyaruniccypriot syllabarymusical symbols tamiltagalogtai xuan jing symbolsarrows teluguhanunooyijing hexagram symbolsbox drawing kannadabuhidaegean numbersgeometric shapes figure 216 example alphabets unicode unicode version 40 160 blocks name collection symbols block multiple 16 example greek starts 0370hex cyrillic 0400 hex e rst three columns show 48 blocks correspond human languages roughly unicode numerical order e last column 16 blocks multilingual order 16bit encoding called utf16 default variablelength encoding called utf8 keeps ascii subset eight bits uses 16 32 bits characters utf32 uses 32 bits per character learn see wwwunicodeorg e mips instruction set explicit instructions load store 16 bit quantities called halfwords load half lh loads halfword memory placing rightmost 16 bits register like load byte load half lh treats halfword signed number thus signextends th bits register load halfword unsigned lhu works unsigned integers us lhu popular two store half sh takes halfword rightmost 16 bits register writes memory copy halfword sequence lhu t00sp read halfword 16 bits sourcesh t00gp write halfword 16 bits destinationstrings standard java class special builtin support pr ned methods concatenation comparison conversion unlike c java includes word gives length string similar java arrays elaboration mips software tries keep stack aligned word addresses allowing program always use lw sw must aligned access stack convention means char variable allocated stack occupies 4 bytes even though needs less however c string variable array bytes pack 4 bytes per word java string variable array shorts packs 2 halfwords per wordelaboration ecting international nature web web pages today use unicode instead ascii following statements characters strings c java true 1 string c takes half memory string java 2 strings informal name singledimension arrays characters c java 3 strings c java use null 0 mark end string 4 operations strings like length faster c java ii type variable contain 1000000000 ten takes memory space 1 int c2 string c3 string java 210 mips addressing 32bit immediates addressesalthough keeping mips instructions 32 bits long simp es hardware times would convenient 32bit constant 32bit address section starts general solution large constants shows optimizations instruction addresses used branches jumps check 210 mips addressing 32bit immediates addresses 111 112 chapter 2 instructions language computer 32bit immediate operandsalthough constants frequently short 16bi eld sometimes bigger e mips instruction set includes instruction load upper immediate lui sp cally set upper 16 bits constant register allowing subsequent instruction specify lower 16 bits constant figure 217 shows operation luiloading 32bit constantwhat mips assembly code load 32bit constant register s00000 0000 0011 1101 0000 1001 0000 0000first would load upper 16 bits 61 decimal using luilui s0 61 61 decimal 0000 0000 0011 1101 binary e value register s0 erward 0000 0000 0011 1101 0000 0000 0000 0000 e next step insert lower 16 bits whose decimal value 2304 ori s0 s0 2304 2304 decimal 0000 1001 0000 0000 e nal value register s0 desired value 0000 0000 0011 1101 0000 1001 0000 0000exampleanswerfigure 217 effect lui instruction e instruction lui transfers 16bit immediate constant eld value 16 bits register lling lower 16 bits 0s machine language version lui t0 255 contents register t0 executing lui t0 255 0011110000001000 0000 0000 1111 1111 0000 0000 1111 1111 0000 0000 0000 0000 t0 register 8 210 mips addressing 32bit immediates addresses 113either compiler assembler must break large constants pieces reassemble register might expect immediat elds size restriction may problem memory addresses loads stores well constants immediate instructions job falls assembler mips ware assembler must temporary register available create long val need reason register assembler temporary reserved assembler hence symbolic representation mips machine language longer limited hardware whatever creator assembler chooses include see section 212 stick close hardware explain architecture computer noting use enhanced language assembler found processor elaboration creating 32bit constants needs care instruction addi copies eld instruction upper 16 bits word logical immediate section 26 loads 0s upper 16 bits hence used assembler conjunction lui create 32bit constantsaddressing branches jumps e mips jump instructions simplest addressin ey use th nal mips instruction format called jtype consists 6 bits operatio eld rest bits addr eld usj 10000 go location 10000could assembled format actually bit complicated see 2100006 bits26 bitswhere value jump opcode 2 jump address 10000unlike jump instruction condit ional branch instruction must specify two operands addition branch addr usis assembled instruction leaving 16 bits branch address 51617exit6 bits5 bits5 bits16 bitshardware software interface 114 chapter 2 instructions language computer addresses program 16bi eld would mean program could bigger 2 16 far small realistic option today alternative would specify register would always added branch address branch instruction would calculate following program counterregisterbranch address sum allows program large 2 32 still able use conditional branches solving branch address size prob en question register e answer comes seeing conditional branches used conditional branches found loops statements tend branch nearby instruction example half conditional branches spec benchmarks go locations less 16 instructions away since program counter pc contains address current instruction branch within 215 words current instruction use pc register added address almost loops statements much smaller 2 16 words pc ideal choice form branch addressing called pcrelative addressing shall see chapter 4 convenient hardware increment pc early point next instruction hence mips address actually relative address following instruction pc 4 opposed current instruction pc yet another example making common case fast case addressing nearby instructions like recent computers mips uses pcrelative addressing conditional branches destination instructions likely close branch hand jumpandlink instructions invoke procedures reason near call normally use forms addressing hence mips architecture ers long addresses procedure calls using jtype format jump jumpandlink instructions since mips instructions 4 bytes long mips stretches distance branch pcrelative addressing refer number words next instruction instead number byt us 16bi eld branch four times far interpreting th eld relative word address rather relative byte address similarly 26bit eld jump instructions also word address meaning represents 28bit byte address elaboration since pc 32 bits 4 bits must come somewhere else jumps mips jump instruction replaces lower 28 bits pc leaving upper 4 bits pc unchanged loader linker section 212 must careful avoid placing program across address boundary 256 mb 64 million instructions otherwise jump must replaced jump register instruction preceded instructions load full 32bit address register pcrelative addressing addressing regime address sum program counter pc constant instruction showing branch offset machine language e loop pages 9293 compiled mips assembler code loopsll t1s32 temp reg t1 4 add t1t1s6 t1 address savei lw t00t1 temp reg t0 savei addi s3s31 1 j loop go loop exitif assume place loop starting location 80000 memory mips machine code loop e assembled instructions addresses exampleanswer800000019920 8000409229032 800083598 08001258212 8001681919 1800202 2000080024 remember mips instructions byte addresses addresses sequential word er 4 number bytes word e bne instruction fourth line adds 2 words 8 bytes address following instruction 80016 specifying branch destination relative following instruction 8 80016 instead relative branch instruction 12 80012 using full destination addr e jump instruction last line use full address 20000 4 80000 corresponding label loop 210 mips addressing 32bit immediates addresses 115 116 chapter 2 instructions language computer conditional branches nearby location occasionally branch far away farther represented 16 bits conditional branch instructio e assembler comes rescue large addresses constants inserts unconditional jump branch target inverts condition branch decides whether skip jump branching far away given branch register s0 equal register s1beq s0 s1 l1replace pair instructions ers much greater branching distance ese instructions replace shortaddress conditional branch bne s0 s1 l2 j l1 l2mips addressing mode summary multiple forms addressing generically called addressing modes figure 218 shows operands iden ed addressing mode e mips addressing modes following 1 immediate addressing operand constant within instruction 2 register addressing operand register 3 base displacement addressing operand memory location whose address sum register constant instruction 4 pcrelative addressing branch address sum pc constant instruction 5 pseudodirect addressing jump address 26 bits instruction concatenated upper bits pc hardware software interfaceexampleansweraddressing mode one several addressing regimes delimited varied use operands andor addresses although show mips 32bit addresses nearly microprocessors including mips 64bit address extensions see appendix e section 218 ese extensions response needs ware larger program e process instruction set extension allows architectures expand way able move ware compatibly upward next generation architecture hardware software interface1 immediate addressing 2 register addressing 3 base addressing 4 pcrelative addressing 5 pseudodirect addressing immediateoprsrt oprsrt funct rdregisterregistersoprsrtaddress word memory registerhalfword byteoprsrtaddress word memory pcopword memory pcaddressfigure 218 illustration ﬁ mips addressing modes e operands shaded color e operand mode 3 memory whereas operand mode 2 register note versions load store access bytes halfwords words mode 1 operand 16 bits instruction modes 4 5 address instructions memory mode 4 adding 16bit addr ed 2 bits pc mode 5 concatenating 26bit addr ed 2 bits 4 upper bits pc note single operation use one addressing mode add example uses immediate addi register add addressing 210 mips addressing 32bit immediates addresses 117 118 chapter 2 instructions language computer decoding machine languagesometimes forced reverseengineer machine language create original assembly language one example looking core dump figure 219 shows mips encoding th elds mips machine language gure helps translating hand assembly language machine language decoding machine codewhat assembly language stat ement corresponding machine instruction 00af8020hex e rst step converting hexadecimal binary nd op eldsbits 31 28 26 5 2 0 0000 0000 1010 1111 1000 0000 0010 0000we look eld determine operation referring figure 219 bits 3129 000 bits 2826 000 rformat instruction lets reformat binary instruction rforma elds listed figure 220 op rs rt rd shamt funct000000 00101 01111 10000 00000 100000 e bottom portion figure 219 determines operation rformat instruction case bits 53 100 bits 20 000 means binary pattern represents add instruction decode rest instruction looking th eld val e decimal values 5 rs eld 15 rt 16 rd shamt unused figure 214 shows numbers represent registers a1 t7 s0 reveal assembly instruction add s0a1t7exampleanswer op312628œ2631œ290000rformatbltzgez jumpjumplinkbrancheqbranch neblezbgtz 1001addimmediateaddiusetlessthanimm setless thanimm unsignedandiorixoriloadupper immediate2010tlbflpt30114100loadbyteloadhalf lwlloadwordloadbyte unsignedloadhalfunsignedlwr5101storebytestorehalf swlstoreword swr6110load linked wordlwc17111store cond wordswc1op3126010000 tlb rs252123œ2125œ24000mfc0cfc0mtc0ctc0101210311op3126000000 rformat funct50 2œ05œ300001001201030114100510161107111 00001001201030114100510161107111 00001001201030114100510161107111 0000shiftleft logicalshiftrightlogicalsrasllvsrlvsrav 1001jumpregisterjalr syscallbreak 2010mfhimthim mtlo3011multmultudivdivu 4100addaddusubtractsubuandor xornotornor 5101setltsetlt unsigned61107111figure 219 mips instruction encoding notation gives value eld row column example top portion th gure shows load word row number 4 100 two bits 3129 instruction column number 3 011 two bits 2826 instruction corresponding value eld bits 3126 100011 two underscore means th eld used elsewhere example rformat row 0 column 0 op 000000two ned bottom part th gure hence subtract row 4 column 2 bottom section means func eld bits 50 instruction 100010 two eld bits 3126 000000 two e floating point value row 2 col ned figure 318 chapter 3 bltzgez opcode four instructions found appendix bltz bgez bltzal bgezal chapter describes instructions given full name using color chapter 3 describes instructions given mnemonics using color appendix covers instructions 210 mips addressing 32bit immediates addresses 119 120 chapter 2 instructions language computer figure 220 shows mips instruction formats figure 21 page 64 shows mips assembly language revealed chapter e remaining hidden portion mips instructions deals mainly arithmetic real numbers covered next chapter range addresses conditional branches mips k 10241 addresses 0 64k 12 addresses 0 256k 13 addresses 32k branch 32k er4 addresses 128k branch 128k er ii range addresses jump jump link mips 1024k1 addresses 0 64m 12 addresses 0 256m 13 addresses 32m branch 32m er4 addresses 128m branch 128m er5 anywhere within block 64m addresses pc supplies upper 6 bits 6 anywhere within block 256m addresses pc supplies upper 4 bits iii mips assembly language instruction corresponding machine instruction value 0000 0000 hex1 j2 rformat3 addi4 sll5 mfc06 un ned opcode legal instruction corresponds 0 check namefieldscommentsfield size6 bits5 bits5 bits5 bits5 bits6 bitsall mips instructions 32 bits long rformatoprsrtrd shamtfunctarithmetic instruction format iformat oprsrt addressimmediate transfer branch imm format jump instruction formatsserddategrat potamrofj figure 220 mips instruction formats 211 parallelism instructions synchronization 121 211 parallelism instructions synchronizationparallel execution easier tasks independent en need cooperate cooperation usually means tasks writing new values others must read know ta nished writing safe another read tasks need synchronize dont synchronize danger data race results program change depending events happen occur example recall analogy eight reporters writing story page 44 chapter 1 suppose one reporter needs read prior sections writing conclusion hence must know reporters nished sections danger sections changed erwards better synchronize writing reading section conclusion consistent printed prior sections computing synchronization mechanisms typically built userlevel ware routines rely hardwaresupplied synchronization instructions section focus implementation lock unlock synchronization operations lock unlock used straightforwardly create regions single processor operate called mutual exclusion well implement complex synchronization mechanisms e critical ability require implement synchronization multiprocessor set hardware primitives ability atomically read modify memory locatio nothing else interpose read write memory location without capability cost building basic synchronization primitives high increase unreasonably processor count increases ere number alternative formulations basic hardware primitives provide ability atomically read modify location together way tell read write performed atomically general architects expect users employ basic hardware primitives instead expect primitives used system programmers build synchronization library process en complex tricky lets start one hardware primitive show used build basic synchronization primitive one typical operation building synchronization operations atomic exchange atomic swap inter changes value register value memory see use build basic synchronization primitive assume want build simple lock value 0 used indicate lock free 1 used indicate lock unavailable processor tries set lock exchange 1 register memory address corresponding loc e value returned exchange instruction 1 processor already claimed access 0 otherwise latter data race two memory accesses form data race fro erent threads location least one write occur one er another 122 chapter 2 instructions language computer case value also changed 1 preventing competing exchange another processor also retrieving 0 example consider two processors try exchange simultaneously race broken since exactly one processors perform exchang rst returning 0 second processor return 1 exchange e key using exchange primitive implement synchronization operation atomic exchange indivisible two simultaneous exchanges ordered hardware impossible two processors trying set synchronization variable manner think simultaneously set variable implementing single atomic memory operation introduces challenges design processor since requires memory read write single uninterruptible instruction alternative pair instructions second instruction returns value showing whether pair instructions executed pair ato e pair instruction ectively atomic appears operations executed processor occurred er pair us instruction pa ectively atomic processor change value instruction pair mips pair instructions includes special load called load linked special store called store conditional ese instructions used sequence contents memory location sp ed load linked changed store conditional address occurs store conditional fa e store conditio ned store value presumably erent register memory change value register 1 succeeds 0 fails since load linked returns initial value store conditional returns 1 succeeds following sequence implements atomic exchange memory location sp ed contents s1again addi t0zero1 copy locked value t10s1 load linked sc t00s1 store conditional beq t0zeroagain branch store fails add s4zerot1 put load value s4any time processor intervenes mo es value memory sc instructions sc returns 0 t0 causing code sequence try end sequence contents s4 memory location sp ed s1 atomically exchanged elaboration although presented multiprocessor synchronization atomic exchange also useful operating system dealing multiple processes single processor make sure nothing interferes single processor store conditional also fails processor context switch two instructions see chapter 5 212 translating starting program 123an advantage load linkedstore conditional mechanism used build synchronization primitives atomic compare swap atomic fetchandincrement used parallel programming models involve instructions sc many since store conditional fail either another attempted store load linked address exception care must taken choosing instructions inserted two instructions particular registerregister instructions safely permitted otherwise possible create deadlock situations processor never complete sc repeated page faults addition number instructions load linked store conditional small minimize probability either unrelated event competing processor causes store conditional fail frequently use primitives like load linked store conditional 1 cooperating threads parallel program need synchronize get proper behavior reading writing shared data 2 cooperating processes uniprocessor need synchronize reading writing shared data 212 translating starting program section describes four steps transforming c progra le disk program running computer figure 221 shows translation hierarchy systems combine steps reduce translation time logical four phases programs go throug section follows translation hierarchy compiler e compiler transforms c program assembly language program symbolic form machine understands highlevel language programs take many fewer lines code assembly language programmer productivity much higher 1975 many operating systems assemblers written assembly language memories small compilers wer cient e millionfold increase memory capacity per single dram chip reduced program size concerns optimizing compilers today produce assembly language programs nearly well assembly language expert sometimes even better large programs check assembly language symbolic language translated binary machine language 124 chapter 2 instructions language computer assemblersince assembly language interface higherlevel ware assembler also treat common variations machine language instructions instructions righ e hardware need implement instructions however appearance assembly language simp es translation programming instructions called pseudoinstructions mentioned mips hardware makes sure register zero always val whenever register zero used supplies 0 programmer change value register zero register zero used create assembly language instruction copies contents one register another us mips assembler accepts instruction even though found mips architecture move t0t1 register t0 gets register t1pseudoinstruction common variation assembly language instructions en treated instruction right loaderc program compilerassembly language program assembler object machine language moduleobject library routine machine language linker memory executable machine language program figure 221 translation hierarchy c highlevel language progra rst compiled assembly language program assemble object module machine language e linker combines multiple modules library routines resolve refer e loader places machine code proper memory locations execution processor speed translation process steps skipped combined compilers produce object modules directly systems use linking loaders perform last two steps identify type le unix follo x convention fo les c sour les named xc assembly les xs objec les named xo statically linked library routines xa dynamically linked library routes xso executab les default called aout msdos uses th xes c asm obj lib dll exe sa ect e assembler converts assembly language instruction machine language equivalent following instruction add t0zerot1 register t0 gets 0 register t1 e mips assembler also converts blt branch less two instructions slt bne mentioned example page 95 examples include bgt bge ble also converts branches faraway locations branch jump mentioned mips assembler allows 32bit constants loaded register despite 16bit limit immediate instructions summary pseudoinstructions give mips richer set assembly language instructions implemented hardware e cost reserving one register use assembler going write assembly programs use pseudoinstructions simplify task understand mips architecture sure get best performance however study real mips instructions found figures 21 219 assemblers also accept numbers variety bases addition binary decimal usually accept base succinct binary yet converts easily bit pattern mips assemblers use hexadecimal features convenient primary task assembler assembly machine code e assembler turns assembly language program obje le combination machine language instructions data information needed place instructions properly memory produce binary version instruction assembly language program assembler must determine addresses corresponding labels assemblers keep track labels used branches data transfer instructions symbol table might expect table contains pairs symbols addresses e objec le unix systems typically contains six distinct pieces e obje le header describes size position pieces ob le e text segment contains machine language code e static data segment contains data allocated life program unix allows programs use static data allocated throughout program dynamic data grow shrink needed program see figure 213 e relocation information iden es instructions data words depend absolute addresses program loaded memory e symbol table contains remaining labels ned external references symbol table table matches names labels addresses memory words instructions occupy 212 translating starting program 125 126 chapter 2 instructions language computer e debugging information contains concise description modules compiled debugger associate machine instructions c sour les make data structures readable e next subsection shows attach routines already assembled library routines linkerwhat presented far suggests single change one line one procedure requires compiling assembling whole program complete retranslation terrible waste computing resour repetition particularly wasteful standard library routines programmers would compiling assembling routines b nition almost never change alternative compile assemble procedure independently change one line would require compiling assembling one procedure alternative requires new systems program called link editor linker takes independently assemb led machine language programs stitches together ere three steps linker 1 place code data modules symbolically memory 2 determine addresses data instruction labels 3 patch internal external references e linker uses relocation information symbol table object module resolv ned labels references occur branch instructions jump instructions data addresses job program much like editor nds old addresses replaces new addresses editing origin name link editor linker shor e reason linker useful much faster patch code recompile reassemble external references resolved linker next determines memory locations module occupy recall figure 213 page 104 shows mips convention allocation program data memory since les assembled isolation assembler could know modules instructions data would placed relative modules linker places module memory absolute references memory addresses relative register must relocated r ect true location e linker produces executable le run computer typically le format ob le except contains unresolved references possible partially linke les library routines still unresolved addresses hence result ob leslinker also called link editor systems program combines independently assembled machine language programs resolves ned labels executab le executable le functional program format object le contains unresolved references contain symbol tables debugging information stripped executable contain information relocation information may included loader linking object files link two objec les show updated addresses th rst instructions completed executab le show instructions assembly language make example understandable reality instructions would numbers note objec les highlighted addresses symbols must updated link process instructions refer addresses procedures b instructions refer addresses data words x yexample le header nameprocedure atext size 100hexdata size20hextext segment addressinstruction 0lw a0 0gp4jal 0data segment0xrelocation informationaddressinstruction typedependency 0lwx4jal bsymbol tablelabeladdressxb le headernameprocedure btext size 200hexdata size30hextext segment addressinstruction 0sw a1 0gp4jal 0data segment0yrelocation informationaddressinstruction typedependency 0swy4jal asymbol tablelabeladdressya 212 translating starting program 127 128 chapter 2 instructions language computer procedure needs nd address variable labeled x put load instruction nd address procedure b place jal instruction procedure b needs address variable labeled store instruction address procedure jal instruction figure 213 page 104 know text segment starts address 40 0000hex data segment 1000 0000hex e text procedure placed th rst address data second e object le header procedure says text 100 hex bytes data 20 hex bytes starting address procedure b text 40 0100hex data starts 1000 0020hexanswer le header text size 300hexdata size50hextext segment addressinstruction 0040 0000hexlw a0 8000hexgp0040 0004hexjal 40 0100hex0040 0100hexsw a1 8020hexgp0040 0104hexjal 40 0000hexdata segmentaddress1000 0000hexx1000 0020hexyfigure 213 also shows text segment starts address 40 0000hex data segment 1000 0000hex e text procedure placed rst address data second e objec le header procedure says text 100 hex bytes data 20 hex bytes starting address procedure b text 40 0100hex data starts 1000 0020hexnow linker updates addr elds instructions uses instruction typ eld know format address edited two types e jals easy use pseudodirect addressin e jal address 40 0004hex gets 40 0100hex address procedure b addr eld jal 40 0104hex gets 40 0000hex address procedure addr eld e load store addresses harder relative base register example uses global pointer base register figure 213 shows gp initialized 1000 8000hex get address 1000 0000hex address word x place 8000hex addr eld lw address 40 0000hex similarly place 8020hex addr eld sw address 40 0100hex get address 1000 0020hex address word elaboration recall mips instructions word aligned jal drops right two bits increase instructions address range thus uses 26 bits create 28bit byte address hence actual address lower 26 bits jal instruction example 10 0040hex rather 40 0100hexloadernow executab le disk operating system reads memory starts e loader follows steps unix systems 1 reads executab le header determine size text data segments 2 creates address space large enough text data 3 copies instructions data executab le memory 4 copies parameters main program onto stack 5 initializes machine registers sets stack pointer th rst free location 6 jumps startup routine copies parameters argument registers calls main routine program main routine returns startup routine terminates program exit system call sections a3 a4 appendix describe linkers loaders detail dynamically linked libraries e rst part section describes traditional approach linking libraries program run although static approach fastest way call library routines disadvantages e library routines become part executable code new version library released xes bugs supports new hardware devices statically linked program keeps using old version loads routines library called anywhere executable even calls executed e library large relative program example standard c library 25 mb ese disadvantages lead dynamically linked libraries dlls library routines linked loaded program run program library routines keep extra information location nonlocal procedures names initial version dlls loader ran dynamic linker using extra information th le nd appropriate libraries update external references loader systems program places object program main memory ready execute dynamically linked libraries dlls library routines linked program execution 212 translating starting program 129virtually every problem computer science solved another level indirection david wheeler 130 chapter 2 instructions language computer e downside initial version dlls still linked routines library might called versus called running progra observation led lazy procedure linkage version dlls routine linked er called like many innovations eld trick relies level indirection figure 222 shows technique starts nonlocal routines calling set dummy routines end program one entry per nonlocal routine ese dummy entries contain indirect jump e rst time library routine called program calls dummy entry follows indirect jump points code puts number register text jala first call dll routineb subsequent calls dll routine lwjrdatatext li idjtext datatext dynamic linkerloader remap dll routinejdll routinejrtext jallwjrdatadll routinejrtext figure 222 dynamically linked library via lazy procedure linkage steps th rst time call made dll routine e steps nd routine remap link skipped subsequent calls see chapter 5 opera ting system may avoid copying desired routine remapping using virtual memory management identify desired library routine jumps dynamic linkerloader e link nds desired routine remaps changes address indirect jump location point routine jumps routine completes returns original calling site erea er call library routine jumps indirectly routine without extra hops summary dlls require extra space information needed dynamic linking require whole libraries copied linked ey pay good deal overhead th rst time routine called single indirect jump therea er note return library pays extra overhead microso windows relies extensively dynamically linked libraries also default executing programs unix systems today starting java program e discussion captures traditional model executing program emphasis fast execution time program targeted sp c instruction set architecture even sp c implementation architecture indeed possible execute java programs like c java invented erent set goals however one run safely computer even might slow execution time figure 223 shows typical translation execution steps java rather compile assembly language target computer java comp rst instructions easy interpret java bytecode instruction set see section 215 instruction set designed close java language compilation step trivial virtually optimizations performed like c compiler java compiler checks types data produces proper operation type java programs distributed binary version bytecodes ware interpreter called java virtual machine jvm execute java bytecodes interpreter program simulates instruction set architecture java bytecode instruction instruction set designed interpret java programs java virtual machine jvm e program interprets java bytecodes java program compilerclass files java bytecodes java virtual machine compiled java methods machine language java library routines machine language time compilerfigure 223 translation hierarchy java java progra rst compiled binary version java bytecodes address ned compiler e java program ready run interpreter called java virtual machine e jvm links desired methods java library program running achieve greater performance jvm invoke jit compiler selectively compiles methods native machine language machine running 212 translating starting program 131 132 chapter 2 instructions language computer example mips simulator used book interpreter ere need separate assembly step since either translation simple comp lls addresses nds runtime e upside interpretation portability e availability ware java virtual machines meant people could write run java programs shortly er java announced today java virtual machines found hundreds millions devices everything cell phones internet browsers e downside interpretation lower performance e incredible advances performance 1980s 1990s made interpretation viable many important applications factor 10 slowdown compared traditionally compiled c programs made java unattractive applications preserve portability improve execution speed next phase java development compilers translated program running time compilers jit typically le running program nd hot methods compile native instruction set virtual machine runnin e compiled portion saved next time program run run faster time r balance interpretation compilation evolves time frequently run java program er little overhead interpretation computers get faster compilers researchers invent betters ways compile java th performance gap java c c closing section 215 goes much greater depth implementation java java bytecodes jvm jit compilers advantages interpreter translator think important designers java 1 ease writing interpreter 2 better error messages 3 smaller object code 4 machine independence 213 c sort example put together one danger showing assembly language code snippets idea full assembly language program looks like section derive mips code two procedures written c one swap array elements one sort time compiler jit e name commonly given compiler operates runtime translating interpreted code segments native code computer check 213 c sort example put together 133the procedure swaplets start code procedure swap figure 224 procedure simply swaps two locations memory translating c assembly language hand follow general steps 1 allocate registers program variables 2 produce code body procedure 3 preserve registers across procedure invocation section describes swap procedure three pieces concluding putting pieces together register allocation swapas mentioned pages 9899 mips convention parameter passing use registers a0 a1 a2 a3 since swap two parameters v k found registers a0 a1 e variable temp associate register t0 since swap leaf procedure see page 100 register allocation corresponds variable declarations th rst part swap procedure figure 224 code body procedure swap e remaining lines c code swap temp vkvk vk1 vk1 temprecall memory address mips refers byte address words really 4 bytes apart hence need multiply index k 4 adding address forgetting sequential word addresses er 4 instead void swapint v int k int temp temp vk vk vk1 vk1 temp figure 224 c procedure swaps two locations memory subsection uses procedure sorting example 134 chapter 2 instructions language computer 1 common mistake assembly language programming hence th rst step get address vk multiplying k b 2 sll t1 a12 reg t1 k 4add t1 a0t1 reg t1 v k 4 reg t1 address vknow load vk using t1 vk1 adding 4 t1lw t0 0t1 reg t0 temp vk lw t2 4t1 reg t2 vk 1 refers next element vnext store t0 t2 swapped addresses sw t2 0t1 vk reg t2 sw t0 4t1 vk1 reg t0 tempnow allocated registers written code perform operations procedure missing code preserving saved registers used within swap since using saved registers leaf procedure nothing preserve full swap procedurewe ready whole routine includes procedure label return jump make easier follow identify figure 225 block code purpose procedure procedure body swap sll t1a12 regt 1k4 add t1a0t1 regt1 vk4 regt1hastheaddressofvk lw t00t1 regt0tempvk lw t24t1 regt2vk1 referstonextelementofv sw t20t1 vkregt2 sw t04t1 vk1regt0temp procedure return jr ra returntocallingroutine figure 225 mips assembly code procedure swap figure 224 procedure sortto ensure appreciate rigor programming assembly language well try second longer example case well build routine calls swap procedure program sorts array integers using bubble exchange sort one simplest fastest sorts figure 226 shows c version program present procedure several steps concluding full procedure void sort int v int n int j 0 n 1 j œ 1 j 0 vj vj 1 j 1 swapvj figure 226 c procedure performs sort array vregister allocation sort e two parameters procedure sort v n parameter registers a0 a1 assign register s0 register s1 jcode body procedure sort e procedure body consists two nested loops call swap includes parameters lets unwrap code outside middle e rst translation step th rst loop 0 n 1 recall c statement three parts initialization loop test iteration increment takes one instruction initialize 0 th rst part statement move s0 zero 0remember move pseudoinstruction provided assembler convenience assembly language progra mmer see page 124 also takes one instruction increment last part statement addi s0 s0 1 1 213 c sort example put together 135 136 chapter 2 instructions language computer e loop exited n true said another way exited e set less instruction sets register t0 1 s0 a1 0 otherwise since want test branch register t0 test takes two instructions for1tstslt t0 s0 a1 beq e bottom loop jumps back loop test j for1tst jump test outer loop exit1 e skeleton code th rst loop move s0 zero 0 body first loop addi s0 s0 1 1 j for1tst jump test outer loop exit1vo e exercises explore writing faster code similar loops e second loop looks like c j 1 j 0 vj vj 1 j 1 e initialization portion loop one instruction addi s1 s0 1 j 1 e decrement j end loop also one instruction addi s1 s1 1 j 1 e loop test two parts exit loop either condition fails th rst test must exit loop fails j 0for2tst slti t0 s1 0 reg t0 1 s1 0 j 0 bne t0 zero exit2 go exit2 s1 0 j 0 branch skip second condition test doesnt skip j 0 e second test exits vj vj 1 true exits vj 1 first create address multiplying j 4 since need byte address add base address vsll t1 s1 2 reg t1 j 4add t2 a0 t1 reg t2 v j 4now load vjlw t3 0t2 reg t3 vjsince know second element following word add 4 address register t2 get vj 1lw t4 4t2 reg t4 vj 1 e test two instructions exit test e bottom loop jumps back inner loop test j for2tst jump test inner loopcombining pieces skeleton second loop looks like addi s1 s0 1 j 1 for2tstslti t0 s1 0 reg t0 1 s1 0 j 0 bne t0 zero exit2 go exit2 s1 0 j 0 sll t1 s1 2 reg t1 j 4 add t2 a0 t1 reg t2 v j 4 lw t3 0t2 reg t3 vj lw t4 4t2 reg t4 vj 1 body second loop addi s1 s1 1 j 1 j for2tst jump test inner loop exit2the procedure call sort e next step body second loop swapvjcalling swap easy enough jal swap 213 c sort example put together 137 138 chapter 2 instructions language computer passing parameters sort e problem comes want pass parameters sort procedure needs values registers a0 a1 yet swap procedure needs parameters placed registers one solution copy parameters sort registers earlier procedure making registers a0 a1 available call swap copy faster saving restoring stack rst copy a0 a1 s2 s3 procedure move s2 a0 copy parameter a0 s2move s3 a1 copy parameter a1 s3 en pass parameters swap two instructions move a0 s2 first swap parameter v move a1 s1 second swap parameter jpreserving registers sort e remaining code saving restoring registers clearly must save return address register ra since sort procedure called itse e sort procedure also uses saved registers s0 s1 s2 s3 must saved e prologue sort procedure addi spsp20 make room stack 5 registers sw ra16sp save ra stack sw s312sp save s3 stack sw s2 8sp save s2 stack sw s1 4sp save s1 stack sw s0 0sp save s0 stack e tail procedure simply reverses instructions adds jr return full procedure sortnow put pieces together figure 227 careful replace references registers a0 a1 loops references registers s2 s3 make code easier follow identify block code purpose procedure example nine lines sort procedure c became 35 lines mips assembly language elaboration one optimization works example procedure inlining instead passing arguments parameters invoking code jal instruction compiler would copy code body swap procedure call swap appears code inlining would avoid four instructions example downside inlining optimization compiled code would bigger inlined procedure called several locations code expansion might turn lower performance increased cache miss rate see chapter 5 saving registers sort addi spspœ20 makeroomonstackfor5registers sw ra16spsaveraonstack sw s312sp saves3onstack sw s28spsaves2onstack sw s14spsaves1onstack sw s00spsaves0onstack procedure body move parameters move s2a0 copyparametera0intos2savea0 move s3a1 copyparametera1intos3savea1 outer loop move s0zeroi0 for1tstslt t0s0s3 regt00ifs0s3in beq t0zeroexit1gotoexit1ifs0s3in inner loop addi s1s0œ1 jiœ1 for2tstslti t0s10 regt01ifs10j0 bne t0zeroexit2gotoexit2ifs 10j0 sll t1s12regt 1j4 add t2s2t1regt 2vj4 lw t30t2regt3 vj lw t44t2regt4 vj1 slt t0t4t3regt 00ift4t3 beq t0zeroexit2gotoexit2ift4t3 pass parametersand call move a0s2 1stparameterofswapisvolda0 move a1s1 2ndparameterofswapisj jal swap swap code shown figure 225 inner loop addi s1s1œ1jœ1 j for2tst jumptotestofinnerloop outer loopexit2 addi s0s01 i1 j for1tst jumptotestofouterloop restoring registers exit1 lw s00sp restores0fromstack lw s14sprestores1fromstack lw s28sprestores2fromstack lw s312sp restores3fromstack lw ra16sp restorerafromstack addi spsp20 restorestackpointer procedure return jr ra returntocallingroutine figure 227 mips assembly version procedure sort figure 226 213 c sort example put together 139 140 chapter 2 instructions language computer figure 228 shows impact compiler optimization sort program performance compile time clock cycles instruction count cpi note unoptimized code best cpi o1 optimization lowest instruction count o3 fastest reminding us time accurate measure program performance figure 229 compares impact programming languages compilation versus interpretation algorithms performance sor e fourth column shows unoptimized c program 83 times faster interpreted java code bubble sort using jit compiler makes java 21 times faster unoptimized c within factor 113 highest optimized c code section 215 gives details interpretation versus compilation java java mips code bubble sor e ratios arent close quicksort column 5 presumably harder amortize cost runtime compilation shorter execution time e last column demonstrates impact better algorithm ering three orders magnitude performance increases sorting 100000 items even comparing interpreted java column 5 c compiler highest optimization column 4 quicksort beats bubble sort factor 50 005 2468 123 times faster unoptimized c code versus 241 times faster elaboration mips compilers always save room stack arguments case need stored reality always decrement sp 16 make room four argument registers 16 bytes one reason c provides vararg option allows pointer pick say third argument procedure compiler encounters rare vararg copies four argument registers onto stack four reserved locations understanding program performance gcc optimizationrelative performance clock cycles millionsinstruction count millionscpi none100158615114938 138 o1 medium23766990 37470179 o2 full2386652139993166 o3 procedure integration2416574744993146 figure 228 comparing performance instruction count cpi using compiler optimization bubble sort e programs sorted 100000 words array initialized random val ese programs run pentium 4 clock rate 306 ghz 533 mhz system bus 2 gb pc2100 ddr sdram used linux version 2420 214 arrays versus pointers 141 214 arrays versus pointers challenge new c programmer understanding pointers comparing assembly code uses arrays array indices assembly code uses pointers ers insights pointer section shows c mips assembly versions two procedures clear sequence words memory one using array indices one using pointers figure 230 shows two c procedures e purpose section show pointers map mips instructions endorse dated programming style well see impact modern compiler optimization two procedures end section array version clear lets start array version clear1 focusing body loop ignoring procedure linkage code assume two parameters array size found registers a0 a1 allocated register t0 e initialization th rst part loop straightforward move t0zero 0 register t0 0to set arrayi 0 must rst get address start multiplying 4 get byte address loop1 sll t1t02 t1 4since starting address array register must add index get address arrayi using add instruction add t2a0t1 t2 address arrayilanguageexecution methodoptimization bubble sort relative performance quicksort relative performance speedup quicksort vs bubble sort ccompilernone1001002468compilero12371501562compilero22381501555compilero32411911955javainterpreter œ0120051050jit compilerœ213029338figure 229 performance two sort algorithms c java using interpretation optimizing compilers relative unoptimized c version e last column shows advantage performance quicksort bubble sort language execution optio ese programs run system figure 228 e jvm sun version 131 jit sun hotspot version 131 142 chapter 2 instructions language computer finally store 0 address sw zero 0t2 arrayi 0 instruction end body loop next step increment addi t0t01 1 e loop test checks less size slt t3t0a1 t3 size bne t3zeroloop1 size go loop1we seen pieces procedure mips code clearing array using indices move t0zero 0 loop1 sll t1t02 t1 4 add t2a0t1 t2 address arrayi sw zero 0t2 arrayi 0 addi t0t01 1 slt t3t0a1 t3 size bne t3zeroloop1 size go loop1 code works long size greater 0 ansi c requires test size loop well skip legality clear1int array int size int 0 size 1 arrayi 0 clear2int array int size int p p array0 p arraysize p p 1 p 0 figure 230 two c procedures setting array zeros clear1 uses indices clear2 uses pointer e second procedure needs explanation unfamiliar c e address variable indicated object pointed pointer indicated b e declarations declare array p pointers integer e rst part loop clear2 assigns address th rst element array pointer p e second part loop tests see pointer pointing beyond last element array incrementing pointer one last part loop means moving pointer next sequential object declared size since p pointer integers compiler generate mips instructions increment p four number bytes mips integer e assignment loop places 0 object pointed p pointer version clear e second procedure uses pointers allocates two parameters array size registers a0 a1 allocates p register t0 e code second procedure starts assigning pointer p address th rst element array move t0a0 p address array0 e next code body loop simply stores 0 ploop2 sw zero0t0 memoryp 0 instruction implements body loop next code iteration increment changes p point next word addi t0t04 p p 4incrementing pointer 1 means moving pointer next sequential object c since p pointer integers uses 4 bytes compiler increments p 4 e loop te e rst step calculating address last element array start multiplying size 4 get byte address sll t1a12 t1 size 4and add product starting address array get address th rst word er array add t2a0t1 t2 address arraysize e loop test simply see p less last element arrayslt t3t0t2 t3 parraysizebne t3zeroloop2 parraysize go loop2with pieces completed show pointer version code zero array move t0a0 p address array0 loop2 sw zero0t0 memoryp 0 addi t0t04 p p 4 sll t1a12 t1 size 4 add t2a0t1 t2 address arraysize slt t3t0t2 t3 parraysize bne t3zeroloop2 parraysize go loop2 th rst example code assumes size greater 0 214 arrays versus pointers 143 144 chapter 2 instructions language computer note program calculates address end array every iteration loop even though change faster version code moves calculation outside loop move t0a0 p address array0 sll t1a12 t1 size 4 add t2a0t1 t2 address arraysizeloop2 sw zero0t0 memoryp 0 addi t0t04 p p 4 slt t3t0t2 t3 parraysize bne t3zeroloop2 parraysize go loop2comparing two versions clear comparing two code sequences side side illustrates th erence array indices pointers changes introduced pointer version highlighted e version th must multiply add inside loop incremented address must recalculated ne e memory pointer version right increments pointer p directly e pointer version moves scalin array bound addition outside loop thereby reducing instructions executed per iteration 6 manual optimization corresponds compiler optimization strength reductio instead multiply induction variable elimination eliminating array address calculations within loops section 215 describes two many optimizations elaboration mentioned ealier c compiler would add test sure size greater 0 one wa rst instruction loop slt instruction move t0zero 0 loop1 sll t1t02 t1 4 add t2a0t1 t2 arrayi sw zero 0t2 arrayi 0 addi t0t01 1 slt t3t0a1 t3 size bne t3zeroloop1 go loop1 move t0 a0 p array0 sll t1 a12 t1 size 4 add t2a0t1 t2 array sizeloop2 sw zero0t0 memoryp 0 addi t0t04 p p 4 slt t3t0 t2 t3parraysize bne t3zeroloop2 go loop2 advanced material compiling c interpreting java section gives brief overview c compiler works java executed comp cantly ect performance computer understanding compiler technology today critical understanding performance keep mind subject compiler construction usually taught one twosemester course introduction necessarily touch basics e second part section starting page 21515 readers interested seeing objectedoriented language like java executes mips architecture shows java bytecodes used interpretation mips code java version c segments prior sections including bubble sort covers java virtual machine justintime jit compilers compiling c rst part section introduces internal anatomy compiler start figure 2151 shows structure recent compilers describe optimizations order passes structure dependencieslanguage dependentmachine independentsomewhat language dependent largely machine independentsmall language dependenciesmachine dependencies slighteg register countstypeshighly machine dependentlanguage independentfront end perlanguagefunctiontransform language common intermediate formfor example looptransformations andprocedure inlining also called procedure integrationincluding global localoptimizations registerallocationdetailed instruction selectionand machinedependentoptimizations may includeor followed assemblerhighleveloptimizationsglobaloptimizercode generatorintermediaterepresentationfigure 2151 structure modern optimizing compiler consists number passes phases logically pass thought running completion next occurs practice passes may handle one procedure time essentially interleaving another pass 59215 215 advanced material compiling c interpreting java 2153to illustrate concepts part section use c version loop page 92 savei k 1 front end e function front end read source program check syntax semantics translate source program intermediate form interprets languagespe c operation program see intermediate forms usually simple fact similar java bytecodes see figure 2158 e front end usually broken four separate functions 1 scanning reads individual characters creates string tokens examples tokens reserved words names operators punctuation symbols example token sequence save k 1 word like recognized reserved word c save j recognized names 1 recognized number 2 parsing takes token stream ensures syntax correct produces abstract syntax tree representation syntactic structure program figure 2152 shows abstract syntax tree might look like program fragment 3 semantic analysis takes abstract syntax tree checks program semantic correctness semantic checks normally ensure variables types properly declared types operators objects match step called type checking process symbol table representing named objectsclasses variables functionsis usually created used typecheck program 4 generation intermediate representation ir takes symbol table abstract syntax tree generates intermediate representation output front end intermediate representations usually use simple operations small set primitive types integers characters reals java bytecodes represent one type intermediate form modern compilers common intermediate form looks much like mips instruction set nite number virtual registers later describe map virtual registers nite set real registers figure 2153 shows example might represented intermediate form capitalize mips instructions section represent ir forms e intermediate form sp es functionality program manner independent original source er front end created intermediate form remaining passes largely language independent 2154 215 advanced material compiling c interpreting java statement ydob tnemetats noitidnoc expression assignment comparison lefthand side expression identifier factor l number 1 k yarraexpression expression expression factor factor array access identifier identifier factor save identifier figure 2152 abstract syntax tree example e roots tree consist informational tokens numbers names long chains straightline descendents en omitted constructing tree highlevel optimizations highlevel optimizations transformations done something close source level e common highlevel transformation probably procedure inlining replaces call function body function substituting callers arguments procedures parameters highlevel optimizations involve loop transformations reduce loop overhead improve memory access exploit hardware ectively example loops execute many iterations traditionally controlled statement optimization loopunrolling en useful loopunrolling involves taking loop replicating body multiple times executing transformed loop fewer times loopunrolling reduces loop overhead provides opportunities many optimizations types highlevel transformations include loopunrolling technique get performance loops access arrays multiple copies loop body made instructions erent iterations scheduled together comments written like thissource code often included savei k loop li r1save loads starting address save r1 lw r2i mult r3r24 multiply r2 4 add r4r3r1 lw r50r4 load savei lw r6k bne r5r6endwhileloop 1 lw r6 add r7r61 increment sw r7i branch loop next iteration endwhileloopfigure 2153 loop example shown using typical intermediate representation practice names save k would replaced sort address reference either local stack pointer global pointer set similar way savei accessed note format mips instructions erent intermediate representations operations capitalized registers use rxx notation 215 advanced material compiling c interpreting java 2155sophisticated loop transformations interchanging nested loops blocking loops obtain better memory behavior see chapter 5 examples local global optimizationswithin pass dedicated local global optimization three classes optimizations performed 1 local optimization works within single basic block local optimization pass en run precursor successor global optimization clean code er global optimization 2 global optimization works across multiple basic blocks see example shortly 3 global register allocation allocates variables registers regions code register allocation crucial getting good performance modern processors several optimizations performed locally globally including common subexpression elimination constant propagation copy propagation dead store elimination strength reduction lets look simple examples optimizations 2156 215 advanced material compiling c interpreting java common subexpression elimination nds multiple instances expression replaces second one rst consider example code segment add 4 array element xi xi 4 e address calculation xi occurs twice identical since neither starting address x value chang us calculation reused lets look intermediate code fragment since allows several optimizations performed e unoptimized intermediate code th right optimized code using comm subexpression elimination replace second address calculation th rst note register allocation yet occurred compiler using virtual register numbers like r100 xi 4 xi 4 li r100x li r100x lw r101i lw r101i mult r102r1014 mult r102r1014 add r103r100r102 add r103r100r102 lw r1040r103 lw r1040r103 add r105r1044 value xi r104 xi li r106x add r105r1044 lw r107i xi mult r108r1074 sw r1050r103 add r109r106r107 sw r1050r109if optimization possible across two basic blocks would instance global common subexpression elimination lets consider optimizations strength reduction replaces complex operations simpler ones applied code segment replacing mult constant propagation sibling constant folding nd constants code propagate collapsing constant values whenever possible copy propagation propagates values simple copies eliminating need reload values possibly enabling optimizations common subexpression elimination dead store elimination nds stores values used eliminates store cousin dead code elimination whic nds unused codecode ect result programand eliminates heavy use macros templates similar techniques designed reuse code highlevel languages dead code occurs surprisingly en compilers must conservative e rst task compiler produce correct code second task usually produce fast code although factors 215 advanced material compiling c interpreting java 2157code size may sometimes important well code fast incorrectfor possible combination inputsis simply wron us say compiler conservative mean performs optimization knows 100 certainty matter inputs code perform user wrote since compilers translate optimize one function procedure time compilers especially lower optimization levels assume worst function calls parameters programmers concerned performance critical loops especially realtime embedded applications en nd staring assembly language produced compiler wondering compiler failed perform global optimization allocate variable register throughout loop e answer en lies dictate compiler conservative e opportunity improving code may seem obvious programmer programmer en knowledge compiler absence aliasing two pointers absence ects function call e compiler may indeed able perform transformation little help could eliminate worstcase behavior must assume insight also illustrates important observation programmers use pointers try improve performance accessing variables especially pointers values stack also names variables elements arrays likely disable many compiler optimization e end result lowerlevel pointer code may run better perhaps even worse higherlevel code optimized compiler global code optimizationsmany global code optimizations aims used local case including common subexpression e limination constant propagation copy propagation dead store dead code elimination ere two important global optimizations code motion induction variable elimination loop optimizations aimed code loops code motion nds code loop invariant particular piece code computes value every iteration loop hence may computed outside loop induction variable elimination combination transformations reduce overhead indexing arrays essentially replacing array indexing pointer accesses rather examine induction variable elimination depth point reader section 214 compares use array indexing pointers loops transformation obvious array code pointer code performed modern optimizing compiler understanding program performance 2158 215 advanced material compiling c interpreting java implementing local optimizationslocal optimizations implemented basic blocks scanning basic block instruction execution order looking optimization opportunities assignment statement example page 2156 duplication entire address calculation recognized series sequential passes code process might proceed including description checks needed 1 determine two li operations return result observing operand x value address changed two li operations 2 replace uses r106 basic block r1013 observe change two lws reference replace uses r107 r1014 observe mult instructions input operands r108 may replaced r1025 observe two add instructions identical input operands r100 r102 replace r109 r1036 use dead store code elimination delete second set li lw mult add instructions since results unused roughout process need know two instances operand value easy determine refer virtual registers since intermediate representation uses registers problem trickier operands variables memory even though considering references within basic block reasonably easy compiler make common subexpression elimination determination conservative fashion case see next subsection cult branches intervene implementing global optimizationsto understand challenge implementing global optimizations lets consider examples consider case opportunity common subexpression elimination say ir statement like add rx r20 r50 determine whether two statements compute value must determine whether values r20 r50 identical two statements practice means values r20 r50 changed th rst statement second single basic block easy decide cult complex program structure involving multiple basic blocks branches consider second lw r107 within earlier example know whether value used consider single basic 215 advanced material compiling c interpreting java 2159block know uses r107 within block easy see optimization proceeds however common subexpression elimination copy propagation may create uses value determining value unused code dead cult case multiple basic blocks finally consider load k loop candidate code motion simple example might argue easy see k changed loop hence loop invariant imagine however complex loop multiple nestings statements within body determining load k loop invariant harder case e information need perform global optimizations similar need know operand ir statement could changed ned us nition informatio e dual information also needed nding uses changed opera nitionuse information data ow analysis obtains types information global optimizations data ow analysis operate contro ow graph nodes represent basic blocks arcs represent contro ow basic blocks figure 2154 shows contro ow graph simple loop example one important transformation introduced describe transformation caption see discover done 8 lw r6i9 add r7r6110 sw r7i1 li r1save 2 lw r2i3 sll r3r224 add r4r3r1 5 lw r50r4 6 lw r6k7 beq r5r6startwhileloopfigure 2154 control ﬂ ow graph loop example node represents basic block terminates branch sequential fallthrough another basic block also target branc e ir statements numbered ease referring th e important transformation performed move test conditional branch end eliminates unconditional branch formerly inside loop places loop transformation important many compilers generation ir e mult also replaced strengthreduced sll 21510 215 advanced material compiling c interpreting java suppose computed us nition information control ow graph figure 2154 information allow us perform code motion consider ir statements number 1 6 cases us nition information tells us ar nitions changes operands statements within loop us ir statements moved outside loop notice li save lw k executed prior loop entrance computatio ect program runs faster since two statements outside loop contrast consider ir statement 2 loads value e nitions ect statement outside loop initiall ned inside loop statement 10 stored hence statement loop invariant figure 2155 shows code er performing code motion induction variable elimination simp es address calculatio e variable still register allocated eliminating need load store every time see done next subsection turn register allocation need mention caveat also illustrates complexity culty optimizers remember compiler must conservative conservative compiler must consider following question way variable k could possibly ever change loop unfortunately one way suppose variable k variable actually refer memory location could happen accessed pointers reference parameters lw r2iadd r7r21add r4r44sw r7ili r1save lw r6k lw r2i sll r3r22 add r4r3r1lw r50r4beq r5r6startwhileloopfigure 2155 control ﬂ ow graph showing representation loop example code motion induction variable elimination e number instructions inner loop reduced 10 6 215 advanced material compiling c interpreting java 21511i sure many readers saying well would certainly stupid piece code alas response open compiler must translate code written recall aliasing information must also conservative thus compilers en nd negating optimization opportunities possible alias exists one place code incomplete information aliasing register allocationregister allocation perhaps important optimization modern loadstore architectures eliminating load store eliminates instruction furthermore register allocation enhances value optimizations common subexpression elimination fortunat ely trend toward larger register counts modern architectures made register allocation simpler ective register allocation done local basis gl obal basis across multiple basic blocks within single function local register allocation usually done late compilation th nal code generated focus challenging opportunistic global register allocation modern global register allocation uses regionbased approach region sometimes called live range represents section code particular variable could allocated particular register region select e process iterative 1 choose nition change variable given basic block add block region 2 find uses nition data ow analysis problem add basic blocks contain uses well basic block value passes reach use region 3 find ot nitions also ect use found previous step add basic blocks containing thos nitions well blocks th nitions pass reach use region 4 repeat steps 2 3 using th nitions discovered step 3 convergence e set basic blocks found technique special property designated variable allocated register basic blocks need loading storing variable modern global register allocators start constructing regions every virtual register function regions constructed key question allocate register region challenge certain regions overlap may use register regions overlap ie share common basic blocks share register one way represent 21512 215 advanced material compiling c interpreting java interference among regions interference graph node represents region arcs nodes represent regions basic blocks common interference graph constructed problem allocating registers equivalent famous problem called graph coloring nd color node graph two adjacent nodes color number colors equals number registers coloring interference graph equivalent allocating register regio insight initial motivation allocation method known regionbased allocation originally called graphcoloring approach figure 2156 shows th ow graph representation loop example er register allocation happens graph colored using number registers availab e allocator must spill registers complete coloring coloring based priority function takes account number memory references saved cost tying register allocator attempts avoid spilling important candidates spilling equivalent splitting region live range region split fewer regions interfere two separate nodes representing original region process splitting regions successive coloring used allow allocation process complete point candidates allocated register course whenever region split loads stores add t2t21add t4t44li t0save lw t1k lw t2i sll t3t22 addu t4t3t0lw t30t4beq t3t1startwhileloopfigure 2156 control ﬂ ow graph showing representation loop example code motion induction variable elimination register allocation using mips register names e number ir statements inner loop dropped four six register allocation ten global optimization e value resides t2 end loop may need stored eventually maintain program semantics unused er loop could store avoided also increment inside loop could eliminated completely hardware software interface 215 advanced material compiling c interpreting java 21513must introduced get value memory store e location chosen split region must balance cost loads stores must introduced advantage freeing register reducing number interferences modern register allocators incredibly ective using large register counts available modern processors many programs th ectiveness register allocation limited availability registers possibilities aliasing cause compiler conservative choice candidates code generation e nal steps compiler code generation assembly compilers use standalone assembler accepts assembly language source code save time instead perform function lling symbolic values generating binary code th nal stage code generation modern processors code generation reasonably straightforward since simple architectures make choice instruction relatively obvious complex architectures x86 code generation complex since multiple ir instructions may collapse single machine instruction modern compilers compilation process uses pattern matching either treebased pattern matcher pattern matcher driven parser code generation th nal stages machinedependent optimization also performed ese include constant folding optimizations well localized instruction scheduling see chapter 4 optimization summary figure 2157 gives examples typical optimizations last column indicates optimization performed gcc compiler cult separate simpler optimizationslocal processordependent optimizationsfrom transformations done code generator optimizations done multiple times especially local optimizations may performed er global optimization well code generation today essentially programming desktop server applications done highlevel languages programming embedded applications development means since instructions executed output compiler instruction set architecture essentially compiler target moores law comes temptation adding sophisticated operations instruction e challenge may exactly match compiler needs produce may general arent fast example consider special loop instructions found computers suppose instead 21514 215 advanced material compiling c interpreting java decrementing one compiler wanted increment four instead branching equal zero compiler wanted branch index less equal limi e loop instruction may mismatch faced objections instruction set designer might generalize operation adding another operand specify increment perhaps option branch condition use en danger common case say incrementing one slower sequence simple operations elaboration sophisticated compilers many research compilers use analysis technique called interprocedural analysis obtain information functions called interprocedural analysis attempts discover properties remain true across function call example might discover function call never change global variables might useful optimizing loop calls function information called mayinformation ﬂ ow insensitive information ciently although analyzing level ccgnoitanalpxeeman noitazimitpo edni rossecorp level ecruos eht raen ro talevel hgihpendent3oydob erudecorp yb llac erudecorp ecalpernoitargetni erudecorpedoc enilthgiarts nihtiwlacolcommon subexpression eliminationreplace two instances computa 1 oypoc elgnis yb noitconstant propagationreplace instances variable signed constant constanto1stack height reductionrearrange expression tree minimize sources needed ex pression evaluationo1 hcnarb ssorcalabolgglobal common subexpression elimi nation2osehcnarb sessorc noisrev siht tub lacol sa emas elbairav fo secnatsni lla ecalpernoitagaporp ypoca assigned x ie x xo22opool eht fo noitareti hcae eulav emas setupmoc taht pool morf edoc evomernoitom edocinduction variable elimina tionsimplifyeliminate array addressing calcula 2 ospool nihtiw snoitprocessor dependentdepends processor knowledge strength reductionmany examples replace multiply con 1 ostfihs htiw tnatspipeline schedulingreorder instructions improve pipeline per 1 oecnamrof1otegrat sehcaer taht tnemecalpsid hcnarb tsetrohs eht esoohcnoitazimitpo tesffo hcnarbfigure 2157 major types optimizations explanation class e third column shows occur erent levels optimization g e gnu organization calls three optimization levels medium o1 full o2 full integration small procedures o3 215 advanced material compiling c interpreting java 21515a call function f requires analyzing functions f calls makes process somewhat time consuming large programs costly property discover function must always change variable information called mustinformation ﬂ owsensitive information recall dictate conservative mayinformation never used mustinformationjust function may change variable mean must change conservative however use negation mayinformation compiler rely fact function never change variable optimizations around call site function one important uses interprocedural analysis obtain called alias information alias occurs two names may designate variable example quite helpful know two pointers passed function may never designate variable alias information usuall ow insensitive must used conservatively interpreting java second part section readers interested seeing object oriented language like java executes mips architecture shows java bytecodes used interpretation mips code java version c segments prior sections including bubble sort lets quickly review java lingo make sure page e big idea objectoriented programming programmers think terms abstract objects operations associated type object new types en thought nements existing types operations existing types used new type without change e hope programmer thinks higher level code reused readily programmer implements common operations many erent types erent perspective led erent set term e type object class th nition new data type together operations ar ned work data type particular object instance class creating object class called instantiation e operations class called methods similar c procedures rather call procedure c invoke method ja e members class elds correspond variables c variables inside objects called instance elds rather access structure pointer java uses object reference access objec e syntax method invocation xy x object reference method name e parentchild relationship older newer classes captured verb extends child class extends sub classes parent cl e child class typically ne methods found parent match new data type methods wo ne child class inherits methods reduce number errors associated pointers explicit memory deallocation java automatically frees unused storage using separate garbage objectoriented language programming language oriented around objects rather actions data versus logic 21516 215 advanced material compiling c interpreting java collector frees memory full hence new creates new instance dynamic object heap free java java also requires array bounds checked runtime catch another class errors occur c programs interpretation mentioned java programs distributed java bytecodes java virtual machine jvm executes java byte co e jvm understands binary format called clas le format cl le stream bytes single class containing table valid methods bytecodes pool constants acts part symbol table information parent class class th rst started looks class method main start java class jvm dynamically loads links initializes cl e jvm loads class rst nding binary representation proper class c le creating class binary representation linking combines class runtime state jvm executed finally executes class initialization method included every class figure 2158 shows java bytecodes corresponding mips instructions illustratin majo erences two 1 simplify compilation java uses stack instead registers operands operands pushed stack operated popped stack e designers jvm concerned code size bytecodes vary length one bytes versus 4byte xedsize mips instructions save space jvm even redundant instructions erent lengths whose erence size immediate decision illustrates code size variation third design principle make common case small e jvm safety features embedded architecture example array data transfer instructions check sure th rst operand reference second index operand within bounds 4 allow garbage collectors nd live pointers jvm us erent instructions operate addresses versus integers jvm know operands contain addresses mips generally lumps integers addresses together 5 finally unlike mips javaspe c instructions perform complex operations like allocating array heap invoking method 215 advanced material compiling c interpreting java 21517edocetyb avajnoitarepoyrogetacsize bitsmips instr meaning pop sonsotsondda8ddaiddacitemhtirapop sonœsotsonbus8busitcartbusb8i a8iemarf a8iemarfidda8b8i a8i cniitnemercnidata transferload local integeraddressiload i8aload i816lw tosframei8 load local integeraddressiload_aload_01238lwtosframe0123 store local integeraddressistore i8astore i816swframei8tos pop load integeraddress arrayialoadaaload8lwnosnostos pop store integeraddress arrayiastoreaastore8swnnosnostos pop2 pop sotsonsonhl8daolasyarra morf flah daol2pop sotsonsonnhs8erotsasyarra otni flah erotspop sotsonsonbl8daolabyarra morf etyb daol2pop sotsonsonnbs8erotsabyarra otni etyb erotsload immediatebipush i8 sipush i1616 24addipush tosi8 i16 load immediateiconst_œ10123458addipush tosœ1012345 pop sonsotsondna8dnaidnalacigolpop sonsotsonro8roiropop sot sonsonlls8lhsitfel tfihspop sot sonsonlrs8rhsuithgir tfihsconditional branchbranch equalif_icompeq i1624beqif tos nos go i16 pop2 branch equalif_icompne i1624bneif tos nos go i16 pop2 2pop 61i ot og son sot fitls4261i egtgeltlpmoci_fierapmocunconditional jump61i ot ogj4261i otogpmujrj8nruteri ternruter3cpsot hsup 61i ot oglaj4261i rsjenituorbus ot pmujstack managementremove stackpop pop28pop pop2 sonsot hsup8pudkcats etacilpudtsot sotson sont8pawskcats snoitisop 2 pot pawssafety checkcheck null referenceifnull i16 ifnotnull i1624if tos null go i16 get length arrayarraylength8push tos length array check object typeinstanceof i1624tos 1 tos matches type consti16 tos 0 otherwiseinvocationinvoke methodinvokevirtual i1624invoke method consti16 dispatching typeallocationcreate new class instancenew i1624allocate object type consti16 heap create new arraynewarray i1624allocate array type consti16 heap figure 2158 java bytecode architecture versus mips although many bytecodes simple last halfdozen rows complex sp c java bytecodes one bytes length hence name e java mnemonics use pr x 32bit integer reference address 16bit integers short b 8bit bytes use i8 8bit constant i16 16bit constant mips uses registers operands jvm uses stac e compiler knows maximum size operand stack method simply allocates space current frame notation meaning column tos top stack nos next position tos nnos next position nos pop remove tos pop2 remove tos nos push add position stack nos nnos mean access memory location pointed address stack positions const refers runtime constant pool class created jvm frame refers variables local method frame e missing mips instructions figure 21 andi ori slti lui e missing bytecodes arithmetic logical operators tricky stack management compares 0 branch support branch tables type conversions variations complex javaspe c instructions plus operations oatingpoint data 64bit integers longs 16bit characters 21518 215 advanced material compiling c interpreting java compiling loop java using bytecodes compile loop page 92 time using java bytecodes savei ki 1assume k save th rst three local variables show addresses byteco e mips version c loop figure 2153 took six instructions twentyfour bytes big bytecode version e rst step put array reference save stack 0 aload_3 push local variable 3 save onto stack 1byte instruction informs jvm address local variable 3 put stac e 0 th instruction byte address rst instruction bytecodes method start e next step put index stack 1 iload_1 push local variable 1 onto stacklike prior instruction 1byte instruction short version general instruction takes 2 bytes load local variable onto stac e next instruction get value array element 2 iaload put array element savei onto stack 1byte instruction checks prior two operands pops stack puts value desired array element onto new top stack next place k stack 3 iload_2 push local variable 2 k onto stackwe ready test 4 if_icompne exit compare exit equal 3byte instruction compares top two elements stack pops stack branches equal ar nally ready body loop 7 iinc 1 1 increment local variable 1 1 i1exampleanswer 215 advanced material compiling c interpreting java 21519 unusual 3byte instruction increments local variable 1 without using operand stack optimization saves space finally return top loop 3byte jump 10 go 0 go top loop byte address 0 us bytecode version takes seven instructions thirteen bytes almost half size mips c code optimize code jump lesscompiling java since java derived c java builtin types c assignment statement examples sections 22 26 chapter 2 java ar e true statement example section 27 e java version loop erent however e designers c leave programmers sure code exceed array bo e designers java wanted catch array bound bugs thus require compiler check violations check bounds compiler needs know java includes extra word every array holds upper bound e lower bo ned 0 compiling loop java modify mips code loop page 94 include array bounds checks required java assume length array located th rst element array lets assume java arrays reserved th rst two words arrays data starts well see use th rst word soon second word array length enter loop lets load length array temporary register lw t24s6 temp reg t2 length array save multiply 4 must test see less 0 greater last element array e rst step check less 0 loop slt t0s3zero temp reg t0 1 0 register t0 set 1 less 0 hence branch see register t0 equal zero give us th ect branching less pair instructions slt bne implements branch less exampleanswer 21520 215 advanced material compiling c interpreting java register zero always contains 0 th nal test accomplished using bne instruction comparing register t0 register zerobne t0zeroindexoutofbounds i0 goto error since array starts 0 index last array element one less length array us test upper array bound sure less length array e second step set temporary register 1 less array length branch error less branch error temporary register equal zero slt t0s3t2 temp reg t0 0 length beq t0zeroindexoutofbounds ilength goto errornote two instructions implement branch greater equal e next two lines mips loop unchanged c version sll t1s32 temp reg t1 4 add t1t1s6 t1 address savei need account th rst 8 bytes reserved java changing addr eld load 0 8 lw t08t1 temp reg t0 savei e rest mips code c loop ne bne t0s5 exit go exit savei k add s3s31 1 j loop go loop exit see exercises optimization sequence invoking methods java e compiler picks appropriate method depending type object cases unambiguous method invoked overhead c procedure general however compiler knows given variable contains pointer object belongs subtype general class since doesnt know compile time subclass object thus method invoked compiler generate code rst tests sure pointer isnt null uses code load pointer table legal methods type e rst word object method table address java arrays reserve two words lets say using th h method declared cl e method order subclass e compiler takes h address table invokes method address 215 advanced material compiling c interpreting java 21521public class sort public static void sort int v int 0 vlength 1 int j 1 j 0 vj vj 1 j œ 1 swapv j protected static void swapint v int k int temp vk vk vk1 vk1 temp figure 2159 initial java procedure performs sort array v changes figures 224 226 highlighted e cost object orientation general method invocation includes 1 conditional branch sure pointer object valid 2 load get address table available methods 3 another load get address proper method 4 placing return address return register nally 5 jump register invoke method e next subsection gives concrete example method invocation sort example java figure 2159 shows java version exchange sort simp erence need pass length array separate parameter since java arrays include length vlength denotes length va cant erence java methods prepended keywords found c procedur e sort method declared public static swap declared protected static public means sort invoked method protected means swap called methods within package methods within derived classes static method another name class methodmethods perform classwide operations apply individual object static methods essentially c procedures straightforward translation c static methods means ambiguity method invocation ju cient c also limited sorting integers mean erent sort written data type demonstrate object orientation java figure 21510 shows new version changes highlighted first declare v type comparable replace vj vj 1 invocation compareto changing v new class use code sort many data types public java keyword allows method invoked method protected java key word restricts invocation method methods package package basically directory contains group related classes static method method applies whole class rather individual object unrelated static c 21522 215 advanced material compiling c interpreting java public class sort public static void sort comparable v int 0 vlength 1 int j œ 1 j 0 vjcomparetovj 1 j œ 1 swapv j protected static void swapcomparable v int k comparable temp vk vk vk1 vk1 temp public class comparable public intcompareto int x return value œ x public int value figure 21510 revised java procedure sorts array v take types changes figure 2159 highlighted e method compareto compares two elements returns value greater 0 parameter larger object 0 equal negative number smaller objec ese two changes generalize code sort integers characters strings subclasses comparable types version compareto type pedagogic purposes ne class comparable method compareto compare integer e actu nition comparable java library considerably erent starting mips code generated c show changes made create mips code java swap cant erences must check sure object reference null array reference within bo e rst test checks address th rst parameter zero swap beq a0zeronullpointer a00goto error next load length v register check index k ok lw t24a0 temp reg t2 length array v slt t0a1zero temp reg t0 1 k 0 215 advanced material compiling c interpreting java 21523bne t0zeroindexoutofbounds k 0 goto errorslt t0a1t2 temp reg t0 0 k length beq t0zeroindexoutofbounds klengthgoto error check followed check k1 within bounds addi t1a11 temp reg t1 k1 slt t0t1zero temp reg t0 1 k1 0bne t0zeroindexoutofbounds k1 0 goto error slt t0t1t2 temp reg t0 0 k1 lengthbeq t0zeroindexoutofbounds k1lengthgoto errorfigure 21511 highlights extra mips instructions swap java compiler might produce must adjust set load store account two words reserved method table length figure 21512 shows method body new instructions sort take saving restoring return figure 227 e rst test make sure pointer v null beq a0zeronullpointer a00goto error next load length array use register s3 keep similar code c version swap 1w s34ao s3 length array v bounds checkswap beq a0zeronullpointer a00goto error lw t24a0 temp reg t2 length array v slt t0a1zero temp reg t0 1 k 0 bne t0zeroindexoutofbounds k 0 goto error slt t0a1t2 temp reg t0 0 k length beq t0zeroindexoutofbounds k length goto error addi t1a11 temp reg t1 k1 slt t0t1zero temp reg t0 1 k1 0 bne t0zeroindexoutofbounds k1 0 goto error slt t0t1t2 temp reg t0 0 k1 length beq t0zeroindexoutofbounds k1 length goto error method body sll t1 a1 2 reg t1 k 4 add t1 a0 t1 reg t1 v k 4 kv fo sserdda eht sah 1t ger lw t0 8t1 reg t0 temp vk lw t2 12 t1 reg t2 vk 1 v fo tnemele txen ot srefer sw t2 8t1 vk reg t2 sw t0 12t1 vk1 reg t0 temp procedure return jr ra return calling routine figure 21511 mips assembly code procedure swap figure 224 21524 215 advanced material compiling c interpreting java must ensure index within bounds since th rst test inner loop test j negative skip initial bound te leaves test big slt t0s1s3 temp reg t0 0 j lengthbeq t0zeroindexoutofbounds jlength goto errormethod bodymove parameters 0a evas 2s otni 0a retemarap ypoc 0a 2s evom test ptr null beq a0zeronullpointer a00 goto error get array length v yarra fo htgnel 3s 0a43s wl outer loop0 orez 0s evom for1tst slt t0 s0 s3 reg t0 0 s0 s3 n beq t0 zero exit1 go exit1 s0 s3 n inner loop start addi s1 s0 œ1 j œ 1 for2tst slti t0 s1 0 reg t0 1 s1 0 j 0 bne t0 zero exit2 go exit2 s1 0 j 0 test j big slt t0s1s3 temp reg t0 0 j length beq t0zeroindexoutofbounds j length goto error get vj sll t1 s1 2 reg t1 j 4 add t2 s2 t1 reg t2 v j 4 lw t3 0t2 reg t3 vj test j1 0or j1 big1j 1t ger pmet 11s1t idda slt t0t1zero temp reg t0 1 j1 0 bne t0zeroindexoutofbounds j1 0 goto error slt t0t1s3 temp reg t0 0 j1 length beq t0zeroindexoutofbounds j1 length goto error get vj1 lw t4 4t2 reg t4 vj 1 load method tableelbat dohtem fo sserdda 5t 0a05t wl get method addr fo sserdda 5t 5t85t wl rst methodpass parameters jv si oterapmoc fo retemarap ts1 3t 0a evom 1jv si oterapmoc fo marap dn2 4t 1a evom set return addr sserdda nruter daol 1lar al call indirectlyoterapmoc rof edoc llac 5t rj test skip swap l1 slt t0 zero v0 reg t0 0 0 v0 beq t0 zero exit2 go exit2 t4 t3 pass parameters call swap v si paws fo retemarap ts1 2s 0a evom j si paws fo retemarap dn2 1s 1a evom 432 erugif ni nwohs edoc paws paws laj inner loop end addi s1 s1 œ1 j œ 1 j for2tst p ool renni fo tset ot pmuj outer loopexit2 addi s0 s0 1 1 j for1tst p ool retuo fo tset ot pmuj figure 21512 mips assembly version method body java version sort e new code highlighted gure must still add code save restore registers return mips code found figure 227 keep code similar gure load vlength s3 instead temporary register reduce number lines code make simplifying assumption compareto leaf procedure need push registers saved stack 215 advanced material compiling c interpreting java 21525 e code testing j 1 quite similar code checking k 1 swap skip e ke erence invocation compareto rst load address table legal methods assume two words beginning array lw t50a0 t5 address method table given address method table object get desired method lets assume compareto third method comparable class pick address third method load address temporary register lw t58t5 t5 address third method ready call compareto e next step save necessary registers stack fortunately dont need temporary registers argument registers er method invocation nothing save us simply pass parameters comparetomove a0 t3 1st parameter compareto vj move a1 t4 2nd parameter compareto vj1 since using jump register invoke compareto need pass return address explicitly use pseudoinstruction load address la label want return indirect jump la ral1 load return address jr t5 code compareto e method returns v0 determining two elements larger v0 0 vj vj1 need swap us skip swap need test v0 ð 0 0 š v0 also need include label return address l1 slt t0 zero v0 reg t0 0 0 š v0 beq t0 zero exit2 go exit2 vj1 š vj e mips code compareto exercise e main changes java versions sort swap testing null object references index outofbounds errors extra method invocation give general compare method invocation expensive c procedure call since requires load conditional branch pair chained loads indirect jump see chapter 4 dependent loads indirect jumps relatively slow modern processor e increasing popularity hardware software interface 21526 215 advanced material compiling c interpreting java java suggests many programmers today willing leverage high performance modern processors pay error checking code reuse elaboration although test reference j j 1 sure indices within bounds assembly language programmer might look code reason follows e inner loop executed j 0 since j 1 j need test j 1 see less 0 2 since takes val datalength 1 since j takes values 1 2 1 0 need test j datalength since largest value j datalength 23 following reasoning need test whether j 1 data length since largest value j 1 datalength 1there coding tricks chapter 2 superscalar execution chapter 4 lower effective cost bounds checking high optimizing compilers reason way note compiler inlined swap method sort many checks would unnecessary elaboration look carefully code swap figure 21511 see anything wrong code least explanation code works implicitly assumes comparable element v 4 bytes long surely need much 4 bytes complex subclass comparable could contain number elds surprisingly code work important property javas semantics forces use small representation variables elds array elements belong comparable subclassesjava types divided primitive types ned types numbers characters booleansand reference types builtin classes like string ned classes arrays values reference types pointers also called references anonymous objects allocated heap programmer means assigning one variable another create new object instead makes variables refer object objects anonymous programs therefore way refer directly program must use indirection variable read write elds variables thus data structure allocated array v consists entirely pointers safe assume size swapping code works comparables subtypes write sorting swapping functions arrays primitive types requires write new versions functions one type replication two reasons first primitive type values include references dispatching tables used comparables determine runtime compare values second primitive values come different sizes 1 2 4 8 bytes pervasive use pointers java elegant consistency penalty level indirection requirement objects allocated heap furthermore language lifetimes heapallocated anonymous 221 historical perspective reading 21527objects independent lifetimes named variables elds array elements reference programmers must deal problem deciding safe deallocate heapallocated storage javas designers chose use garbage collection course use garbage collection rather explicit user memory management also improves program safety c provides interesting contrast although programmers write essentially pointermanipulating solution c another option c programmers elect forgo level indirection directly manipulate array objects rather array pointers objects c programmers would typically use template capability allows class function parameterized type data acts templates however compiled using equivalent macro expansion declared instance sort capable sorting types x c would create two copies code class one sort x one sort specialized accordingly solution increases code size exchange making comparison faster since function calls would indirect might even subject inline expansion course speed advantage would canceled swapping objects required moving large amounts data instead single pointers always best design depends details problem 216 real stuff armv7 32bit instructions 145people used taught use pointers c get great ciency available arrays use pointers even cant understand code modern optimizing compilers produce code array version good programmers today prefer compiler heav ing advanced material compiling c interpreting java section gives brief overview c compiler works java executed comp cantly ect performance computer understanding compiler technology today critical understanding performance keep mind subject compiler construction usually taught one twosemester course introduction necessarily touch basics e second part section readers interested seeing object oriented language like java executes mips architecture shows java bytecodes used interpretation mips code java version c segments prior sections including bubble sort covers java virtual machine jit compilers e rest section 215 found online 216 real stuff armv7 32bit instructions arm popular instruction set architecture embedded devices 9 billion devices 2011 using arm recent growth 2 billion per year standing originally acorn risc machine later changed advanced risc machine arm came year mips followed similar philosophies figure 231 lists similari e princi erence mips registers arm addressing modes ere similar core instruction sets arithmeticlogical data transfer instructions mips arm figure 232 shows addressing modesfigure 233 shows data addressing modes supported arm unlike mips arm reserve register contain 0 although mips three simple data addressing modes see figure 218 arm nine including fairly complex calculations example arm addressing mode ca one register understanding program performance 215object oriented language programming language oriented around objects rather actions data versus logic 146 chapter 2 instructions language computer arm mips date announced19851985instruction size bits 3232address space size model 32 bits 32 bits data alignmentalignedaligneddata addressing modes 93integer registers number model size15 gpr 32 bits 31 gpr 32 bits iomemory mapped memory mapped figure 231 similarities arm mips instruction sets registerregister dda bus lum ivid dna ro rox oc data transferaol rots rots instruction name armmipsaddadd trap ow adds swivs addaddu addiusubtcart subtract trap owsubs swivs subsubumult multumulylpit div divušed andandororrxoreorload high part registerš luishift left logicallsl1sllv sllshift right logicallsr 1srlv srlshift right arithmeticasr 1srav sra sltisltiucmp cmn tst teqerapm load byte signedldrsblb load byte unsignedldrblbu load halfword signedldrshlh load halfword unsignedldrhlhu lwldrdrowd sbstrbetybe store halfword strhshswstrdrowe read write special registersmrs msr move atomic exchangeswp swpbllscfigure 232 arm registerregister data transfer instructions equivalent mips core dashes mean operation available architecture synthesized instructions several choices instructions equivalent mips core separated commas arm incl part every data operation instruction th superscript 1 variation move instruction lsr1 note arm divide instruction amount add registers form address update one register new address addressing mode mipsregister operandxximmediate operandxxregister offset displacement based xxregister register indexed šxregister scaled register scaled šxregister offset update register šxregister register update register šxautoincrement autodecrement šxpcrelative data šxarmfigure 233 summary data addressing modes arm separate register indirect register set addressing modes rather putting 0 set latter mode get greater addressing range set 1 2 bits data size halfword word compare conditional branchmips uses contents registers evaluate conditional branches arm uses traditional four condition code bits stored program status word negative zero carry ow ey set arithmetic logical instruction unlike earlier architectures setting optional instruction explicit option leads fewer problems pipelined implementation arm uses conditional branches test condition codes determine possible unsigned signed relations cmp subtracts one operand th erence sets condition codes compare negative cmn adds one operand sum sets condition codes tst performs logical two operands set condition codes ow teq uses exclusive set th rst three condition codes one unusual feature arm every instruction option executing conditionally depending condition codes every instruction starts 4bit eld determines whether act operation instruction nop real instruction depending condition codes hence conditional branches properly considered conditionally executing unconditional branch instruction conditional execution allows avoiding branch jump single instruction takes less code space time simply conditionally execute one instruction figure 234 shows instruction formats arm e principal erences 4bit conditional executio eld every instruction smaller regist eld arm half number registers 216 real stuff armv7 32bit instructions 147 148 chapter 2 instructions language computer unique features arm figure 235 shows arithmeticlogical instructions found mips since arm dedicated register 0 separate opcodes perform operations mips zero addition arm support multiword arithmetic arms 12bit immediate eld novel interpretatio e eight least cant bits zeroextended 32bit value rotated right number bits sp ed th rst four bits th eld multiplied two one advantage scheme represent powers two 32bit word whether split actually catches immediates simple 12bit eld would interesting study opera ing limited immediat e second register arithmetic logical processing operations option bein ed operated e options ar logical right logical right arithmetic rotate right register constant opcodearmregisterregister opx 4312827 2827 2827 2827 191615 1615 1615 1615 1615 1112 430 op8rs14rd4rs24opx 8data transfer armopx 4311112 0op8rs14rd4const 12brancharmjumpcall opx 4312324 0op4const 24armopx 4312324 0op4const 24mips312526 202120 2526 2120 2120 19201110650 const 5rs15rs25rd5opx 6op6mips310const 16rs15rd5op6mips312526 2526 0rs15opx 5rs25const 16op6310op6mipsconst 26figure 234 instruction formats arm mips e erences result whether architecture 16 32 registers 217 real stuff x86 instructions 149arm also instructions save groups registers called block loads stores control 16bit mask within instructions 16 registers loaded stored memory single instructio ese instructions save restore registers procedure entry retur ese instructions also used block memory copy today block copies important use instructions 217 real stuff x86 instructions designers instruction sets sometimes provide powerful operations found arm e goal generally reduce number instructions executed progra e danger reduction occur cost simplicity increasing time program takes execute instructions slower slowness may result slower clock cycle time requiring clock cycles simpler sequence e path toward operation complexity thus fraught peril section 219 demonstrates pitfalls complexity evolution intel x86arm mips vision single small groups 1985 pieces architectur nicely together whole architecture described succinctly case x86 product several independent groups evolved architecture 35 years adding new features original instruction set someone might add clothing packed bag important x86 milestones beauty altogether eye beholder margaret wolfe hungerford molly bawn 1877name deþ nition arm mips load immediaterd immmovaddi 0notrd rs1mvnnor 0 moverd rs1movor 0 rotate rightrd rs ird0 iœ1 rs31œi 31ror notrd rs1 rs2bic reverse subtractrd rs2 œ rs1rsb rsc support multiword integer addcarryout rd rd rs1 oldcarryout adcsšsupport multiword integer subcarryout rd rd œ rs1 oldcarryout sbcsšfigure 235 arm arithmeticlogical instructions found mips 150 chapter 2 instructions language computer 1978 e intel 8086 architecture announced assembly languagecompatible extension successful intel 8080 8bit microprocessor e 8086 16bit architecture internal registers 16 bits wide unlike mips registers dedicated uses hence 8086 considered generalpurpose register architecture 1980 e inte oatingpoint coprocessor announced archi tecture extends 8086 abou oatingpoint instructions instead using registers relies stack see section 221 section 37 1982 e 80286 extended 8086 architecture increasing address space 24 bits creating elaborate memorymapping protection model see chapter 5 adding instructions round instruction set manipulate protection model 1985 e 80386 extended 80286 architecture 32 bits addition 32bit architecture 32bit registers 32bit address space 80386 added new addressing modes additional operation e added instructions make 80386 nearly generalpurpose register machine e 80386 also added paging support addition segmented addressing see chapter 5 like 80286 80386 mode execute 8086 programs without change 198995 e subsequent 80486 1989 pentium 1992 pentium pro 1995 aimed higher performance four instructions added uservisible instruction set three help multiprocessing chapter 6 conditional move instruction 1997 er pentium pentium pro shipping intel announced would expand pentium pentium pro architectures mmx multi media extension new set 57 instructions uses th oating point stack accelerate multimedia communication applications mmx instructions typically operate multiple short data elements time tradition single instruction multiple data simd architectures see chapter 6 pentium ii introduce new instructions 1999 intel added another 70 instructions labeled sse streaming simd extensions part penti e primary changes add eight separate registers double width 128 bits add single precision oatingpoint data type hence four 32bit oatingpoint operations performed parallel improve memory performance sse includes cache prefetch instructions plus streaming store instructions bypass caches write directly memory 2001 intel added yet another 144 instructions time labeled ss e new data type double precision arithmetic allows pairs 64bit oatingpoint operations parallel almost 144 instructions versions existing mmx sse instructions operate 64 bits data generalpurpose register gpr register used addresses data virtually instruction parallel change enable multimedia operations gives comp erent target fo oatingpoint operations unique stack architecture compilers choose use eight sse register oatingpoint registers like found computer change boosted oatingpoint performance pentium 4 th rst microprocessor include sse2 instructions 2003 company intel enhanced x86 architecture time amd announced set architectural extensions increase address space 32 64 bits similar transition 16 32bit address space 1985 80386 amd64 widens registers 64 bits also increases number registers 16 increases number 128 bit sse registers e primary isa change comes adding new mode called long mode nes execution x86 instructions 64bit addresses data address larger number registers adds new pr x instructions depending count long mode also adds four ten new instructions drops 27 old ones pcrelative data addressing another extension amd64 still mode identical x86 legacy mode plus mode restricts user programs x86 allows operating systems use amd64 compatibility mode ese modes allow graceful transition 64bit addressing hpintel ia64 architecture 2004 intel capitulates embraces amd64 relabeling extended memory 64 technology e majo erence intel added 128bit atomic compare swap instruction probably included amd64 time intel announced another generation media extensions sse3 adds 13 instructions support complex arithmetic graphics operations arrays structures video encodin oatingpoint conversion thread synchronization see section 211 amd added sse3 subsequent chips missing atomic swap instruction amd64 maintain binary compatibility intel 2006 intel announces 54 new instructions part sse4 instruction set extension ese extensions perform tweaks like sum absolut erences dot products arrays structures sign zero extension narrow data wider sizes population count ey also added support virtual machines see chapter 5 2007 amd announces 170 instructions part sse5 including 46 instructions base instruction set adds three operand instructions like mips 2011 intel ships advanced vector extension expands sse register width 128 256 bits thereby ning 250 instructions adding 128 new instructions 217 real stuff x86 instructions 151 152 chapter 2 instructions language computer history illustrates impact golden handc compatibility x86 existing ware base step important jeopardize cant architectural changes whatever artistic failures x86 keep mind instruction set largely drove pc generation computers still dominates cloud portion postpc era manufacturing 350m x86 chips per year may seem small compared 9 billion armv7 chips many companies would love control market nevertheless checkered ancestry led architecture cult explain impossible love brace see try read section care would need write x86 programs goal instead give familiarity strengths weaknesses worlds popular desktop architecture rather show entire 16bit 32bit 64bit instruction set section concentrate 32bit subset originated 80386 start explanation registers addressing modes move integer operations conclude examination instruction encoding x86 registers data addressing modes e registers 80386 show evolution instruction set figure 236 e 80386 extended 16bit registers except segment registers 32 bits pre xing e name indicate 32bit version well refer generically gprs generalpurpose registers e 80386 contains eight means mips programs use four times many armv7 twice many figure 237 shows arithmetic logical data transfer instructions twooperand instruction ere two importan erences e x86 arithmetic logical instructions must one operand act source destination armv7 mips allow separate registers source destinatio restriction puts pressure limited registers since one source register must mo ed e second importan erence one operands memory us virtually instruction may one operand memory unlike armv7 mips data memoryaddressing modes described detail er two sizes addresses within instructio ese socalled displacements 8 bits 32 bits although memory operand use addressing mode restrictions registers used mode figure 238 shows x86 addressing modes gprs used mode well get sa ect using mips instructions x86 integer operations e 8086 provides support 8bit byte 16bit word data typ e 80386 adds 32bit addresses data double words x86 amd64 adds 64 gpr 0gpr 1gpr 2gpr 3gpr 4gpr 5gpr 6gpr 7code segment pointerstack segment pointer top stack data segment pointer 0data segment pointer 1data segment pointer 2data segment pointer 3instruction pointer pc condition codesuse031nameeaxecxedxebxespebpesiedicsssdsesfsgseipeflags figure 236 80386 register set starting 80386 top eight registers extended 32 bits could also used generalpurpose registers sourcedestination operand type second source operand registerregisterregisterimmediate registermemory memoryregister memoryimmediate figure 237 instruction types arithmetic logical data transfer instructions e x86 allows combinations sho e restriction absence memorymemory mode immediates may 8 16 32 bits length register one 14 major registers figure 236 eip eflags 217 real stuff x86 instructions 153 154 chapter 2 instructions language computer bit addresses data called quad words well stick 80386 section e data type distinctions apply register operations well memory accesses almost every operation works 8bit data one longer data size size determined mode either 16 bits 32 bits clearly programs want operate data three sizes 80386 architects provided convenient way specify version without expanding co cantly ey decided either 16bit 32bit data dominates programs made sense able set default large size default data size set bit code segment register override default data size 8bit pre x attached instruction tell machine use large size instruction e pr x solution borrowed 8086 allows multiple pr xes modify instruction behavior e three original pr xes override default segment register lock bus support synchronization see section 211 repeat following instruction register ecx counts last pre x intended paired byte move instruction move variable number byt e 80386 also added pr x override default address size e x86 integer operations divided four major classes 1 data movement instructions including move push pop 2 arithmetic logic instructions including test integer decimal arithmetic operations 3 control ow including conditional branches unconditional jumps calls returns 4 string instructions including string move string compare modedescriptionregister restrictions mips equivalentregister indirect address register esp ebplws00s1 based mode 8 32bit displacementaddress contents base register plus displacementnot esp lws0100s1 16bit displacement base plus scaled indexthe address base 2scale x index scale value 0 1 2 3 base gprindex espmult0s24 addt0t0s1 lws00t0 base plus scaled index 8 32bit displacementthe address base 2scale x index displacementwhere scale value 0 1 2 3 base gprindex espmult0s24 addt0t0s1 lws0100t0 16bit displacement figure 238 x86 32bit addressing modes register restrictions equivalent mips code e base plus scaled index addressing mode found arm mips included avoid multiplies 4 scale factor 2 turn index register byte address see figures 225 227 scale factor 1 used 16bit data scale factor 3 64bi data scale factor 0 means address scaled displacement longer 16 bits second fourth modes mips e quivalent mode would need two instructions lui load upper 16 bits displacement add sum upper address base register s1 intel gives tw erent names called based addressing modebased indexedbut essentially identical combine e rst two categories unremarkable except arithmetic logic instruction operations allow destination either register memory location figure 239 shows typical x86 instructions functions conditional branches x86 based condition codes ags like armv7 condition codes ect operation used compare value result 0 branches test condition codes pc instruction functionje nameifequalconditioncodeeipname eipœ128nameeip128 jmp nameeipnamecall namespspœ4mspeip5eipname movwebxedi45 ebxmedi45pushesi spspœ4mspesi popedi edimspspsp4 addeax6765 eaxeax6765 testedx42 set condition code ags edx 42 movslmedimesi ediedi4esiesi4 figure 239 typical x86 instructions functions list frequent operations appears figure 240 e call saves eip next instruction stack eip intel pc relative branch addresses must sp ed number bytes since unlike armv7 mips 80386 instructions 4 bytes length string instructions part 8080 ancestry x86 commonly executed program ey en slower equivalent ware routines see fallacy page 159 figure 240 lists integer x86 instructions many instructions available byte word formats x86 instruction encoding saving worst last encoding instructions 80386 complex many erent instruction formats instructions 80386 may vary 1 byte operands 15 bytes figure 241 shows instruction format several example instructions figure 239 e opcode byte usually contains bit saying whether operand 8 bits 32 bits instructions opcode may include addressing mode register true many instructions form register register op immediate instructions use postbyte extra opcode byte labeled mod reg rm contains addressing mode informatio postbyte used many 217 real stuff x86 instructions 155 156 chapter 2 instructions language computer instructions address memory e base plus scaled index mode uses second postbyte labeled sc index base figure 242 shows encoding two postbyte address sp ers 16bit 32bit mode unfortunately understand fully registers addressing modes available need see encoding addressing modes sometimes even encoding instructions x86 conclusionintel 16bit microprocessor two years competitors elegant architectures motorola 68000 head start led selection 8086 cpu ibm pc intel engineers generally acknowledge x86 cult build computers like armv7 mips large market meant pc era amd intel could ord resources instruction meaningcontrolconditional unconditional branches jnzjz jump condition eip 8bit offset jne forjnz je jz alternative names jmpunconditional jumpš8bit 16bit offset callsubroutine callš16bit offset return address pushed onto stack retpops return address stack jumps looploop branchšdecrement ecx jump eip 8bit displacement ecx 0 data transfermove data registers register memory movemove two registers register memory pushpop push source operand stack pop operand stack top register lesload es one gprs memory arithmetic logicalarithmetic logical operations using data registers memory addsub add source destination subtract source destination registermemory format cmpcompare source destination registermemory format shlshrrcr shift left shift logical right rotate right carry condition code cbwconvert byte eight rightmost bits eax 16bit word right eax testlogical source destination sets condition codes incdec increment destination decrement destination orxor logical exclusive registermemory format string move string operands length given repeat preþ xmovscopies string source destination incrementing esi edi may repeated lodsloads byte word doubleword string eax register figure 240 typical operations x86 many operations use registermemory format either source destination may memory may register immediate operand help overcome added complexity x86 lacks style made market size making beautiful right perspective saving grace frequently used x86 architectural components cult implement amd intel demonstrated rapidly improving performance integer programs since 1978 get performance figure 241 typical x86 instruction formats figure 242 shows encoding postbyte many instructions contain 1bi eld w says whether operation byte double word e eld mov used instructions may move memory shows direction move e add instruction requires 32 bits immediat eld 32bit mode immediates either 8 bits 32 bi e immediate eld test 32 bits long 8bit immediate test 32bit mode overall instructions may vary 1 15 bytes lengt e long length comes extra 1byte pr xes 4byte immediate 4byte displacement address using opcode 2 bytes using scaled index mode sp er adds another byte 217 real stuff x86 instructions 157a je eip displacement b call c mov ebx edi 45 push esi e add eax 6765 f test edx 42 immediatepostbyte testaddpushmovcalljewwimmediateregregwd displacementrmpostbyte offsetdisplacementcondition448 83268118 534323173218 158 chapter 2 instructions language computer compilers must avoid portions architecture hard implement fastin postpc era however despite considerable architectural manufacturing expertise x86 yet competitive personal mobile device 218 real stuff armv8 64bit instructions many potential problems instruction set one almost impossible overcome small memory address x86 successfully ext rst 32bit addresses later 64bit addresses many brethren wer behind example 16bit address mostek 6502 powered apple ii even given headstart th rst commercially successful personal computer lack address bits condemned dustbin history arm architects could see writing wall 32bit address computer began design 64bit address version arm 2007 nally revealed 2013 rather minor cosmetic changes make registers 64 bits wide basically happened x86 arm complete overhaul e good news know mips easy pick armv8 64bit version called first compared mips arm dropped virtually unusual features v7 ere conditional executio eld nearly every instruction v7regw 0w 1rmmod 0 mod 1mod 2mod 316b32b16b 32b16b32b16b32b 0alaxeax0addrbxsieax samesamesamesamesame 1clcxecx1addrbxdiecx addr addr addr addr 2dldxedx2addrbpsiedx mod0mod0mod0mod0reg 3blbxebx3addrbpsiebx disp8 disp8 disp16 disp32þ eld 4ahspesp4addrsi sibsidisp8sibdisp8sidisp8 sibdisp32ﬁ 5chbpebp5addrdidisp32didisp8ebpdisp8didisp16ebpdisp32ﬁ 6dhsiesi6addrdisp16esibpdisp8esidisp8bpdisp16esidisp32ﬁ 7bhdiedi7addrbxedibxdisp8edidisp8bxdisp16edidisp32ﬁ figure 242 encoding ﬁ rst address speciﬁ er x86 mod reg rm e rst four columns show encoding 3bit r eld depends w bit opcode whether machine 16bit mode 8086 32bit mode 80386 e remaining columns explain mod elds e meaning 3bi eld depends value 2bit mo eld address size basically registers used address calculation listed sixth seventh columns mod 0 mod 1 adding 8bit displacement mod 2 adding 16bit 32bit displacement depending address mode e exceptions 1 rm 6 mod 1 mod 2 16bit mode selects bp plus displacement 2 rm 5 mod 1 mod 2 32bit mode selects ebp plus displacement 3 rm 4 32bit mode mod equal 3 sib means use scaled index mode shown figure 238 mod 3 th eld indicates register using encoding r eld combined w bit 219 fallacies pitfalls 159 e immediate eld simply 12 bit constant rather essentially input function produces constant v7 arm dropped load multiple store multiple instructions e pc longer one registers resulted unexpected branches wrote second arm added missing features useful mips v8 32 generalpurpose registers compiler writers surely love like mips one register hardwired 0 although load store instructions instead refers stack pointer addressing modes work word sizes armv8 case armv7 includes divide instruction omitted armv7 adds equivalent mips branch equal branch equal philosophy v8 instruction set much closer mips v7 conclusion main similarity armv7 armv8 name 219 fallacies pitfalls fallacy powerful instructions mean higher performance part power intel x86 pr xes modify execution following instruction one pr x repeat following instruction counter counts us move data memory would seem natural instruction sequence use move repeat pr x perform 32bit memorytomemory moves alternative method uses standard instructions found computers load data registers store registers back memory second version program code replicated reduce loop overhead copies 15 times fast third version uses larg oatingpoint registers instead integer registers x86 copies 20 times fast complex move instruction fallacy write assembly language obtain highest performance one time compilers programming languages produced naïve instruction sequences increasing sophistication compilers means gap compiled code code produced hand closing fast fact compete current compilers assembly la nguage programmer needs understand concepts chapters 4 5 thoroughly processor pipelining memory hierarchy 160 chapter 2 instructions language computer battle compilers assembly language coders another situation humans losing ground example c ers programmer chance give hint compiler variables keep registers versus spilled memory compilers poor register allocation hints vital performance fact old c textbooks spent fair amount time giving examples ectively use register hints todays c compilers generally ignore hints compiler better job allocation programmer even writing hand resulted faster code dangers writing assembly language longer time spent coding debugging loss portability th culty maintaining code one widely accepted axioms ware engineering coding takes longer write lines clearly takes many lines write program assembly language c java moreover coded next danger become popular program programs always live longer expected meaning someone update code several years make work new releases operating systems new models machines writing higherlevel language instead assembly language allows future compilers tailor code future machines also makes ware easier maintain allows program run brands computers fallacy e importance commercial binary compatibility means successful instruction sets dont change backwards binary compatibility sacrosanct figure 243 shows x86 architecture grown dramatically e average one instruction per month 35year lifetime pitfall forgetting sequential word addresses machines byte addressing di er one many assembly language programmer toiled errors made assuming address next word found incrementing address register one instead word size bytes forewarned forearmed pitfall using pointer automatic variable outside ning procedure common mistake dealing pointers pass result procedure includes pointer array local procedure following stack discipline figure 212 memory contains local array reused soon procedure returns pointers automatic variables lead chaos 220 concluding remarks 161 220 concluding remarks e two principles storedprogram computer use instructions indistinguishable numbers use alterable memory programs ese principles allow single machine aid environmental scien nancial advisers novelists specialt e selection set instructions machine understand demands delicate balance among number instructions needed execute program number clock cycles needed instruction speed clock illustrated chapter three design principles guide authors instruction sets making delicate balance 1 simplicity favors regularity regularity motivates many features mips instruction set keeping instructions single size always requiring three register operands arithmetic instructions keeping regist elds place instruction format 2 smaller faster e desire speed reason mips 32 registers rather many 3 good design demands good compromises one mips example compromise providing larger addresses constants instructions keeping instructions length less robert browning andrea del sarto 18550100200300 400500600 700 8009001000197819801982198419861988199019921994199619982000200220042006200820102012yearnumber instructionsfigure 243 growth x86 instruction set time clear technical value extensions rapid change also increases th culty companies try build compatible processors 162 chapter 2 instructions language computer also saw great idea making common cast fast applied instruction sets well computer architecture examples making common mips case fast include pcrelative addressing conditional branches immediate addressing larger constant operands machine level assembly language language humans read e assembler translates binary numbers machines understand even extends instruction set creating symbolic instructions arent hardware instance constants addresses big broken properly sized pieces common variations instructions given name figure 244 lists mips instructions covered mips instructionsnameformatpseudo mipsnameformat addaddrmove moversubtractsubrmultiply multradd immediateaddiimultiply immediate multiiload word lwiload immediate liistore word swibranch less bltiload halflhibranch less equalbleiload half unsignedlhuistore half shibranch greater bgtiload bytelbibranch greater equalbgeiload byte unsignedlbuistore byte sbiload linkedllistore conditional sciload upper immediateluiiand andrororrnornorrand immediateandiior immediateoriishift left logicalsllr shift right logicalsrlr branch equalbeqibranch equalbneiset less thansltrset less immediatesltiiset less immediate unsignedsltiuijumpjjjump register jrrjump linkjaljfigure 244 mips instruction set covered far real mips instructions left pseudoinstructions right appendix section a10 describes full mips architecture figure 21 shows details mips architecture revealed chapter e information given also found columns 1 2 mips reference data card front book 221 historical perspective reading 163so far real pseudoinstructions hiding details higher level another example great idea abstraction category mips instructions associated constructs appear programming languages arithmetic instructions correspond operations found assignment statements transfer instructions likely occur dealing data structures like arrays structures conditional branches used statements loops unconditional jumps used procedure calls returns case switch statements ese instructions born equal popularity dominates many example figure 245 shows popularity class instructions sp e varying popularity instructions plays important role chapters datapath control pipelining instruction classmips examples hll correspondence frequency integerft pt arithmeticaddsubaddi operations assignment statements data transferlwswlb lbu lh lhusblui logicalandornorandiori sllsrl 0perations assignment statements conditional branchbeqbnesltslti sltiuif statements loopsjumpjjrjal procedure calls r eturns caseswitch statements163512 342483648 0references data structures arraysfigure 245 mips instruction classes examples correspondence highlevel program language constructs percentage mips instructions executed category average integer ﬂ oating point spec cpu2006 benchmarks figure 326 chapter 3 shows average percentage individual mips instructions executed er explain computer arithmetic chapter 3 reveal rest mips instruction set architecture historical perspective reading section surveys history instruction set architectures isas time give short history programming languages compilers isas 221 164 chapter 2 instructions language computer include accumulator architectures generalpurpose register architectures stack architectures brief history arm x86 also review controversial subjects highlevellanguage computer architectures reduced instruction set computer architectur e history programming languages includes fortran lisp algol c cobol pascal simula smalltalk c java history compilers includes key milestones pioneers achieved th e rest section 221 found online 222 exercisesappendix describes mips simulator helpful exercises although simulator accepts pseudoinstructions try use pseudoinstructions exercises ask produce mips code goal learn real mips instruction set asked count instructions count r ect actual instructions executed pseudoinstructions ere cases pseudoinstructions must used example la instruction actual value known assembly time many cases quite convenient result readable code example li move instructions choose use pseudoinstructions reasons please add sentence two solution stating pseudoinstructions used 21 5 22 following c statement corresponding mips assembly code assume variables f g h given could considered 32bit integers declared c program use minimal number mips assembly instructions f g h 522 5 22 following mips assembly instructions corresponding c statement add f g hadd f f 222 exercises 16523 5 22 23 following c statement corresponding mips assembly code assume variables f g h j assigned registers s0 s1 s2 s3 s4 respectively assume base address arrays b registers s6 s7 respectively b8 aij24 5 22 23 mips assembly instructions corresponding c statement assume variables f g h j assigned registers s0 s1 s2 s3 s4 respectively assume base address arrays b registers s6 s7 respectively sll t0 s0 2 t0 f 4add t0 s6 t0 t0 af sll t1 s1 2 t1 g 4 add t1 s7 t1 t1 bg lw s0 0t0 f af addi t2 t0 4 lw t0 0t2 add t0 t0 s0 sw t0 0t125 5 22 23 mips assembly instructions exercise 24 rewrite assembly code minimize number mips instructions possible needed carry function 26 e table shows 32bit values array stored memory addressdata 242 384 323 366 401 166 chapter 2 instructions language computer 261 5 22 23 memory locations table write c code sort data lowest highest placing lowest value smallest memory location shown figure assume data shown represents c variable called array array type int first number array shown first element array assume particular machine byteaddressable machine word consists four bytes 262 5 22 23 memory locations table write mips code sort data lowest highest placing lowest value smallest memory location use minimum number mips instructions assume base address array stored register s627 5 23 show value 0xabcdef12 would arranged memory littleendian bigendian machine assume data stored starting address 0 28 5 24 translate 0xabcdef12 decimal 29 5 22 23 translate following c code mips assume variables f g h j assigned registers s0 s1 s2 s3 s4 respectively assume base address arrays b registers s6 s7 respectively assume elements arrays b 4byte words b8 ai aj210 5 22 23 translate following mips code c assume variables f g h j assigned registers s0 s1 s2 s3 s4 respectively assume base address arrays b registers s6 s7 respectively addi t0 s6 4add t1 s6 0 sw t1 0t0 lw t0 0t0 add s0 t1 t0211 5 22 25 mips instruction show value opcode op source register rs target register r elds itype instructions show value immediat eld rtype instructions show value destination regist eld 222 exercises 167212 assume registers s0 s1 hold values 0x80000000 0xd0000000 respectively 2121 5 24 value t0 following assembly code add t0 s0 s12122 5 24 result t0 desired result ow 2123 5 24 contents registers s0 s1 sp ed value t0 following assembly code sub t0 s0 s12124 5 24 result t0 desired result ow 2125 5 24 contents registers s0 s1 sp ed value t0 following assembly code add t0 s0 s1add t0 t0 s02126 5 24 result t0 desired result ow 213 assume s0 holds value 128 ten 2131 5 24 instruction add t0 s0 s1 ranges values s1 would result ow 2132 5 24 instruction sub t0 s0 s1 ranges values s1 would result ow 2133 5 24 instruction sub t0 s1 s0 ranges values s1 would result ow 214 5 22 25 provide type assembly language instruction following binary value 0000 0010 0001 0000 1000 0000 0010 0000two215 5 22 25 provide type hexadecimal representation following instruction sw t1 32t2 168 chapter 2 instructions language computer 216 5 25 provide type assembly language instruction binary representation instruction described followin eldsop0 rs3 rt2 rd3 shamt0 funct34217 5 25 provide type assembly language instruction binary representation instruction described followin eldsop0x23 rs1 rt2 const0x4218 assume would like expand mips regist le 128 registers expand instruction set contain four times many instructions 2181 5 25 would ect size bit elds rtype instructions 2182 5 25 would ect size bit elds itype instructions 2183 5 25 210 could two proposed changes decrease size mips assembly program hand could proposed change increase size mips assembly program 219 assume following register contents t0 0xaaaaaaaa t1 0x123456782191 5 26 register values shown value t2 following sequence instructions sll t2 t0 44or t2 t2 t12192 5 26 register values shown value t2 following sequence instructions sll t2 t0 4 andi t2 t2 12193 5 26 register values shown value t2 following sequence instructions srl t2 t0 3 andi t2 t2 0xffef 222 exercises 169220 5 26 find shortest sequence mips instructions extracts bits 16 11 register t0 uses value eld replace bits 31 26 register t1 without changing 26 bits register t1221 5 26 provide minimal set mips instructions may used implement following pseudoinstruction t1 t2 bitwise invert222 5 26 following c statement write minimal sequence mips assembly instructions identical operation assume t1 t2 b s1 base address c c0 4223 5 27 assume t0 holds value 0x00101000 value t2 er following instructions slt t2 0 t0bne t2 0 else j doneelse addi t2 t2 2 done224 5 27 suppose program counter pc set 0x2000 0000 possible use jump j mips assembly instruction set pc address 0x4000 0000 possible use branchonequal beq mips assembly instruction set pc address 225 e following instruction included mips instruction set rpt t2 loop ifrrs0 rrsrrs1 pcpc4branchaddr2251 5 27 instruction implemented mips instruction set appropriate instruction format 2252 5 27 shortest sequence mips instructions performs operation 170 chapter 2 instructions language computer 226 consider following mips loop loop slt t2 0 t1beq t2 0 donesubi t1 t1 1 addi s2 s2 2 j loopdone2261 5 27 assume register t1 initialized value 10 value register s2 assuming s2 initially zero 2262 5 27 loops write equivalent c code routine assume registers s1 s2 t1 t2 integers b temp respectively 2263 5 27 loops written mips assembly assume register t1 initialized value n many mips instructions executed 227 5 27 translate following c code mips assembly code use minimum number instructions assume values b j registers s0 s1 t0 t1 respectively also assume register s2 holds base address array fori0 ia iforj0 jb jd4j j228 5 27 many mips instructions take implement c code exercise 227 variables b initialized 10 1 elements initially 0 total number mips instructions executed complete loop 229 5 27 translate following loop c assume clevel integer held register t1 s2 holds clevel integer called result s0 holds base address integer memarray addi t1 0 0loop lw s1 0s0 add s2 s2 s1 addi s0 s0 4 222 exercises 171 addi t1 t1 1 slti t2 t1 100 bne t2 s0 loop230 5 27 rewrite loop exercise 229 reduce number mips instructions executed 231 5 28 implement following c code mips assembly total number mips instructions needed execute function int fibint n n0 return 0 else n 1 return 1 else return fibn1 fibn2232 5 28 functions en implemented compilers inline inline function body function copied program space allowing overhead function call eliminated implement inline version c code mips assembly reduction total number mips assembly instructions needed complete function assume c variable n initialized 5 233 5 28 function call show contents stack er function call made assume stack pointer originally addr c follow register conventions sp ed figure 211 234 translate function f mips assembly language need use registers t0 t7 use lowernumbered register rst assume function declaration func int fint int b e code function f follows int fint int b int c int return funcfuncabcd 172 chapter 2 instructions language computer 235 5 28 use tailcall optimization function explain yes th erence number executed instructions f without optimization 236 5 28 right function f exercise 234 returns know contents registers t5 s3 ra sp keep mind know entire function f looks like function func know declaration 237 5 29 write program mips assembly language convert ascii number string containing positive negative integer decimal strings integer program expect register a0 hold address null terminated string containing combination digits 0 9 program compute integer value equivalent string digits place number register v0 nondigit character appears anywhere string program stop value 1 register v0 example register a0 points sequence three bytes 50ten 52ten 0ten null terminated string 24 program stops register v0 contain value 24 ten 238 5 29 consider following code lbu t0 0t1sw t0 0t2assume register t1 contains address 0x1000 0000 register t2 contains address 0x1000 0010 note mips architecture utilizes bigendian addressing assume data hexadecimal address 0x1000 0000 0x11223344 value stored address pointed register t2239 5 210 write mips assembly code creates 32bit constant 0010 0000 0000 0001 0100 1001 0010 0100two stores value register t1240 5 26 210 current value pc 0x00000000 use single jump instruction get pc address shown exercise 239 241 5 26 210 current value pc 0x00000600 use single branch instruction get pc address shown exercise 239 222 exercises 173242 5 26 210 current value pc 0x1ffff000 use single branch instruction get pc address shown exercise 239 243 5 211 write mips assembly code implement following c code locklk shvarmaxshvarx unlocklkassume address lk variable a0 address shvar variable a1 value variable x a2 critical section contain function calls use llsc instructions implement lock operation unlock operation simply ordinary store instruction 244 5 211 repeat exercise 243 time use llsc perform atomic update shvar variable directly without using lock unlock note problem variable lk245 5 211 using code exercise 243 example explain happens two processors begin execute critical section time assuming processor executes exactly one instruction per cycle 246 assume given processor cpi arithmetic instructions 1 cpi loadstore instructions 10 cpi branch instructions 3 assume program following instruction breakdowns 500 million arithmetic instructions 300 million loadstore instructions 100 million branch instructions 2461 5 219 suppose new powerful arithmetic instructions added instruction set average use powerful arithmetic instructions reduce number arithmetic instructions needed execute program 25 cost increasing clock cycle time 10 good design choice 2462 5 219 suppose w nd way double performance arithmetic instructions overall speedup machine nd way improve performance arithmetic instructions 10 times 247 assume given program 70 executed instructions arithmetic 10 loadstore 20 branch 174 chapter 2 instructions language computer 2471 5 219 given instruction mix assumption arithmetic instruction requires 2 cycles loadstore instruction takes 6 cycles branch instruction takes 3 cyc nd average cpi 2472 5 219 25 improvement performance many cycles average may arithmetic instruction take loadstore branch instructions improved 2473 5 219 50 improvement performance many cycles average may arithmetic instruction take loadstore branch instructions improved 22 page 66 mips c java 23 page 72 2 slow 24 page 79 2 8ten 25 page 87 4 sub t2 t0 t126 page 89 mask pattern 1s leaves 0s everywhere desir eld shi ing correct amount removes bits th th eld shi ing right appropriate amount puts th eld right bits word 0s rest word note leaves eld originally th pair moves th eld rightmost part word 27 page 96 true ii 1 28 page 106 true 29 page 111 1 2 ii 3 210 page 120 4 128k ii 6 block 256m iii 4 sll 211 page 123 true 212 page 132 4 machine independence answers check 3numerical precision soul science sir darcy wentworth thompson growth form 1917arithmetic computers 31 introduction 17832 addition subtraction 17833 multiplication 18334 division 18935 floating point 19636 parallelism computer arithmetic subword parallelism 22237 real stuff streaming simd extensions advanced vector extensions x86 224computer organization design doi 2013 elsevier inc rights reservedhttpdxdoiorg101016b97801240772630000112013 38 going faster subword parallelism matrix multiply 22539 fallacies pitfalls 229310 concluding remarks 232311 historical perspective reading 236312 exercises 237the five classic components computer 178 chapter 3 arithmetic computers 31 introductioncomputer words composed bits thus words represented binary numbers chapter 2 shows integers represented either decimal binary form numbers commonly occur example fractions real numbers happens operation creates number bigger represented underlying questions mystery hardware really multiply divide numbers e goal chapter unravel mysteries including representation real numbers arithmetic algorithms hardware follows algorithms implications instruction ese insights may explain quirks already encountered computers moreover show use knowledge make arithmeticin tensive programs go much faster 32 addition subtraction addition would expect computers digits added bit bit right carries passed next digit th would hand subtraction uses addition appropriate operand simply negated added binary addition subtraction lets try adding 6 ten 7 ten binary subtracting 6 ten 7 ten binary 0000 0000 0000 0000 0000 0000 0000 0111 two 7ten 0000 0000 0000 0000 0000 0000 0000 0110 two 6ten 0000 0000 0000 0000 0000 0000 0000 1101 two 13ten e 4 bits right action figure 31 shows sums carr e carries shown parentheses arrows showing passed subtracting 6 ten 7 ten done directly subtraction additions tricky pal 10 top ten courses athletes football factory david letterman et al book top ten lists 1990exampleanswer 32 addition subtraction 179 0000 0000 0000 0000 0000 0000 0000 0111 two 7ten 0000 0000 0000 0000 0000 0000 0000 0110 two 6ten 0000 0000 0000 0000 0000 0000 0000 0001 two 1tenor via addition using twos complement representation 6 0000 0000 0000 0000 0000 0000 0000 0111 two 7ten 1111 1111 1111 1111 1111 1111 1111 1010 two 6ten 0000 0000 0000 0000 0000 0000 0000 0001 two 1ten000 0000 0 0010 0 1111 1 1101 1 00carries 1 0 10 figure 31 binary addition showing carries right left e rightmost bit adds 1 0 resulting sum bit 1 carry bit 0 hence operation second digit right 0 1 generates 0 sum bit carry e third digit sum 1 1 1 resulting carry 1 sum bit e fourth bit 1 0 0 yielding 1 sum carry recall ov ow occurs result operation represented available hardware case 32bit word ow occur addition adding operands wit erent signs ow occur e reason sum must larger one operands example 10 4 6 since opera 32 bits sum larger operand sum mu 32 bits well erefore ow occur adding positive negative operands ere similar restrictions occurrence ow subtract opposite principle signs operands ow occur see remember c c subtract negating second operand add erefore subtract operands sign end adding operands erent signs prior paragraph know ow occur case either knowing ow occur addition subtraction well good detect occur clearly adding subtracting two 32bit numbers yield result needs 33 bits fully expressed e lack 33rd bit means ow occurs sign bit set value result instead proper sign result since need one extra bit sign bit wrong hence ow occurs adding two positive numbers sum negative vice vers spurious sum means carry occurred sign bit ow occurs subtraction subtract negative number positive number get negative result subtract positive number negative number get positive result ridiculous result means borrow occurred sign bit figure 32 shows combination operations operands results indicate ow 180 chapter 3 arithmetic computers seen detect ow twos complement numbers computer ow unsigned integers unsigned integers commonly used memory addresses ows ignored e computer designer must therefore provide way ignore ow cases recognize e mips solution two kinds arithmetic instructions recognize two choices add add add immediate addi subtract sub cause exceptions ow add unsigned addu add immediate unsigned addiu subtract unsigned subu cause exceptions ow c ignores ows mips c compilers always generate unsigned versions arithmetic instructions addu addiu subu matter type variab e mips fortran compilers however pick appropriate arithmetic instructions depending type operands appendix b describes hardware performs addition subtraction called arithmetic logic unit alu elaboration constant source confusion addiu name happens eld u stands unsigned means addition cause ow exception however eld sign extended 32 bits like addi slti sltiu thus eld signed even operation unsigned e computer designer must decide ho w handle arithmetic ows although languages like c java ignore integer ow languages like ada fortran require program ed e programmer programming environment must decide ow occurs mips detects ow exception also called interrupt many computers exception interrupt essentially unscheduled procedure call e address instruction owed saved register computer jumps pr ned address invoke appropriate routine exceptio e interrupted address saved situations program continue er corrective code executed section 49 covers exceptions arithmetic logic unit alu hardware performs addition subtraction usually logical operations hardware software interfaceexception also called interrupt many computers unscheduled event disrupts program execution used detect ow figure 32 overﬂ ow conditions addition subtraction operationoperand aoperand b result indicating overßowa b 0 0 0a b 0 0 0a œ b 0 0 0 œ b 0 0 0 32 addition subtraction 181more detail chapter 5 describes situations exceptions interrupts occur mips includes register called exception program counter epc contain address instruction caused exceptio e instruction move system control mfc0 used copy epc generalpurpose register mips ware option returning ending instruction via jump register instruction summary major point section independent representation th nite word size computers means arithmetic operations create results large xed word size easy detect ow unsigned numbers although almost always ignored programs dont want detect ow address arithmetic common use natural numbers twos complement presents greater challenge yet ware systems require detection ow today computers way detect programming languages allow twos complement integer arithmetic variables declared byte half whereas mips integer arithmetic operations full words recall chapter 2 mips data transfer operations bytes halfwords mips instructions generated byte halfword arithmetic operations 1 load lbu lhu arithmetic add sub mult div store using sb sh2 load lb lh arithmetic add sub mult div store using sb sh3 load lb lh arithmetic add sub mult div using mask result 8 16 bits er operation store using sb shelaboration one feature generally found generalpurpose microprocessors saturating operations saturation means calculation ows result set largest positive number negative number rather modulo calculation twos complement arithmetic saturation likely want media operations example volume knob radio set would frustrating turned volume would get continuously louder immediately soft knob saturation would stop highest volume matter far turned multimedia extensions standard instruction sets often offer saturating arithmetic elaboration mips trap ow unlike many computers conditional branch test ow sequence mips instructions discover interrupt exception comes outside processor architectures use term interrupt exceptions check 182 chapter 3 arithmetic computers ow signed addition sequence following see elaboration page 89 chapter 2 description xor instruction addu t0 t1 t2 t0 sum dont trapxor t3 t1 t2 check signs differ slt t3 t3 zero t3 1 signs differ overflow xor t3 t0 t1 signs sign sum match t3 negative sum sign different slt t3 t3 zero t3 1 sum sign different unsigned addition t0 t1 t2 test addu t0 t1 t2 t0 sum t3 t1 zero t3 t1 2s comp 1 232 t1 1sltu t3 t3 t2 232 t1 1 t2 232 1 t1 t2bne t3zerooverflow if2321t1t2 goto overflowelaboration preceding text said copy epc register via mfc0 return interrupted code via jump register directive leads rst transfer epc register use jump register jump register return interrupted code restore original values registers either restore old register rst thereby destroying return address epc placed register use jump register restore registers one return address jumpmeaning exception would result changing one register time program execution neither option satisfactory rescue hardware dilemma mips programmers agreed reserve registers k0 k1 operating system registers restored exceptions mips compilers avoid using register assembler use temporary register see hardware software interface section 210 compilers also abstain using registers k0 k1 make available operating system exception routines place return address one registers use jump register restore instruction address elaboration speed addition increased determining carry highorder bits sooner variety schemes anticipate carry worstcase scenario function log 2 number bits adder anticipatory signals faster go fewer gates sequence takes many gates anticipate proper carry popular carry lookahead section b6 appendix b describes 33 multiplication 183 33 multiplicationnow completed explanation addition subtraction ready build vexing operation multiplication first lets review multiplication decimal numbers longhand remind steps multiplication names operands reasons become clear shortly limit decimal example using digits 0 1 multiplying 1000 ten 1001 ten multiplicand 1000tenmultiplier x 1001ten1000000000001000product 1001000ten e rst operand called multiplicand second multiplier e nal result called product may recall algorithm learned grammar school take digits multiplier one time right multiplying multiplicand single digit multiplier ing intermediate product one digit th earlier intermediate products e rst observation number digits product considerably larger number either multiplicand multiplier fact ignore sign bits length multiplication nbit multiplicand mbit multiplier product n bits long n bits required represent possible products hence like add multiply must cope ow frequently want 32bit product result multiplying two 32bit numbers example restricted decimal digits 0 1 two choices step multiplication simple 1 place copy multiplicand 1 multiplicand proper place multiplier digit 1 2 place 0 0 multiplicand proper place digit 0 although decimal example happens use 0 1 multiplication binary numbers must always use 0 1 thus always ers two choices reviewed basics multiplication traditional next step provide highly optimized multiply hardware break tradition belief gain better understanding seeing evolution multiply hardware algorithm multiple generations lets assume multiplying positive numbers multiplication vexation division ba e rule three doth puzzle practice drives mad anonymous elizabethan manuscript 1570 184 chapter 3 arithmetic computers sequential version multiplication algorithm hardware design mimics algorithm learned grammar school figure 33 shows hardware drawn hardware dat ows top bottom resemble closely paperandpencil method lets assume multiplier 32bit multiplier register 64 bit product register initialized 0 paperandpencil example clear need move multiplican one digit step may added intermediate products 32 steps 32bit multiplicand would move 32 bits th hence need 64bit multiplicand register initialized 32bit multiplicand right half zero th register th ed 1 bit step align multiplicand sum accumulated 64bit product register figure 34 shows three basic steps needed bi e le cant bit multiplier multiplier0 determines whether multiplicand added product register e step 2 th ect moving intermediate operands th multiplying paper pencil e right step 3 gives us next bit multiplier examine following iteration ese three steps repeated 32 times obtain product step took clock cycle algorithm would require almost 100 clock cycles multiply two 32bit number e relative importance arithmetic operations like multiply varies program addition subtraction may anywhere 5 100 times popular multiply accordingly many applications multiply take multiple clock cycles withou cantly ecting performance yet amdahls law see section 110 reminds us even moderate frequency slow operation limit performance multiplicandshift left64 bits64bit aluproductwrite 64 bitscontrol testmultipliershift right 32 bitsfigure 33 first version multiplication hardware e multiplicand register alu product register 64 bits wide multiplier register containing 32 bits appendix b describes alu e 32bit multiplicand starts right half multiplicand register ed 1 bit step e multip ed opposite direction step e algorithm starts product initialized 0 control decides multiplicand multiplier registers write new values product register 33 multiplication 185 algorithm hardware easily r ned take 1 clock cycle per step e speedup comes performing operations parallel multiplier multiplicand ar ed multiplicand added product multiplier bi e hardware ensure tests right bit multiplier gets pr ed version multiplicand e hardware usually optimized halve width adder registers noticing unused portions registers adders figure 35 shows revised hardware 32nd repetition1a add multiplicand product place result product registermultiplier0 01 test multiplier0start multiplier0 12 shift multiplicand register left 1 bit 3 shift multiplier register right 1 bit 32 repetitions yes 32 repetitions donefigure 34 ﬁ rst multiplication algorithm using hardware shown figure 33 le cant bit multiplier 1 add multiplicand product go next step multiplican multiplier right next two st ese three steps repeated 32 times 186 chapter 3 arithmetic computers replacing arithmetic b also occur multiplying constants compilers replace multiplies short constants series adds one bit th represents number twice large bas ing bi e ect multiplying power 2 mentioned chapter 2 almost every compiler perform strength reduction optimization substitutin multiply power 2 multiply algorithmusing 4bit numbers save space multiply 2 ten 3ten 0010 two 0011two figure 36 shows value register steps labeled according figure 34 th nal value 0000 0110 two 6 ten color used indicate register values change step bit circled one examined determine operation next step hardware software interfaceexampleanswermultiplicand32 bits32bit aluproductwrite 64 bitscontroltestshift right figure 35 reﬁ ned version multiplication hardware compare th rst version figure 33 e multiplicand register alu multiplier register 32 bits wide product regist 64 bits produc ed righ e separate multiplier register also disappeared e multiplier placed instead right half product register ese changes highlighted color e product register really 65 bits hold carry adder shown 64 bits highlight evolution figure 33 33 multiplication 187signed multiplicationso far dealt positive number e easiest way understand deal signed numbers rst convert multiplier multiplicand positive numbers remember original sign e algorithms run 31 iterations leaving signs calculation learned grammar school need negate product original signs disagree turns last algorithm work signed numbers provided remember dealing numbers hav nite digits representing 32 bits hence th ing steps would need extend sign product signed numbers algorithm completes lower word would 32bit product faster multiplication moores law provided much resources hardware designers build much faster multiplication hardware whether multiplicand added known beginning multiplication looking 32 multiplier bits faster multiplications possible essentially providing one 32bit adder bit multiplier one input multiplicand anded multiplier bit output prior adder straightforward approach would connect outputs adders right inputs adders th making stack adders 32 high alternative way organize 32 additions parallel tree figure 37 shows instead waiting 32 add times wait log 2 32 32bit add timesiterationstepmultipliermultiplicandproduct 0 initial values 00110000 0010 0000 000011a 1 prod prod mcand00110000 0010 0000 00102 shift left multiplicand 00110000 01000000 00103 shift right multiplier00010000 01000000 001021a 1 prod prod mcand00010000 0100 0000 01102 shift left multiplicand 00010000 10000000 01103 shift right multiplier00000000 10000000 011031 0 operation00000000 1000 0000 01102 shift left multiplicand0000 0001 00000000 01103 shift right multiplier00000001 00000000 011041 0 operation00000001 0000 0000 01102 shift left multiplicand0000 0010 00000000 01103 shift right multiplier00000010 00000000 0110figure 36 multiply example using algorithm figure 34 e bit examined determine next step circled color 188 chapter 3 arithmetic computers fact multiply go even faster tha add times use carry save adders see section b6 appendix b easy pipeline design able support many multiplies simultaneously see chapter 4 multiply mipsmips provides separate pair 32bit registers contain 64bit product called hi lo produce properly signed unsigned product mips two instructions multiply mult multiply unsigned multu fetch integer 32bit product programmer uses move lo mflo e mips assembler generates pseudoinstruction multiply sp es three generalpurpose registers generating mflo mfhi instructions place product registers summary multiplication hardware simpl add derived paperand pencil method learned grammar school compilers even us instructions multiplications powers 2 much hardware adds parallel much faster mips multiply instructions ignore ow ware check see product big 32 bi ere ow hi 0 multu replicated sign lo mult e instruction move hi mfhi used transfer hi generalpurpose register test ow hardware software interfaceproduct1 product0 product63product62 product4716 1 bit1 bit1 bit1 bit 32 bits32 bits32 bits32 bits32 bits32 bits32 bitsmplier31 mcandmplier30 mcandmplier29 mcandmplier28 mcandmplier3 mcandmplier2 mcandmplier1 mcandmplier0 mcand figure 37 fast multiplication hardware rather use single 32bit adder 31 times hardware unrolls loop use 31 adders organizes minimize delay 34 division 189 34 division e reciprocal operation multiply divide operation even less frequent even quirky even ers opportunity perform mathematically invalid operation dividing 0 lets start example long division using decimal numbers recall names operands grammar school division algorithm reasons similar previous section limit decimal digits 0 1 e example dividing 1001010 ten 1000 ten 1001tenquotient divisor 1000ten1001010tendividend100010101 1010100010tenremainderdivides two operands called dividend divisor result called quotient accompanied second result called remainder another way express relationship components dividend quotient divisor remainder remainder smaller divisor infrequently programs use divide instruction get remainder ignoring quotient e basic grammar school division algorithm tries see big number subtracted creating digit quotient attempt carefully selected decimal example uses numbers 0 1 easy gure many times divisor goes portion dividend either 0 times 1 time binary numbers contain 0 1 binary division restricted two choices thereby simplifying binary division lets assume dividend divisor positive hence quotient remainder nonnegative e division operands results 32bit values ignore sign division algorithm hardware figure 38 shows hardware mimic grammar school algorithm start 32bit quotient register set 0 iteration algorithm needs move divisor right one digit start divisor placed th half 64bit divisor register right 1 bit step align dividend e remainder register initialized dividend divide et impera latin divide rule ancient political maxim cited machiavelli 1532 dividend number divided divisor number dividend divided quotient e primary result division number multiplied divisor added remainder produces dividend remainder e secondary result division number added product quotient divisor produces dividend 190 chapter 3 arithmetic computers figure 39 shows three steps th rst division algorithm unlike human computer isnt smart enough know advance whether divisor smaller dividend mu rst subtract divisor step 1 remember performed comparison set less instruction result positive divisor smaller equal dividend generate 1 quotient step 2a result negative next step restore original value adding divisor back remainder generate 0 quotient st e diviso ed right iterate aga e remainder quotient found namesake registers er iterations complete divide algorithmusing 4bit version algorithm save pages lets try dividing 7 ten 2 ten 0000 0111 two 0010 two figure 310 shows value register steps quotient 3 ten remainder 1 ten notice test step 2 whether remainder positive negative simply tests whether sign bit remainder register 0 e surprising requirement algorithm takes n 1 steps get proper quotient remainder exampleanswerdivisorshift right 64 bits64bit aluremainderwrite 64 bitscontroltestquotientshift left32 bitsfigure 38 first version division hardware e divisor register alu remainder register 64 bits wide quotient register 32 bi e 32bit divisor starts half divisor register ed right 1 bit iteratio e remainder initialized dividend control decides divisor quotient registers write new value remainder register 34 division 19133rd repetition2a shift quotient register left setting new rightmost bit 1 remainder 0remainder 0test remainder start 3 shift divisor register right 1 bit 33 repetitions yes 33 repetitions done1 subtract divisor register remainder register place result remainder register2b restore original value adding divisor register remainderregister placing sum theremainder register also shift quotient register left setting thenew least significant bit 0 figure 39 division algorithm using hardware figure 38 remainder positive divisor go dividend step 2a generates 1 quotient negative remainder er step 1 means divisor go dividend step 2b generates 0 quotient adds divisor remainder thereby reversing subtraction st e nal step 3 aligns divisor properly relative dividend next iteratio ese steps repeated 33 times algorithm hardware r ned faster cheaper e speed comes ing operands quotient simultaneously subtractio nement halves width adder registers noticing unused portions registers adders figure 311 shows revised hardware 192 chapter 3 arithmetic computers signed divisionso far ignored signed numbers divisio e simplest solution remember signs divisor dividend negate quotient signs disagree iterationstepquotientdivisorremainder 0 initial values00000010 0000 0000 011111 rem rem œ div 00000010 0000 1110 01112b rem 0 div sll q q0 0 00000010 00000000 01113 shift div right 00000001 00000000 011121 rem rem œ div00000001 0000 1111 01112b rem 0 div sll q q0 0 00000001 00000000 01113 shift div right 00000000 10000000 011131 rem rem œ div00000000 1000 1111 11112b rem 0 div sll q q0 0 00000000 10000000 01113 shift div right 00000000 01000000 011141 rem rem œ div00000000 0100 0000 00112a rem 0 sll q q0 1 00010000 01000000 00113 shift div right 00010000 00100000 001151 rem rem œ div00010000 0010 0000 00012a rem 0 sll q q0 1 00110000 00100000 00013 shift div right 00110000 00010000 0001figure 310 division example using algorithm figure 39 e bit examined determine next step circled color divisor32 bits32bit aluremainderwrite 64 bitscontroltestshift leftshift right figure 311 improved version division hardware e divisor register alu quotient register 32 bits wide remainder regist 64 bits compared figure 38 alu divisor registers halved rema ed version also combines quotient register right half remainder register figure 35 remainder register really 65 bits make sure carry adder lost 34 division 193elaboration one complication signed division must also set sign remainder remember following equation must always hold dividend quotient divisor remainderto understand set sign remainder lets look example dividing combinations 7ten 2ten rst case easy 7 2 quotient 3 remainder 1checking results7 3 2 1 61if change sign dividend quotient must change well 7 2 quotient 3rewriting basic formula calculate remainder remainder dividend quotient divisor 7 3x 2 7 6 1so7 2 quotient 3 remainder 1checking results again7 3 2 1 61the reason answer isnt quotient 4 remainder 1 would also formula absolute value quotient would change depending sign dividend divisor clearly x x yprogramming would even greater challenge anomalous behavior avoided following rule dividend remainder must signs matter signs divisor quotientwe calculate combinations following rule 7 2 quotient 3 remainder 17 2 quotient 3 remainder 1 194 chapter 3 arithmetic computers thus correctly signed division algorithm negates quotient signs operands opposite makes sign nonzero remainder match dividend faster division moores law applies division hardware well multiplication would like able speed division throwing hardware used many adders speed multiply trick divide e reason need know sign th erence perform next step algorithm whereas multiply could calculate 32 partial products immediately ere techniques produce one bit quotient per step e srt division technique tries predict several quotient bits per step using table lookup based upper bits dividend remainder relies subsequent steps correct wrong predictions typical value today 4 bi e key guessing value subtract binary division single choice ese algorithms use 6 bits remainder 4 bits divisor index table determines guess step e accuracy fast method depends proper values lookup table e fallacy page 231 section 39 shows happen table incorrect divide mipsyou may already observed sequential hardware used multiply divide figures 35 311 e requirement 64bit register ca right 32bit alu adds subtracts hence mips uses 32bit hi 32bit lo registers multiply divide might expect algorithm hi contains remainder lo contains quotient er divide instruction completes handle signed integers unsigned integers mips two instructions divide div divide unsigned divu e mips assembler allows divide instructions specify three registers generating mflo mfhi instructions place desired result generalpurpose register summary e common hardware support multiply divide allows mips provide single pair 32bit registers used multiply divide accelerate division predicting multliple quotient bits correcting mispredictions later figure 312 summarizes enhancements mips architecture last two sections 34 division 195mips assembly languagecategory instruction examplemeaningcommentsarithmeticadd add s1s2s3s1 s2 s3three operands overow detected subtractsub s1s2s3s1 s2 œ s3three operands overow detected add immediateaddi s1s2100s1 s2 100 constant overow detected add unsignedaddu s1s2s3s1 s2 s3three operands overow undetected subtract unsignedsubu s1s2s3s1 s2 œ s3three operands overow undetected add immediate unsignedaddiu s1s2100s1 s2 100 constant overow undetected move coprocessor register mfc0 s1epcs1 epccopy exception pc special regs multiply mult s2s3hi lo s2 s364bit signed product hi lo multiply unsignedmultu s2s3hi lo s2 s364bit unsigned product hi lo divide div s2s3lo s2 s3 hi s2 mod s3lo quotient hi remainder divide unsigneddivu s2s3lo s2 s3 hi s2 mod s3unsigned quotient remaindermove hi mfhi s1s1 hiused get copy hi move lo mßo s1s1 loused get copy lo data transferload wordlw s120s2s1 memory s2 20word memory register store wordsw s120s2memory s2 20 s1word register memory load half unsignedlhu s120s2s1 memory s2 20halfword memory register store halfsh s120s2memory s2 20 s1halfword register memory load byte unsigned lbu s120s2s1 memory s2 20byte memory register store byte sb s120s2memory s2 20 s1byte register memory load linked word s120s2s1 memory s2 20load word 1st half atomic swap store conditional wordsc s120s2memory s220s1s10 1store word 2nd half atomic swap load upper immediatelui s1100s1 100 216loads constant upper 16 bitslogicaland s1s2s3s1 s2 s3 three reg operands bitbybit oror s1s2s3s1 s2 s3 three reg operands bitbybit nornor s1s2s3s1 s2 s3 three reg operands bitbybit immediateandi s1s2100s1 s2 100 bitbybit constant immediateori s1s2100s1 s2 100 bitbybit constant shift left logicalsll s1s210s1 s2 10shift left constant shift right logicalsrl s1s210s1 s2 10shift right constant condi tional branchbranch equalbeq s1s225if s1 s2 go pc 4 100equal test pcrelative branchbranch equalbne s1s225if s1 s2 go pc 4 100not equal test pcrelative set less thanslt s1s2s3if s2 s3 s1 1 else s1 0compare less twos complementset less immediateslti s1s2100if s2 100 s1 1 else s10compare constant twos complementset less unsignedsltu s1s2s3if s2 s3 s1 1 else s10compare less natural numbers set less immediate unsignedsltiu s1s2100if s2 100 s1 1 else s1 0compare constant natural numbers uncondi tional jumpjumpj 2500go 10000jump target addressjump registerjr rago rafor switch procedure return jump linkjal 2500ra pc 4 go 10000for procedure call figure 312 mips core architecture e memory registers mips architecture included space reasons section added hi lo registers support multiply divide mips machine language listed mips reference dat card front book 196 chapter 3 arithmetic computers mips divide instructions ignore ow ware must determine whether quotient large addition ow division also result improper calculation division 0 computers distinguish two anomalous events mips ware must check divisor discover division 0 well ow elaboration even faster algorithm immediately add divisor back remainder negative simply adds dividend shifted remainder following step since r 2 r 2 2 r 2 nonrestoring division algorithm takes 1 clock cycle per step explored exercises algorithm called restoring division third algorithm doesnt save result subtract negative called nonperforming division algorithm averages onethird fewer arithmetic operations 35 floating point going beyond signed unsigned inte gers programming languages support numbers fractions called reals mathematics examples reals 314159265 ten pi 271828 ten e0000000001ten 10 ten 109 seconds nanosecond 3155760000ten 315576 ten 109 seconds typical century notice last case number didnt represent small fraction bigger could represent 32bit signed integer e alternative notation last two numbers called scienti c notation single digit th decimal point number scien c notation leading 0s called normalized number usual way write example 10 ten 109 normalized scien c notation 01 ten 108 100ten 1010 show decimal numbers scien c notation also show binary numbers scien c notation 10two 21to keep binary number normalized form need base increase decrease exactly number bits number must b ed one nonzero digit th decimal point base 2 fu lls need since base 10 also need new name decimal point binary point nehardware software interfacespeed gets nowhere youre headed wrong way american proverb scienti c notation notation renders numbers single digit th decimal point normalized number oatingpoint notation leading 0s 35 floating point 197computer arithmetic supports numbers called oating point represents numbers binary point xed integer e programming language c uses name oat numbers scien c notation numbers represented single nonzero digit binary point binary form 1xxxxxxxxxtwo 2yyyyalthough computer represents exponent base 2 well rest number simplify notation show exponent decimal standard scien c notation reals normalized form ers three advantages simp es exchange data incl oatingpoint numbers simp es th oatingpoint arithmetic algorithms know numbers always form increases accuracy numbers stored word since unnecessary leading 0s replaced real digits right binary point floatingpoint representation designer oatingpoint representation mu nd compromise size fraction size exponent becaus xed word size means must take bit one add bit tradeo precision range increasing size fraction enhances precision fraction increasing size exponent increases range numbers represented design guideline chapter 2 reminds us good design demands good compromise floatingpoint numbers usually multiple size word e representation oatingpoint number shown sign th oatingpoint number 1 meaning negative exponent value 8bit exponen eld including sign exponent fraction 23bit number recall chapter 2 representation sign magnitude since sign separate bit rest number 313029282726252423222120191817161514131211109876543210 sexponentfraction 1 bit 8 bits23 bitsin general oatingpoint numbers form 1s f 2ef involves value fractio eld e involves value exponent eld exact relationship thes elds spelled soon shortly see mips something slightly sophisticated oating point computer arithmetic represents numbers binary point xed fraction e value generally 0 1 placed fraction eld e fraction also called mantissa exponent numerical representation system oatingpoint arithmetic value placed exponent eld 198 chapter 3 arithmetic computers ese chosen sizes exponent fraction give mips computer arithmetic extraordinary range fractions almost small 20 ten 1038 numbers almost large 20 ten 1038 represented computer alas extraordinary ers fro nite still possible numbers large us ow interrupts occ oatingpoint arithmetic well integer arithmetic notice ow means exponent large represented exponen eldfloating point ers new kind exceptional event well programmers want know calculated number large represented want know nonzero fraction calculating become small represented either event could result program giving incorrect answers distinguish ow call event und ow situation occurs negative exponent large exponen eldone way reduce chances ow ow er another format larger exponent c number called double operations doubles called double precision oatingpoint arithmetic single precision oating point name earlier format e representation double precisio oatingpoint number takes two mips words shown still sign number exponent value 11bit exponen eld fraction 52bit number fractio eld ow oating point situation positive exponent becomes large exponen eldund ow oating point situation negative exponent becomes large exponent elddouble precision oatingpoint value represented two 32bit words single precision oatingpoint value represented single 32 bit word mips double precision allows numbers almost small 20 ten 10308 almost large 20 ten 10308 although double precision increase exponent range primary advantage greater precision much larger fraction ese formats go beyo ey part oatingpoint standard found virtually every computer invent standard greatly improved ease portin oatingpoint programs quality computer arithmetic pack even bits th cand ieee 754 makes leading 1bit normalized binary numbers implicit hence number actually 24 bits long single precision implied 1 23bit fraction 53 bits long double precision 1 52 precise use term signi cand represent 24 53bit number 1 plus fraction fraction mean 23 52bit number since 0 leading 1 given reserved exponent value 0 hardware wont attach leading 1 313029282726252423222120191817161514131211109876543210 fractionexponents1 bit11 bits20 bitsfraction continued32 bits 35 floating point 199 us 00 00 two represents 0 representation rest numbers uses form hidden 1 added 1s 1 fraction 2ewhere bits fraction represent number 0 1 e sp es value exponen eld given detail shortly number bits fraction right s1 s2 s3 value 1s 1 s1 21 s2 22 s3 23 s4 24 2efigure 313 shows encodings oatingpoint numbers features ieee 754 special symbols represent unusual events example instead interrupting divide 0 ware set result bit pattern representing r largest exponent reserved special symbols programmer prints results program print nity symbol mathematically trained purpose nity form topological closure reals ieee 754 even symbol result invalid operations 00 subtractin nity fro nity symbol nan number e purpose nans allow programmers postpone tests decisions later time program convenient e designers ieee 754 also want oatingpoint representation could easily processed integer comparisons especially sortin desire sign th cant bit allowing quick test less greater equal 0 little complicated simple integer sort since notation essentially sign magnitude rather twos complement placing exponent th cand also simp es sorting oatingpoint numbers using integer comparison instructions since numbers bigger exponents look larger numbers smaller exponents long exponents sign single precision double precision object represented exponentfractionexponentfraction 00000 0 nonzero0 nonzero denormalized number 1œ254anything1œ2046anything oatingpoint number 255020470 innity255nonzero2047nonzero nan numberfigure 313 eee 754 encoding ﬂ oatingpoint numbers separate sign bit determines sign denormalized numbers described elaboration pag information also found column 4 mips reference data card front book 200 chapter 3 arithmetic computers negative exponents pose challenge simp ed sorting use twos complement notation negative exponents 1 cant bit exponen eld negative exponent look like big number example 10 two 21 would represented 313029282726252423222120191817161514131211109876543210 01111111100000000000000000000 remember leading 1 implicit th cand e value 10 two 21 would look like smaller binary number 313029282726252423222120191817161514131211109876543210 00000000100000000000000000000 e desirable notation must therefore represent negative exponent 00 00two positive 11 11 two convention called biased notation bias number subtracted normal unsigned representation determine real value ieee 754 uses bias 127 single precision exponent 1 represented bit pattern value 1 127ten 126 ten 0111 1110two 1 represented 1 127 128 ten 1000 0000two e exponent bias double precision 1023 biased exponent means value represented oatingpoint number really 1s 1 fraction 2exponent bias e range single precision numbers small 100000000000000000000000two 2126to large 111111111111111111111111two 2127lets demonstrate 35 floating point 201floatingpoint representation show ieee 754 binary representation number 075ten single double precision e number 075ten also 34ten 322ten also represented binary fraction 11two 22ten 011two scien c notation value 011two 20and normalized scien c notation 11two 21 e general representation single precision number 1s 1 fraction 2exponent 127subtracting bias 127 exponent 11two 21 yields 11 1 1000 0000 0000 0000 0000 000two 2126127 e single precision binary representation 075ten 313029282726252423222120191817161514131211109876543210 10111111010000000000000000000000 1 bit 8 bits23 bits e double precision representation exampleanswer11 1 1000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000two 210221023313029282726252423222120191817161514131211109876543210 10111111111010000000000000000000 1 bit 11 bits20 bits00000000000000000000000000000000 32 bits 202 chapter 3 arithmetic computers lets try going direction converting binary decimal floating point decimal number represented single precisio oat example313029282726252423222120191817161514131211109876543210 11000000101000000000000000000 e sign bit 1 exponen eld contains 129 fractio eld contains 1 22 14 025 using basic equation 1s 1 fraction 2exponent bias 11 1 025 2129127 1 125 22 125 4 50in next subsections give algorithms fo oatingpoint addition multiplication core use corresponding integer operations th cands extra bookkeeping necessary handle exponents normalize result w rst give intuitive derivation algorithms decimal give detailed binary version th gures elaboration following ieee guidelines ieee 754 committee reformed 20 years standard see changes made revised standard ieee 7542008 includes nearly ieee 7541985 adds 16bit format half precision 128bit format quadruple precision hardware yet built supports quadruple precision surely come revised standard oating point arithmetic ibm mainframes implemented elaboration attempt increase range without remo cand computers ieee 754 standard used base 2 example ibm 360 370 mainframe computers use base 16 since changing ibm exponent b cand 4 bits normalized base 16 numbers 3 leading bits 0s hence hexadecimal digits mean 3 bits must cand leads surprising problems accuracy oatingpoint arithmetic ibm mainframes support ieee 754 well hex format answer 35 floating point 203floatingpoint addition lets add numbers scien c notation hand illustrate problems oatingpoint addition 9999 ten 101 1610ten 101 assume store four decimal digits th cand two decimal digits exponent step 1 able add numbers properly must align decimal point number smaller exponent hence need form smaller number 1610 ten 101 matches larger exponent obtain observing multiple representations unnor oatingpoint number scien c notation 1610ten 101 01610ten 100 001610ten 101 e number right version desire since exponent matches exponent larger number 9999 ten 101 us rst st th cand smaller number right corrected exponent matches larger number represent four decimal digits er ing number really 0016 101 step 2 next comes addition th cands 9999ten 0016ten 10015ten e sum 10015 ten 101 step 3 sum normalized scien c notation need adjust 10015ten 101 10015ten 102 us er addition may sum put normalized form adjusting exponent appropriately example sho ing right one number positive negative would possible sum many leading 0s requirin whenever exponent increased decreased must check ow owthat must make sure exponent ts eld step 4 since assumed th cand four digits long excluding sign must round number grammar school algorithm rules truncate number digit right desired point 0 4 add 1 digit number right 5 e number 10015ten 102 204 chapter 3 arithmetic computers rounded four digits th cand 1002ten 102 since fourth digit right decimal point 5 9 notice bad luck rounding adding 1 string 9s sum may longer normalized would need perform step 3 figure 314 shows algorithm binar oatingpoint addition follows decimal example steps 1 2 similar example discussed adjust th cand number smaller exponent add tw cands step 3 normalizes results forcing check ow ow e test ow ow step 3 depends precision operands recall pattern 0 bits exponent reserved used th oatingpoint representation zero moreover pattern 1 bits exponent reserved indicating values situations outside scope normal oatingpoint numbers see elaboration page 222 example remember single precision maximum exponent 127 minimum exponent 126binary floatingpoint addition try adding numbers 05 ten 04375ten binary using algorithm figure 314 let rst look binary version two numbers normalized scien c notation assuming keep 4 bits precision 05ten 12ten 121ten 01two 01two 20 1000two 2104375ten 716ten 724ten 00111two 00111two 20 1110two 22now follow algorithm step 1 e cand number lesser exponent 111two 22 ed right exponent matches larger number 1110two 22 0111two 21 step 2 add th cands 1000two 21 0111two 21 0001two 21exampleanswer 35 floating point 205still normalized 4 round significand appropriate number bits yes overflow underflow start noyes done1 compare exponents two numbers shift smaller number right exponent would match larger exponent 2 add significands 3 normalize sum either shifting right incrementing exponent shifting left decrementing exponent noexceptionfigure 314 floatingpoint addition e normal path execute steps 3 4 rounding causes sum unnormalized must repeat step 3 206 chapter 3 arithmetic computers step 3 normalize sum checking ow ow 0001two 21 0010two 22 0100two 23 1000two 24 since 127 4 126 ow ow e biased exponent would 4 127 123 1 254 smallest largest unreserved biased exponents step 4 round sum 1000two 24 e sum alread ts exactly 4 bits change bits due rounding sum 1000two 24 00001000two 00001two 124ten 116ten 00625ten sum would expect adding 05 ten 04375ten many computers dedicate hardware r oatingpoint operations fast possible figure 315 sketches basic organization hardware fo oatingpoint addition floatingpoint multiplication expla oatingpoint addition lets tr oatingpoint multiplication start multiplying decimal numbers scien c notation hand 1110 ten 1010 9200ten 105 assume store four digits th cand two digits exponent step 1 unlike addition calculate exponent product simply adding exponents operands together new exponent 10 5 5 lets biased exponents well make sure obtain result 10 127 137 5 127 122 new exponent 137 122 259 result large 8bit exponen eld something e problem bias adding biases well exponents new exponent 10 127 5 127 5 2 127 259 accordingly get correct biased sum add biased numbers must subtract bias sum 35 floating point 207compareexponents small aluexponentdifference controlexponentsignfraction big aluexponentsignfraction 010101shift right 0101increment ordecrementshift left right rounding hardware exponentsignfraction shift smaller number right addnormalize roundfigure 315 block diagram arithmetic unit dedicated ﬂ oatingpoint addition e steps figure 314 correspond block top bottom first exponent one operand subtracted using small alu determine larger muc erence controls three multiplexors fro right select larger exponent th cand smaller number th cand larger number ca ed right th cands added together using big alu e normalization step th th right increments decrements exponent rounding creates th nal result may require normalizing produce actu nal result 208 chapter 3 arithmetic computers new exponent 137 122 127 259 127 132 5 127 5 indeed exponent calculated initially step 2 next comes multiplication th cands 1110ten 9200ten 0000 0000 2220 9990 10212000ten ere three digits right decimal point operand decimal point placed six digits right produc cand 10212000ten assuming keep three digits right decimal point product 10212 105 step 3 product unnormalized need normalize 10212ten 105 10212ten 106 us er multiplication product b ed right one digit put normalized form adding 1 exponent point check ow ow ow may occur operands smallthat large negative exponents step 4 assumed th cand four digits long excluding sign must round number e number 10212ten 106 rounded four digits th cand 1021ten 106 step 5 e sign product depends signs original operands sign positive otherwise negative hence product 1021ten 106 e sign sum addition algorithm determined addition th cands multiplication sign product determined signs operands 35 floating point 2095 set sign product positive signs original operands differ make sign negative still normalized 4 round significand appropriate number bits yes overflow underflow start noyes done1 add biased exponents two numbers subtracting bias sum get new biased exponent 2 multiply significands 3 normalize product necessary shifting right incrementing exponent noexceptionfigure 316 floatingpoint multiplication e normal path execute steps 3 4 rounding causes sum unnormalized must repeat step 3 210 chapter 3 arithmetic computers figure 316 shows multiplication binar oatingpoint numbers quite similar steps completed start calculating new exponent product adding biased exponents sure subtract one bias get proper result next multiplication cands followed optional normalization step e size exponent checked ow ow product rounded rounding leads normalization check exponent size finally set sign bit 1 signs operands wer erent negative product 0 positive product binary floatingpoint multiplication lets try multiplying numbers 05 ten 04375ten using steps figure 316 binary task multiplying 1000 two 21 1110two 22 step 1 adding exponents without bias 1 2 3 using biased representation 1 127 2 127 127 1 2 127 127 127 3 127 124 step 2 multiplying th cands 1000two 1110two 0000 1000 1000 1000 1110000two e product 1110000 two 23 need keep 4 bits 1110two 23 step 3 check product make sure normalized check exponent ow ow e product already normalized since 127 3 126 ow ow using biased representation 254 124 1 exponen ts step 4 rounding product makes change 1110two 23exampleanswer 35 floating point 211 step 5 since signs original opera er make sign product negative hence product 1110two 23 converting decimal check results 1110two 23 0001110two 000111two 725ten 732ten 021875ten e product 05 ten 04375ten indeed 021875ten floatingpoint instructions mips mips supports ieee 754 single precision double precision formats instructions floatingpoint addition single adds addition double addd floatingpoint subtraction single subs subtraction double subd floatingpoint multiplication single muls multiplication double muld floatingpoint division single divs division double divd floatingpoint comparison single cxs comparison double cxd x may equal eq equal neq less lt less equal le greater gt greater equal ge floatingpoint branch true bc1t branch false bc1ffloatingpoint comparison sets bit true false depending comparison condition oatingpoint branch decides whether branch depending condition e mips designers decided add separate oatingpoint registerscalled f0 f1 f2 used either single precision double precision hence included separate loads stores fo oatingpoint registers lwc1 swc1 e base registers fo oatingpoint data transfers used addresses remain integer register e mips code load two single precision numbers memory add store sum might look like lwc1 f4csp load 32bit fp number f4lwc1 f6asp load 32bit fp number f6 adds f2f4f6 f2 f4 f6 single precision swc1 f2bsp store 32bit fp number f2a double precision register really evenodd pair single precision registers using even register number name us pair single precision registers f2 f3 also form double precision register named f2figure 317 summarizes th oatingpoint portion mips architecture revealed chapter additions suppor oating point shown color similar figure 219 chapter 2 figure 318 shows encoding instructions 212 chapter 3 arithmetic computers mips oatingpoint operandsnameexamplecomments32 oating point registers f0 f1 f2 f31mips oatingpoint registers used pairs double precision numbers 230 memory words memory0 memory4 memory4294967292 accessed data transfer instructions mips uses byte addresses sequential word addresses differ 4 memory holds data structures arrays spilled registers saved procedure calls mips oatingpoint assembly languagecategory instruction examplemeaningcommentsarithmeticfp add singleadds f2f4f6 f2 f4 f6fp add single precisionfp subtract singlesubs f2f4f6 f2 f4 ð f6fp sub single precisionfp multiply singlemuls f2f4f6 f2 f4 f6fp multiply single precisionfp divide singledivs f2f4f6 f2 f4 f6fp divide single precisionfp add doubleaddd f2f4f6 f2 f4 f6fp add double precisionfp subtract doublesubd f2f4f6 f2 f4 ð f6fp sub double precisionfp multiply doublemuld f2f4f6 f2 f4 f6fp multiply double precisionfp divide doubledivd f2f4f6 f2 f4 f6fp divide double precisiondata transferload word copr 1lwc1 f1100s2 f1 memorys2 10032bit data fp registerstore word copr 1swc1 f1100s2 memory s2 100 f132bit data memory condi tional branchbranch fp truebc1t 25 cond 1 go pc 4 100pcrelative branch fp condbranch fp falsebc1f 25 cond 0 go pc 4 100pcrelative branch condfp compare single eqneltlegtgeclts f2f4if f2 f4 cond 1 else cond 0fp compare less single precisionfp compare double eqneltlegtgecltd f2f4if f2 f4 cond 1 else cond 0fp compare less double precisionmips oatingpoint machine languagenameformat examplecommentsadds r17166420 adds f2f4f6subs r17166421 subs f2f4f6muls r17166422 muls f2f4f6divs r17166423 divs f2f4f6addd r17176420 addd f2f4f6subd r17176421 subd f2f4f6muld r17176422 muld f2f4f6divd r17176423 divd f2f4f6lwc1 i4920 2100lwc1 f2100s4swc1 i5720 2100swc1 f2100s4bc1t i1781 25 bc1t 25bc1f i1780 25 bc1f 25cltsr171642060 clts f2f4cltdr171742060 cltd f2f4field size 6 bits5 bits5 bits5 bits5 bits6 bitsall mips instructions 32 bits figure 317 mips ﬂ oatingpoint architecture revealed thus far see appendix section a10 detail information also found column 2 mips reference data card front book 35 floating point 213op312628œ2631œ2900001001201030114100510161107111 0000rfmtbltzgezj jalbeqbneblezbgtz 1001addiaddiusltisltiuandiori xorilui 2010tlbflpt30114100lblhlwllw lbulhulwr 5101sbshswlsw swr6110lwc0lwc17111swc0swc1op3126 010001 flpt rt1616 0 c f rt1616 1 c rs252123œ2125œ2400001001201030114100510161107111 000mfc1cfc1mtc1ctc1101bc1c210f singlef double311op3126 010001 flpt f 10000 f 10001 f funct502œ0 5œ300001001201030114100510161107111 0000addfsubfmulfdivfabsfmovfnegf1001201030114100cvtsfcvtdfcvtwf5101 6110cffcunfceqfcueqfcoltfcultfcolefculef7111csffcnglefcseqfcnglfcltfcngefclefcngtffigure 318 mips ﬂ oatingpoint instruction encoding notation gives value eld row column example top portion th gure lw found row number 4 100 two bits 3129 instruction column number 3 011 two bits 2826 instruction corresponding value eld bits 3126 100011 two underscore means th eld used elsewhere example flpt row 2 column 1 op 010001two ned bottom part th gure hence subf row 0 column 1 bottom section means func eld bits 50 instruction 000001 two eld bits 3126 010001 two note 5bit rs eld sp ed middle portion th gure determines whether operation single precision f rs 10000 double precision f rs 10001 similarly bit 16 instruction determines bc1c instruction tests true bit 16 1 bc1t false bit 16 0 bc1f instructions color described chapter 2 chapter appendix covering instructions information also found column 2 mips reference data card front book 214 chapter 3 arithmetic computers one issue architects face supportin oatingpoint arithmetic whether use registers used integer instructions add special set fo oating point programs normally perform integer operations oatingpoint operations erent data separating registers slightly increase number instructions needed execute progra e major impact create separate set data transfer instructions move data betw oatingpoint registers memory e ts separate oatingpoint registers twice many registers without using bits instruction format twice register bandwidth separate integer oatingpoint register sets able customize registers oating point example computers convert sized operands registers single internal format compiling floatingpoint c program mips assembly code lets convert temperature fahrenheit celsius float f2c float fahr return 5090 fahr 320 assume oatingpoint argument fahr passed f12 result go f0 unlike integer register oatingpoint register 0 contain number mips assembly code assume compiler places thre oatingpoint constants memory within easy reach global pointer gp e rst two instruc tions load constants 50 90 int oatingpoint registers f2c lwc1 f16const5gp f16 50 50 memory lwc1 f18const9gp f18 90 90 memory ey divided get fraction 5090 divs f16 f16 f18 f16 50 90hardware software interfaceexampleanswer 35 floating point 215many compilers would divide 50 90 compile time save single constant 5090 memory thereby avoiding divide runtime next load constant 320 subtract fahr f12 lwc1 f18 const32gp f18 320 subs f18 f12 f18 f18 fahr 320finally multiply two intermediate results placing product f0 return result return muls f0 f16 f18 f0 59fahr 320 jr ra returnnow lets perfor oatingpoint operations matrices code commonly found scien c programs compiling floatingpoint c procedure twodimensional matrices mipsmost oatingpoint calculations performed double precision lets per form matrix multiply c c b commonly called dgemm double precision general matrix multiply well see versions dgemm section 38 subsequently chapters 4 5 6 lets assume c b square matrices 32 elements dimension void mm double c double double b int j k 0 32 1 j 0 j 32 j j 1 k 0 k 32 k k 1 cij cij aik bkj e array starting addresses parameters a0 a1 a2 assume integer variables s0 s1 s2 respectively mips assembly code body procedure note cij used innermost loop since loop index k index ect cij avoid loading storing cij iteration instead compiler loads cij register outside loop accumulates sum products aik exampleanswer 216 chapter 3 arithmetic computers bkj register stores sum cij upon termination innermost loop keep code simpler using assembly language pseudoinstructions li loads constant register ld sd assembler turns pair data transfer instructions lwc1 swc1 pair oatingpoint registers e body procedure starts saving loop termination value 32 temporary register initializing three loop variables mm li t1 32 t1 32 row sizeloop end li s0 0 0 initialize 1st loop l1 li s1 0 j 0 restart 2nd loop l2 li s2 0 k 0 restart 3rd loopto calculate address cij need know 32 32 two dimensional array stored memory might expect layout 32 singledimension arrays 32 elements rst step skip singledimensional arrays rows get one wan us multiply index th rst dimension size row 32 since 32 power 2 us instead sll t2 s0 5 t2 25 size row cnow add second index select jth element desired row addu t2 t2 s1 t2 sizerow jto turn sum byte index multiply size matrix element bytes since element 8 bytes double precision inste 3 sll t2 t2 3 t2 byte offset ijnext add sum base address c giving address cij load double precision number cij f4addu t2 a0 t2 t2 byte address cijld f4 0t2 f4 8 bytes cij e followin instructions virtually identical th calculate address load double precision number bkjl3 sll t0 s2 5 t0 k 2 5 size row b addu t0 t0 s1 t0 k sizerow j sll t0 t0 3 t0 byte offset kj addu t0 a2 t0 t0 byte address bkj ld f16 0t0 f16 8 bytes bkjsimilarly th instructions like th calculate address load double precision number aik 35 floating point 217sll t0 s0 5 t0 2 5 size row aaddu t0 t0 s2 t0 sizerow ksll t0 t0 3 t0 byte offset ik addu t0 a1 t0 t0 byte address aik ld f18 0t0 f18 8 bytes aiknow loaded data ar nally ready oating point operations multiply elements b located registers f18 f16 accumulate sum f4muld f16 f18 f16 f16 aik bkj addd f4 f4 f16 f4 cij aik bkj e nal block increments index k loops back index 32 32 thus end innermost loop need store sum accumulated f4 cijaddiu s2 s2 1 k k 1bne s2 t1 l3 k 32 go l3 sd f4 0t2 cij f4similarly thes nal four instructions increment index variable middle outermost loops looping back index 32 exiting index 32 addiu s1 s1 1 j j 1bne s1 t1 l2 j 32 go l2 addiu s0 s0 1 1 bne s0 t1 l1 32 go l1 figure 322 shows x86 assembly language code slightl erent version dgemm figure 321 elaboration array layout discussed example called rowmajor order used c many programming languages fortran instead uses columnmajor order whereby array stored column column elaboration oatingpoint registers could originally used double precision operations f0 f2 f4 f30 double precision computed using pairs single precision register oatingpoint registers w oatingpoint numbers mips32 added ld sd instruction set mips32 also added paired single versions oatingpoint instructions single instr oatingpoint operations two 32bit operands inside 64bit registers see section 36 example addps f0 f2 f4 equivalent adds f0 f2 f4 followed adds f1 f3 f5 218 chapter 3 arithmetic computers elaboration another reason separate integer oatingpoint registers microprocessors 1980s didnt enough transistor oatingpoint unit chip integer unit hence oatingpoint unit oatingpoint registers optionally available second chip optional accelerator chips called coprocessors explain acron oatingpoint loads mips lwc1 means load word coprocessor 1 oatingpoint unit coprocessor 0 deals virtual memory described chapter 5 since early 1990s microprocessors ha oating point everything else chip hence term coprocessor joins accumulator core memory quaint terms date speaker elaboration mentioned section 34 accelerating division challenging multiplication addition srt another technique leverage fast multiplier newtons iteration nd reciprocal 1c multiplied operand iteration techniques rounded properly without calculating many extra bits ti chip solved problem calculating extraprecise reciprocal elaboration java embraces ieee 754 b nition ja oatingpoint data types operations thus rst example could well generated class method converted fahrenheit celsius second example uses multiple dimensional arrays explicitly supported java java allows arrays arrays array may length unlike multiple dimensional arrays c like examples chapter 2 java version second example would require good deal checking code array bounds including new length calculation end row access would also need check object reference nullaccurate arithmeticunlike integers represent exactly every number smallest largest number oatingpoint numbers normally approximations number cant really represen e reason nite variety real numbers exists say 0 1 2 53 represented exactly double precisio oating poin e best getting th oatingpoint representation close actual number us ieee 754 ers several modes rounding let programmer pick desired approximation rounding sounds simple enough round accurately requires hardware include extra bits calculation preceding examples vague number bits intermediate representation occupy clearly every intermediate result truncated exact number digits would opportunity round ieee 754 therefore always keeps two extra bits right intermediate additions called guard round respectively lets decimal example illustrate value guard e rst two extra bits kept right intermediate calculations oating point numbers used improve rounding accuracy round method make intermediate oatingpoint result th oatingpoint format goal typically nd nearest number represented format 35 floating point 219rounding guard digitsadd 256 ten 100 234 ten 102 assuming thre cant decimal digits round nearest decimal number thre cant decimal digi rst guard round digits without first mu smaller number right align exponents 256ten 100 becomes 00256 ten 102 since guard round digits able represent two le cant digits align expo nen e guard digit holds 5 round digit ho e sum 23400ten 00256ten 23656ten us sum 23656 ten 102 since two digits round want values 0 49 round 51 99 round 50 tiebreaker rounding sum thre cant digits yields 237 ten 102doing without guard round digits drops two digits calculatio e new sum 234ten 002ten 236ten e answer 236 ten 102 1 last digit sum since worst case rounding would actual number halfway tw oatingpoint representations accurac oating point normally measured terms number bits error le cant bits cand measure called number units last place ulp number 2 le cant bits would called 2 ulps provided ow ow invalid operation exceptions ieee 754 guarantees computer uses number within onehalf ulp elaboration although example really needed one extra digit multiply need two binary product may one leading 0 bit hence normalizing step cant bit product leaving round bit help accurately round product ieee 754 four rounding modes always round tow always round toward truncate round nearest e nal mode determines number exactly halfway us internal revenue service irs always rounds 050 dollars irs equitable way would round case half time round half ieee 754 sa cant bit retained halfway case would odd add one exampleanswerunits last place ulp e number bits error least cant bits cand actual number number represented 220 chapter 3 arithmetic computers even truncate method alwa cant bit tiebreaking case giving rounding mode name mode commonly used one java supports goal extra rounding bits allow computer get results intermediate results w nite precision rounded support goal round nearest even standard third bit addition guard round set whenever nonzero bits right round bit sticky bit allows computer see difference 050 00 ten 050 01ten rounding sticky bit may set example addition smaller number shifted right suppose added 501 ten 101 234ten 102 example even guard round would adding 00050 234 sum 23450 sticky bit would set since nonzero bits right without sticky bit remember whether 1s shifted would assume number equal 2345000 00 round nearest even 234 sticky bit remember number larger 2345000 00 round instead 235 elaboration powerpc sparc64 amd sse5 intel avx architectures provide single instruction multiply add three registers b c obviously instr oatingpoint performance common operation equally important instead performing two roundingsafter multiply addwhich would happen separate instructions multiply add instruction perform single rounding add single rounding step increases precision multiply add operations single rounding called fused multiply add added ieee 7542008 standard see section 311summary e big picture follows reinforces storedprogram concept chapter 2 meaning information determined looking bits bits represent variety objec section shows computer arit nite thus disagree natural arithmetic example ieee 754 standard oatingpoint representation 15 1 fraction 2exponent bias almost always approximation real number computer systems must take care minimize gap computer arithmetic arithmetic real world programmers times need aware implications approximation sticky bit bit used rounding addition guard round set whenever nonzero bits right round bit fused multiply add oatingpoint instruction performs multiply add rounds er add bit patterns inherent meanin ey may represent signed integers unsigned integer oatingpoint numbers instructions represented depends instruction operates bits word bigpicture 35 floating point 221c typejava typedata transfers operationsintintlw sw lui addu addiu subu mult div andi ori slt sltiunsigned intlw sw lui addu addiu subu multu divu andi ori sltu sltiucharlb sb lui add addi sub mult div andi ori slt slticharlh sh lui addu addiu subu multu divu andi ori sltu sltiufloatfloatlwc1 swc1 adds subs mults divs ceqs clts clesdoubledoubleld sd addd subd multd divd ceqd cltd cledin last chapter presented storage classes programming language c see hardwareso ware interface section sectio e table shows c java data types mips data transfer instructions instructions operate types appear chapter 2 chapter note java omits unsigned integers e revised ieee 7542008 standard added 16bi oatingpoint format wi exponent bits think likely range numbers could represent 1 10000 00 20 11111 1111 11 231 02 10000 0000 0 214 11111 1111 1 215 0 3 10000 0000 00 214 11111 1111 11 215 0 4 10000 0000 00 215 11111 1111 11 214 0 elaboration accommodate comparisons may include nans standard includes ordered unordered options compares hence full mips instruction set man avors compares support nans java support unordered compareshardware software interfacecheck e majo erence computer numbers numbers real world computer numbers limited size hence limited precision possible calculate number big small represented word programmers must remember limits write programs accordingly 222 chapter 3 arithmetic computers attempt squeeze ever oatingpoint operation standard allows numbers represented unnormalized form rather gap 0 smallest normalized number ieee allows denormalized numbers also known denorms subnormals exponent zero nonzero fraction cance becomes 0 called gradual underﬂ ow example smallest positive single precision normalized number 10000 0000 0000 0000 0000 000two 2126but smallest single precision denormalized number 00000 0000 0000 0000 0000 001two 2126 10two 2149for double precision denorm gap goes 10 21022 10 21074the possibility occasional unnormalized operand given headaches oatingpoint designers tr oatingpoint units hence many computers cause exception operand denormalized letting software complete operation although software implementations perfectly valid lower performance lessened popularity denorms por oatingpoint software moreover programmers expect denorms programs may surprise 36 parallelism computer arithmetic subword parallelism since every desktop microprocessor nition graphical displays transistor budgets increased inevitable support would added graphics operations many graphics systems originally used 8 bits represent three primary colors plus 8 bits location pixel e addition speakers microphones teleconferencing video games suggested support sound well audio samples need 8 bits precision 16 bits ar cient every microprocessor special support bytes halfwords take less space stored memory see section 29 due infrequency arithmetic operations data sizes typical integer programs little support beyond data transfers architects recognized many graphics audio applications would perform operation vectors data partitioning carry chains within 128bit adder processor could use parallelism perform simultaneous operations short vectors sixteen 8bit operands eight 16bit operands four 32bit operands two 64bit opera e cost partitioned adders small given parallelism occurs within wide word extensions cl ed subword parallelism also cl ed general name data level parallelism ey also called vector simd single instruction multiple data see sectio e rising popularity multimedia 36 parallelism computer arithemtic subword parallelism 223applications led arithmetic instructions support narrower operations easily operate parallel example arm added 100 instructions neon multimedia instruction extension support subword parallelism used either armv7 armv8 added 256 bytes new registers neon viewed 32 registers 8 bytes wide 16 registers 16 bytes wide neon supports subword data types imagine except 64bi oating point numbers 8bit 16bit 32bit 64bit signed unsigned integers 32bit oating point numbers figure 319 gives summary basic neon instructions figure 319 summary arm neon instructions subword parallelism use curly brackets show optional variations basic operations s8u88 stand signed unsigned 8bit integers 8bit data type doesnt mat ter 16 128bit register s16u1616 stand signed unsigned 16bit integers 16bit typeless data whic 128bit register s32u3232 stand signed unsigned 32bit integers 32bit typeless data whic 128bit register s64u6464 stand signed unsigned 64bit integers typeless 64bit data whic 128bit register f32 stan signed unsigned 32bit oating point numbers whic 128bit register vector load reads one nelement structure memory 1 2 3 4 neon registers loads single nelement structure one lane see section 66 elements register loade unchanged vector store writes one nelement structure memory 1 2 3 4 neon registers elaboration addition signed unsigned integers xedpoint format four sizes called i8 i16 i32 i64 16 8 4 128 bit register respectively por xed point fraction right binary point rest data integer portion left binary point location binary point software many arm processors ha oating point hardw oating point operations must performed library routines f cantly faster softw oating point routines work programmer data transferarithmeticlogicalcompare821dnav46dnav23u23s61u61s8u8swlddav23fddav 23frdlv 821rrov46rrov23u23s61u61s8u8swlbusv23fbusv 23frtsv vld1234i8i16i32vmulf32 vmulls8u8s16u16s32u32veor64 veor128 vst1234i8i16i32vmlaf32 vmlals8u8s16u16s32u32vbic64 vbic128 vmovi8i16i32f32 immvmlsf32 vmlsls8u8s16u16s32u32vorn64 vorn128 vmvni8i16i32f32 immvmaxs8u8s16u16s32u32f32 vceqi8i16i32f32vmovi64i128 vmins8u8s16u16s32u32f32vcges8u8s16u16s32u32f3223f23u23s61u61s8u8stgcv 23f23s61s8ssbav 821i46invmv 224 chapter 3 arithmetic computers 37 real stuff streaming simd extensions advanced vector extensions x86 e original mmx multimedia extension sse streaming simd extension instructions x86 included similar operations found arm neon chapter 2 notes 2001 intel added 144 instructions architecture part sse2 including double precisio oatingpoint registers operations includes eight 64bit registers used fo oatingpoint operands amd expanded number 16 registers called xmm part amd64 intel relabeled em64t use figure 320 summarizes sse sse2 instructions addition holding single precision double precision number register intel allows multip oatingpoint operands packed single 128bit sse2 register four single precision two double precisio us 16 oatingpoint registers sse2 actually 128 bits wide operands arranged memory 128bit aligned data 128bit data transfers load store multiple operands per instructio pack oatingpoint format supported arithmetic operations operate simultaneously four singles ps two doubles pd data transferarithmeticcompare movausspssdpd xmm memxmmaddsspssdpd xmmmemxmm cmpsspssdpd subsspssdpd xmmmemxmm mov hl pspd xmm memxmm mulsspssdpd xmmmemxmm divsspssdpd xmmmemxmm sqrtsspssdpd memxmmmax sspssdpd memxmm minsspssdpd memxmmfigure 320 ssesse2 ﬂ oatingpoint instructions x86 xmm means one operand 128bit sse2 register memxmm means operand either memory sse2 register use curly brackets show optional variations basic operations ss stands scalar single precisio oating point one 32bit operand 128bit register ps stands packed single precision oating point four 32bit operands 128bit register sd stands scalar double precisio oating point one 64bit operand 128bit register pd stands packed double precisio oating point two 64bit operands 128bit register means 128bit operand aligned memory u means 128bit operand unaligned memory h mean move high half 128bit operand l means move low half 128bit operand 38 going faster subword parallelism matrix multiply 225in 2011 intel doubled width registers called ymm advanced vector extensions avx us single operation specify eight 32bi oatingpoint operations four 64bit oatingpoint operation e legacy sse sse2 instructions operate lower 128 bits ymm register us go 128bit 256bit operations prepend letter v vector front sse2 assembly language operations use ymm register names instead xmm register name example sse2 instruction perform two 64bi oatingpoint multiplies addpd xmm0 xmm4it becomes vaddpd ymm0 ymm4 produces four 64bi oatingpoint multiplies elaboration avx also added three address instructions x86 example vaddpd specify vaddpd ymm0 ymm1 ymm4 ymm4 ymm1 ymm2instead standard two address version addpd xmm0 xmm4 xmm4 xmm4 xmm0unlike mips destination right x86 three addresses reduce number registers instructions needed computation 38 going faster subword parallelism matrix multiplyto demonstrate performance impact subword parallelism well run code intel cor rst without avx figure 321 shows unoptimized version matrixmatrix multiply written c saw section 35 program commonly called dgemm stands double precision general matrix multiply starting edition added new section entitled going faster demonstrate performance b adapting ware underlying hardware case sandy bridge version intel core i7 microprocessor new section chapters 3 4 5 6 incrementally improve dgemm performance using ideas chapter introduces figure 322 shows x86 assembly language output inner loop figure 321 e oating pointinstructions start v like avx instructions note use xmm registers instead ymm include sd name stands scalar double precision wel ne subword parallel instructions shortly 226 chapter 3 arithmetic computers figure 322 x86 assembly language body nested loops generated compiling optimized c code figure 321 although dealing 64bits data compiler uses avx version instructions instead sse2 presumably use three address per instruction instead two see elaboratio n section 37 figure 321 unoptimized c version double precision matrix multiply widely known dgemm doubleprecision general matrix multiply gemm passing matrix dimension parameter n version dgemm uses single dimensional versions matrices c b address arithmetic get better performance instead using intuitive twodimensional arrays saw sectio e comments remind us intuitive notation 1 void dgemm int n double double b double c 2 3 int 0 n 4 int j 0 j n j 5 6 double cij cijn cij cij 7 int k 0 k n k 8 cij aikn bkjn cij aikbkj 9 cijn cij cij cij 10 11 1 vmovsd r10xmm0 load 1 element c xmm0 2 mov rsircx register rcx rsi 3 xor eaxeax register eax 0 4 vmovsd rcxxmm1 load 1 element b xmm1 5 add r9rcx register rcx rcx r9 6 vmulsd r8rax8xmm1xmm1 multiply xmm1 element 7 add 0x1rax register rax rax 1 8 cmp eaxedi compare eax edi 9 vaddsd xmm1xmm0xmm0 add xmm1 xmm0 10 jg 30 dgemm0x30 jump eax edi 11 add 0x1r11d register r11 r11 112 vmovsd xmm0r10 store xmm0 c element 38 going faster subword parallelism matrix multiply 227figure 323 optimized c version dgemm using c intrinsics generate avx subwordparallel instructions x86 figure 324 shows assembly language produced compiler inner loop compiler writers may eventually able routinely produce high quality code uses avx instructions x86 must cheat using c intrinsics less tell compiler exactly produce good code figure 323 shows enhanced version figure 321 gnu c compiler produces avx code figure 324 shows annotated x86 code output compiling using gcc o3 level optimization e declaration line 6 figure 323 uses __m256d data type tells compiler variable hold 4 doubleprecisio oatingpoint val e intrinsic _mm256_load_pd also line 6 uses avx instructions load 4 doubleprecisio oatingpoint numbers parallel _pd matrix c c0 e address calculation cijn line 6 represents element cijn symmetrically th nal step line 11 uses intrinsic _mm256_store_pd store 4 doubleprecisio oatingpoint numbers c0 matrix c going 4 elements iteration outer loop line 4 increments 4 instead 1 line 3 figure 321 inside loops line 9 w rst load 4 elements using _mm256_load_pd multiply elements one element b line 10 rst use intrinsic _mm256_broadcast_sd makes 4 identical copies scalar double precision numberin case element bin one ymm registers use _mm256_mul_pd line 9 multiply four doubleprecision results parallel finally _mm256_add_pd line 8 adds 4 products 4 sums c0figure 324 shows resulting x86 code body inner loops produced compiler see th avx instructionsthey start v 1 include x86intrinh 2 void dgemm int n double double b double c 3 4 int 0 n i4 5 int j 0 j n j 6 __m256d c0 _mm256_load_pdcijn c0 cij 7 int k 0 k n k 8 c0 _mm256_add_pdc0 c0 aikbkj 9 _mm256_mul_pd_mm256_load_pdaikn 10 _mm256_broadcast_sdbkjn 11 _mm256_store_pdcijn c0 cij c0 12 13 228 chapter 3 arithmetic computers four th use pd parallel double precisionthat correspond c intrinsics mentioned e code similar figure 322 use 12 instructions integer instructions nearly identical bu erent registers th oatingpoint instructio erences generally going scalar double sd using xmm registers parallel double pd ymm register e one exception line 4 figure 324 every element must multiplied one element b one solution place four identical copies 64bit b element sidebyside 256bit ymm register instruction vbroadcastsd matrices dimensions 32 32 unoptimized dgemm figure 321 runs 17 gigaflops floating point operations per second one core 26 ghz intel core i7 sandy bridg e optimized code figure 323 performs 64 gigaflo e avx version 385 times fast close factor 40 increase might hope performing 4 times many operations time using subword parallelism elaboration mentioned elaboration section 16 intel offers turbo mode temporarily runs higher clock rate chip gets hot intel core i7 sandy bridge increase 26 ghz 33 ghz turbo mode results turbo mode turned turn improve results increase clock rate 3326 127 21 gflops unoptimized dgemm 81 gflops avx turbo mode works particularly well using single core eightcore chip case lets single core use much fair share power since cores idle figure 324 x86 assembly language body nested loops generated compiling optimized c code figure 323 note similarities figure 322 primar erence oatingpoint operations using ymm registers using pd versions instructions parallel double precision instead sd version scalar double precision 1 vmovapd r11ymm0 load 4 elements c ymm0 2 mov rbxrcx register rcx rbx 3 xor eaxeax register eax 0 4 vbroadcastsd raxr81ymm1 make 4 copies b element 5 add 0x8rax register rax rax 8 6 vmulpd rcxymm1ymm1 parallel mul ymm14 elements 7 add r9rcx register rcx rcx r9 8 cmp r10rax compare r10 rax 9 vaddpd ymm1ymm0ymm0 parallel add ymm1 ymm0 10 jne 50 dgemm0x50 jump r10 rax11 add 0x1esi register esi esi 112 vmovapd ymm0r11 store ymm0 4 c elements 39 fallacies pitfalls 229 39 fallacies pitfalls arithmetic fallacies pitfalls generally stem th erence limited precision computer arithmetic unlimited precision natural arithmetic fallacy instruction replace integer multiply power 2 right shi integer division power 2 recall binary number c xi means ith bit represents number x3 23 x2 22 1 x1 21 x0 20s ing bits c right n bits would seem dividing 2n true unsigned integer e problem signed integers example suppose want divide 5ten 4 ten quotient 1ten e twos complement representation 5ten is1111 1111 1111 1111 1111 1111 1111 1011two according fallacy ing right two divide 4 ten 220011 1111 1111 1111 1111 1111 1111 1110two 0 sign bit result clearly wron e value created th right actually 1073741822 ten instead 1ten solution would arithmetic righ extends sign bit instead ing 0s 2bit arit right 5ten produces 1111 1111 1111 1111 1111 1111 1111 1110two e result 2ten instead 1ten close cigar pitfall floatingpoint addition associative associativity holds sequence twos complement integer additions even computation ows alas becaus oatingpoint numbers approximations real numbers computer arithmetic limited precision hold fo oatingpoint numbers given great range numbers represente oating point problems occur adding two large numbers opposite signs plus small number example lets see c b c b assume c 15ten 1038 15ten 1038 b 10 single precision numbers us mathematics ned subject never know talking whether saying true bertrand russell recent words principles mathematics 1901 230 chapter 3 arithmetic computers c1510151010 151015 ten 38ten 38ten 38teabnn 38ten 38ten 38ten 10 00c1510151010 00ab 10 10si oatingpoint numbers limited precision result approximations real results 15 ten 1038 much larger 10 ten 15 ten 1038 10 still 15ten 1038 sum c b 00 10 depending order th oatingpoint additions c b c b erefore oating point addition associative fallacy parallel execution strategies work integer data types also work oatingpoint data types programs typically writt rst run sequentially rewritten run concurrently natural question two versions get answer answer presume bug parallel version need track approach assumes computer arithmetic ect results going sequential parallel add million numbers together would get results whether used 1 processor 1000 processor assumption holds twos complement integers since integer addition associative oatingpoint addition associative assumption hold vexing version fallacy occurs parallel computer operating system scheduler may us erent number processors depending programs running parallel computer varying number processors run would cause th oatingpoint sums calculat erent orders getting slightl erent answers time despite running identical code identical input ummox unaware parallel programmers given quandary programmers write parallel code oatingpoint numbers need verify whether results credible even dont give exact answer sequential code e eld deals issues called numerical analysis subject textbooks right concerns one reason popularity numerical libraries lapack scalapak validated sequential parallel forms pitfal e mips instruction add immediate unsigned addiu signextends 16bit immediat eld 39 fallacies pitfalls 231despite name add immediate unsigned addiu used add constants signed integers dont care ow mips subtract immediate instruction negative numbers need sign extension mips architects decided signextend immediate eld fallacy theoretical mathematicians care abou oatingpoint accuracy newspaper headlines november 1994 prove statement fallacy see figure 325 e following inside story behind headlines e pentium used standar oatingpoint divide algorithm generates multiple quotient bits per step using th cant bits divisor dividend guess next 2 bits quotien e guess taken lookup table containing 2 1 0 1 e guess multiplied divisor subtracted remainder generate new remainder like nonrestoring division previous guess gets large remainder partial remainder adjusted subsequent pass evidently wer elements table 80486 intel engineers thought could never accessed optimized logic return 0 instead 2 situations pentium intel wrong th rst 11 figure 325 sampling newspaper magazine articles november 1994 including new york times san jose mercury news san francisco chronicle infoworld e penti oatingpoint divide bug even made top 10 list david letterman late show television intel eventually took 300 million writeo replace buggy chips 232 chapter 3 arithmetic computers bits always correct errors would show occasionally bits 12 52 4th 15th decimal digits math professor lynchburg college virg omas nicely discovered bug septemb er calling intel technical support getting cial reaction posted discovery intern post led story trade magazine turn caused intel issue press release called bug glitch would ect theoretical mathematicians average spreadsheet user seeing error every 27000 years ibm research soon counterclaimed average spreadsheet user would see error every 24 days intel soon threw towel making following announcement december 21 intel wish sincerely apologize handling recently publicized pentium processo aw e intel inside symbol means computer microprocessor second none quality performanc ousands intel employees work hard ensure true microprocessor ever perfect intel continues believe technically extremely minor problem taken life although inte rmly stands behind quality current version pentium processor recognize many users concerns want resolve concerns intel exchange current version pentium processor updated version oatingpoint div aw corrected owner requests free charge anytime life computer analysts estimate recall cost intel 500 million intel engineers get christmas bonus year story brings points everyone ponder much cheaper would x bug july 1994 cost repair damage intels reputation corporate responsibility disclosing bugs product widely used relied upon microprocessor 310 concluding remarks decades computer arithmetic become largely standardized greatly enhancing portability programs twos complement binary integer arithmetic found every computer sold today incl oating point support ers ieee 754 binar oatingpoint arithmetic computer arithmetic distinguished paperandpencil arithmetic constraints limited precisio limit may result invalid operations calculating numbers larger smaller pr ned limits anomalies called ow ow may result exceptions interrupts emergency events similar unplanned subroutine calls chapters 4 5 discuss exceptions detail floatingpoint arithmetic added challenge approximation real numbers care needs taken ensure computer number 310 concluding remarks 233selected representation closest actual number e challenges imprecision limited representation oating point part inspiration th eld numerical anal e recent switch parallelism shines searchlight numerical analysis solutions long considered safe sequential computers must reconsidered trying nd fastest algorithm parallel computers still achieves correct result datalevel parallelism sp cally subword parallelism ers simple path higher performance programs intensive arithmetic operations either integer oatingpoint data showed could speed matrix multiply nearly fourfold using instructions could execute fo oating point operations time explanation computer arithmetic chapter comes description much mips instruction set one point confusion instructions covered chapters versus instructions executed mips chips versus instructions accepted mips assemblers tw gures try make clear figure 326 lists mips instructions covered chapter chapter 2 call set instructions th hand side th gure mips core e instructions right call mips arithmetic core th figure 327 instructions mips processor executes found figure 326 call full set hardware instructions mips32 right figure 327 instructions accepted assembler part mips32 call set instructions pseudo mips figure 328 gives popularity mips instructions spec cpu2006 integer oatingpoint benchmarks instructions listed responsible least 02 instructions executed note although programmers compiler writers may use mips32 richer menu options mips core instructions dominate integer spec cpu2006 execution integer core plus arithmetic core dominate spec oating point table shows instruction subset integerfl pt mips core9831 mips arithmetic core266 remaining mips3203 rest book concentrate mips core instructionsthe integer instruction set excluding multiply divideto make explanation computer design easier see mips core includes popular mips instructions assured understanding computer runs mips core give su cient background understand even ambitious computers matter instruction set sizemips arm x86never forget bit patterns inherent meanin e bit pattern may represent signed integer unsigned integer oatingpoint number string instruction stored program computers operation bit pattern determines meaning 234 chapter 3 arithmetic computers mips core instructionsnameformatmips arithmetic corenameformat addaddrmultiply multradd immediateaddiimultiply unsigned multuradd unsignedaddurdivide divradd immediate unsignedaddiuidivide unsigned divursubtractsubrmove hi mfhirsubtract unsignedsuburmove lo mßorandandrmove system control epc mfc0rand immediateandiioatingpoint add single addsrororroatingpoint add double adddror immediateoriioatingpoint subtract single subsrnornorroatingpoint subtract double subdrshift left logicalsllroatingpoint multiply single mulsrshift right logicalsrlroatingpoint multiply double muldrload upper immediateluiioatingpoint divide single divsrload wordlwioatingpoint divide double divdrstore wordswiload word oatingpoint single lwc1iload halfword unsignedlhuistore word oatingpoint single swc1istore halfwordshiload word oatingpoint double ldc1iload byte unsigned lbuistore word oatingpoint double sdc1istore byte sbibranch oatingpoint true bc1tiload linked atomic updatellibranch oatingpoint falsebc1fistore cond atomic updatescioatingpoint compare single cxsrbranch equalbeqix eq neq lt le gt gebranch equalbneioatingpoint compare double cxdrjumpjjx eq neq lt le gt gejump linkjaljjump registerjrrset less thansltrset less immediatesltiiset less unsignedslturset less immediate unsignedsltiuifigure 326 mips instruction set book concentrates instructions th col information also found columns 1 2 mips reference data card front book 310 concluding remarks 235remaining mips32nameformatpseudo mipsname format exclusive rs rtxorrabsolute value absrdrs exclusive immediatexoriinegate signed unsignednegsrdrs shift right arithmeticsrarrotate left rolrdrsrt shift left logical variablesllvrrotate right rorrdrsrt shift right logical variablesrlvrmultiply dont check ow signed unsmulsrdrsrt shift right arithmetic variablesravrmultiply check ow signed unsmulosrdrsrt move hi mthirdivide check overow divrdrsrt move lo mtlordivide dont check overow divurdrsrt load halfwordlhiremainder signed unsignedremsrdrsrt load byte lbiload immediate lirdimmload word left unalignedlwliload address lardaddrload word right unalignedlwriload double ldrdaddrstore word left unalignedswlistore double sdrdaddrstore word right unalignedswriunaligned load word ulwrdaddrload linked atomic updatelliunaligned store word uswrdaddrstore cond atomic updatesciunaligned load halfword signed unsulhsrdaddrmove zero movzrunaligned store halfword ushrdaddrmove zero movnrbranch blabelmultiply add unsmaddsrbranch equal zero beqzrsl multiply subtract unsmsubsibranch compare signed unsignedbxsrsrtl branch zero linkbgezalix lt le gt gebranch zero linkbltzaliset equal seqrdrsrt jump link registerjalrrset equal snerdrsrt branch compare zerobxziset compare signed unsignedsxsrdrsrt branch compare zero likely bxzlix lt le gt gex lt le gt geload oating point dlfrdaddrbranch compare reg likely bxlistore oating point dsfrdaddrtrap compare regtxrtrap compare immediatetxiix eq neq lt le gt gereturn exception rfersystem callsyscallibreak cause exceptionbreakimove fp integer mfc1rmove fp integer mtc1rfp move dmovfrfp move zero dmovzfrfp move zero dmovnfrfp square root dsqrtfrfp absolute value dabsfrfp negate dnegfrfp convert w cvtffrfp compare un dcxnfrfigure 327 remaining mips32 pseudo mips instruction sets f means single double precisio oatingpoint instructions means signed unsigned u versions mips32 also fp instructions multiply addsub maddf msubf ceiling ceilf truncate truncf round roundf reciprocal recipf e underscore represents letter include represent datatype 236 chapter 3 arithmetic computers core mips nameintegerfl ptarithmetic core mips32 nameintegerfl pt addadd0000fp add double addd00106 add immediateaddi0000fp subtract double subd0049 add unsignedaddu5235fp multiply double muld00150 add immediate unsignedaddiu9072fp divide double divd0002 subtract unsignedsubu2206fp add single adds0015 andand0201fp subtract single subs0018 immediateandi0702fp multiply single muls0024 oror4012fp divide single divs0002 immediateori1002load word fp double ld00175 nornor0402store word fp double sd0049 shift left logicalsll4419load word fp single ls0042 shift right logicalsrl1105store word fp single ss0011 load upper immediatelui3305branch oatingpoint true bc1t0002 load wordlw18658branch oatingpoint false bc1f0002 store wordsw7620oatingpoint compare double cxd0006 load byte lbu3701multiply mul0002 store byte sb0600shift right arithmetic sra0503 branch equal zerobeq8622load half lhu1300 branch equal zerobne8414store half sh0100 jump linkjal0702 jump registerjr1102 set less thanslt9923set less immediateslti3103 set less unsignedsltu3408 set less imm unssltiu1101 figure 328 frequency mips instructions spec cpu2006 integer ﬂ oating point instructions accounted least 02 instructions included table pseudoinstructions converted mips32 execution hence appear 311 historical perspective readingthis section surveys history floating point going back von neumann including surprisingly controversial ieee standards effort plus rationale 80bit stack architecture floating point x86 see rest section 311 online greshams law bad money drives good computers would say e fast drives slow even fast wrong w kahan 1992 312 exercises 237 312 exercises31 5 32 5ed4 07a4 values represent unsigned 16 bit hexadecimal number e result written hexadecimal show work 32 5 32 5ed4 07a4 values represent signed 16 bit hexadecimal numbers stored signmagnitude forma e result written hexadecimal show work 33 10 32 convert 5ed4 binary number makes base 16 hexadecimal attractive numbering system representing values computers 34 5 32 4365 3412 values represent unsigned 12bit octal number e result written octal show work 35 5 32 4365 3412 values represent signed 12bit octal numbers stored signmagnitude forma e result written octal show work 36 5 32 assume 185 122 unsigned 8bit decimal integers calculate 185 122 ow ow neither 37 5 32 assume 185 122 signed 8bit decimal integers stored signmagnitude format calculate 185 122 ow ow neither 38 5 32 assume 185 122 signed 8bit decimal integers stored signmagnitude format calculate 185 122 ow ow neither 39 10 32 assume 151 214 signed 8bit decimal integers stored twos complement format calculate 151 214 using saturating arit e result written decimal show work 310 10 32 assume 151 214 signed 8bit decimal integers stored twos complement format calculate 151 214 using saturating arit e result written decimal show work 311 10 32 assume 151 214 unsigned 8bit integers calculate 151 214 using saturating arit e result written decimal show work 312 20 33 using table similar shown figure 36 calculate product octal unsigned 6bit integers 62 12 using hardware described figure 33 show contents register step never give never give never never neverin nothing great small large pettynever give winston churchill address harrow school 1941 238 chapter 3 arithmetic computers 313 20 33 using table similar shown figure 36 calculate product hexadecimal unsigned 8bit integers 62 12 using hardware described figure 35 show contents register step 314 10 33 calculate time necessary perform multiply using approach given figures 33 34 integer 8 bits wide step operation takes 4 time units assume step 1a addition always performedeither multiplicand added zero also assume registers already initialized counting long takes multiplication loop done hardware multiplicand multiplier done simultaneously done ware done one er solve case 315 10 33 calculate time necessary perform multiply using approach described text 31 adders stacked vertically integer 8 bits wide adder takes 4 time units 316 20 33 calculate time necessary perform multiply using approach given figure 37 integer 8 bits wide adder takes 4 time units 317 20 33 discussed text one possible performance enhancement add instead actual multiplication since 9 6 example written 2 2 2 1 6 calculate 9 6 ing 6 th 3 times adding 6 result show best way calculate 0 33 055 usin addssubtracts assume inputs 8bit unsigned integers 318 20 34 using table similar shown figure 310 calculate 74 divided 21 using hardware described figure 38 show contents register step assume inputs unsigned 6bit integers 319 30 34 using table similar shown figure 310 calculate 74 divided 21 using hardware described figure 311 show contents register step assume b unsigned 6bit integer algorithm requires slightl erent approach shown figure 39 want think hard experiment two else go web gure make work correctly hint one possible solution involves using fact figure 311 implies remainder register ed either direction 320 5 35 decimal number bit pattern 00c000000 represent twos complement integer unsigned integer 321 10 35 bit pattern 00c000000 placed instruction register mips instruction executed 322 10 35 decimal number bit pattern 00c000000 represent oating point number use ieee 754 standard 312 exercises 239323 10 35 write binary representation decimal number 6325 assuming ieee 754 single precision format 324 10 35 write binary representation decimal number 6325 assuming ieee 754 double precision format 325 10 35 write binary representation decimal number 6325 assuming stored using single precision ibm format base 16 instead base 2 7 bits exponent 326 20 35 write binary bit pattern represent 15625 101 assuming format similar employed dec pdp8 12 bits exponent stored twos complement number rightmost 24 bits fraction stored twos complement number hidden 1 used comment range accuracy 36bit pattern compares single double precision ieee 754 standards 327 20 35 ieee 7542008 contains half precision 16 bits wide e bit still sign bit exponent 5 bits wide bias 15 mantissa 10 bits long hidden 1 assumed write bit pattern represent 15625 101 assuming version format uses excess16 format store exponent comment range accuracy 16bi oating point format compares single precision ieee 754 standard 328 e hewlettpackard 2114 2115 2116 used format th 16 bits fraction stored twos complement format followed another 16bit eld th 8 bits extension fraction making fraction 24 bits long rightmost 8 bits representing exponent however interesting twist exponent stored sign magnitude format sign bit far right write bit pattern represent 15625 101 assuming format hidden 1 used comment range accuracy 32bit pattern compares single precision ieee 754 standard 329 20 35 calculate sum 26125 101 4150390625 101 hand assuming b stored 16bit half precision described exercise 327 assume 1 guard 1 round bit 1 sticky bit round nearest even show steps 330 30 35 calculate product 80546875 100 179931640625 101 hand assuming b stored 16bit half precision format described exercise 327 assume 1 guard 1 round bit 1 sticky bit round nearest even show steps however done example text multiplication humanreadable format instead using techniques described exercises 312 314 indicate ow ow write answer 16bi oating point format described exercise 327 also decimal number accurate result compare number get multiplication calculator 240 chapter 3 arithmetic computers 331 30 35 calculate hand 8625 101 divided 4875 100 show steps necessary achieve answer assume guard round bit sticky bit use necessary write th nal answer 16bit oating point format described exercise 327 decimal compare decimal result get use calculator 332 20 39 calculate 3984375 101 34375 101 1771 103 hand assuming values stored 16bit half precision format described exercise 327 also described text assume 1 guard 1 round bit 1 sticky bit round nearest even show steps write answer 16bi oating point format decimal 333 20 39 calculate 3984375 101 34375 101 1771 103 hand assuming values stored 16bit half precision format described exercise 327 also described text assume 1 guard 1 round bit 1 sticky bit round nearest even show steps write answer 16bi oating point format decimal 334 10 39 based answers 332 333 3984375 101 34375 101 1771 103 3984375 101 34375 101 1771 103335 30 39 calculate 341796875 10 3 634765625 103 105625 102 hand assuming values stored 16bit half precision format described exercise 327 also described text assume 1 guard 1 round bit 1 sticky bit round nearest even show steps write answer 16bi oating point format decimal 336 30 39 calculate 341796875 10 3 634765625 103 105625 102 hand assuming values stored 16bit half precision format described exercise 327 also described text assume 1 guard 1 round bit 1 sticky bit round nearest even show steps write answer 16bi oating point format decimal 337 10 39 based answers 335 336 341796875 10 3 634765625 103 105625 102 341796875 103 634765625 103 105625 102338 30 39 calculate 1666015625 100 19760 104 19744 104 hand assuming values stored 16bit half precision format described exercise 327 also described text assume 1 guard 1 round bit 1 sticky bit round nearest even show steps write answer 16bi oating point format decimal 339 30 39 calculate 1666015625 100 19760 104 1666015625 100 19744 104 hand assuming values stored 16bit half precision format described exercise 327 also described text assume 1 guard 1 round bit 1 sticky bit round nearest even show steps write answer 16bi oating point format decimal 312 exercises 241340 10 39 based answers 338 339 1666015625 100 19760 104 1666015625 100 19744 104 1666015625 100 19760 104 19744 104341 10 35 using th oating point format write bit pattern would represent 14 represent 14 exactly 342 10 35 get add 14 4 times 14 4 343 10 35 write bit pattern fraction value 13 assuming oating point format uses binary numbers fraction assume 24 bits need normalize representation exact 344 10 35 write bit pattern fraction assumin oating point format uses binary coded decimal base 10 numbers fraction instead base 2 assume 24 bits need normalize representation exact 345 10 35 write bit pattern assuming using base 15 numbers fraction instead base 2 base 16 numbers use symbols 09 af base 15 numbers would use 09 ae assume 24 bits need normalize representation exact 346 20 35 write bit pattern assuming using base 30 numbers fraction instead base 2 base 16 numbers use symbols 09 af base 30 numbers would use 09 assume 20 bits need normalize representation exact 347 e following c code implements fourta lter input array sig_in assume arrays 16bi xedpoint values i3i128i sig_outisig_ini3 f0sig_ini 22 f1 sig_ini1 f2sig_ini f3 assume write optimized implementation code assembly language processor simd instructions 128bit registers without knowing details instruction set br describe would implement code maximizing use subword operations minimizing amount data transferred registers memory state assumptions instructions use 32 page 182 2 35 page 221 3 answers check 4in major matter details small french proverb processor41 introduction 24442 logic design conventions 24843 building datapath 25144 simple implementation scheme 25945 overview pipelining 27246 pipelined datapath control 28647 data hazards forwarding versus stalling 30348 control hazards 31649 exceptions 325410 parallelism via instructions 332computer organization design doi 2013 elsevier inc rights reservedhttpdxdoiorg101016b97801240772630000112013 411 real stuff arm cortexa8 intel core i7 pipelines 344412 going faster instructionlevel parallelism matrix multiply 351413 advanced topic introduction digital design using hardware design language describe model pipeline pipelining illustrations 354414 fallacies pitfalls 355415 concluding remarks 356416 historical perspective reading 357417 exercises 357the five classic components computer 244 chapter 4 processor 41 introductionchapter 1 explains performance computer determined three key factors instruction count clock cycle time clock cycles per instruction cpi chapter 2 explains compiler instruction set architecture determine instruction count required given program however implementation processor determines clock cycle time number clock cycles per instruction chapter construct datapath control unit tw erent implementations mips instruction set chapter contains explanation principles techniques used implementing processor starting highly abstract simp ed overview section followed section builds datapath constructs simple version processo cient implement instruction set like mips e bulk chapter covers realistic pipelined mips implementation followed section develops concepts necessary implement complex instruction sets like x86 reader interested understanding highlevel interpretation instructions impact program performance initial section section 45 present basic concepts pipelining recent trends covered section 410 section 411 describes recent intel core i7 arm cortexa8 architectures section 412 shows use instructionlevel parallelism double performance matrix multiply sectio ese sections provide enough background understand pipeline concepts high level reader interested understanding processor performance depth sections 43 44 46 useful ose interested learning build processor also cover 42 47 48 49 readers interest modern hardware design section 413 describes hardware design languages cad tools used implement hardware use hardware design language describe pipelined implementation also gives several illustrations pipelining hardware executes basic mips implementationwe examining implementation includes subset core mips instruction set e memoryreference instructions load word lw store word sw e arithmeticlogical instructions add sub slt e instructions branch equal beq jump j add last subset include integer instructions example multiply divide missing include oatingpoint instructions 41 introduction 245however illustrates key principles used creating datapath designing control e implementation remaining instructions similar examining implementation opportunity see instruction set architecture determines many aspects implementation choice various implementation strategies ects clock rate cpi computer many key design principles introduced chapter 1 illustrated looking implementation simplicity favors regularity addition concepts used implement mips subset chapter basic ideas used construct broad spectrum computers highperformance servers generalpurpose microprocessors embedded processors overview implementation chapter 2 looked core mips instructions including integer arithmeticlogical instructions memor yreference instructions branch instructions much needs done implement instructions independent exact class instruction every instruction th rst two steps identical 1 send program counter pc memory contains code fetch instruction memory 2 read one two registers usin elds instruction select registers read load word instruction need read one register instructions require reading two registers er two steps actions required complete instruction depend instruction class fortunately three instruction classes memoryreference arithmeticlogical branches actions largely independent exact instructio e simplicity regularity mips instruction set simp es implementation making execution many instruction classes similar example instruction classes except jump use arithmeticlogical unit alu er reading register e memoryreference instructions use alu address calculation arithmeticlog ical instructions operation execution branches compariso er using alu actions required complete various instruction class er memoryreference instruction need access memory either read data load write data store arithmeticlogical load instruction must write data alu memory back register lastly branch instruction may need change next instruction address based comparison otherwise pc incremented 4 get address next instruction figure 41 shows highlevel view mips implementation focusing various functional units interconnection although gure shows th ow data processor omits two important aspects instruction execution 246 chapter 4 processor first several places figure 41 shows data going particular unit coming tw erent sources example value written pc come one two adders data written regist le come either alu data memory second input alu come register immediat eld instruction practice data lines simply wired together must add logic element chooses among multiple sources steers one sources destinatio selection commonly done device called multiplexor although device might better called data selector appendix b describes multiplexor selects among several inputs based setting contro e control lines set based primarily information taken instruction executed e second omission figure 41 several units must controlled depending type instruction example data memory must read figure 41 abstract view implementation mips subset showing major functional units major connections instructions start using program counter supply instruction address instruction memory er instruction fetched register operands used instruction sp ed elds instruction register operands fetched operated compute memory address load store compute arithmetic result inte ger arithmeticlogical instruction compare branch instruction arithmeticlogical instruction result alu must written register operation load store alu result used address either store value registers load value memory register e result alu memory written back regist le branches require use alu output determine next instruction address comes either alu pc branch set summed adder increments current pc b e thick lines interconnecting functional units represent buses consist multip e arrows used guide reader knowing informatio ows since signal lines may cross explicitly show cros sing lines connected presence dot lines cross datapcaddressinstruction instructionmemory registers aluaddressdatadatamemory addadd4register register register 41 introduction 247on load written store e regist le must written load arithmeticlogical instruction course alu must perform one several operations appendix b describes detailed design alu like multiplexors control lines set basis variou elds instruction direct operations figure 42 shows datapath figure 41 three required multiplexors added well control lines major functional units control unit instruction input used determine set control lines functional units two multiplexor e third multiplexor datapcaddressinstruction instructionmemory registers aluaddressdatadatamemory addadd4memwrite memreadmuxmuxmuxcontrol regwrite zerobranch alu operation register register register figure 42 basic implementation mips subset including necessary multiplexors control lines e top multiplexor mux controls value replaces pc pc 4 branch destination address multiplexor c ontrolled gate ands together zero output alu control signal indicates instruction branc e middle multiplexor whose output returns regist le used steer output alu case arithmeticlogical instruction output data memory case load writing regist le finally bottommost multiplexor used determine whether second alu input registers arithmeticlogical instruction branch set eld instruction load stor e added control lines straightforward determine operation performed alu whether data memory read write whether registers perform write operatio e control lines shown color make easier see 248 chapter 4 processor determines whether pc 4 branch destination address written pc set based zero output alu used perform comparison beq instructio e regularity simplicity mips instruction set means simple decoding process used determine set control lines remainder chapter ne view details requires add functional units increase number connections units course enhance control unit control actions taken fo erent instruction classes sections 43 44 describe simple implementation uses single long clock cycle every instruction follows general form figures 41 42 rst design every instruction begins execution one clock edge completes execution next clock edge easier understand approach practical since clock cycle must severely stretched accommodate longest instructio er designing control simple computer look pipelined implementation complexities including exceptions many th classic components computershown page 243do figures 41 42 include 42 logic design conventions discuss design computer must decide hardware logic implementing computer operate computer clocked section reviews key ideas digital logic use extensively chapter little background digital logic yo nd helpful read appendix b continuing e datapath elements mips implementation consist tw erent types logic elements elements operate data values elements contain state e elements operate data values combinational means outputs depend current inputs given input combinational element always produces outpu e alu shown figure 41 discussed appendix b example combinational element given set inputs always produces output internal storage elements design combinational instead contain state element contains state internal storage call elements state elements pulled power plug computer could restart accurately loading state elements values contained pulled plug furthermore saved restored state elements would computer never lost power us state elements completely characterize computer figure 41 instruction data memories well registers examples state elements check combinational element operational element gate alu state element memory element register memory 42 logic design conventions 249a state element least two inputs one outpu e required inputs data value written element clock determines data value writt e output state element provides value written earlier clock cycle example one logically simplest state elements dtyp op see appendix b exactly two inputs value clock one output addition ops mips implementation uses two types state elements memories registers appear figure 41 e clock used determine state element written state element read time logic components contain state also called sequential outputs depend inputs contents internal state example output functional unit representing registers depends register numbers supplied written registers previously e operation combinational sequential elements construction discussed detail appendix b clocking methodology clocking methodology nes signals read written important specify timing reads writes signal written time read value read could correspond old value newly written value even mix two computer designs tolerate unpredictability clocking methodology designed make hardware predictable simplicity assume edgetriggered clocking methodology edgetriggered clocking methodology means values stored sequential logic element updated clock edge quick transition low high vice versa see figure 43 state elements store data value collection combinational logic must inputs come set state elements outputs written set state elemen e inputs values written previous clock cycle outputs values used following clock cycle clocking methodology e approach used determine data valid stable relative clock edgetriggered clocking clocking scheme state changes occur clock edge stateelement1stateelement2combinational logicclock cycle figure 43 combinational logic state elements clock closely related synchronous digital system clock determines elements state write values internal storage inputs state element must reach stable value reached value change er clock edge active clock edge causes state updated state elements chapter including memory assumed positive edgetriggered change rising clock edge 250 chapter 4 processor figure 43 shows two state elements surrounding block combinational logic operates single clock cycle signals must propagate state element 1 combinational logic state element 2 time one clock cycle e time necessary signals reach state elemen nes length clock cycle simplicity show write control signal state element written every active clock edge contrast state element updated every clock explicit write control signal required clock signal write control signal inputs state element changed write control signal asserted clock edge occurs use word asserted indicate signal logically high assert specify signal shou ld driven logically high deassert deasserted represent logically low use terms assert deassert implement hardware times 1 represents logically high times represent logically low edgetriggered methodology allows us read contents register send value combinational logic write register clock cycle figure 44 gives generic example doesnt matter whether assume writes take place rising clock edge low high falling clock edge high low since inputs combinational logic block change except chosen clock edge book use rising clock edge edgetriggered timing methodology feedback within single clock cycle logic figure 44 works correctly appendix b br discuss additional timing constraints setup hold times well timing methodologies 32bit mips architecture nearly state logic elements inputs outputs 32 bits wide since width data handled processor make clear whenever unit input output 32 bits widt e gures indicate buses signals wider 1 bit thicker lines times want combine several buses form wider bus example may want obtain 32bit bus combining two 16bit buses cases labels bus lines make control signal signal used multiplexor selection directing operation functional unit contrasts data signal contains information operated functional unit asserted e signal logically high true deasserted e signal logically low false stateelementcombinational logicfigure 44 edgetriggered methodology allows state element read written clock cycle without creating race could lead indeterminate data values course clock cycle still must long enough input values stable active clock edge occurs feedback occur within one clock cycle edgetriggered update state element feedback poss ible design could work properly designs chapter next rely edgetriggered timing methodology structures like one shown th gure 43 building datapath 251clear concatenating buses form wider bus arrows also added help clarify direction th ow data elements finally color indicates control signal opposed signal carries data distinction become clearer proceed chapter true false regist le read written clock cycle mips datapath using edgetriggered writes must one copy regist le elaboration also 64bit version mips architecture naturally enough paths implementation would 64 bits wide 43 building datapath reasonable way start datapath design examine major components required execute class mips instructions lets start top looking datapath elements instruction needs work way levels abstraction show datapath elements also show control signals use abstraction explanation starting bottom figure 45a shows th rst element need memory unit store instructions program supply instructions given address figure 45b also shows program counter pc saw chapter 2 register holds address current instruction lastly need adder increment pc address next instructio adder combinational built alu described detail appendix b simply wiring control lines control always sp es add operation draw alu label add figure 45 indicate permanently made adder perform alu functions execute instruction must start fetching instruction memory prepare executing next instruction must also increment program counter points next instruction 4 bytes later figure 46 shows combine three elements figure 45 form datapath fetches instructions increments pc obtain address next sequential instruction lets consider rformat instructions see figure 220 page 120 ey read two registers perform alu operation contents registers write result register call instructions either rtype instructions arithmeticlogical instructions since perform arithmetic logical operation instruction class includes add sub slt check datapath element unit used operate hold data within processor mips implementation datapath elements include instruction data memories register le alu adders program counter pc e register containing address instruction program executed 252 chapter 4 processor introduced chapter 2 recall typical instance instruction add t1t2t3 reads t2 t3 writes t1 e processors 32 generalpurpose registers stored structure called register le regist le collection registers register read written specifying number register th le e regist le contains register state computer addition need alu operate values read registers rformat instructions three register operands need read two data words regist le write one data word regist le instruction data word read registers need input regist le sp es register number read output regist le carry value read registers write data word need two inputs one specify register number written one supply data written register e regist le always outputs contents whatever register numbers read register inputs writes however controlled write control signal must asserted write occur clock edge figure 47a shows result need total four inputs three register numbers one data two outputs dat e register number inputs 5 bits wide specify one 32 registers 32 2 5 whereas data input two data output buses 32 bits wide figure 47b shows alu takes two 32bit inputs produces 32bit result well 1bit signal resul e 4bit control signal alu described detail appendix b review alu control shortly need know set register le state element consists set registers read written supplying register number accessed instruction addressinstruction instructionmemory instruction memory pcb program counter add sumc adder figure 45 two state elements needed store access instructions adder needed compute next instruction address e state elements instruction memory program counter e instruction memory need provide read access datapath write instructions since instruction memory reads treat combinational logic output time r ects contents location sp ed address input read control signal needed need write instruction memory load program hard add ignore simplicity e program counter 32bit register written end every clock cycle thus need write control signal e adder alu wired always add two 32bit inputs place sum output 43 building datapath 253pcreadaddressinstructioninstructionmemoryadd4figure 46 portion datapath used fetching instructions incrementing program counter e fetched instruction used parts datapath read register 1registers aludatadatazeroaluresultregwrite registers b alu 55 5registernumbers readdata 1readdata 2alu operation 4read register 2write registerwrite datafigure 47 two elements needed implement rformat alu operations register ﬁ le alu e regist le contains registers two read ports one write por e design multiported regist les discussed section b8 appendix b e regist le always outputs contents registers corresponding read register inputs outputs control inputs needed contrast register write must explicitly indicated asserting write control signal remember writes edgetriggered write inputs ie value written register number write control signal must valid clock edge since writes regist le edgetriggered design legally read write register within clock cycle read get value written earlier clock cycle value written available read subsequent clock cycle e inputs carrying register number regist le 5 bits wide whereas lines carrying data values 32 bits wide e operation performed alu controlled alu operation signal 4 bits wide using alu designed appendix b use zero detection output alu shortly implement branch e ow output needed section 49 discuss exceptions omit 254 chapter 4 processor next consider mips load word store word instructions general form lw t1offset_valuet2 sw t1offset_value t2 ese instructions compute memory address adding base register t2 16bit signed set eld contained instruction instruction store value stored must also read regist le resides t1 instruction load value read memory must written regist le sp ed register t1 us need regist le alu figure 47 addition need unit signextend 16bit set eld instruction 32bit signed value data memory unit read write e data memory must written store instructions hence data memory read write control signals address input input data written memory figure 48 shows two elements e beq instruction three operands two registers compared equality 16bit set used compute branch target address relative branch instruction address form beq t1t2offset implement instruction must compute branch target address adding signextended set eld instruction th ere two details th nition branch instructions see chapter 2 must pay attention e instruction set architecture sp es base branch address calculation address instruction following branch since compute pc 4 address next instruction instruction fetch datapath easy use value base computing branch target address e architecture also states set ed 2 bits word set th increases th ective range set eld factor 4 deal latter complication need set eld 2 well computing branch target address must also determine whether next instruction instruction follows sequentially instruction branch target address condition true ie operands equal branch target address becomes new pc say branch taken operands equal incremented pc replace current pc normal instruction case say branch taken us branch datapath must two operations compute branch target address compare register contents branches also ect instruction fetch portion datapath deal shortly figure 49 shows structure datapath segment handles branches compute branch target address branch datapath includes sign extension unit figure 48 adder perform compare need use regist le shown figure 47a supply two register operands although need write regist le addition comparison done using alu signextend increase size data item replicating highorder sign bit original data item high order bits larger destination data item branch target address e address sp ed branch becomes new program counter pc branch taken mips architecture branch target given sum set eld instruction address instruction following branch branch taken branch branch condition satis ed program counter pc becomes branch target unconditional jumps taken branches branch taken untaken branch branch branch condition false program counter pc becomes address instruction sequentially follows branch 43 building datapath 255designed appendix b since alu provides output signal indicates whether result 0 send two register operands alu control set subtract zero signal alu unit asserted know two values equal although zero output always signals result 0 using implement equal test branches later show exactly connect control signals alu use datapath e jump instruction operates replacing lower 28 bits pc lower 26 bits instructio ed 2 bits simply concatenating 00 jump set accomplishes th described chapter 2 elaboration mips instruction set branches delayed meaning instruction immediately following branch always executed independent whether branch condition true false condition false execution looks like normal branch condition true dela rst executes instruction immediately following branch sequential instruction order ed branch target address motivation delayed branches arises pipelining affects branches see section 48 simplicity generally ignore delayed branches chapter implement nondelayed beq instruction branch type branch instruction immediately following branch always executed independent whether branch condition true false addressreaddatadatamemory data memory unit write datamemreadmemwrite b sign extension unit signextend 1632figure 48 two units needed implement loads stores addition register ﬁ le alu figure 47 data memory unit sign extension unit e memory unit state element inputs address write data single output read resul ere separate read write controls although one may asserted given cloc e memory unit needs read signa l since unlike regist le reading value invalid address cause problems see chapt e sign extension unit 16bit input signextended 32bit result appearing output see chapter 2 assume data memory edgetriggered writes standard memory chips actually write enable signal used writes although write enable edg etriggered edgetriggered design could easily adapted work real memory chips see section b8 appendix b discussion real memory chips work 256 chapter 4 processor creating single datapathnow examined datapath components needed individual instruction classes combine single datapath add control complete implementatio simplest datapath attempt execute instructions one clock cycle means datapath resource used per instruction element needed must duplicated therefore need memory instructions separate one data although functional units need duplicated many elements shared b erent instructio ows share datapath element tw erent instruction classes may need allow multiple connections input element using multiplexor control signal select among multiple inputs readregister 1registers aluzeroregwrite readdata 1readdata 2alu operation 4to branch control logicadd sumbranch targetpc4 instruction datapath signextend 1632instruction shiftleft 2read register 2write registerwrite datafigure 49 datapath branch uses alu evaluate branch condition separate adder compute branch target sum incremented pc signextended lower 16 bits instruction branch displacement shifted left 2 bits e unit labeled shi 2 simply routing signals input output adds 00 two loworder end signextended set eld actu hardware needed since amount constant since know set signextended 16 bits th throw away sign bits control logic used decide whether incremented pc branch target replace pc based zero output alu 43 building datapath 257building datapath e operations arithmeticlogical rtype instructions memory instructions datapath quite similar e ke erences following e arithmeticlogical instructions use alu inputs coming two register e memory instructions also use alu address calculation although second input sign extended 16bit set eld instruction e value stored destination register comes alu rtype instruction memory load show build datapath operational portion memory reference arithmeticlogical instructions uses single regist le single alu handle types instructions adding necessary multiplexors create datapath single regist le single alu must support tw erent sources second alu input well tw erent sources data stored regist le us one multiplexor placed alu input another data input regist le figure 410 shows operational portion combined datapath combine pieces make simple datapath core mips architecture adding datapath instruction fetch figure 46 datapath rtype memory instructions figure 410 datapath branches figure 49 figure 411 shows datapath obtain composing separate pi e branch instruction uses main alu comparison register operands must keep adder figure 49 computing branch target address additional multiplexor required select either sequentially following instruction address pc 4 branch target address written pc completed simple datapath add control unit e control unit must able take inputs generate write signal state element selector control multiplexor alu control e alu contro erent number ways useful design rst design rest control unit following correct load instruction refer figure 410 memtoreg set cause data memory sent regist le exampleanswercheck 258 chapter 4 processor readregister 1readregister 2write registerwrite datawrite dataregisters aluzeroregwrite memreadmemwrite memtoregreaddata 1readdata 2alu operation 4signextend 1632instruction aluresultmux01mux1 0alusrcaddressdatamemory readdatafigure 410 datapath memory instructions rtype instructions example shows single datapath assembled pieces figures 47 48 adding multiplexors two multiplexors needed descri bed example readregister 1write dataregisters aluadd zeroregwrite memreadmemwrite pcsrcmemtoregreaddata 1readdata 2alu operation 4signextend 1632instruction aluresultaddaluresultmuxmuxmuxalusrcaddressdatamemory readdatashiftleft 24read addressinstructionmemory pcread register 2write registerwrite datafigure 411 simple datapath core mips architecture combines elements required different instruction classes e components come figures 46 49 410 datapath execute basic instructions loadstore word alu operations branches single clock cycle one additional multiplexor needed integrate branch e support jumps added later 44 simple implementation scheme 259b memtoreg set cause correct register destination sent regist le c care setting memtoreg loads e singlecycle datapath conceptually described section must separate instruction data memories formats data instructions ar erent mips hence erent memories needed b separate memories less expensive c processor operates one cycle use singleported memory tw erent accesses within cycle 44 simple implementation scheme section look might thought simplest possible implementation mips subset build simple implementation using datapath last section adding simple control functio simple implementation covers load word lw store word sw branch equal beq arithmeticlogical instructions add sub set less later enhance design include jump instruction jthe alu control e mips alu appendix b nes 6 following combinations four control inputs alu control linesfunction0000and0001or 0010add 0110subtract 0111set less 1100nor depending instruction class alu need perform one rst functions needed parts mips instruction set found subset implementing load word store word instructions use alu compute memory address addition rtype instructions alu needs perform one th actions subtract add set less depending value 6bit funct function eld 260 chapter 4 processor loworder bits instruction see chapter 2 branch equal alu must perform subtraction generate 4bit alu control input using small control unit inputs functio eld instruction 2bit contro eld call aluop aluop indicates whether operation performed add 00 loads stores subtract 01 beq determined operation encoded func e output alu control unit 4bit signal directly controls alu generating one 4bit combinations shown previously figure 412 show set alu control inputs based 2bit aluop control 6bit function code later chapter see aluop bits generated main control unit style using multiple levels decodingthat main control unit generates aluop bits used input alu control generates actual signals control alu unitis common implementation technique using multiple levels control reduce size main control unit using several smaller control units may also potentially increase speed control unit optimizations important since speed control unit en critical clock cycle time ere sev erent ways implement mapping 2bit al eld 6bit func eld four alu operation control bits small number 64 possible values functio eld interest function eld used aluop bits equal 10 use small piece logic recognizes subset possible values causes correct setting alu control bits step designing logic useful create truth table interesting combinations function co eld aluop bits weve instruction opcodealuopinstruction operationfunct þelddesired alu actionalu control inputlw 00load word xxxxxxadd 0010sw00store wordxxxxxxadd0010 branch equal01branch equalxxxxxxsubtract0110 rtype10add100000add0010 rtype10subtract100010subtract0110 rtype10and100100and0000 rtype10or100101or0001 rtype10set less than101010set less than0111 figure 412 alu control bits set depends aluop control bits different function codes rtype instruction e opcode listed th rst column determines setting aluop bits encodings shown binary notice aluop code 00 01 desired alu action depend function co eld case say dont care value function code func eld shown xxxxxx aluop value 10 function code used set alu control input see appendix b 44 simple implementation scheme 261done figure 413 truth table shows 4bit alu control set depending two inpu elds since full truth table large 2 8 256 entries dont care value alu control many input combinations show truth table entries alu control must sp c value roughout chapter use practice showing truth table entries outputs must asserted showing deasserted dont care practice disadvantage discuss section d2 appendix many instances care values inputs wish keep tables compact also include dontcare terms dontcare term truth table represented x input column indicates output depend value input corresponding column example aluop bits 00 th rst row figure 413 always set alu control 0010 independent function code case function code inputs dont cares line truth table later see examples another type dontcare term unfamiliar concept dontcare terms see appendix b information truth table constructed optimized turned gat process completely mechanical us rather show th nal steps describe process result section d2 appendix designing main control unitnow described design alu uses function code 2bit signal control inputs return looking rest control start process lets identify th elds instruction control lines needed datapath constructed figure 411 understand connect th elds instruction datapath useful review truth table logic representation logical operation listing values inputs case showing resulting outputs dontcare term element logical function output depend values inputs dontcare terms may sp ed erent ways aluopfunct þeldoperationaluop1aluop0f5f4f3f2f1f0 00xxxxxx 0010x1xxxxxx 0110 1xxx0000 0010 1xxx0010 0110 1xxx0100 00001xxx0101 0001 1xxx1010 0111 figure 413 truth table 4 alu control bits called operation e inputs aluop function co eld entries alu control asserted shown dontcare entries added example aluop use encoding 11 truth table contain entries 1x x1 rather 10 01 note functio eld used th rst 2 bits f5 f4 instructions always 10 dontcare terms replaced xx truth table 262 chapter 4 processor formats three instruction classes rtype branch loadstore instructions figure 414 shows formats ere several major observations instruction format rely e eld saw chapter 2 called opcode always contained bits 3126 refer eld op50 e two registers read always sp ed rs rt elds positions 2521 true rtype instructions branch equal store e base register load store instructions always bit positions 2521 rs e 16bit set branch equal load store always positions 150 e destination register one two places load bit positions 2016 rt rtype instruction bit positions 1511 rd us need add multiplexor select whic eld instruction used indicate register number written e rst design principle chapter 2 simplicity favors regularity pays specifying control opcode e eld denotes operation format instruction field 0rs rt rdshamtfunct bit positions312625212016151110650 rtype instruction field 35 43rs rt addressbit positions312625212016 150b load store instruction field 4rs rt addressbit positions312625212016 150c branch instruction figure 414 three instruction classes rtype load store branch use two different instruction formats e jump instructions use another format discuss shortly instruction format rformat instructions opcode ese instructions three register operands rs rt rd fields rs rt sources rd destinatio e alu function func eld decoded alu control design previous sectio e rtype instructions implement add sub slt e sham eld used fo ignore chapter b instruction format load opcode 35 ten store opcode 43 ten instruction e register rs base register added 16bit addr eld form memory address loads rt destination register loaded value fo r stores rt source register whose value stored memory c instruction format branch equal opco e registers rs rt source registers compared equality e 16bit addr eld signextended ed added pc 4 compute branch target address 44 simple implementation scheme 263using information add instruction labels extra multiplexor write register number input regist le simple datapath figure 415 shows additions plus alu control block write signals state elements read signal data memory control signals multiplexors since multiplexors two inputs require single control line figure 415 shows seven singlebit control lines plus 2bit aluop control signal alread ned aluop contro l signal works useful ne seven control signals informally determine set control signals instruction execution figure 416 describes function seven control lines looked function control signals look set th e control unit set one control signals based solely opco eld instructio e pcsrc control line exceptio control line asserted instruction branch equal decision control unit make zero output alu used equality comparison asserted generate pcsrc signal need together signal control unit call branch zero signal alu readregister 1write dataregisters aluadd zeromemreadmemwrite regwrite pcsrcmemtoregreaddata 1readdata 2signextend 1632instruction 310aluresultadd aluresultmuxmuxmuxalusrcaddressdatamemory readdatashiftleft 24read addressinstructionmemory pc100 101mux01alucontrolaluopinstruction 50 instruction 2521 instruction 1511 instruction 2016 instruction 150 regdstreadregister 2write registerwrite datafigure 415 datapath figure 411 necessary multiplexors control lines identiﬁ ed e control lines shown color e alu control block also added e pc require write control since written end every clock cycle branch control logic determines whether written incremented pc branch target ad dress 264 chapter 4 processor signal nameeffect deassertedeffect asserted regdstthe register destination number write register comes rt þeld bits 2016the register destination number write register comes rd þeld bits 1511regwritenone register write register input written value write data input alusrcthe second alu operand comes second register þle output read data 2the second alu operand sign extended lower 16 bits instruction pcsrcthe pc replaced output adder computes value pc 4the pc replaced output adder computes branch targetmemreadnone data memory contents designated address input put read data output memwritenone data memory contents designated address input replaced value write data inputmemtoregthe value fed register write data input comes aluthe value fed register write data input comes data memory figure 416 effect seven control signals 1bit control two way multiplexor asserted multiplexor selects input corresponding 1 otherwise control deasserted multiplexor selects 0 input remember state elements clock implicit input clock used controlling writes gating clock externally state element create timing problems see appendix b discussion problem ese nine control signals seven figure 416 two aluop set basis six input signals control unit opcode bits 31 26 figure 417 shows datapath control unit control signals try write set equations truth table control unit useful try ne control function informally setting control lines depends opcode w ne whether control signal 0 1 dont care x opcode values figure 418 nes control signals set opcode information follows directly figures 412 416 417 operation datapathwith information contained figures 416 418 design control unit logic lets look instruction uses datapath next fe gures show th ow thre erent instruction classes datapat e asserted control signals active datapath elements highlighted note multiplexor whose control 0 nite action even control line highlighted multiplebit control signals highlighted co nstituent signal asserted figure 419 shows operation datapath rtype instruction add t1t2t3 although everything occurs one clock cycle 44 simple implementation scheme 265think four steps execute instruction steps ordered th ow information e instruction fetched pc incremented 2 two registers t2 t3 read regist le also main control unit computes setting control lines step e alu operates data read regist le using function code bits 50 func eld instruction generate alu function readregister 1write dataregisters aluadd zeroreaddata 1readdata 2signextend 1632instruction 31ð0aluresultadd aluresultmuxmuxmuxaddressdatamemory readdatashiftleft 24read addressinstructionmemory pc100 101mux01alucontrol instruction 5ð0 instruction 25ð21 instruction 31ð26 instruction 15ð11 instruction 20ð16 instruction 15ð0 regdstbranch memread memtoreg aluop memwrite alusrc regwrite control readregister 2write registerwrite datafigure 417 simple datapath control unit e input control unit 6bit opco eld instruction e outputs control unit consist three 1bit signals used control multiplexors regdst alusrc memtor eg three signals controlling reads writes regist le data memory regwrite memread memwrite 1bit signal used determining whether possibly branch branch 2bit control signal alu aluop gate used combine branch control signal zero output alu gate output controls selection next pc notice pcsrc derived signal rather one coming directly control uni us drop signal name subsequen gures 266 chapter 4 processor instructionregdstalusrc memto regreg write mem readmem writebranchaluop1aluop0 rformat 1001000 10lw 011110000 swx1x001000 beqx0x000101 figure 418 setting control lines completely determined opcode ﬁ elds instruction e rst row table corresponds rformat instructions add sub slt instructions source regist elds rs rt destination regist eld rd th nes signals alusrc regdst set furthermore rtype instruction writes register regwrite 1 neither reads writes data memory branch control signal 0 pc unc onditionally replaced pc 4 otherwise pc replaced branch target zero output alu also hig e al eld rtype instructions set 10 indicate alu control generated func eld e second third rows table give control signal settings lw sw ese alusrc al elds set perform address calculatio e memread memwrite set perform memory access finally regdst regwrite set load cause result stored rt register e branch instruction similar rformat operation since sends rs rt registers alu e al eld branch set subtract alu control 01 used test equality notice memt eld irrelevant regwrite signal 0 since register written value data register data write port used us entry memtoreg last two rows table replaced x dont care dont cares also added regdst regwrite type dont care must added designer since depends knowledge datapath works readregister 1write dataregisters aluadd zeroreaddata 1readdata 2signextend 1632instruction 31œ0aluresultadd aluresultmuxmuxmuxaddressdatamemory readdatashiftleft 24read addressinstructionmemory pc100 101mux01alucontrol instruction 5œ0 instruction 25œ21 instruction 31œ26 instruction 15œ11 instruction 20œ16 instruction 15œ0 regdstbranch memread memtoreg aluop memwrite alusrcregwrite control readregister 2write registerwrite datafigure 419 datapath operation rtype instruction add t1t2t3 e control lines datapath units connections active highlighted 44 simple implementation scheme 267 e result alu written regist le using bits 1511 instruction select destination register t1similarly illustrate execution load word lw t1 offsett2in style similar figure 419 figure 420 shows active functional units asserted control lines load think load instruction operating steps similar rtype executed four 1 instruction fetched instruction memory pc incremented 2 register t2 value read regist le readregister 1write dataregisters aluadd zeroreaddata 1readdata 2signextend 1632instruction 31œ0aluresultadd aluresultmuxmuxmuxaddressdatamemory readdatashiftleft 24read addressinstructionmemory pc100 101mux01alucontrol instruction 5œ0 instruction 25œ21 instruction 31œ26 instruction 15œ11 instruction 20œ16 instruction 15œ0 regdstbranch memread memtoreg aluop memwrite alusrcregwrite control readregister 2write registerwrite datafigure 420 datapath operation load instruction e control lines datapath units connections active highlighted store instruction would operate similarly e erence would memory control would indicate write rather read second register value read would used data store operation writing data memory value regist le would occur 268 chapter 4 processor e alu computes sum value read regist le signextended lower 16 bits instruction offset e sum alu used address data memory e data memory unit written regist le register destination given bits 2016 instruction t1finally show operation branchonequal instruction beq t1 t2 offset fashion operates much like rformat instruction alu output used determine whether pc written pc 4 branch target address figure 421 shows four steps execution 1 instruction fetched instruction memory pc incremented readregister 1write dataregisters aluaddzeroreaddata 1readdata 2signextend 1632instruction 31œ0aluresultadd aluresultmuxmuxmuxaddressdatamemoryreaddatashiftleft 24read addressinstructionmemory pc100101mux01alucontrol instruction 5œ0 instruction 25œ21 instruction 31œ26instruction 15œ11 instruction 20œ16 instruction 15œ0regdstbranch memread memtoreg aluop memwrite alusrc regwrite control readregister 2write registerwritedatafigure 421 datapath operation branchonequal instruction e control lines datapath units connections active highlighted er using regist le alu perform compare zero output used select next program counter two candidates 44 simple implementation scheme 2692 two registers t1 t2 read regist le e alu performs subtract data values read regist le e value pc 4 added signextended lower 16 bits instruction offset ed two result branch target address e zero result alu used decide adder result store pc finalizing control seen instructions operate steps lets continue control implementatio e control function precisel ned using contents figure 418 e outputs control lines input 6bit opco eld us create truth table outputs based binary encoding opcodes figure 422 shows logic control unit one large truth table combines outputs uses opcode bits inputs completely sp es control function implement directly gates automated fashion show th nal step section d2 appendix input outputsignal namerformat lwswbeq inputsop50110op40000op30010op20001op10110op00110outputsregdst10xxalusrc0110memtoreg01xxregwrite1100memread0100memwrite0010branch0001aluop11000aluop00001figure 422 control function simple singlecycle implementation completely speciﬁ ed truth table e top half table gives combinations input signals correspond four opcodes one per column determine control output settings remember op 50 corresponds bits 3126 instruction eld e bottom portion table gives outputs four opco us output regwrite asserted tw erent combinations inputs consider four opcodes shown table simplify truth table using dont cares input portion example detect rformat instruction expression op5 op2 since th cient distinguish rformat instructions lw sw beq take advantage simp cation since rest mips opcodes used full implementation 270 chapter 4 processor singlecycle implementation mips core instruction set lets add jump instruction show basic datapath control extended handle instructions instruction set implementing jumpsfigure 417 shows implementation many instructions looked chapter 2 one class instructions missing jump instruction extend datapath control figure 417 include jump instruction describe set new control lines e jump instruction shown figure 423 looks somewhat like branch instruction computes targ erently conditional like branch loworder 2 bits jump address always 00 two e next lower 26 bits 32bit address come 26bit immediat eld instructio e upper 4 bits address replace pc come pc jump instruction pl us implement jump storing pc concatenation upper 4 bits current pc 4 bits 3128 sequentially following instruction address 26bit immediate eld jump instruction bits 00 two figure 424 shows addition control jump added figure 417 additional multiplexor used select source new pc value either incremented pc pc 4 branch target pc jump target pc one additional control signal needed additional multiplexor control signal called jump asserted instruction jump opcode 2 exampleanswerfield 000010addressbit positions3126250figure 423 instruction format jump instruction opcode 2 e destination address jump instruction formed concatenating upper 4 bits current pc 4 26bit addr eld jump instruction adding 00 2 loworder bits singlecycle implementation also called single clock cycle implementation implementation instruction executed one clock cycle easy understand slow practical 44 simple implementation scheme 271why singlecycle implementation used today although singlecycle design work correctly would used modern designs cient see notice clock cycle must length every instruction singlecycle design course longest possible path processor determines clock cycle path almost certainly load instruction us functional units series instruction memory regist le alu data memory regist le although cpi 1 see chapter 1 overall performance singlecycle implementation likely poor since clock cycle long e penalty using singlecycle design wit xed clock cyc cant might considered acceptable small instruction set historically early readregister 1write dataregisters aluadd zeroreaddata 1readdata 2signextend 1632instruction 31œ0aluresultadd aluresultmuxmuxmuxaddressdatamemory readdatashiftleft 24read addressinstructionmemory pc100101mux01alucontrol instruction 5œ0 instruction 25œ21 instruction 31œ26 instruction 15œ11 instruction 20œ16instruction 15œ0 regdstjump branch memread memtoregaluop memwrite alusrc regwrite control readregister 2write registerwrite datamux10shiftleft 2instruction 25œ0 jump address 31œ0 2628pc 4 31œ28figure 424 simple control datapath extended handle jump instruction additional multiplexor upper right used choose jump target either branch target sequential instruction following one multiplexor controlled jump control signal e jump target address obtained ing lower 26 bits jump instruction 2 bi ectively adding 00 loworder bits concatenating upper 4 bits pc 4 highorder bits thus yield ing 32bit address 272 chapter 4 processor computers simple instruction sets use implementation technique however tried implement th oatingpoint unit instruction set complex instructions singlecycle design wouldnt work well must assume clock cycle equal worstcase delay instructions useless try implementation techniques reduce delay common case improve worstcase cycle time single cycle implementation thus violates great idea chapter 1 making common case fast next section well look another implementation technique called pipelining uses datapath similar singlecycle datapath much e cient much higher throughput pipelining improves ciency executing multiple instructions simultaneously look control signals figure 422 combine together control signal output th gure replaced inverse another hint take account dont cares use one signal without adding inverter 45 overview pipelining pipelining implementation technique multiple instructions overlapped execution today pipelining nearly universal section relies heavily one analogy give overview pipelining terms issues interested big picture concentrate section skip sections 410 411 see introduction advanced pipelining techniques used recent processors intel core i7 arm cortexa8 interested exploring anatomy pipelined computer section good introduction sections 46 49 anyone done lot laundry intuitively used pipelinin e non pipelined approach laundry would follows 1 place one dirty load clothes washer 2 th nished place wet load dryer 3 dry nished place dry load table fold 4 foldin nished ask roommate put clothes away roommate done start next dirty load e pipelined approach takes much less time figure 425 shows soon th nished th rst load placed dryer load washer second dirty load th rst load dry place table start folding move wet load dryer put next dirty load check pipelining implementation technique multiple instructions overlapped execution much like assembly line never waste time american proverb 45 overview pipelining 273into washer next roommate put th rst load away start folding second load dryer third load put fourth load washer point stepscalled stages pipeliningare operating concurrently long separate resources stage pipeline tasks e pipelining paradox time placing single dirty sock washer dried folded put away shorter pipelining reason pipelining faster many loads everything working parallel loads ar nished per hour pipelining improves throughput laundry system hence pipelining would decrease time complete one load laundry many loads laundry improvement throughput decreases total time complete work stages take amount time enough work speedup due pipelining equal number stages timetaskorderab c d6 pm78910111212 timetaskorderab cd6 pm78910111212 figure 425 laundry analogy pipelining ann brian cathy dirty clothes washed dried folded put away e washer dryer folder storer take 30 minutes task sequential laundry takes 8 hours 4 loads wash whi le pipelined laundry takes 35 hours show pipeline stage erent loads time showing copies four resources twodimensional time line really one resource 274 chapter 4 processor pipeline case four washing drying folding putting away erefore pipelined laundry potentially four tim es faster nonpipelined 20 loads would take 5 times long 1 load 20 loads sequential laundry takes 20 times long 1 load 23 times faster figure 425 show 4 loads notice beginning end workload pipelined version figure 425 pipeline completely full startup wind ects performance number tasks large compared number stages pipeline number loads much larger 4 stages full time increase throughput close 4 e principles apply processors pipeline instructionexecution mips instructions classically tak steps 1 fetch instruction memory 2 read registers decoding instructio e regular format mips instructions allows reading decoding occur simultaneously 3 execute operation calculate address 4 access operand data memory 5 write result register hence mips pipeline explore chapt stag e following example shows pipelining speeds instruction execution speeds laundry singlecycle versus pipelined performance make discussion concrete lets create pipeline example rest chapter limit attention eight instructions load word lw store word sw add add subtract sub set less slt branch equal beqcompare average time instructions singlecycle implementation instructions take one clock cycle pipelined implementatio e operation times major functional units example 200 ps memory access 200 ps alu operation 100 ps regist le read write singlecycle model every instruction takes exactly one clock cycle clock cycle must stretched accommodate slowest instruction figure 426 shows time required eight instructions e singlecycle design must allow slowest instructionin figure 426 lwso time required every instruction 800 ps similarly exampleanswer 45 overview pipelining 275to figure 425 figure 427 compares nonpipelined pipelined execution three load word instruction us time th rst fourth instructions nonpipelined design 3 800 ns 2400 ps pipeline stages take single clock cycle clock cycle must long enough accommodate slowest operation singlecycle design must take worstcase clock cycle 800 ps even though instructions fast 500 ps pipelined execution clock cycle must worstcase clock cycle 200 ps even though stages take 100 ps pipelining still ers fourfold performance improvement time th rst fourth instructions 3 200 ps 600 ps turn pipelining speedup discussion formula stages perfectly balanced time instructions pipelined processorassuming ideal conditionsis equal time bet tions time ins tructio pipelined ween instruc nn nonpipelinednumber pipe stages ideal conditions large number instructions speedup pipelining approximately equal number pipe stag vestage pipeline nearly times faster e formula suggests tha vestage pipeline er nearly vefold improvement 800 ps nonpipelined time 160 ps clock cycle e example shows however stages may imperfectly balanced moreover pipelining involves overhead source clearer shortly us time per instruction pipelined processor exceed minimum possible speedup less number pipeline stages instruction class instruction fetchregister read alu operationdata accessregister writetotal timeload word lw200 ps100 ps200 ps200 ps100 ps800 ps store word sw200 ps100 ps200 ps200 ps 700 psrformat add sub slt200 ps100 ps200 ps100 ps600 ps branch beq200 ps100 ps200 ps 500 psfigure 426 total time instruction calculated time component calculation assumes multiplexors control unit pc accesses sign extension unit delay 276 chapter 4 processor moreover even claim fourfold improvement example ected total execution time three instructions 1400 ps versus 2400 ps course number instructions large would happen increased number instructions could extend previo gures 1000003 instructions would add 1000000 instructions pipelined example instruction adds 200 ps total execution time e total execution time would 1000000 200 ps 1400 ps 200001400 ps nonpipelined example would add 1000000 instructions taking 800 ps total execution time would 1000000 800 ps 2400 ps 800002400 ps conditions ratio total execution times real programs nonpipelined pipelined pr ocessors close ratio times instructions 800002400 200001400 pspspsps800 200400programexecution order instructionslw 1 1000lw 2 2000 lw 3 3000time100012001400 200400600800 100012001400 200400600800 16001800 instructionfetchdataaccessreginstructionfetchdataaccessreginstructionfetch800 ps800 ps800 psprogramexecution order instructionslw 1 1000lw 2 2000 lw 3 3000timeinstructionfetchdataaccessreginstructionfetchinstructionfetchdataaccessregdataaccessreg200 ps200 ps200 ps200 ps200 ps200 ps200 psaluregaluregalualualuregregregfigure 427 singlecycle nonpipelined execution top versus pipelined execution bottom use hardware components whose time listed figure 426 case see fourfold speedup average time instructions 800 ps 200 ps compare gure figure 425 laundry assumed stages equal dryer slowest dryer stage would set stage time e pipeline stage times computer also limited slowest resource either alu operation memory access assume write regist le occurs th rst half clock cycle read regist le occurs second half use assumption throughout chapter 45 overview pipelining 277pipelining improves performance increasing instruction throughput opposed decreasing execution time individual instruction instruction throughput important metric real programs execute billions instructions designing instruction sets pipelining even simple explanation pipelining get insight design mips instruction set designed pipelined execution first mips instructions lengt restriction makes much easier fetch instructions th rst pipeline stage decode second stage instruction set like x86 instructions vary 1 byte 15 bytes pipelining considerably challenging recent implementations x86 architecture actually translate x86 instructions simple operations look like mips instructions pipeline simple operations rather native x86 instructions see section 410 second mips instruction formats source regist elds located place instructio symmetry means second stage begin reading regist le time hardware determining type instruction fetched mips instruction formats symmetric would need sp lit stage 2 resulting six pipeline stages shortly see downside longer pipelines ird memory operands appear loads stor restriction means use execute stage calculate memory address access memory following stage could operate operands memory x86 stages 3 4 would expand address stage memory stage execute stage fourth discussed chapter 2 operands must aligned memory hence need worry single data transfer instruction requiring two data memory accesses requested data transferred processor memory single pipeline stage pipeline hazards ere situations pipelining next instruction execute following clock cycle ese events called hazards thre erent types hazards e rst hazard called structural hazard means hardware support combination instructions want execute clock cycle structural hazard laundry room would occur used washer dryer combination instead separate washer dryer roommate busy something else wouldnt put clothes away carefully scheduled pipeline plans would foiled structural hazard planned instruction execute proper clock cycle hardware support combination instructions set execute 278 chapter 4 processor said mips instruction set designed pipelined making fairly easy designers avoid structural hazards designing pipeline suppose however single memory instead two memories pipeline figure 427 fourth instruction would see clock cycle th rst instruction accessing data memory fourth instruction fetching instruction memory without two memories pipeline could structural hazard data hazardsdata hazards occur pipeline must stalled one step must wait another complete suppose found sock folding station match existed one possible strategy run room search clothes bureau see ca nd match obviously search loads must wait completed drying ready fold well hav nished washing ready dry computer pipeline data hazards arise dependence one instruction earlier one still pipeline relationship really exist laundry example suppose add instruction followed immediately subtract instruction uses sum s0add s0 t0 t1sub t2 s0 t3without intervention data hazard could severely stall pipeline e add instruction doesnt write result th h stage meaning would waste three clock cycles pipeline although could try rely compilers remove hazards results would satisfactory ese dependences happen en delay long expect compiler rescue us dilemma e primary solution based observation dont need wait instruction complete trying resolve data hazard code sequence soon alu creates sum add supply input subtract adding extra hardware retrieve missing item early internal resources called forwarding bypassing forwarding two instructions two instructions show pipeline stages would connected forwarding use drawing figure 428 represent datapath th stages pipeline align copy datapath instruction similar laundry pipeline figure 425 data hazard also called pipeline data hazard planned instruction execute proper clock cycle data needed execute instruction yet available forwarding also called bypassing method resolving data hazard retrieving missing data element internal bu ers rather waiting arrive programmer visible registers memory example 45 overview pipelining 279figure 429 shows connection forward value s0 er execution stage add instruction input execution stage sub instruction graphical representation events forwarding paths valid destination stage later time source stage example valid forwarding path output memory access stage th rst instruction input execution stage following since would mean going backward time forwarding works well described detail section 47 prevent pipeline stalls however example suppose th rst instruction load s0 instead add imagine looking figure 429 answertimeadd s0 t0 t1ifmemidwbex2004006008001000 figure 428 graphical representation instruction pipeline similar spirit laundry pipeline figure 425 use symbols representing physical resources abbreviations pipeline stages used throughout chapter e symbols th stages instruction fetch stage box representing instruction memory id instruction decode regist le read stage drawing showing regist le read ex execution stage drawing representing alu mem memory access stage box representing data memory wb writeback stage drawing showing regist le writt e shading indicates element used instruction hence mem white background add access data memory shading right half regist le memory means element read stage shading th half means written stage hence right half id shaded second stage regist le read th half wb shaded th h stage regist le written timeadd s0 t0 t1sub t2 s0 t3 ifmemidwbexifmemidwbexprogram execution order instructions 2004006008001000 figure 429 graphical representation forwarding e connection shows forwarding path output ex stage add input ex stage sub replacing value register s0 read second stage sub 280 chapter 4 processor desired data would available er fourth stage th rst instruction dependence late input third stage sub hence even forwarding would stall one stage loaduse data hazard figure 430 sho gure shows important pipeline concept cially called pipeline stall en given nickname bubble shall see stalls elsewhere pipeline section 47 shows handle hard cases like using either hardware detection stalls ware reorders code try avoid loaduse pipeline stalls example illustrates reordering code avoid pipeline stalls consider following code segment c b ec b fhere generated mips code segment assuming variables memory addressable sets t0lw t1 0t0lw t2 4t0 add t3 t1t2 sw t3 12t0 lw t4 8t0 add t5 t1t4 sw t5 16t0loaduse data hazard sp c form data hazard data loaded load instruction yet become available needed another instruction pipeline stall also called bubble stall initiated order resolve hazard example200400600800100012001400 timelw s0 20t1sub t2 s0 t3 ifmemidwbexifmemidwbexprogramexecution order instructionsbubblebubblebubblebubblebubblefigure 430 need stall even forwarding rformat instruction following load tries use data without stall path memory access stage output execution stage input would going backward time impossible gure actually simp cation since know er subtract instruction fetched decoded whether stall necessary section 47 shows details really happens case hazard 45 overview pipelining 281find hazards preceding code segment reorder instructions avoid pipeline stalls add instructions hazard respective dependence immediately preceding lw instruction notice bypassing eliminates several potential hazards including dependence th rst add th rst lw hazards store instructions moving third lw instruction become third instruction eliminates hazards lw t1 0t0lw t2 4t0lw t4 8t0add t3 t1t2sw t3 12t0 add t5 t1t4 sw t5 16t0on pipelined processor forwar ding reordered sequence complete two fewer cycles original version forwarding yields another insight mips architecture addition four mentioned page 277 mips instruction writes one result last stage pipeline forwarding harder multiple results forward per instruction need write result early instruction execution elaboration name forwarding comes idea result passed forward earlier instruction later instruction bypassing comes le desired unit control hazards e third type hazard called control hazard arising need make decision based results one instruction others executing suppose laundry crew given happy task cleaning uniforms football team given ho lthy laundry need determine whether detergent water temperature setting select strong enough get uniforms clean strong uniforms wear sooner laundry pipeline wait er second stage examine dry uniform see need change washer setup th rst two solutions control hazards laundry room computer equivalent stall operate sequentially th rst batch dry repeat right formula conservative option certainly works slow answercontrol hazard also called branch hazard proper instruction execute proper pipeline clock cycle instruction fetched one needed th ow instruction addresses pipeline expected 282 chapter 4 processor e equivalent decision task computer branch instruction notice must begin fetching instruction following branch next clock cycle nevertheless pipeline po ssibly know next instruction since received branch instruction memory laundry one possible solution stall immediately er fetch branch waiting pipeline determines outcome branch knows instruction address fetch lets assume put enough extra hardware test registers calculate branch address update pc second stage pipeline see section 48 details even extra hardware pipeline involving conditional branches would look like figure 431 e lw instruction executed branch fails stalled one extra 200 ps clock cycle starting performance stall branch estimate impact clock cycles per instruction cpi stalling branches assume instructions cpi 1 figure 327 chapter 3 shows branches 17 instructions executed specint2006 since instructions run cpi 1 branches took one extra clock cycle stall would see cpi 117 hence slowdown 117 versus ideal case exampleansweradd 4 5 6beq 1 2 40or 7 8 9timeinstructionfetchdataaccessdataaccessdataaccessreginstructionfetchinstructionfetchregreg200 ps400 psbubblebubblebubblebubblebubble200400600800100012001400 programexecution order instructionsregaluregalu regalu figure 431 pipeline showing stalling every conditional branch solution control hazards example assumes conditional branch taken instruction destination branch instructio ere onestage pipeline stall bubble er branch reality process creating stall slightly complicated see sectio e ect performance however would occur bubble inserted 45 overview pipelining 283if resolve branch second stage en case longer pipelines wed see even larger slowdown stall branch e cost option high computers use motivates second solution control hazard using one great ideas chapter 1 predict youre pretty sure right formula wash uniforms predict work wash second load waiting th rst load dry option slow pipeline correct wrong however need redo load washed guessing decision computers indeed use prediction handle branches one simple approach predict always branches untaken youre right pipeline proceeds full speed branches taken pipeline stall figure 432 shows example add 4 5 6beq 1 2 40 lw 3 3000 timeinstructionfetchinstructionfetchdataaccessreginstructionfetchdataaccessdataaccessregregregalu regalu regaluregalu regalu regalu 200 ps200 psadd 4 5 6 beq 1 2 40or 7 8 9timeinstructionfetchdataaccessreginstructionfetchinstructionfetchdataaccessregdataaccessreg200 ps400 psbubblebubblebubblebubblebubble200400600800100012001400 programexecution order instructions200400600800100012001400 program execution order instructionsfigure 432 predicting branches taken solution control hazard e top drawing shows pipeline branch tak e bottom drawing shows pipeline branch taken noted figure 431 insertion bubble fashion simp es actually happens least th rst clock cycle immediately following branch section 48 reveal details 284 chapter 4 processor sophisticated version branch prediction would branches predicted taken untaken analogy dark home uniforms might take one formula light road uniforms might take another case programming bottom loops branches jump back top loop since likely taken branch backward could always predict taken branches jump earlier address rigid approaches branch prediction rely stereotypical behavior dont account individuality sp c branch instruction dynamic hardware predictors stark contrast make guesses depending behavior branch may change predictions branch life program following analogy dynamic prediction person would look dirty uniform guess formula adjusting next prediction depending success recent guesses one popular approach dynamic prediction branches keeping history branch taken untaken using recent past behavior predict future see later amount type history kept become extensive result dynamic branch predictors correctly predict branches 90 accuracy see section 48 guess wrong pipeline control must ensure instructions following wrongly guessed branch hav ect must restart pipeline proper branch address laundry analogy must stop taking new loads restart load incorrectly predicted case solutions control hazards longer pipelines exacerbate problem case raising cost misprediction solutions control hazards described detail section 48 elaboration third approach control hazard called delayed decision analogy whenever going make decision laundry place load nonfootball clothes washer waiting football uniforms dry long enough dirty clothes affected test solution wor ne called delayed branch computers mentioned solution actually used mips architecture delayed branch always executes next sequential instruction branch taking place one instruction delay hidden mips assembly language programmer assembler automatically arrange instructions get branch behavior desired programmer mips software place instruction immediately delayed branch instruction affected branch taken branch changes address instruction follows safe instruction example add instruction branch figure 431 affect branch moved branch fully hide branch delay since delayed branches useful branches short processor uses delayed branch one cycle longer branch delays hardwarebased branch prediction usually usedbranch prediction method resolving branch hazard assumes given outcome branch proceeds assumption rather waiting ascertain actual outcome 45 overview pipelining 285pipeline overview summary pipelining technique exploits parallelism among instructions sequential instruction stream substantial advantage unlike programming multiprocessor fundamentally invisible programmer next sections chapter cover concept pipelining using mips instruction subset singlecycle implementation section 44 show simp ed version pipeline look problems pipelining introduces performance attainable typical situations wish focus ware performance implications pipelining cient background skip section 410 section 410 introduces advanced pipelining concepts superscalar dynamic scheduling section 411 examines pipelines recent microprocessors alternatively interested understanding pipelining implemented challenges dealing hazards proceed examine design pipelined datapath basic control explained section 46 use understanding explore implementation forwarding stalls section 47 read section 48 learn solutions branch hazards see exceptions handled section 49 code sequence state whether must stall avoid stalls using forwarding execute without stalling forwarding sequence 1sequence 2sequence 3lw t00t0add t1t0t0addi t1t01add t1t0t0addi t2t05addi t2t02 addi t4t15addi t3t02 addi t3t04addi t5t05outside memory system th ective operation pipeline usually important factor determining cpi processor hence performance see section 410 understanding performance modern multipleissue pipelined processo r complex requires understanding issues arise simple pipelined processor nonetheless structural data control hazards remain important simple pipelines sophisticated ones modern pipelines structural hazards usually revolve around th oating point unit may fully pipelined control hazards usually problem integer programs tend higher branch frequencies well less predictable branches data hazards performance bottlenecks check understanding program performance 286 chapter 4 processor integer oatingpoint program en easier deal data hazard oatingpoint programs lower branch frequency regular memory access patterns allow compiler try schedule instructions avoid hazards cult perform optimizations integer programs less regular memory access involving use pointers see section 410 ambitious compiler hardware techniques reducing data dependences scheduling pipelining increases number simultaneously executing instructions rate instructions started completed pipelining reduce time takes complete individual instruction also called latency example th vestage pipeline still takes 5 clock cycles instruction complete terms used chapter 1 pipelining improves instruction throughput rather individual instruction execution time latency bigpicturelatency pipeline e number stages pipeline number stages two instructions execution instruction sets either simplify make life harder pipeline designers must already cope structural control data hazards branch prediction forwarding help make computer fast still getting right answers 46 pipelined datapath control figure 433 shows singlecycle datapath section 44 pipeline stages iden ed e division instruction int stages mean vestage pipeline turn means instructions execution single clock cycle us must separate datapath pieces piece named corresponding stage instruction execution 1 instruction fetch 2 id instruction decode regist le read 3 ex execution address calculation 4 mem data memory access 5 wb write back figure 433 thes components correspond roughly way data path drawn instructions data move generally right ere less meets eye tallulah bankhead remark alexander woollcott 1922 46 pipelined datapath control 287 stages complete execution returning laundry analogy clothes get cleaner drier organized move line never move backward ere however two exceptions toright ow instructions e writeback stage places result back regist le middle datapath e selection next value pc choosing incremented pc branch address mem stage data owing right ect current instruction reverse data movemen uence later instructions pipeline note wb write backmem memory accessif instruction fetchex executeaddress calculation1mux00mux1addresswritedatareaddatadatamemoryread register 1readregister 2writeregister write dataregistersreaddata 1readdata 2aluzeroaluresultaddaddresultshift left 2addressinstructioninstructionmemoryadd4pcsignextend0mux132id instruction decoderegister file read16figure 433 singlecycle datapath section 44 similar figure 417 step instruction mapped onto datapath le righ e exceptions update pc writeback step shown color sends either alu result data memory th written regist le normally use color lines control data lines 288 chapter 4 processor th rst rightt ow data lead data hazards second leads control hazards one way show happens pipelined execution pretend instruction datapath place datapaths timeline show relationship figure 434 shows execution instructions figure 427 displaying private datapaths common timeline use stylized version datapath figure 433 show relationships figure 434 figure 434 seems suggest three instructions need three datapaths instead add registers hold data portions single datapath shared instruction execution example figure 434 shows instruction memory used one stages instruction allowing shared following instructions four stages retain value individual instruction four stages value read instruction memory must saved register similar arguments apply every pipeline stage must place registers wherever dividing lines stages figure 433 returning laundry analogy might basket pair stages hold clothes next step programexecution order instructionslw 1 1000lw 2 2000lw 3 3000time clock cyclesimdmregregaluimdmregregaluimdmregregalucc 1cc 2cc 3cc 4cc 5cc 6cc 7 figure 434 instructions executed using singlecycle datapath figure 433 assuming pipelined execution similar figures 428 430 gure pretends instruction datapath shades portion according use unlike thos gures stage labeled physical resource used stage corresponding portions datapath figure 433 im represents instruction memory pc instruction fetch stage reg stands regist le sign extender instruction decoderegist le read stage id maintain proper time order stylized datapath breaks regist le two logical parts registers read register fetch id registers written write bac dual use represented drawing un half regist le using dashed lines id stage written unshaded right half dashed lines wb stage read assume regist le written th rst half clock cycle regist le read second half 46 pipelined datapath control 289figure 435 shows pipelined datapath pipeline registers high lighted instructions advance clock cycle one pipeline register th e registers named two stages separated register example pipeline register id stages called ifid notice pipeline register end writeback stage instructions must update state processorthe regist le memory pcso separate pipeline register redundant state updated example load instruction place result 1 32 registers later instruction needs data simply read appropriate register course every instruction updates pc whether incrementing setting branch destination addr e pc thought pipeline register one feeds stage pipeline unlike shaded pipeline registers figure 435 however pc part visible architectural state contents must saved exception occurs contents pipeline registers discarded th e laundry analogy could think pc corresponding basket holds load dirty clothes wash step show pipelining works throughout chapter show sequences gures demonstrate operation time ese extra pages would seem require much time understand fear sequences take much addaddressinstructionmemoryreadregister 1instructionread register 2writeregisterwritedataread data 1readdata 2registersaddresswritedatareaddatadatamemoryaddaddresultalualuresultzeroshift left 2signextendpc4idexifidexmem16320mux10mux11mux0memwbfigure 435 pipelined version datapath figure 433 e pipeline registers color separate pipeline stage ey labeled stages separate example th rst labeled ifid separates instruction fetch instruction decode stag e registers must wide enough store data corresponding lines go example ifid register must 64 bits wide must hold 32bit instruction fetched memory incremented 3 2bit pc address expand registers course chapter three pipeline registers contain 128 97 64 bits respectively 290 chapter 4 processor less time might appear compare see changes occur clock cycle section 47 describes happens data hazards pipelined instructions ignore figures 436 438 rst sequence show active portions datapath highlighted load instruction goes th stages pipelined execution sho rst active stages figures 428 430 highlight right half registers memory read highlight half written show instruction abbreviation lw name pipe stage active gure e stages following 1 instruction fetch e top portion figure 436 shows instruction read memory using address pc placed ifid pipeline register e pc address incremented 4 written back pc ready next clock cycle incremented address also saved ifid pipeline register case needed later instruction beq e computer know type instruction fetched must prepare instruction passing potentially needed information pipeline 2 instruction decode regist le read e bottom portion figure 436 shows instruction portion ifid pipeline register supplying 16bit immediate eld signextended 32 bits register numbers read two registers three values stored idex pipeline register along cremented pc address transfer everything might needed instruction later clock cycle 3 execute address calculation figure 437 shows load instruction reads contents register 1 signextended immediate idex pipeline register adds using alu sum placed exmem pipeline register 4 memory access e top portion figure 438 shows load instruction reading data memory using address exmem pipeline register loading data memwb pipeline register 5 writeback e bottom portion figure 438 shows th nal step reading data memwb pipeline register writing register le middle th gure walkthrough load instruction shows information needed later pipe stage must passed stage via pipeline register walking store instruction shows similarity instruction execution well passing information later stages th pipe stages store instruction 46 pipelined datapath control 291instruction decodelwinstruction fetchlwaddaddressinstructionmemoryreadregister 1instructionread register 2writeregisterwritedataread data 1readdata 2registersaddresswritedatareaddatadatamemoryaddaddresultalualuresultzeroshift left 2signextendpc4idexifidexmem16320mux10mux10mux1memwbaddaddressinstructionmemoryread register 1instructionread register 2writeregisterwritedataread data 1readdata 2registersaddresswritedatareaddatadatamemoryaddaddresultalualuresultzeroshift left 2signextendpc4idexifidexmem16320mux10mux11mux0memwbfigure 436 id first second pipe stages instruction active portions datapath figure 435 highlighted e highlighting convention used figure 428 section 42 confusion reading writing registers contents change clock edge although load needs top registe r stage 2 processor doesnt know instruction decoded signextends 16bit constant reads registers nto idex pipeline register dont need three operands simp es control keep three 292 chapter 4 processor 1 instruction fetch e instruction read memory using address pc placed ifid pipeline register stage occurs instruction iden ed top portion figure 436 works store well load 2 instruction decode regist le read e instruction ifid pipeline register supplies register numbers reading two registers extends sign 16bit immediate ese three 32bit values stored idex pipeline register e bottom portion figure 436 load instructions also shows operations second stage stor ese rst two stages executed instructions since early know type instruction 3 execute address calculation figure 439 shows third step ective address placed exmem pipeline register 4 memory access e top portion figure 440 shows data written memory note register containing data stored read earlier stage stor e way make data available mem stage place data exmem pipeline register ex stage stored th ective address exmem executioniwaddaddressinstructionmemoryreadregister 1instructionread register 2write registerwritedataread data 1readdata 2registersaddresswrite datareaddatadatamemoryaddaddresultalualuresultzeroshift left 2signextendpc4idexifidexmem16320mux10mux11mux0memwbfigure 437 ex third pipe stage load instruction highlighting portions datapath figure 435 used pipe stage e register added signextended immediate sum placed exmem pipeline register 46 pipelined datapath control 293memoryiwwriteback iwaddaddressinstructionmemoryreadregister 1instructionread register 2writeregisterwritedataread data 1readdata 2registersaddresswritedatareaddatadatamemoryaddaddresultalualuresultzeroshift left 2signextendpc4idexifidexmem16320mux10mux10mux1memwbaddaddressinstructionmemoryread register 1instructionread register 2writeregisterwritedataread data 1readdata 2registersaddresswritedatareaddatadatamemoryaddaddresultalualuresultzeroshift left 2signextendpc4idexifidexmem16320mux10mux11mux0memwbfigure 438 mem wb fourth ﬁ fth pipe stages load instruction highlighting portions datapath figure 435 used pipe stage data memory read using address exmem pipeline registers data placed memwb pipeline register next data ad memwb pipeline register written regis le middle datapath note bug design repaired figure 441 294 chapter 4 processor 5 writeback e bottom portion figure 440 shows th nal step store instruction nothing happens writeback stage since every instruction behind store already progress way accelerate instructions hence instruction passes stage even nothing later instructions already progressing maximum rate e store instruction illustrates pass something early pipe stage later pipe stage information must placed pipeline register otherwise information lost next instruction enters pipeline stage store instruction needed pass one registers read id stage mem stage stored memory e dat rst placed idex pipeline register pa ssed exmem pipeline register load store illustrate second key point logical component datapathsuch instruction memory register read ports alu data memory register write portcan used within single pipeline stage otherwise would structural hazard see page 277 hence components control associated single pipeline stage uncover bug design load instruction see register changed th nal stage load sp cally executionswaddaddressinstructionmemoryreadregister 1instructionread register 2writeregisterwritedataread data 1readdata 2registersaddresswritedatareaddatadatamemoryaddaddresultalualuresultzeroshift left 2signextendpc4idexifidexmem16320mux10mux11mux0memwbfigure 439 ex third pipe stage store instruction unlike third stage load instruction figure 437 second register value loaded exmem pipeline register used next stage although wouldnt hurt al ways write second register exmem pipeline register write second register store instruction make pipelin e easier understand 46 pipelined datapath control 295memoryswwriteback swaddaddressinstructionmemoryreadregister 1instructionreadregister 2writeregisterwritedataread data 1readdata 2registersaddresswritedatareaddatadatamemoryaddaddresultalualuresultzeroshiftleft 2signextendpc4idexifidexmem16320mux10mux10mux1memwbaddaddressinstructionmemoryread register 1instructionread register 2writeregisterwritedataread data 1readdata 2registersaddresswritedatareaddatadatamemoryaddaddresultalualuresultzeroshift left 2signextendpc4idexifidexmem16320mux10mux11mux0memwbfigure 440 mem wb fourth ﬁ fth pipe stages store instruction fourth stage data written data memory store note data comes exmem pipeline register nothing changed memwb pipeline register data written memory nothin store instruction nothing happens stage 5 296 chapter 4 processor instruction supplies write register numb e instruction ifid pipeline register supplies write register number yet instruction occurs considerably er load instruction hence need preserve destination register number load instruction store passed register contents idex ex mem pipeline registers use mem stage load must pass register number idex exmem memwb pipeline register use wb stage another way think passing register number share pipelined datapath need preserve instruction read stage pipeline register contains portion instruction needed stage later stages figure 441 shows correct version datapath passing write register numb rst idex register exmem register nally memwb register e register number used wb stage specify register written figure 442 single drawing corrected datapath highlighting hardware us stages load word instruction figures 436 438 see section 48 explanation make branch instruction work expected graphically representing pipelinespipelining b cult understand since many instructions simultaneously executing single datapath every clock cycle aid understanding addaddressinstructionmemoryreadregister 1instructionread register 2writeregisterwritedataread data 1readdata 2registersaddresswritedatareaddatadatamemoryaddaddresultalualuresultzeroshift left 2signextendpc4idexifidexmem16320mux10mux11mux0memwbfigure 441 corrected pipelined datapath handle load instruction properly e write register number comes memwb pipeline register along dat e register number passed id pipe stage reaches mem wb pipeline register addin bits last three pipeline register new path shown color 46 pipelined datapath control 297two basic styles pip gures multipleclockcycle pipeline diagrams figure 434 page 288 singleclockcycle pipeline diagrams figures 436 440 e multipleclockcycle diagrams simpler contain details example consider followin veinstruction sequence lw 10 201sub 11 2 3 add 12 3 4 lw 13 241 add 14 5 6figure 443 shows multipleclockcycle pipeline diagram instructions time advances fro right across page diagrams instructions advance top bottom page similar laundry pipeline figure 425 representation pipeline stages placed portion along instruction axis occupying proper clock cycles ese stylized datapaths represent th stages pipeline graphically rectangle naming pipe stage works well figure 444 shows traditional version multipleclockcycle pipeline diagram note figure 443 shows physical resources used stage figure 444 uses name stage singleclockcycle pipeline diagrams show state entire datapath single clock cycle usuall instructions pipeline iden ed labels respective pipeline stages use type gure show details happening within pipeline clock cycle typically addaddressinstructionmemoryreadregister 1instructionread register 2writeregisterwritedataread data 1readdata 2registersaddresswritedatareaddatadatamemoryaddaddresultalualuresultzeroshift left 2signextendpc4idexifidexmem16320mux10mux11mux0memwbfigure 442 portion datapath figure 441 used ﬁ stages load instruction 298 chapter 4 processor drawings appear groups show pipeline operation sequence clock cycles use multipleclockcycle diagrams give overviews pipelining situations section 413 gives illustrations singleclock diagrams would like see details figure 443 singleclockcycle diagram represents vertical slice set multipleclockcycle diagrams showing usage datapath instructions pipeline designated clock cycle example figure 445 shows singleclockcycle diagram corresponding clock cycle 5 figures 443 444 obviously singleclockcycle diagrams detail tak cantly space show number clock cyc e exercises ask create diagrams code sequences group students debating th ciency th vestage pipeline one student pointed instructions active every stage pipeline er deciding ignore th ects hazards made following four statements ones correct check programexecution order instructionslw 10 201sub 11 2 3 add 12 3 4lw 13 241add 14 5 6time clock cyclesimregregimdmregregimregregregregregregalualualualualudmdmdmcc 1cc 2cc 3cc 4cc 5cc 6cc 7cc 8cc 9 dmimimfigure 443 multipleclockcycle pipeline diagram ﬁ instructions style pipeline representation shows complete execution instructions sing gure instructions listed instruction execution order top bottom clock cycles move fro right unlike figure 428 show pipeline registers stage figure 444 shows traditional way draw diagram 46 pipelined datapath control 299programexecution order instructionslw 10 201sub 11 2 3add 12 3 4 lw 13 241add 14 5 6time clock cyclesinstructionfetchinstructiondecodeexecutiondataaccessdataaccessdataaccessdataaccessdataaccesswritebackcc 9cc 8cc 7cc 6cc 5cc 4cc 3cc 2cc 1instructionfetchinstructionfetchinstructionfetchinstructionfetchinstructiondecodeinstructiondecodeinstructiondecodeinstructiondecodeexecutionwritebackexecutionwritebackexecutionwritebackexecutionwritebackfigure 444 traditional multipleclockcycle pipeline diagram ﬁ instructions figure 443 addaddressinstructionmemoryreadregister 1read register 2write registerwritedataread data 1read data 2registersaddresswritedatareaddatadatamemoryaddaddresultalualuresultzeroshiftleft 2signextendpc4idexifidexmemmemorysub 11 2 3writebacklw 10 201executionadd 12 3 4instruction decodelw 13 24 1instruction fetchadd 14 5 61632instructionmemwb0mux10mux11mux0figure 445 singleclockcycle diagram corresponding clock cycle 5 pipeline figures 443 444 see singleclockcyc gure vertical slice multipleclockcycle diagram 1 allowing jumps branches alu instructions take fewer stages th required load instruction increase pipeline performance circumstances 300 chapter 4 processor 2 trying allow instructions take fewer cycles help since throughput determined clock cycle number pipe stages per instruction ects latency throughput 3 make alu instructions take fewer cycles write back result branches jumps take fewer cycles opportunity improvement 4 instead trying make instructions take fewer cycles explore making pipeline longer instructions take cycles cycles shorter could improve performance pipelined controljust added control singlecycle datapath section 43 add control pipelined datapath start simple design views problem rosecolored glasses e rst step label control lines existing datapath figure 446 shows lines borrow much control simple datapath figure 417 particular use alu control logic branch logic destinationregisternumber multiplexor contro ese functions ar ned figures 412 416 418 reproduce key information figures 447 449 single page make following discussion easier follow case singlecycle implementation assume pc written clock cycle separate write signal pc argument separate write signals pipeline registers id idex exmem memwb since pipeline registers also written clock cycle specify control pipeline need set control values pipeline stage control line associated component active single pipeline stage divide control lines int groups according pipeline stage 1 instruction fetch e control signals read instruction memory write pc always asserted nothing special control pipeline stage 2 instruction decoderegist le read previous stage thing happens every clock cycle optional control lines set 3 executionaddress calculation e signals set regdst aluop alusrc see figures 447 448 e signals select th e result register alu operation either read data 2 signextended immediate alu 6600 computer perhaps even previous computer control system di erence ja ornton design computer e control data 6600 1970 46 pipelined datapath control 301memwritepcsrcmemtoregmemreadaddaddressinstructionmemoryreadregister 1instructionread register 2writeregisterwritedatainstruction15œ0instruction20œ16instruction15œ11readdata 1read data 2registersaddresswritedatareaddatadatamemoryaddaddresultaddaluresultzeroshiftleft 2signextendpc4idexifidexmem16326alucontrolregdstaluopalusrcregwritebranchmemwb0mux10mux10mux10mux1figure 446 pipelined datapath figure 441 control signals identiﬁ ed datapath borrows control logic pc source register destination number alu control section 44 note need 6bit func eld function code instruction ex stage input alu control bits must also included idex pipeline reg ister recall 6 bits also 6 le cant bits immediate eld instruction idex pipeline register supply immediate eld since sign extension leaves bits unchanged instruction opcodealuop instruction operationfunction code desired alu actionalu control inputlw 00load word xxxxxxadd 0010sw00store word xxxxxxadd 0010branch equal01branch equal xxxxxxsubtract 0110rtype10add 100000add 0010rtype10subtract 100010subtract 0110rtype10and 100100and 0000rtype10or 100101or 0001rtype10set less 101010set less 0111figure 447 copy figure 412 gure shows alu control bits set depending aluop control bits erent function codes rtype instruction 302 chapter 4 processor 4 memory access e control lines set stage branch memread memwrite e branch equal load stor e instructions set signals respectively recall pcsrc figure 448 selects next sequential address unless control asserts branch alu result 0 5 writeback e two control lines memtoreg decides sending alu result memory value regist le reg write writes chosen value since pipelining datapath leaves meaning control lines unchanged use control values figure 449 values section 44 nine control lines grouped pipeline stage signal nameeffect deasserted 0 effect asserted 1 regdstthe register destination number write register comes rt þeld bits 2016 register destination number write register comes rd þeld bits 1511regwritenonethe register write register input written value write data input alusrcthe second alu operand comes second register þle output read data 2the second alu operand signextended lower 16 bits instruction pcsrcthe pc replaced output adder computes value pc 4the pc replaced output adder computes branch targetmemreadnone data memory contents designated address input put read data output memwritenone data memory contents designated address input replaced value write data input memtoregthe value fed register write data input comes aluthe value fed register write data input comes data memory figure 448 copy figure 416 e function seven contro ned e alu control lines aluop ar ned second column figure 447 1bit control 2way multiplexor asserted multiplexor selects input corresponding 1 otherwise control deasserted multiplexor selects 0 input note pcsrc controlled gat e figure 446 branch signal alu zero signal set pcsrc 1 otherwise 0 control sets branch signal beq instruction otherwise pcsrc set 0 instruction executionaddress calculation stage control lines memory access stage control lines writeback stage control lines regdstaluop1aluop0alusrc branch mem readmem write reg write memto regrformat1 10000010lw000101011swx0010010x beqx0101000x figure 449 values control lines figure 418 shufﬂ ed three groups corresponding last three pipeline stages 47 data hazards forwarding versus stalling 303implementing control means setting nine control lines values stage instructio e simplest way extend pipeline registers include control information since control lines start ex stage create control information instruction decode figure 450 shows control signals used appropriate pipeline stage instruction moves pipeline destination register number loads moves pipeline figure 441 figure 451 shows full datapath extended pipeline registers control lines connected proper stage section 413 gives examples mips code executing pipelined hardware using singleclock diagrams would like see details 47 data hazards forwarding versus stalling e examples previous section show power pipelined execution hardware performs task time take rosecolored glasses look happens real program e instructions figures 443 445 independent none used results calculated others yet section 45 saw data hazards obstacles pipelined execution wbmexwbmwbcontrolifididexexmemmemwbinstructionfigure 450 control lines ﬁ nal three stages note four nine control lines used ex phase remainin control lines passed exmem pipeline register extended hold control lines three used mem stage last two passed mem wb use wb stage mean whys got built bypass youve got build bypasses douglas adams e hitchhikers guide galaxy 1979 304 chapter 4 processor lets look sequence many dependences shown color sub 2 13 register 2 written suband 1225 1st operand2 depends subor 1362 2nd operand2 depends subadd 1422 1st2 2nd2 depend subsw 151002 base 2 depends sub e last four instructions dependent result register 2 rst instruction register 2 value 10 subtract instruction 20 erwards programmer intends 20 used following instructions refer register 2wbmexwbmwbmemwritepcsrcmemtoregmemreadaddaddressinstructionmemoryreadregister 1readregister 2instruction15œ0instruction20œ16instruction15œ11writeregisterwritedatareaddata 1readdata 2registersaddresswritedataread datadatamemoryaddaddresultalualuresultzeroshiftleft 2signextendpc4idexifidexmemmemwb16632alucontrolregdstaluopalusrcregwriteinstructionbranchcontrol0mux10muxmuxmux11001figure 451 pipelined datapath figure 446 control signals connected control portions pipeline registers e control values last three stages created instruction decode stage placed idex pipeline register e control lines pipe stage used remaining control lines passed next pipeline stage 47 data hazards forwarding versus stalling 305how would sequence perform pipeline figure 452 illustrates execution instructions using multipleclockcycle pipeline representation demonstrate execution instruction sequence current pipeline top figure 452 shows value register 2 changes middle clock cycle 5 sub instruction writes result e last potential hazard resolved design regist le hardware happens register read written clock cycle assume write th rst half clock cycle read second half read delivers written case many implementations regist les data hazard case figure 452 shows values read register 2 would result sub instruction unless read occurred clock cycle 5 later us instructions would get correct value 20 add sw programexecution order instructionssub 2 1 3and 12 2 5 13 6 2add 14 22 sw 15 1002time clock cyclescc 1cc 2cc 3cc 4cc 5cc 6cc 7cc 8cc 9 imdmregregimdmregregimdmregregimdmregregimdmregreg10 10 10 10 value ofregister 210œ20œ20œ20œ20œ20 figure 452 pipelined dependences ﬁ veinstruction sequence using simpliﬁ ed datapaths show dependences dependent actions shown color cc 1 top th gure means clock cyc e rst instruction writes 2 following instructions read 2 register written clock cycle 5 proper value unavailable clock cycle 5 read register clock cycle returns value written end th rst half cycle write occur e colored lines top datapath lower ones show dep ose must go backward time pipeline data hazards 306 chapter 4 processor instructions would get incorrect value 10 using style drawing problems become apparent dependence line goes backward time mentioned section 45 desired result available end ex stage clock cycle 3 data actually needed instructions beginning ex stage clock cycles 4 5 respectively us execute segment without stalls simply forward data soon available units need available read regist le forwarding work simplicity rest section consider challenge forwarding operation ex stage may either alu operation ective address calculatio means instruction tries use register ex stage earlier instruction intends write wb stage actually need values inputs alu notation names th elds pipeline registers allows precise notation dependences example idexregisterrs refers number one register whose value found pipeline register idex one th rst read port regist le e rst part name period name pipeline register second part name th eld register using notation two pairs hazard conditions 1a exmemregisterrd idexregisterrs 1b exmemregisterrd idexregisterrt 2a memwbregisterrd idexregisterrs 2b memwbregisterrd idexregisterrt e rst hazard sequence page 304 register 2 result sub 213 th rst read operand 1225 hazard detected instruction ex stage prior instruction mem stage hazard 1a exmemregisterrd idexregisterrs 2dependence detectionclassify dependences sequence page 304 sub 2 1 3 register 2 set sub 12 2 5 1st operand2 set sub 13 6 2 2nd operand2 set sub add 14 2 2 1st2 2nd2 set sub sw 15 1002 index2 set subexample 47 data hazards forwarding versus stalling 307as mentioned suband type 1a hazard e remaining hazards follows e subor type 2b hazard memwbregisterrd idexregisterrt 2 e two dependences subadd hazards register le supplies proper data id stage add ere data hazard sub sw sw reads 2 clock cycle er sub writes 2because instructions write registers policy inaccurate sometimes would forward shouldnt one solution simply check see regwrite signal active examining wb contro eld pipeline register ex mem stages determines whether regwrite asserted recall mips requires every use 0 operand must yield operand value 0 event instruction pipeline 0 destination example sll 0 1 2 want avoid forwarding possibly nonzero result value forwarding results destined 0 frees assembly programmer compiler requirement avoid using 0 destinatio e conditions thus work properly long add exmem registo th rst hazard condition memwbregisto second detect hazards half problem resolvedbut must still forward proper data figure 453 shows dependences pipeline registers inputs alu code sequence figure 452 e change dependence begins pipeline register rather waiting wb stage write regist le us required data exists time later instructions pipeline registers holding data forwarded take inputs alu pipeline register rather idex forward proper data adding multiplexors input alu proper controls run pipeline full speed presence data dependences assume instructions need forward four rformat instructions add sub figure 454 shows closeup alu pipeline register er adding forwarding figure 455 shows values control lines alu multiplexors select either regist le values one forwarded values forwarding control ex stage alu forwarding multiplexors found stage us must pass operand register numbers id stage via idex pipeline register determine whether forward values already r eld bits 2016 forwarding idex register need include space hold r eld hence rs bits 2521 added idex answer 308 chapter 4 processor lets write conditions detecting hazards control signals resolve 1 ex hazard exmemregwrite exmemregisterrd idexregisterrs forwarda 10if exmemregwrite exmemregisterrd idexregisterrt forwardb 10programexecution orderin instructionssub2 1 3and 12 2 5or 13 6 2add 14 22sw 15 1002time clock cyclescc 1 cc 2 cc 3 cc 4 cc 5 cc 6 cc 7 cc 8 cc 9 imregregimregregimregregimregregimdmdmdmdmdmregreg10 10 10 10 10œ20 œ20 œ20 œ20 œ20 value register 2 value exmem x x x œ20 x x x x x value memwb x x x x œ20 x x x x figure 453 dependences pipeline registers move forward time possible supply inputs alu needed instruction instruction forwarding results found pipeline registers e values pipeline registers show desired value available written regist le assume regist le forwards values read written clock cycle add stall values come regist le instead pipeline register regist le forwardingthat read gets value write clock cycleis clock cycle 5 shows register 2 value 10 beginning 20 end clock cycle rest section handle forwarding except value stored store instruction 47 data hazards forwarding versus stalling 309datamemoryregistersmuxalualuidexa forwardingb forwardingexmemmemwbdatamemoryregistersmuxmuxmuxmuxidexexmemmemwbforwardingunitexmemregisterrdmemwbregisterrdrsrtrtrdforwardbforwardafigure 454 top alu pipeline registers adding forwarding bottom multiplexors expanded add forwarding paths show forwarding uni e new hardware shown color gure stylized drawing however leaving details full datapath sign extension hardware note idexregisterr eld shown twice connect mux forwarding unit single signal earlier discussion ignores forwarding store value store instruction also note mechanism works slt instructions well 310 chapter 4 processor note exmemregist eld register destination either alu instruction comes th eld instruction load comes r eld case forwards result previous instruction either input alu previous instruction going write regist le write register number matches read register number alu inputs b provided register 0 steer multiplexor pick value instead pipeline register exmem 2 mem hazard memwbregwrite memwbregisterrd idexregisterrs forwarda 01 memwbregwrite memwbregisterrd idexregisterrt forwardb 01 mentioned hazard wb stage assume regist le supplies correct result instruction id stage reads register written instruction wb stage regist le performs another form forwarding occurs within regist le one complication potential data hazard result instruction wb stage result instruction mem stage source operand instruction alu stage example summing vector numbers single register sequence instructions read write register add 112add 113 add 114 mux controlsource explanationforwarda 00idexthe þrst alu operand comes register þle forwarda 10exmemthe þrst alu operand forwarded prior alu result forwarda 01memwbthe þrst alu operand forwarded data memory earlier alu resultforwardb 00idexthe second alu operand comes register þle forwardb 10exmemthe second alu operand forwarded prior alu result forwardb 01memwbthe second alu operand forwarded data memory earlier alu result figure 455 control values forwarding multiplexors figure 454 e signed immediate another input alu described elaboration end section 47 data hazards forwarding versus stalling 311in case result forwarded mem stage result mem stage recent resul us control mem hazard would additions highlighted memwbregwrite memwbregisterrd idexregisterrs forwarda 01 memwbregwrite memwbregisterrd idexregisterrt forwardb 01 figure 456 shows hardware necessary support forwarding operations use results ex stage note exmemregist eld register destination either alu instruction comes th eld instruction load comes r eldfigure 456 datapath modiﬁ ed resolve hazards via forwarding compared datapath figure 451 additions multiplexors inputs alu gure stylized drawing however leaving details full datapath branch hardware sign extension hardware mwbwbregistersinstructionmemorymuxmuxmuxmuxaluidexexmemmemwbforwardingunitexmemregisterrdmemwbregisterrdrsrtrtrdpccontrolexmwbifidregisterrsifidregisterrtifidregisterrtifidregisterrdinstructionifiddatamemory 312 chapter 4 processor section 413 shows two pieces mips code hazards cause forwarding would like see illustrated examples using singlecycle pipeline drawings elaboration forwarding also help hazards store instructions dependent instructions since use one data value mem stage forwarding easy however consider loads immediately followed stores useful performing memorytomemory copies mips architecture since copies frequent need add forwarding hardware make run faster redraw figure 453 replacing sub instructions lw sw would see possible avoid stall since data exists memwb register load instruction time use mem stage store instruction would need add forwarding memory access stage option leave cation exercise reader addition signedimmediate input alu needed loads stores missing datapath figure 456 since central control decides register immediate since forwarding unit chooses pipeline register register datamemoryregistersmuxmuxmuxmuxmuxaluidexexmem memwbforwardingunitalusrcfigure 457 closeup datapath figure 45 4 shows 21 multiplexor added select signed immediate alu input 47 data hazards forwarding versus stalling 313input alu easiest solution add 21 multiplexor chooses forwardb multiplexor output signed immediate figure 457 shows additiondata hazards stallsas said section 45 one case forwarding save day instruction tries read register following load instruction writes register figure 458 illustrates prob e data still read memory clock cycle 4 alu performing operation following instruction something must stall pipeline combination load followed instruction reads result hence addition forwarding unit need hazard detection unit operates id stage insert stall load programexecution order instructionslw 2 201and 4 2 5or 8 2 6 add 9 4 2 slt 1 6 7time clock cyclescc 1 cc 2 cc 3 cc 4 cc 5 cc 6 cc 7 cc 8 cc 9 imdmregregimdmregregimdmregregimdmregregimdmregregfigure 458 pipelined sequence instructions since dependence load following instruction goes backward time hazard solved forwarding hence combination must result stall hazard detection unit rst dont succeed ne success anonymous 314 chapter 4 processor use checking load instructions control hazard detection unit single condition idexmemread idexregisterrt ifidregisterrs idexregisterrt ifidregisterrt stall pipeline e rst line tests see instruction load instruction reads data memory load e next two lines check see destination register eld load ex stage matches either source register instruction id stage condition holds instruction stalls one clock cycle er 1cycle stall forwarding logic handle dependence execution proceeds forwarding instructions figure 458 would need another stall cycle instruction id stage stalled instruction stage must also stalled otherwise would lose fetched instruction preventing two instructions making progress accomplished simply preventing pc register ifid pipeline register changing provided registers preserved instruction stage continue read using pc registers id stage continue read using instructio elds ifid pipeline register returning favorite analogy restart washer clothes let dryer continue tumbling empty course like dryer back half pipeline starting ex stage must something executing instructions ect nops insert nops act like bubbles pipeline figure 449 see deasserting nine control signals setting 0 ex mem wb stages create nothing nop instruction identifying hazard id stage insert bubble pipeline changing ex mem wb contro elds idex pipeline register ese benign control values percolated forward clock cycle prop ect registers memories written control values 0 figure 459 shows really happens hardware pipeline execution slot associated instruction turned nop instructions beginning instruction delayed one cycle like air bubble water pipe stall bubble delays everything behind proceeds instruction pipe one stage cycle exits end example hazard forces instructions repeat clock cycle 4 clock cycle 3 reads registers decodes refetched instruction memory repeated work stall looks like ect stretch time instructions delay fetch add instruction figure 460 highlights pipeline connections hazard detection unit forwarding unit forwarding unit controls alu nop instruction operation change state 47 data hazards forwarding versus stalling 315multiplexors replace value generalpurpose register value proper pipeline register e hazard detection unit controls writing pc ifid registers plus multiplexor chooses real control values e hazard detection unit stalls deasserts control elds loaduse hazard test true section 413 gives example mips code hazards causes stalling illustrated using singleclock pipeline diagrams would like see details although compiler generally relies upon hardware resolve hazards thereby ensure correct execution compiler must understand pipeline achieve best performance otherwise unexpected stalls reduce performance compiled code bigpicturebubbleprogramexecution order instructionslw 2 201and becomes nopand 4 2 5or 8 2 6 add 9 4 2time clock cyclescc 1 cc 2 cc 3 cc 4 cc 5 cc 6 cc 7 cc 8 cc 9cc 10 imdmregregimdmregregimdmregregimdmregregimdmregregfigure 459 way stalls really inserted pipeline bubble inserted beginning clock cycle 4 changing instruction nop note instruction really fetched decoded clock cycles 2 3 ex stage delayed clock cycle 5 versus unstalled position clock cycle 4 likewise instruction fetched clock cycle 3 id stage delayed clock cycle 5 versus unstalled clock cycle 4 positio er insertion bubble dependences go forward time hazards occur 316 chapter 4 processor elaboration regarding remark earlier setting control lines 0 avoid writing registers memory signals regwrite memwrite need 0 control signals dont cares 48 control hazards us far limited concern hazards involving arithmetic operations data transfers however saw section 45 also pipeline hazards involving branches figure 461 shows sequence instructions indicates branch would occur pipeline instruction must fetched every clock cycle sustain pipeline yet design decision whether branch doesnt occur mem pipeline stage mentioned section 45 0mwbwbdatamemoryinstructionmemoryaluidexexmemmemwbforwardingunitpccontrolexmwbifidmuxmuxmuxmuxmuxhazarddetectionunitidexmemreadifidregisterrsinstructionifidregisterrtifidregisterrtifidregisterrdidexregisterrtpcwriteifdwriteregistersrtrdrsrtfigure 460 pipelined control overview showing two multiplexors forwarding hazard detection unit forwarding unit although id ex stages simp edthe signextended immediate branch logic missing drawing gives essence forwarding hardware requirements ere thousand hacking branches evil one striking root henry da oreau walden 1854 48 control hazards 317this delay determining proper instruction fetch called control hazard branch hazard contrast data hazards examined section control hazards shorter previous sections data hazard e reasons control hazards relatively simple understand occur less frequently data hazards nothin ective control hazards forwarding data hazards hence use simpler schemes look two schemes resolving control hazards one optimization improve schemes regprogramexecution order instructions40 beq 1 3 2844 12 2 548 13 6 252 add 14 2 272 lw 4 507time clock cyclescc 1 cc 2 cc 3 cc 4 cc 5 cc 6 cc 7 cc 8 cc 9 imdmregregimdmregregimdmregimdmregregimdmregregfigure 461 impact pipeline branch instruction e numbers th instruction 40 44 addresses instructions since branch instruction decides whether branch mem stageclock cycle 4 fo r beq instruction abovethe three sequential instructions follow branch fetched begin execution without interve ntion three following instructions begin execution beq branches lw location 72 figure 431 assumed extra hardware reduce control hazard one clock cycle gure uses nonoptimized datapath 318 chapter 4 processor assume branch taken saw section 45 stalling branch complete slow one improvement branch stalling predict branch taken thus continue execution sequential instruction stream branch taken instructions fetched decoded must discarded execution continues branch target branches untaken half time costs little discard instructions optimization halves cost control hazards discard instructions merely change original control values 0s much stall loaduse data hazard e erence must also change three instructions id ex stages branch reaches mem stage loaduse stalls change control 0 id stage let percolate pipeline discarding instructions means must able ush instructions id ex stages pipeline reducing delay branches one way improve branch performance reduce cost taken branch us far assumed next pc branch selected mem stage move branch execution earlier pipeline fewer instructions need ushed e mips architecture designed support fast singlecycle branches could pipelined small branch penalty e designers observed many branches rely simple tests equality sign example tests require full alu operation done gates complex branch decision required separate instruction uses alu perform comparison requireda situation similar use condition codes branches see chapter 2 moving branch decision requires two actions occur earlier computing branch target address evaluating branch decisio e easy part change move branch address calculation already pc value immediate eld ifid pipeline register move branch adder ex stage id stage course branch target address calculation performed instructions used needed e harder part branch decision branch equal would compare two registers read id stage see equal equality tested rst exclusive oring respective bits oring results moving branch test id stage implies additional forwarding hazard detection hardware since branch dependent result still pipeline must still work properly optimization example implement branch equal inverse need forward results equality test logic operates id ere two complicating factors 1 id must decode instruction decide whether bypass equality unit needed complete equality comparison instruction branch set pc branch target address ush discard instructions pipeline usually due unexpected event 48 control hazards 319forwarding operands branches formerly handled alu forwarding logic introduction equality test unit id require new forwarding logic note bypassed source operands branch come either alumem memwb pipeline latches 2 values branch comparison needed id may produced later time possible data hazard occur stall needed example alu instruction immediately preceding branch produces one operands comparison branch stall required since ex stage alu instruction occur er id cycle branch extension load immediately followed conditional branch load result two stall cycles needed result load appears end mem cycle needed beginning id branch despite thes culties moving branch execution id stage improvement reduces penalty branch one instruction branch taken namely one currently fetched e exercises explore details implementing forwarding path detecting hazard ush instructions stage add control line called ifflush zeros instructio eld ifid pipeline register clearing register transforms fetched instruction nop instruction action changes state pipelined branchshow happens branch taken instruction sequence assuming pipeline optimized branches taken moved branch execution id stage 36 sub 10 4 840 beq 1 3 7 pcrelative branch 40 4 7 4 72 44 12 2 5 48 13 2 6 52 add 14 4 2 56 slt 15 6 7 72 lw 4 507figure 462 shows happens branch taken unlike figure 461 one pipeline bubble taken branch exampleanswer 320 chapter 4 processor mwbwbdatamemoryregistersinstructionmemoryaluidexexmemmemwbforwardingunitpccontrolexmwbifid0hazarddetectionunitsignextendshiftleft 2ifflush472484428441384710and 12 2 5beq 1 3 7sub 10 4 8before1before2mwbwbdatamemoryregistersinstructionmemorymuxaluidexexmemmemwbforwardingunitpccontrolexmwbifid0hazarddetectionunitsignextendshiftleft 2ifflush476727672723101lw 4 507clock 3clock 4bubble nopbeq 1 3 7sub 10 before1muxmuxmuxmuxmuxmuxmuxmuxmuxfigure 462 id stage clock cycle 3 determines branch must taken selects 72 next pc address zeros instruction fetched next clock cycle clock cycle 4 shows instruction location 72 fetched single bubble nop instruction pipeline result taken branch since nop really sll 0 0 0 arguable whether id stage clock 4 highlighted 48 control hazards 321dynamic branch predictionassuming branch taken one simple form branch prediction case predict branches untak ushing pipeline wrong simp vestage pipeline approach possibly coupled compiler based prediction probably adequate deeper pipelines branch penalty increases measured clock cycles similarly multiple issue see section 410 branch penalty increases terms instruction combination means aggressive pipeline simple static prediction scheme probably waste much performance mentioned section 45 hardware possible try predict branch behavior program execution one approach look address instruction see branch taken last time instruction executed begin fetching new instructions place last time technique called dynamic branch prediction one implementation approach branch prediction bu er branch history table branch prediction bu er small memory indexed lower portion address branch instructio e memory contains bit says whether branch recently taken simplest sort bu er dont know fact prediction right oneit may put another branch loworder address bits however doesnt ect correctness prediction hint hope correct fetching begins predicted direction hint turns wrong incorrectly predicted instructions deleted prediction bit inverted stored back proper sequence fetched executed simple 1bit prediction scheme performance shortcoming even branch almost always taken predict incorrectly twice rather tak e following example shows dilemma loops predictionconsider loop branch branches nine times row taken prediction accuracy branch assuming prediction bit branch remains prediction b er e steadystate prediction behavior mispredict th rst last loop iterations mispredicting last iteration inevitable since prediction bit indicate taken branch taken nine times row poin e misprediction th rst iteration happens bit ipped prior execution last iteration loop since branch taken exiting iteratio us prediction accuracy dynamic branch prediction prediction branches runtime using runtime information branch prediction bu er also called branch history table small memory indexed lower portion address branch instruction contains one bits indicating whether branch recently taken exampleanswer 322 chapter 4 processor branch taken 90 time 80 two incorrect predictions eight correct ones ideally accuracy predictor would match taken branch frequency highly regular branches remedy weakness 2bit prediction schemes en used 2bit scheme prediction must wrong twice changed figure 463 shows th nitestate machine 2bit prediction scheme branch prediction bu er implemented small special b er accessed instruction address pipe stage instruction predicted taken fetching begins target soon pc known mentioned page 318 early id stage otherwise sequential fetching executing continue prediction turns wrong prediction bits changed shown figure 463 elaboration described section 45 vestage pipeline make control hazard feature b ning branch delayed branch always executes following instruction second instruction following branch affected branchcompilers assemblers try place instruction always executes branch branch delay slot job software make successor instructions valid useful figure 464 shows three ways branch delay slot scheduled branch delay slot e slot directly er delayed branch instruction mips architecture lled instruction ect branch predict taken taken taken taken taken taken taken taken taken predict taken predict taken predict taken figure 463 states 2bit prediction scheme using 2 bits rather 1 branch strongly favors taken takenas many branches dowill mispredicted e 2 bits used encode four states syst e 2bit scheme general instance counterbased predictor incremented prediction accurate decremented otherwise uses midpoint range division taken taken 48 control hazards 323the limitations delayed branch scheduling arise 1 restrictions instructions scheduled delay slots 2 ability predict compile time whether branch likely taken delayed branching w vestage pipeline issuing one instruction clock cycle processors go longer pipelines issuing multiple instructions per clock cycle see section 410 branch delay becomes longer single dela cient hence delayed branching exible dynamic approaches simultaneously growth available transistors per chip due moores law made dynamic prediction relatively cheaper add s1 s2 s3if s2 0 thendelay slotif s2 0 thenadd s1 s2 s3becomesa beforesub t4 t5 t6 add s1 s2 s3 s1 0 thendelay slotadd s1 s2 s3if s1 0 thensub t4 t5 t6becomesb targetadd s1 s2 s3 s1 0 thendelay slotadd s1 s2 s3if s1 0 thensub t4 t5 t6becomesc fallthroughsub t4 t5 t6figure 464 scheduling branch delay slot e top box pair shows code scheduling bottom box shows scheduled code delay slot scheduled independent instruction branc best choice strategies b c used possible code sequences b c use s1 branch condition prevents add instruction whose destination s1 moved branch delay slot b branch delay slot scheduled target branch usually target instruction need copied reached another path strategy b preferred branch taken high probability loop branch finally branch may scheduled nottaken fallthrough c make optimization legal b c must ok execute sub instruction branch goes unexpected direction ok mean th e work wasted program still execute correctly case example t4 unused temporary register branch goes unexpected direction 324 chapter 4 processor elaboration branch predictor tells us whether branch taken still vestage pipeline calculation takes one cycle meaning taken branches 1cycle penalty delayed branches one approach eliminate penalty another approach use cache hold destination program counter destination instruction using branch target bufferthe 2bit dynamic prediction scheme uses information particular branch researchers noticed using information local branch global behavior recently executed branches together yields greater prediction accuracy number prediction bits predictors called correlating predictors typical correlating predictor might two 2bit predictors branch choice predictors made based whether last executed branch taken taken thus global branch behavior thought adding additional index bits prediction lookupa recent innovation branch prediction use tournament predictors tournament predictor uses multiple predictors tracking branch predictor yields best results typical tournament predictor might contain two predictions branch index one based local information one based global branch behavior selector would choose predictor use given prediction selector operate similarly 1 2bit predictor favoring whichever two predictors accurate recent microprocessors use elaborate predictors elaboration one way reduce number conditional branches add conditional move instructions instead changing pc conditional branch instruction conditionally changes destination register move condition fails move acts nop example one version mips instruction set architecture two new instructions called movn move zero movz move zero thus movn 8 11 4 copies contents register 11 register 8 provided value register 4 nonzero otherwise nothing armv7 instr eld instructions hence arm programs could fewer conditional branches mips programs pipeline summary started laundry room showing principles pipelining everyday setting using analogy guide explained instruction pipelining stepbystep starting singlecycle datapath adding pipeline registers forwarding paths data hazard detection branch prediction ushing instructions exceptions figure 465 shows th nal evolved datapath control ready yet another control hazard sticky issue exceptions consider three branch prediction schemes predict taken predict taken dynamic prediction assume zero penalty predict correctly two cycles wrong assume average predict branch target bu er structure caches destination pc destination instruction branch usually organized cache tags making costly simple prediction bu er correlating predictor branch predictor combines local behavior particular branch global information behavior recent number executed branches tournament branch predictor branch predictor multiple predictions branch selection mechanism chooses predictor enable given branch check 49 exceptions 325accuracy dynamic predictor 90 predictor best choice following branches 1 branch taken 5 frequency 2 branch taken 95 frequency 3 branch taken 70 frequency 49 exceptionscontrol challenging aspect processor design hardest part get right hardest part make fast one hardest parts controlhazarddetectionunit4pcinstructionmemorysignextendregistersfowardingunitaluidexmemwbexmemwbmexshiftleft 2ifflushifidmuxmuxdatamemorywbwbm0muxmuxmuxmuxfigure 465 ﬁ nal datapath control chapter note sty gure rather detailed datapath missing alusrc mux figure 457 multiplexor controls figure 451 make computer automatic programinterruption facilities behave sequentially easy matter number instructions various stages processing interrupt signal occurs may large fred brooks jr planning computer system project stretch 1962 326 chapter 4 processor control implementing exceptions interrupts events branches jumps change normal ow instruction executio ey initially created handle unexpected events within processor like arithmetic ow e basic mechanism extended io devices communicate processor see chapter 5 many architectures authors distinguish interrupts exceptions en using older name interrupt refer types events example intel x86 uses interrupt follow mips convention using term exception refer unexpected change contro ow without distinguishing whether cause internal external use term interrupt event externally caused ar examples showing whether situation internally generated processor externally generated type event wheremips terminology io device request external interrupt invoke operating system user programinternal exceptionarithmetic ow internal exception ned instruction internal exceptionhardware malfunctions eitherexception interrupt many requirements support exceptions come sp c situation causes exception occur accordingly return topic chapter 5 better understand motivation additional capabilities exception mechanism section deal control implementation detecting two types exceptions arise portions instruction set implementation already discussed detecting exceptional conditions taking appropriate action en critical timing path processor determines clock cycle time thus performance without proper attention exceptions design control unit attempts add exceptions complicated implementation ca cantly reduce performance well complicate task getting design correct exceptions handled mips architecture e two types exceptions current implementation generate execution ned instruction arithmetic ow well use arithmetic ow instruction add 1 2 1 example exception next pag e basic action processor must perform exception occurs save address ending instruction exception program counter epc transfer control operating system sp ed address e operating system take appropriate action may involve providing service user program taking pr ned action exception also called interrupt unscheduled event disrupts program execution used detect ow interrupt exception comes outside processor architectures use term interrupt exceptions 49 exceptions 327response ow stopping execution program reporting error er performing whatever action required exception operating system terminate program may continue execution using epc determine restart execution program chapter 5 look closely issue restarting execution operating system handle exception must know reason exception addition instruction caused ere two main methods used communicate reason exceptio e method used mips architecture include status register called cause register ho eld indicates reason exception second method use vectored interrupts vectored interrupt address control transferred determined cause exception example accommodate two exception types listed might ne following two exception vector addresses exception typeexception vector address hex ned instruction 8000 0000hexarithmetic ow 8000 0180hex e operating system knows reason exception address initiated e addresses separated 32 bytes eight instructions operating system must record reason exception may perform limited processing sequence exception vectored single entry point exceptions used operating system decodes status register nd cause perform processing required exceptions adding extra registers control signals basic implementation slightly extending control lets assume implementing exception system used mips architecture single entry point address 8000 0180 hex implementing vectored exceptions mor cult need add two additional registers current mips implementation epc 32bit register used hold address ected instruction register needed even exceptions vectored cause register used record cause exception mips architecture register 32 bits although bits currently unused assume ther vebit eld encodes two possible exception sources mentioned 10 representing ned instruction 12 representing arithmetic ow exceptions pipelined implementationa pipelined implementation treats exceptions another form control hazard example suppose arithmetic ow add instruction vectored interrupt interrupt address control transferred determined cause exception 328 chapter 4 processor taken branch previous section mu ush instructions follow add instruction pipeline begin fetching instructions new address use mechanism used taken branches time exception causes deasserting control lines dealt branch mispredict saw ush instruction stage turning nop ush instructions id stage use multiplexor already id stage zeros control signals stalls new control signal called idflush ored stall signal hazard detection unit ush id ush instruction ex phase use new signal called exflush cause new multiplexors zero control lines start fetching instructions location 8000 0180 hex mips exception address simply add additional input pc multiplexor sends 8000 0180hex pc figure 466 shows changes example points problem exceptions stop execution middle instruction programm er able see original value register 1 helped cause ow clobbered destination register add instruction careful planning ow exception detected ex stage hence use exflush signal prevent instruction ex stage writing result wb stage many exceptions require eventually complete instruction caused exception executed normally e easiest way ush instruction restart beginning er exception handled e nal step save address ending instruction exception program counter epc reality save address 4 exception handling ware routine mu rst subtract 4 saved value figure 466 shows stylized version datapath including branch hardware necessary accommodations handle exceptions exception pipelined computergiven instruction sequence 40hex sub 11 2 444hex 12 2 548hex 13 2 64chex add 1 2 150hex slt 15 6 754hex lw 16 507 example 49 exceptions 329assume instructions invoked exception begin like 80000180hex sw 26 1000080000184hex sw 27 10040 show happens pipeline ow exception occurs add instruction figure 467 shows events starting add instruction ex stage e ow detected phase 8000 0180 hex forced pc clock cycle 7 shows add following instructions ar ushed th rst instruction exception code fetched note address instruction following add saved 4c hex 4 50hexanswer000mwbwbdatamemoryinstructionmemorymuxmuxmuxmuxmuxaluidexexmemcauseepcmemwbforwardingunitpccontrolexmwbifidmuxmuxhazarddetectionunitshiftleft 2ifflushidflushexflush4signextend80000180registersmuxfigure 466 datapath controls handle exceptions e key additions include new input value 8000 0180 hex multiplexor supplies new pc value cause register record cause exception exception pc r egister save address instruction caused exceptio e 8000 0180 hex input multiplexor initial address begin fetching instructions event exception although shown alu ow signal input control unit 330 chapter 4 processor lw 16 507slt 15 6 7add 1 2 1or 13 12 sw 26 10000clock 6clock 7bubble nopbubblebubbleor 13 0000050010101000000000000000mwbwbdatamemoryinstructionmemorymuxidexexmemmemwbforwardingunitpccontrolexmwbifidmuxhazarddetectionunitshiftleft 2ifflushidflushexflush4585454115signextend80000180registersmuxmuxcauseepc126217131200mwbwbdatamemoryinstructionmemorymuxmuxmuxidexexmemmemwbforwardingunitpccontrolexmwbifidmuxmuxmuxhazarddetectionunitshiftleft 2ifflushidflushexflush458signextend80000180800001808000018080000184registersmuxcauseepc1313alumuxmuxmuxmuxmuxfigure 467 result exception due arithmetic overﬂ ow add instruction e ow detected ex stage clock 6 saving address following add epc register 4c 4 50 hex ow causes flush signals set near end clock cycle deasserting control values setting 0 add clock cycle 7 shows instructions converted bubbles pipeline plus fetching th rst instruction exception routine sw 2510000from instruction location 8000 0180hex note instructions prior add still complete although shown alu ov ow signal input control unit 49 exceptions 331we mentio examples exceptions page 326 see others chapter 5 wit instructions active clock cycle challenge associate exception appropriate instruction moreover multiple exceptions occur simultaneously single clock cycle e solution prioritize exceptions easy determine serv rst mips implementations hardware sorts exceptions earliest instruction interrupted io device requests hardware malfunctions associated sp c instruction implementation exibility interrupt pipeline hence mechanism used exceptions works ju ne e epc captures address interrupted instructions mips cause register records possible exceptions clock cycle exception ware must match exception instruction important clue knowing pipeline stage type exception occur example ned instruction discovered id stage invoking operating system occurs ex stage exceptions collected cause register pending exception eld hardware interrupt based later exceptions earliest one serviced e hardware operating system must work conjunction exceptions behave would expec e hardware contract normally stop ending instruction midstream let prior instructions complete ush following instructions set register show cause exception save address ending instruction jump prearranged addr e operating system contract look cause exception act appropriately ned instruction hardware failure arithmetic ow exception operating system normally kills program returns indicator reason io device request operating system service call operating system saves state program performs desired task point future restores program continue execution case io device requests may en choose run another task resuming task requested io since task may en able proceed io complete exceptions ability save restore state task critical one important frequent uses exceptions handling page faults tlb exceptions chapter 5 describes exceptions handling detail elaboration culty always associating correct exception correct instruction pipelined computers led computer designers relax requirement noncritical cases processors said imprecise interrupts imprecise exceptions example pc would normally 58 hex start clock cycle exception detected even though offending instruction hardware software interfaceimprecise interrupt also called imprecise exception interrupts exceptions pipelined computers associated exact instruction cause interrupt exception 332 chapter 4 processor address 4chex processor imprecise exceptions might put 58hex epc leave operating system determine instruction caused problem mips vast majority computers today support precise interrupts precise exceptions one reason support virtual memory shall see chapter 5 elaboration although mips uses exception entry address 8000 0180 hex almost exceptions uses address 8000 0000 hex improve performance exception handler tlbmiss exceptions see chapter 5which exception rst sequence 1 add 1 2 1 arithmetic ow2 xxx 1 2 1 ned instruction 3 sub 1 2 1 hardware error 410 parallelism via instructions forewarned section brief overview fascinating advanced topics want learn details consult advanced book computer architecture quantitative approach h edition material covered 13 pages expanded almost 200 pages including appendices pipelining exploits potential parallelism among instruction parallelism called instructionlevel parallelism ilp ere two primary methods increasing potential amount instructionlevel pa e rst increasing depth pipeline overlap instructions using laundry analogy assuming washer cycle longer others could divide washer three machines perform wash rinse spin steps traditional washer would move fourstage sixstage pipeline get full speedup need rebalance remaining steps length processors laundry e amount parallelism exploited higher since operations overlapped performance potentially greater since clock cycle shorter another approach replicate internal components computer launch multiple instructions every pipeline stage e general name technique multiple issue multipleissue laundry would replace household washer dryer say three washers three dryers would also recruit assistants fold put away three times much laundry amount time e downside extra work keep machines busy transferring loads next pipeline stage check instructionlevel parallelism e parallelism among instructions multiple issue scheme whereby multiple instructions launched one clock cycle precise interrupt also called precise exception interrupt exception always associated correct instruction pipelined computers 410 parallelism via instructions 333launching multiple instructions per stage allows instruction execution rate exceed clock rate stated alternatively cpi less 1 mentioned chapter 1 sometimes useful ip metric use ipc instructions per clock cycle hence 4 ghz fourway multipleissue microprocessor execute peak rate 16 billion instructions per second bestcase cpi 025 ipc 4 assumin vestage pipeline processor would 20 instructions execution given time todays highend microprocessors attempt issue three six instructions every clock cycle even moderate designs aim peak ipc ere typically however many constraints types instructions may executed simultaneously happens dependences arise ere two major ways implement multipleissue processor majo erence division work compiler hardware division work dictates whether decisions made statically compile time dynamically execution approaches sometimes called static multiple issue dynamic multiple issue see approaches commonly used names may less precise restrictive ere two primary distinct responsibilities must dealt multipleissue pipeline 1 packaging instructions issue slots processor determine many instructions instructions issued given clock cycle static issue processors process least partially handled compiler dynamic issue designs normally dealt runtime processor although compiler en already tried help improve issue rate placing instructions b cial order 2 dealing data control hazards static issue processors compiler handles consequences data control hazards statically contrast dynamic issue processors attempt alleviate least classes hazards using hardware techniques operating execution time although describe distinct approaches reality one approach en borrows techniques neither approach claim perfectly pure concept speculationone important methods fo nding exploiting ilp speculation based great idea prediction speculation approach allows compiler processor guess properties instruction enable execution begin instructions may depend speculated instruction example might speculate outcome branch instructions er branch could executed earlier static multiple issue approach implementing multipleissue processor many decisions made compiler execution dynamic multiple issue approach implementing multiple issue processor many decisions made execution processor issue slots e positions instructions could issue given clock cycle analogy correspond positions starting blocks sprint speculation approach whereby compiler processor guesses outcome instruction remove dependence executing instructions 334 chapter 4 processor another example might speculate store precedes load refer address would allow load executed stor e culty speculation may wrong speculation mechanism must include method check guess right method unroll back th ects instructions executed speculatively e implementation backout capability adds complexity speculation may done compiler hardware example compiler use speculation reorder instructions moving instruction across branch load across store e processor hardware perform transformation runtime using techniques discuss later section e recovery mechanisms used incorrect speculation rath erent case speculation ware compiler usually inserts additional instructions check accuracy speculation prov xup routine use speculation incorrect hardware speculation processor usually bu ers speculative results knows longer speculative speculation correct instructions completed allowing contents b ers written registers memory speculation incorrect hardwar ushes bu ers reexecutes correct instruction sequence speculation introduces one possible problem speculating certain instructions may introduce exceptions formerly present example suppose load instruction moved speculative manner address uses legal speculation incorrec e result would exception occurred e problem complicated fact load instruction speculative exception must occur compilerbased speculation problems avoided adding special speculation support allows exceptions ignored clear really occur hardwarebased speculation exceptions simply b ered clear instruction causing longer speculative ready complete point exception raised normal exception handling proceeds since speculation improve performance done properly decrease performance done carelessly cant ort goes deciding appropriate speculate later section examine static dynamic techniques speculation static multiple issuestatic multipleissue processors use compiler assist packaging instructions handling hazards static issue processor think set instructions issued given clock cycle called issue packet one large instruction multiple operation view analogy since static multipleissue processor usuall restricts mix instructions initiated given clock cycle useful think issue packet single issue packet e set instructions issues together one clock cycle packet may determined statically compiler dynamically processor 410 parallelism via instructions 335instruction allowing several operations certain pr ned elds view led original name approach long instruction word vliw static issue processors also rely compiler take responsibility handling data control hazard e compilers responsibilities may include static branch prediction code scheduling reduce prevent hazards lets look simple static issue version mips processor describe use techniques aggressive processors example static multiple issue mips isato give avor static multiple issue consider simple twoissue mips processor one instructions integer alu operation branch load store design like used embedded mips processors issuing two instructions per cycle require fetching decoding 64 bits instructions many static multipleissue processors essentially vliw processors layout simultaneously issuing instructions restricted simplify decoding instruction issue hence require instructions paired aligned 64bit boundary alu branch portion appearin rst furthermore one instruction pair used require replaced nop us instructions always issue pairs possibly nop one slot figure 468 shows instructions look go pipeline pairs static multipleissue processors vary deal potential data control hazards designs compiler takes full responsibility removing hazards scheduling code inserting noops code executes without need hazard detection hardwaregenerated stalls others hardware detects data hazards generates stalls two issue packets requiring compiler avoid dependences within instruction pair even hazard generally forces entire issue packet containing dependent instruction type pipe stagesalu branch instructionifidexmemwb load store instructionifidexmemwb alu branch instructionifidexmemwb load store instructionifidexmemwb alu branch instructionifidexmemwb load store instructionifidexmemwb alu branch instructionifidexmemwb load store instructionifidexmemwb figure 468 static twoissue pipeline operation e alu data transfer instructions issued time assumed sa vestage structure used singleissue pipeline although strictly necessary advantages particular keeping register writes end pipeline simp es handling exceptions maintenance precise exception model become cult multipleissue processors long instruction word vliw style instruction set architecture launches many operations ned independent single wide instruction typically many separate opcode elds 336 chapter 4 processor instruction stall whether ware must handle hazards try reduce fraction hazards separate issue packets appearance large single instruction multiple operations reinforced assume second approach example issue alu data transfer operation parallel th rst need additional hardwarebeyond usual hazard detection stall logicis extra ports regist le see figure 469 one clock cycle may need read two registers alu operation two store also one write port alu operation one write port load since alu tied alu operation also need separate adder calculate th ective address data transfers without th ese extra resources twoissue pipeline would hindered structural hazards clearly twoissue processor improve performance factor two however requires twice many instructions overlapped execution additional overlap increases relative performance loss data control hazards example simp vestage pipeline datamemoryinstructionmemorymuxmuxalualupcsignextendregisters4mux80000180writedataaddresssignextendfigure 469 static twoissue datapath e additions needed double issue highlighted another 32 bits instruction memory two read ports one write port regist le another alu assume bottom alu handles address calculations data transfers top alu handles everything else 410 parallelism via instructions 337loads use latency one clock cycle prevents one instruction using result without stalling twoissue vestage pipeline result load instruction used next clock cycle means next two instructions use load result without stalling furthermore alu instructions use latency simp vestage pipeline oneinstruction use latency since results used paired load store ectively exploit parallelism av ailable multipleissue processor ambitious compiler hardware scheduling techniques needed static multiple issue requires compiler take role simple multipleissue code schedulinghow would loop scheduled static twoissue pipeline mips loop lw t0 0s1 t0array element addu t0t0s2 add scalar s2 sw t0 0s1 store result addi s1s14 decrement pointer bne s1zeroloop branch s10reorder instructions avoid many pipeline stalls possible assume branches predicted control hazards handled hardware e rst three instructions data dependences last two figure 470 shows best schedule instructions notice one pair instructions issue slots used takes four clocks per loop iteration four clocks execut instructions get disappointing cpi 08 versus best case 05 ipc 125 versus 20 notice computing cpi ipc count nops executed useful instructions would improve cpi performance use latency number clock cycles load instruction instruction use result load without stalling pipeline exampleanswerfigure 470 scheduled code would look twoissue mips pipeline e empty slots noops alu branch instructiondata transfer instructionclock cycle looplw t0 0s1 1addi s1s1œ42addu t0t0s23bne s1zeroloopsw t0 4s1 4 338 chapter 4 processor important compiler technique get performance loops loop unrolling multiple copies loop body made unrolling ilp available overlapping instructions different iterations loop unrolling technique get performance loops access arrays multiple copies loop body made instructions erent iterations scheduled together figure 471 unrolled scheduled code figure 470 would look static twoissue mips pipeline e empty slots noops since th rst instruction loop decrements s1 16 addresses loaded original value s1 address minus 4 minus 8 minus 12 loop unrolling multipleissue pipelinessee well loop unrolling scheduling work example simplicity assume loop index multiple four schedule loop without delays turns need make four copies loop body er unrolling eliminating unnecessary loop overhead instructions loop contain four copies lw add sw plus one addi one bne figure 471 shows unrolled scheduled code unrolling process compiler introduced additional registers t1 t2 t3 e goal process called register renaming eliminate dependences tr ue data dependences could either lead potential hazards prevent compiler fro exibly scheduling code consider unrolled code would look using t0 ere would repeated instances lw t00s1 addu t0 t0 s2 followed sw t04s1 sequences despite using t0 actually completely independentno data val ow one set instructions next case called antidependence name dependence ordering forced purely reuse name rather real data dependence also called true dependence renaming registers unrolling process allows compiler move independent instructions subsequently better schedule exampleanswerregister renaming e renaming registers compiler hardware remove antidependences antidependence also called name dependence ordering forced reuse name typically register rather true dependence carries value two instructions alu branch instructiondata transfer instructionclock cycle loopaddi s1s1œ16 lw t0 0s1 1lw t112s12addu t0t0s2lw t2 8s1 3addu t1t1s2lw t3 4s1 4addu t2t2s2sw t0 16s1 5addu t3t3s2sw t112s1 6sw t2 8s1 7bne s1zeroloopsw t3 4s1 8 410 parallelism via instructions 339the code e renaming process eliminates name dependences preserving true dependences notice 12 14 instructions loop execute pairs takes 8 clocks 4 loop iterations 2 clocks per iteration yields cpi 814 057 loop unrolling scheduling dual issue gave us improvement factor almost 2 partly reducing loop control instructions partly dual issue executio e cost performance improvement using four temporary registers rather one cant increase code size dynamic multipleissue processors dynamic multipleissue processors also known superscalar processors simply superscalars simplest superscalar processors instructions issue order processor decides whether zero one instructions issue given clock cycle obviously achieving good performance processor still requires compiler try schedule instructions move dependences apart thereby improve instruction issue rate even compiler scheduling importan erence simple superscalar vliw processor code whether scheduled guaranteed hardware execute correctly furthermore compiled code always run correctly independent issue rate pipeline structure processor vliw designs case recompilation required moving acr erent processor models ot static issue processors code would run correctly acr erent implementations en poorly make compilatio ectively required many superscalars extend basic framework dynamic issue decisions include dynamic pipeline scheduling dynamic pipeline scheduling chooses instructions execute given clock cycle trying avoid hazards stalls lets start simple example avoiding data hazard consider following code sequence lw t0 20s2addu t1 t0 t2sub s4 s4 t3slti t5 s4 20even though sub instruction ready execute must wait lw addu complet rst might take many clock cycles memory slow chapter 5 explains cache misses reason memory accesses sometimes slow dynamic pipeline scheduling allows hazards avoided either fully partially dynamic pipeline schedulingdynamic pipeline scheduling chooses instructions execute next possibly reordering avoid stalls processors pipeline divided three major units instruction fetch issue unit multiple functional units superscalar advanced pipelining technique enables processor execute one instruction per clock cycle selecting execution dynamic pipeline scheduling hardware support reordering order instruction execution avoid stalls 340 chapter 4 processor dozen highend designs 2013 commit unit figure 472 shows model e rst unit fetches instructions decodes sends instruction corresponding functional unit execution functional unit bu ers called reservation stations hold operands operatio e elaboration discusses alternative reservation stations used many recent processors soon bu er contains operands functional unit ready execute result calculated result completed sent reservation stations waiting particular result well commit unit b ers result safe put result regist le store memory e b er commit unit en called reorder bu er also used supply operands much way forwarding logic stat ically scheduled pipeline result committed regist le fetched directly normal pipeline e combination b ering operands reservation stations results reorder b er provides form register renaming like used compiler earlier loopunrolling example page 338 see conceptually works consider following steps commit unit e unit dynamic outoforder execution pipeline decides safe release result operation programmer visible registers memory reservation station b er within functional unit holds operands operation reorder bu er e bu er holds results dynamically scheduled processor safe store results memory register instruction fetchand decode unitreservationstationreservationstationreservationstationreservationstationintegerintegerfloatingpointloadstorecommitunitinorder issueoutoforder executefunctionalunitsinorder commit figure 472 three primary units dynamically scheduled pipeline e nal step updating state also called retirement graduation 410 parallelism via instructions 3411 instruction issues copied reservation station appropriate functional unit operands available register le reorder b er also immediately copied reservation station e instruction b ered reservation station operands functional unit available issuing instruction register copy operand longer required write register occurred value could overwritten 2 operand regist le reorder b er must waiting produced functional uni e name functional unit produce result tracked unit eventually produces result copied directly waiting reservation station functional unit bypassing registers ese st ectively use reorder bu er reservation stations implement register renaming conceptually think dynamically scheduled pipeline analyzing data ow structure progra e processor executes instructions order preserves dat ow order progra style execution called outoforder execution since instructions execut erent order fetched make programs behave running simple inorder pipeline instruction fetch decode unit required issue instructions order allows dependences tracked commit unit required write results registers memory program fetch order conservative mode called inorder commit hence exception occurs computer point last instruction executed registers updated written instructions instruction causing exception although front end fetch issue back en commit pipeline run order functional units free initiate execution whenever data need available today dynamically scheduled pipelines use inorder commit dynamic scheduling en extended including hardwarebased speculation especially branch outcomes predicting direction branch dynamically scheduled processor continue fetch execute instructions along predicted path instructions committed order know whether branch correctly predicted instructions predicted path committed speculative dynamically scheduled pipeline also support speculation load addresses allowing loadstore reordering using commit unit avoid incorrect speculation next section look use dynamic scheduling speculation intel core i7 design outoforder execution situation pipelined execution instruction blocked executing cause following instructions wait inorder commit commit results pipelined execution written programmer visible state order instructions fetched 342 chapter 4 processor given compilers also schedule code around data dependences might ask superscalar processor would use dynamic schedulin ere three major reasons first stalls predictable particular cache misses see chapter 5 memory hierarchy cause unpredictable stalls dynamic scheduling allows processor hide stalls continuing execute instructions waiting stall end second processor speculates branch outcomes using dynamic branch prediction know exact order instructions compile time since depends predicted actual behavior branches incorporating dynamic speculation exploit instructionlevel parallelism ilp without incorporating dynamic scheduling wo cantly restrict bene ts speculation ird pipeline latency issue width change one implementation another best way compile code sequence also changes example schedule sequence dependent instructions ected issue width latency e pipeline structure ects number times loop must unrolled avoid stalls well process compilerbased register renaming dynamic scheduling allows hardware hide detai us users ware distributors need worry multiple versions program erent implementations instruction set similarly old legacy code get much b new implementation without need recompilation pipelining multipleissue execution increase peak instruction throughput attempt exploit instructionlevel parallelism ilp data control dependences programs however er upper limit sustained performance processor must sometimes wait dependence resolved warecentric approaches exploiting ilp rely ability compiler nd reduce th ects dependences hardwarecentric approaches rely extensions pipeline issue mechanisms speculation performed compiler hardware increase amount ilp exploited via prediction although care must taken since speculating incorrectly likely reduce performance bigpictureunderstanding program performance 410 parallelism via instructions 343modern highperformance microprocessors capable issuing several instructions per clock unfortunately sustaining issue rate cult example despite existence processors four six issues per clock applications sustain two instructions per cloc ere two primary reasons first within pipeline major performance bottlenecks arise dependences alleviated thus reducing parallelism among instructions sustained issue rate although little done true data dependences en compiler hardware know precisely whether dependence exists must cons ervatively assume dependence exists example code makes use pointers particularly ways may lead aliasing lead implied pote ntial dependences contrast greater regularity array accesses en allows compiler deduce dependences exist similarly branches accurately predicted whether runtime compile time limit ability exploit ilp en additional ilp available ability compiler hardware nd ilp may widely separated sometimes execution thousands instructions limited second losses memory hierarchy topic chapter 5 also limit ability keep pipeline full memory system stalls hidden limited amounts ilp also limit extent stalls hidden energy efﬁ ciency advanced pipelining e downside increasing exploitation instructionlevel parallelism via dynamic multiple issue speculation potential energ ciency innovation able turn transistors performance en ciently hit power wall seeing designs multiple processors per chip processors deeply pipelined aggressively speculative predecessors e belief simpler processors fast sophisticated brethren deliver better performance per joule deliver performance per chip designs constrained energy number transistors figure 473 shows number pipeline stages issue width speculation level clock rate cores per chip power several past recent microprocessors note drop pipeline stages power companies switch multicore designs elaboration le memory dynamically scheduled processor le immediately execution using extra registers implement renaming function preserving older copy register instruction updating register longer speculative processors buffer result typically structure called reorder buffer actual update le occurs later part commit stores memory must buffered commit time either store buffer see chapter 5 reorder buffer commit unit allows store write memory buffer buffer valid address valid data store longer dependent predicted branches hardware software interface 344 chapter 4 processor elaboration memor nonblocking caches continue servicing cache accesses cache miss see chapter 5 outoforder execution processors need cache design allow instructions execute miss state whether following techniques components associated primarily ware hardwarebased approach exploiting ilp cases answer may 1 branch prediction 2 multiple issue 3 vliw 4 superscalar 5 dynamic scheduling 6 outoforder execution 7 speculation 8 reorder bu er9 register renaming 411 real stuff arm cortexa8 intel core i7 pipelinesfigure 474 describes two microprocessors examine section whose targets two bookends postpc era check microprocessoryearclock rate pipeline stagesissue width outoforder speculationcores chippower intel 486198925 mhz5 1no1 5 w intel pentium 199366 mhz5 2no1 10 w intel pentium pro 1997200 mhz103 yes 1 29 w intel pentium 4 willamette20012000 mhz223 yes 1 75 w intel pentium 4 prescott 20043600 mhz313 yes 1 103 w intel core20062930 mhz144yes yes yes 2 75 w intel core i5 nehalem2010 3300 mhz144187w intel core i5 ivy bridge20123400 mhz144877w figure 473 record intel microprocessors terms pipeline complexity number cores power e pentium 4 pipeline stages include commit stages included pentium 4 pipelines would even deeper 411 real stuff arm cortexa8 intel core i7 pipelines 345processorintel core i7 920arm a8marketthermal design power clock ratecoreschipfloating pointmultiple issuepeak instructionsclock cyclepipeline stagespipeline schedulebranch prediction1st level caches core2nd level cache core3rd level cache sharedpersonal mobile device2 watts1 ghz1nodynamic214static inorder2level32 kib 32 kib d128 1024 kibserver cloud130 watts266 ghz4yesdynamic414dynamic outoforder speculation2level32 kib 32 kib d256 kib2 8 mibfigure 474 speciﬁ cation arm cortexa8 intel core i7 920 arm cortexa8 e arm corxtexa8 runs 1 ghz 14stage pipeline uses dynamic multiple issue two instructions per clock cycle static inorder pipeline instructions issue execute commit order e pipeline consists three sections instruction fetch instruction decode execute figure 475 shows overall pipeline e rst three stages fetch two instructions time try keep 12instruction entry prefetch bu er full uses twolevel branch predictor using 512entry branch target bu er 4096entry global history b er 8entry return stack predict future returns branch prediction wrong empties pipeline resulting 13clock cycle misprediction penalty e stages decode pipeline determine dependences pair instructions would force sequential execution pipeline execution stages send instructions e six stages instruction execution section er one pipeline load store instructions two pipelines arithmetic operations although th rst pair handle multiplies either instruction pair issued loadstore pipeline e execution stages full bypassing three pipelines figure 476 shows cpi a8 using small versions programs derived spec2000 benchmarks ideal cpi 05 best case 14 median case 20 worst case 52 median case 80 stalls due pipelining hazards 20 stalls due memory 346 chapter 4 processor hierarchy pipeline stalls caused branch mispredictions structural hazards data dependencies pairs instructions given static pipeline a8 compiler try avoid structural hazards data dependences elaboration cor gurable core supports armv7 instruction set architecture delivered ip intellectual property core ip cores dominant form technology delivery embedded personal mobile device related markets billions arm mips processors created ip cores note ip cores different cores intel i7 multicore computers ip core may multicore designed incorporated logic hence core chip c processors encoder decoder video io interfaces memory interfaces fabricated yield processor optimized particular application although processor core almost identical resultant chips many differences one parameter size l2 cache vary factor eight intel core i7 920x86 microprocessors employ sophisticated pipelining approaches using dynamic multiple issue dynamic pipeline scheduling outoforder execution speculation 14stage pipeline ese processors however still faced challenge implementing complex x86 instruction set described chapter 2 intel fetches x86 instructions translates internal mipslike instructions intel calls microoperations e micro operations executed sophisticated dynamically scheduled speculative pipeline capable sustaining execution rate six microoperations per clock cycle section focuses microoperation pipeline figure 475 a8 pipeline e rst three stages fetch instructions 12entry instruction fetch bu er e address generation unit agu uses branch target er btb global history bu er ghb return stack rs predict branches try keep fetch queue full instruction deco stages instruction execution six stages f0f1f2d0d1 branch mispredict penalty13 cyclesinstruction execute loadstorealu pipe 1ls pipe 0 1d2d3 instruction decodearchitectural register fileinstructionfetchagu ramtlb12entry fetch queuebtbghbrsd4e0e1e2e3e4e5 bpupdatealumul pipe 0bpupdatebpupdate 411 real stuff arm cortexa8 intel core i7 pipelines 347when consider design sophisticated dynamically scheduled processors design functional units cache regist le instruction issue overall pipeline control become intermingled making cult separate datapath pipeline many engineers researchers adopted term microarchitecture refer detailed internal architecture processor e intel core i7 uses scheme resolving antidependences incorrect speculation uses reorder b er together register renaming register renaming explicitly renames architectural registers processor 16 case 64bit version x86 architecture larger set physical register e core i7 uses register renaming remove antidependences register renaming requires processor maintain map architectural registers physical registers indicating physical register current copy architectural register keeping track renamings occurred register renaming ers another approach recovery event incorrect speculation simply undo mappings occurred since th rst incorrectly speculated instructio cause state processor return last correctly executed instruction keeping correct mapping architectural physical registers figure 477 shows overall organization pipeline core i7 eight steps x86 instruction goes execution 1 instruction fetc e processor uses multilevel branch target b er achieve balance speed prediction accuracy ere also return address stack speed function return mispredictions cause penalty 15 cycles using predicted address instruction fetch unit fetches 16 bytes instruction cache e 16 bytes placed predecode instruction b er e predecode stage transforms 16 bytes individual x86 instruction predecode microarchitecture e organization processor including major functional units interconnection control architectural registers e instruction set visible registers processor example mips 32 integer oating point registers 100twolfbzip2gzipparsergapperlbmkgcccraftyvprvortexeonmcf 200300 400 500600memory hierarchy stalls pipeline stalls ideal cpi141163 169 170 185195 201 207 211 241320 517figure 476 cpi arm cortex a8 minnespec benchmarks small versions spec2000 benchmarks ese benchmarks use much smaller inputs reduce running time several orders magnitude e smaller size cantly underestimates cpi impact memory hierarchy see chapter 5 348 chapter 4 processor nontrivial since length x86 instruction 1 15 bytes predecoder must look number bytes knows instruction length individual x86 instructions placed 18entry instruction queue 3 microop decodeindividual x86 instructions translated micro operations microo ree decoders handle x86 instructions translate directly one microop x86 instructions complex semantics microcode engine used produce microop sequence produce four microops every cycle continues necessary microop sequence generated e microops placed according order x86 instructions 28entry microop b er e microop b er performs loop stream detection small sequence instructions less 28 instructions 256 bytes length comprises loop loop stream detecto nd loop directly figure 477 core i7 pipeline memory components e total pipeline depth 14 stages branch mispredictions costing 17 clock cyc design bu er 48 loads 32 stor e six independent units begin execution ready risc operation clock cycle 256 kb unified l2cache eightway register alias table allocator 128entry reorder buffer 36entry reservation station retirementregister filealushiftsseshufflealu128bitfmulfdiv128bitfmulfdiv128bitfmulfdivsseshufflealusseshufflealumemory order buffer alushiftalushiftloadaddressstoreaddressstoredatastore loadmicrocodecomplex macroopdecoder28entry microop loop stream detect buffer simplemacroopdecodersimplemacroopdecodersimplemacroopdecoder128entry inst tlb fourway instruction fetch hardware 18entry instruction queue 32 kb inst cache fourway associative 16byte predecodemacroopfusion fetch buffer 64entry data tlb 4way associative 32kb dualported data cache 8way associative 512entry unified l2 tlb 4way 8 mb core shared inclusive l3 cache 16way associative uncore arbiter handles scheduling andclockpower state differences 411 real stuff arm cortexa8 intel core i7 pipelines 349issue microops bu er eliminating need instruction fetch instruction decode stages activated 5 perform basic instruction issuelooking register location register tables renaming registers allocating reorder b er entry fetching results registers reorder b er sending microops reservation stations e i7 uses 36entry centralized reservation station shared six functional units six microops may dispatched functional units every clock cycle e individual function units execute microops results sent back waiting reservation station well register retirement unit update register state known instruction longer speculative e entry corresponding instruction reorder b er marked complete 8 one instructions head reorder bu er marked complete pending writes register retirement unit executed instructions removed reorder b er elaboration hardware second fourth steps combine fuse operations together reduce number operations must performed macroop fusion second step takes x86 instruction combinations compare followed branch fuses single operation microfusion fourth step combines microoperation pairs loadalu operation alu operationstore issues single reservation station still issue independently thus increasing usage buffer study intel core architecture also incorporated microfusion macrofusion bird et al 2007 discovered microfusion little impact performance macrofusion appears modest positive impact integer perfor oatingpoint performance performance intel core i7 920 figure 478 shows cpi intel core i7 spec2006 benchmarks ideal cpi 025 best case 044 median case 079 worst case 267 cult erentiate pipeline stalls memory stalls dynamic outoforder execution pipeline show th ectiveness branch prediction speculation figure 479 shows percentage branches mispredicted percentage work measured numbers micro ops dispatched pipeline retire results annulled relative microop dispatch e min median max branch mispredictions 0 2 10 wasted work 1 18 39 e wasted work cases closely matches branch misprediction rates gobmk astar several instances mcf wasted work seems relatively larger misprediction rate divergence likely due 350 chapter 4 processor 325215cpi105044 059 061 065074 077082102 106 123 212 2670libquantumh264refhmmerperlbench bzip2xalancbmksjenggobmkastargccomnetppmcfstalls misspeculation ideal cpifigure 478 cpi intel core i7 920 running spec2006 integer benchmarks figure 479 percentage branch mispredictions wasted work due unfruitful speculation intel core i7 920 running spec2006 integer benchmarks 4035 30252015 105 0libquantumh264refhmmerperlbench bzip2xalancbmksjenggobmkastargccomnetppmcfbranch misprediction wasted work 0 2 2 2 5 1 5 109 2 2 6 1 5 6 11 24 7 25 32 38 15 22 39 412 going faster instructionlevel parallelism matrix multiply 351to memory behavior high data cache miss rates mcf dispatch many instructions incorrect speculation lon cient reservation stations available stalled memory references branch among many speculated instructions nally mispredicted microops corresponding instructions ushed e intel core i7 combines 14stage pipe line aggressive multiple issue achieve high performance keeping latencies backtoback operations low impact data dependences reduced serious potential performance bottlenecks programs running processo e following list includes potential performance problems last three apply form highperformance pipelined processor e use x86 instructions map simple microoperations branches ar cult predict causing misprediction stalls restarts speculation fails long dependencestypically caused longrunning instructions memory hierarchy lead stalls performance delays arising accessing memory see chapter 5 cause processor stall 412 going faster instructionlevel parallelism matrix multiply returning dgemm example chapter 3 see impact instruction level parallelism unrolling loop multiple issue outof order execution processor instructions work figure 480 shows unrolled version figure 323 contains c intrinsics produce avx instructions like unrolling example figure 471 going unroll loop 4 times use constant unroll c code control amount unrolling case want try values rather manually unrolling loop c making 4 copies intrinsics figure 323 rely gcc compiler unrolling o3 optimization surround intrinsic simple loop 4 iterations lines 9 14 20 replace scalar c0 figure 323 4element array c lines 8 10 16 21 figure 481 shows assembly language output unrolled code expected figure 481 4 versions avx instructions figure 324 one exception need 1 copy vbroadcastsd understanding program performance 352 chapter 4 processor instruction since use four copies b element register ymm0 repeatedly throughout loop us 5 avx instructions figure 324 become 17 figure 481 7 integer instructions appear although constants addressing changes account unrolling hence despite unrolling 4 times number instructions body loop doubles 12 24 figure 482 shows performance increase dgemm 32x32 matrices going unoptimized avx avx unrolling unrolling doubles performance going 64 gflops 146 gflops optimizations subword parallelism instruction level parallelism result overall speedup 88 versus unoptimized dgemm figure 321 elaboration mentioned elaboration section 38 results turbo mode turned turn like chapter 3 improve results temporary increase clock rate 3326 127 21 gflops unoptimized dgemm 81 gflops avx 186 gflops unrolling avx mentioned section 38 turbo mode works particularly well case using single core eightcore chip1 include x86intrinh 2 define unroll 43 4 void dge mm int n double double b double c 5 6 int 0 n iunroll 4 7 int j 0 j n j 8 __ m256d c4 9 int x 0 x unroll x 10 cx _ mm256_load_pdcix4jn11 12 int k 0 k n k 13 14 __ m256d b _mm256_broadcast_sdbkjn15 int x 0 x unroll x 16 cx _ mm256_add_pdcx17 _ mm256_mul_pd_mm256_load_pdankx4i b18 19 20 int x 0 x unroll x 21 _ mm256_store_pdcix4jn cx22 23 figure 480 optimized c version dgemm using c intrinsics generate avx subword parallel instructions x86 figure 323 loop unrolling create opportunities instructionlevel parallelism figure 481 shows assembly language produced compiler inner loop unrolls three forloop bodies expose instruction level parallelism 412 going faster instructionlevel parallelism matrix multiply 353elaboration pipeline stalls despite reuse register ymm5 lines 9 17 figure 481 intel core i7 pipeline renames registers following statements true false e intel core i7 uses multipleissue pipeline directly execute x86 instructions 2 a8 core i7 use dynamic multiple issue e core i7 microarchitecture many registers x86 requires e intel core i7 uses less half pipeline stages earlier intel pentium 4 prescott see figure 473 check vmovapd r11ymm4 load 4 elements c ymm41mov rbxrax register rax rbx2xor ecxecx register ecx 03vmovapd 0x20r11ymm3 load 4 elements c ymm3 4vmovapd 0x40r11ymm2 load 4 elements c ymm2 5vmovapd 0x60r11ymm1 load 4 elements c ymm1 6vbroadcastsd rcxr91ymm0 make 4 copies b element 7add 0x8rcx register rcx rcx 88vmulpd raxymm0ymm5 parallel mul ymm14 elements 9mm4vaddpd ymm5ymm4ymm4 parallel add ymm5 10vmulpd 0x20raxymm0ymm5 parallel mul ymm14 elements 11vaddpd ymm5ymm3ymm3 parallel add ymm5 ymm3 12vmulpd 0x40raxymm0ymm5 parallel mul ymm14 elements 13vmulpd 0x60raxymm0ymm0 parallel mul ymm14 elements 14add r8rax register rax rax r8 15cmp r10rcx compare r8 rax 16vaddpd ymm5ymm2ymm2 parallel add ymm5 ymm2 17vaddpd ymm0ymm1ymm1 parallel add ymm0 ymm1 18jne 68 dgemm0x68 jump r8 rax 19add 0x1esi register esi esi 1 20vmovapd ymm4r11 store ymm4 4 c elements 21vmovapd ymm30x20r11 store ymm3 4 c elements 22vmovapd ymm20x40r11 store ymm2 4 c elements 23vmovapd ymm10x60r11 store ymm1 4 c elements 24figure 481 x86 assembly language body nested loops generated compiling unrolled c code figure 480 354 chapter 4 processor 413 advanced topic introduction digital design using hardware design language describe model pipeline pipelining illustrationsmodern digital design done using hardware description languages modern computeraided synthesis tools create detailed hardware designs descriptions using libraries logic synthesis entire books written languages use digit section appears online gives brief introduction shows hardware design language verilog case used describe mips control behaviorally form suitable hardware synthesis provides series behavioral models verilog th vestage pipeline e initial model ignores hazards additions model highlight changes forwarding data hazards branch hazards provide dozen illustrations using singlecycle graphical pipeline representation readers want see detail pipelines work sequences mips instructions 413figure 482 performance three versions dgemm 32x32 matrices subword parallelism instruction level parallelism led speedup almost factor 9 unoptimized code figure 321 ð40unoptimized 1764146avx avxunroll 80gflops120160 4132 413 introduction digital design using hardware design language describe introduction digital design using hardware design language describe model pipeline pipelining illustrations cd section covers hardware decription languages gives dozen examples pipeline diagrams starting page 41318 mentioned appendix c verilog describe processors simulation intention verilog sp cation synthesized achieve acceptable synthesis results size speed behavioral sp cation intended synthesis must carefully de lineate highly combinational portions design datapath control e datapath synthesized using available libraries verilog sp cation intended synthesis usually longer complex start behavioral model 5stage pipeline illustrate dichotomy behavioral synthesizeable designs give two verilog descriptions multiplecycleperinstruction mips processor one intended solely simulations one suitable synthesis using verilog behavioral speciﬁ cation simulation 5stage pipelinefigure 4131 shows verilog behavioral description pipeline handles alu instructions well loads stores accommodate branches even incorrectly postpone including later chapter verilog lacks ability ne registers na elds structures c use several independent registers pipeline register name registers pr x using convention hence ifidir ir portion ifid pipeline register version behavioral description intended synthesis instructions take number clock cycles hardware design control done simpler fashion repeatedly decodin elds instruction pipe stage th erence instruction register ir needed throughout pipeline entire ir passed pipe stage pipe stage read verilog descriptions chapter remember actions always block occur parallel every clock cycle since blocking assignments order events within always block arbitrary 413 413 introduction digital design using hardware design language 4133figure 4131 verilog behavorial model mips ﬁ vestage pipeline ignoring branch data hazards design earlier chapter 4 use separate instruction data memories would implemented using separate caches describe chapter 5 continues next page module cpu clock instruction opcodes parameter lw 6b100011 sw 6b101011 beq 6b000100 noop 32b00000_100000 aluop 6b0 input clock reg310 pc regs031 imemory01023 dmemory01023 separate memories ifidir idexa idexb idexir exmemir exmemb pipeline registers exmemaluout memwbvalue memwbir pipeline registers wire 40 idexrs idexrt exmemrd memwbrd memwbrt access register elds wire 50 exmemop memwbop idexop access opcodeswire 310 bin alu inputs assignments de ne elds pipeline registers assign idexrs idexir2521 rs eld assign idexrt idexir2016 rt eld assign exmemrd exmemir1511 rd eld assign memwbrd memwbir1511 rd eld assign memwbrt memwbir2016 rt eldused loads assign exmemop exmemir3126 opcode assign memwbop memwbir3126 opcode assign idexop idexir3126 opcode inputs alu come directly idex pipeline registers assign idexa assign bin idexb reg 50 used initialize registers initial begin pc 0 ifidir noop idexir noop exmemir noop memwbir noop put noops pipeline registers i0i31ii1 regsi initialize registersjust arent cares end always posedge clock begin remember actions happen every pipe stage use happen parallel rst instruction pipeline fetched ifidir imemorypc2 pc pc 4 end fetch increment pc second instruction pipeline fetching registers idexa regsifidir2521 idexb regsifidir2016 get two registers idexir ifidir pass along ircan happen anywhere since affects next stage third instruction address calculation alu operation idexoplw idexopsw address calculation exmemaluout idexa 16idexir15 idexir150 else idexopaluop case idexir50 case various rtype instructions 32 exmemaluout bin add operation default rtype operations subtract slt etc endcase 4134 413 introduction digital design using hardware design language describe figure 4131 verilog behavorial model mips ﬁ vestage pipeline ignoring branch data hazards continued implementing forwarding verilog extend verilog model figure 4132 shows addition forwarding logic case source destination alu instructions neither load stalls branches handled add shortly e changes earlier verilog description highlighted someone proposed moving write result alu instruction wb mem stage pointing would reduce maximum length forwards alu instruction one cycle following accurate reasons consider change 1 would actually change forwarding logic advantage 2 impossible implement change circumstance since write alu result must stay pipe stage write load result 3 moving write alu instructions would create possibility writes occurring tw erent instructions clock cycle either extra write port would required regist le structural hazard would created e result alu instruction available time write mem check exmemir idexir exmemb idexb pass along ir b register mem stage pipeline exmemopaluop memwbvalue exmemaluout pass along alu result else exmemop lw memwbvalue dmemoryexmemaluout2 else exmemop sw dmemoryexmemaluout2 exmemb store memwbir exmemir pass along ir wb stage memwbopaluop memwbrd 0 update registers alu operation destination 0 regsmemwbrd memwbvalue alu operation else exmemop lw memwbrt 0 update registers load destination 0 regsmemwbrt memwbvalue endendmodule 413 introduction digital design using hardware design language 4135module cpu clockparameter lw 6b100011 sw 6b101011 beq 6b000100 noop 32b00000_100000 aluop 6b0 input clock reg310 pc regs031 imemory01023 dmemory01023 separate memories ifidir idexa idexb idexir exmemir exmemb pipeline registers exmemaluout memwbvalue memwbir pipeline registers wire 40 idexrs idexrt exmemrd memwbrd memwbrt hold register elds wire 50 exmemop memwbop idexop hold opcodes wire 310 bin declare bypass signals wire bypassafrommem bypassafromaluinwbbypassbfrommem bypassbfromaluinwb bypassafromlwinwb bypassbfromlwinwb assign idexrs idexir2521 assign idexrt idexir1511 assign exmemrd exmemir1511 assign memwbrd memwbir2016 assign exmemop exmemir3126 assign memwbrt memwbir2520 assign memwbop memwbir3126 assign idexop idexir3126 bypass input mem stage alu operation assign bypassafrommem idexrs exmemrd idexrs0 exmemopaluop yes bypass bypass input b mem stage alu operation assign bypassbfrommem idexrt exmemrdidexrt0 exmemopaluop yes bypass bypass input wb stage alu operation assign bypassafromaluinwb idexrs memwbrd idexrs0 memwbopaluop bypass input b wb stage alu operation assign bypassbfromaluinwb idexrt memwbrd idexrt0 memwbopaluop bypass input wb stage lw operation assign bypassafromlwinwb idexrs memwbir2016 idexrs0 memwboplw bypass input b wb stage lw operation assign bypassbfromlwinwb idexrt memwbir2016 idexrt0 memwboplw input alu bypassed mem bypass otherwise wb bypass otherwise comes idex register assign bypassafrommem exmemaluout bypassafromaluinwb bypassafromlwinwb memwbvalue idexa b input alu bypassed mem bypass otherwise wb bypass otherwise comes idex register assign bin bypassbfrommem exmemaluout bypassbfromaluinwb bypassbfromlwinwb memwbvalue idexb reg 50 used initialize registers initial begin pc 0 ifidir noop idexir noop exmemir noop memwbir noop put noops pipeline registers 0i31i i1 regsi initialize registersjust arent cares end always posedge clock begin rst instruction pipeline fetched ifidir imemorypc2 pc pc 4 end fetch increment pcfigure 4132 behavioral deﬁ nition ﬁ vestage mips pipeline bypassing alu operations address calculations e code added figure 4131 handle bypassing highlighted bypasses require changing alu inputs come changes required combinational logic responsible selecting alu inputs continues next page 4136 413 introduction digital design using hardware design language describe behavioral verilog stall detection ignore branches stalls data hazards mips pipeline co ned one simple case loads whose results currently wb clock stage us extending verilog handle load destination either alu instruction ective address calculation reasonably straightforward figure 4133 shows additions needed someone asked possibility data hazards occurring memory opposed register following statements hazards true 1 since memory accesses occur mem stage memory operations done order instruction execution making hazards impossible pipeline 2 hazards possible pipeline discussed yet 3 pipeline ever hazard involving memory since programmers job keep order memory references accurate check second instruction register fetch idexa regsifidir2521 idexb regsifidir2016 get two registers idexir ifidir pass along ircan happen anywhere since affects next stage third instruction address calculation alu operation idexoplw idexopsw address calculation copy b exmemaluout idexa 16idexir15 idexir150 else idexopaluop case idexir50 case various rtype instructions 32 exmemaluout bin add operation default rtype operations subtract slt etc endcase exmemir idexir exmemb idexb pass along ir b register mem stage pipeline exmemopaluop memwbvalue exmemaluout pass along alu result else exmemop lw memwbvalue dmemoryexmemaluout2 else exmemop sw dmemoryexmemaluout2 exmemb store memwbir exmemir pass along ir wb stage memwbopaluop memwbrd 0 regsmemwbrd memwbvalue alu operation else exmemop lw memwbrt 0 regsmemwbrt memwbvalue endendmodulefigure 4132 behavioral deﬁ nition ﬁ vestage mips pipeline bypassing alu operations address calculations continued 413 introduction digital design using hardware design language 4137figure 4133 behavioral deﬁ nition ﬁ vestage mips pipeline stalls loads destination alu instruction effective address calculation e changes figure 4132 highlighted continues next page module cpu clockparameter lw 6b100011 sw 6b101011 beq 6b000100 noop 32b00000_100000 aluop 6b0 input clock reg310 pc regs031 imemory01023 dmemory01023 separate memories ifidir idexa idexb idexir exmemir exmemb pipeline registers exmemaluout memwbvalue memwbir pipeline registers wire 40 idexrs idexrt exmemrd memwbrd memwbrt hold register elds wire 50 exmemop memwbop idexop hold opcodes wire 310 bin declare bypass signals wire stall bypassafrommem bypassafromaluinwbbypassbfrommem bypassbfromaluinwb bypassafromlwinwb bypassbfromlwinwb assign idexrs idexir2521 assign idexrt idexir1511 assign exmemrd exmemir1511 assign memwbrd memwbir2016 assign exmemop exmemir3126 assign memwbrt memwbir2520 assign memwbop memwbir3126 assign idexop idexir3126 bypass input mem stage alu operation assign bypassafrommem idexrs exmemrd idexrs0 exmemopaluop yes bypass bypass input b mem stage alu operation assign bypassbfrommem idexrt exmemrdidexrt0 exmemopaluop yes bypass bypass input wb stage alu operation assign bypassafromaluinwb idexrs memwbrd idexrs0 memwbopaluop bypass input b wb stage alu operation assign bypassbfromaluinwb idexrtmemwbrd idexrt0 memwbopaluop bypass input wb stage lw operation assign bypassafromlwinwb idexrs memwbir2016 idexrs0 memwboplw bypass input b wb stage lw operation assign bypassbfromlwinwb idexrtmemwbir2016 idexrt0 memwboplw input alu bypassed mem bypass otherwise wb bypass otherwise comes idex register assign bypassafrommem exmemaluout bypassafromaluinwb bypassafromlwinwb memwbvalue idexa b input alu bypassed mem bypass otherwise wb bypass otherwise comes idex register assign bin bypassbfrommem exmemaluout bypassbfromaluinwb bypassbfromlwinwb memwbvalue idexb signal detecting stall based use result lw assign stall memwbir3126lw source instruction load idexoplwidexopsw idexrsmemwbrd stall address calc idexopaluop idexrsmemwbrdidexrtmemwbrd alu use reg 50 used initialize registers initial begin pc 0 ifidir noop idexir noop exmemir noop memwbir noop put noops pipeline registers 0i31i i1 regsi initialize registersjust arent cares end always posedge clock begin stall begin rst three pipeline stages stall load hazard 4138 413 introduction digital design using hardware design language describe figure 4133 behavioral deﬁ nition ﬁ vestage mips pipeline stalls loads destination alu instruction effective address calculation continued 4 memory hazards may possible pipelines occur particular pipeline 5 although pipeline control would obligated maintain ordering among memory references avoid hazards impossible design pipeline references could order implementing branch hazard logic verilog extend verilog behavioral model implement control branches add code model branch equal using predict taken strategy e verilog code shown figure 4134 implements branch hazard detecting taken branch id using signal squash instruction setting ir 0 ective noop mips32 addition pc assigned branch target note prevent unexpected latch important pc clearly assigned every path always block hence assign pc single statement lastly note although figure 4134 incorporates basic logic branches control hazards incorporation branches requires additional bypassing data hazard detection included rst instruction pipeline fetched ifidir imemorypc2 pc pc 4 idexir ifidir pass along ircan happen anywhere since affects next stage second instruction register fetch idexa regsifidir2521 idexb regsifidir2016 get two registers third instruction address calculation alu operation idexoplw idexopsw address calculation copy b exmemaluout idexa 16idexir15 idexir150 else idexopaluop case idexir50 case various rtype instructions 32 exmemaluout bin add operation default rtype operations subtract slt etc endcase exmemir idexir exmemb idexb pass along ir b register end else exmemir noop freeze rst three stages pipeline inject nop ex output mem stage pipeline exmemopaluop memwbvalue exmemaluout pass along alu result else exmemop lw memwbvalue dmemoryexmemaluout2 else exmemop sw dmemoryexmemaluout2 exmemb store memwbir exmemir pass along ir wb stage memwbopaluop memwbrd 0 regsmemwbrd memwbvalue alu operation else exmemop lw memwbrt 0 regsmemwbrt memwbvalue endendmodule 413 introduction digital design using hardware design language 4139module cpu clockparameter lw 6b100011 sw 6b101011 beq 6b000100 noop 32b0000000_0000000_0000000_0000000 aluop 6b0input clock reg310 pc regs031 imemory01023 dmemory01023 separate memories ifidir idexa idexb idexir exmemir exmemb pipeline registers exmemaluout memwbvalue memwbir pipeline registers wire 40 idexrs idexrt exmemrd memwbrd hold register elds wire 50 exmemop memwbop idexop hold opcodes wire 310 bin declare bypass signals wire takebranch stall bypassafrommem bypassafromaluinwbbypassbfrommem bypassbfromaluinwb bypassafromlwinwb bypassbfromlwinwb assign idexrs idexir2521 assign idexrt idexir1511 assign exmemrd exmemir1511 assign memwbrd memwbir2016 assign exmemop exmemir3126 assign memwbop memwbir3126 assign idexop idexir3126 bypass input mem stage alu operation assign bypassafrommem idexrs exmemrd idexrs0 exmemopaluop yes bypass bypass input b mem stage alu operation assign bypassbfrommem idexrt exmemrdidexrt0 exmemopaluop yes bypass bypass input wb stage alu operation assign bypassafromaluinwb idexrs memwbrd idexrs0 memwbopaluop bypass input b wb stage alu operation assign bypassbfromaluinwb idexrt memwbrd idexrt0 memwbopaluop bypass input wb stage lw operation assign bypassafromlwinwb idexrs memwbir2016 idexrs0 memwboplw bypass input b wb stage lw operation assign bypassbfromlwinwb idexrt memwbir2016 idexrt0 memwboplw input alu bypassed mem bypass otherwise wb bypass otherwise comes idex register assign bypassafrommem exmemaluout bypassafromaluinwb bypassafromlwinwb memwbvalue idexa b input alu bypassed mem bypass otherwise wb bypass otherwise comes idex register assign bin bypassbfrommem exmemaluout bypassbfromaluinwb bypassbfromlwinwb memwbvalue idexb signal detecting stall based use result lw assign stall memwbir3126lw source instruction load idexoplwidexopsw idexrsmemwbrd stall address calc idexopaluop idexrsmemwbrdidexrtmemwbrd alu usefigure 4134 behavioral deﬁ nition ﬁ vestage mips pipeline stalls loads destination alu instruction effective address calculation e changes figure 4132 highlighted continues next page 41310 413 introduction digital design using hardware design language describe figure 4134 behavioral deﬁ nition ﬁ vestage mips pipeline stalls loads destination alu instruction effective address calculation continued signal taken branch instruction beq registers equalassign takebranch ifidir3126beq regsifidir2521 regsifidir2016 reg 50 used initialize registers initial begin pc 0 ifidir noop idexir noop exmemir noop memwbir noop put noops pipeline registers 0i31i i1 regsi initialize registersjust arent dont cares end always posedge clock begin stall begin rst three pipeline stages stall load hazard takebranch begin rst instruction pipeline fetched normally ifidir imemorypc2 pc pc 4 end else begin taken branch id instruction wrong insert noop reset pc ifdir noop pc pc 4 16ifidir15 ifidir1502 end second instruction register fetch idexa regsifidir2521 idexb regsifidir2016 get two registers third instruction address calculation alu operation idexir ifidir pass along ir idexoplw idexopsw address calculation copy b exmemaluout idexa 16idexir15 idexir150 else idexopaluop case idexir50 case various rtype instructions 32 exmemaluout bin add operation default rtype operations subtract slt etc endcase exmemir idexir exmemb idexb pass along ir b register end else exmemir noop freeze rst three stages pipeline inject nop ex output mem stage pipeline exmemopaluop memwbvalue exmemaluout pass along alu result else exmemop lw memwbvalue dmemoryexmemaluout2 else exmemop sw dmemoryexmemaluout2 exmemb store wb stagememwbir exmemir pass along ir memwbopaluop memwbrd 0 regsmemwbrd memwbvalue alu operation else exmemop lw memwbir2016 0 regsmemwbir2016 memwbvalue endendmodule 413 introduction digital design using hardware design language 41311using verilog behavioral speciﬁ cation synthesis demonstate contrasting types verilog show two descriptions erent nonpipelined implementation style mips uses multiple clock cycles per instruction since instructors make synthesizable description mips pipe line project class chose include would also long figure 4135 gives behavioral sp cation multicycle implementation mips processor use behavioral operations would cult synthesize separate datapath control unit reasonable ciency version demonstrates another approach control using meal nitestate machine see discussion section c10 app e use mealy machine allows output depend inputs current state allows us decrease total number states since version mips design intended synthesis considerably complex relied number verilog modules sp ed appendix b including following e 4to1 multiplexor shown figure b42 3to1 multiplexor trivially derived based 4to1 multiplexor e mips alu shown figure b515 e mips alu contro ned figure b516 e mips regist le ned figure b811 lets look verilog version mips processor intended synthesis figure 4136 shows structural version mips datapath figure 4137 uses datapath module specify mips cpu version also demonstrates another approach implementing control unit well optimizations rely relationships various control signals observe state machine sp cation provides sequencing actions e setting control lines done series assign statements depend state well opco eld instruction register one fold setting control state sp cation would look like mealysty nitestate control unit setting control lines sp ed using assign statements outside always block logic synthesis systems generate small implementation nitestate machine determines setting state register uses external logic derive control inputs datapath writing version control also taken advantage number insights relationship various control signals well situations dont care control signal value examples given following elaboration 41312 413 introduction digital design using hardware design language describe module cpu clockparameter lw 6b100011 sw 6b101011 beq6b000100 j6d2 input clock clock external input architecturally visible registers scratch registers implementationreg 310 pc regs031 memory 01023 ir aluout mdr breg 20 state processor state wire 50 opcode use get opcode easily wire 310 signextendpcoffset used get signextended offset eldassign opcode ir3126 opcode upper 6 bits assign signextend 16ir15ir150 sign extension lower 16 bits instruction assign pcoffset signextend 2 pc offset shifted set pc 0 start control state 0initial begin pc 0 state 1 endthe state machinetriggered rising clockalways posedge clock begin regs0 0 make r0 0 shortcut way make sure r0 always 0 case state action depends state 1 begin rst step fetch instruction increment pc go next state ir memorypc2 pc pc 4 state 2 next state end 2 begin second step instruction decode register fetch also compute branch address regsir2521 b regsir2016 state 3 aluout pc pcoffset compute pcrelative branch target end 3 begin third step loadstore execution alu execution branch completion state 4 default next state opcodelw opcodesw aluout signextend compute effective address else opcode6b0 case ir50 case various rtype instructions 32 aluout b add operation default aluout rtype operations subtract slt etc endcasefigure 4135 behavioral speciﬁ cation multicycle mips design cycle behavior multicycle design purely simulation sp cation used synthesis continues next page 413 introduction digital design using hardware design language 41313 else opcode beq begin ab pc aluout branch takenupdate pc state 1 end else opocdej begin pc pc3128 ir2502b00 jump target pc state 1 end jumps else opcodes exception unde ned instruction would go end 4 begin opcode6b0 begin alu operation regsir1511 aluout write result state 1 end rtype nishes else opcode lw begin load instruction mdr memoryaluout2 read memory state 5 next state end else opcode lw begin memoryaluout2 b write memory state 1 return state 1 end store nishes else instructions go end 5 begin lw instruction still execution regsir2016 mdr write mdr register state 1 end complete lw instruction endcase end endmodulefigure 4135 behavioral speciﬁ cation multicycle mips design continued 41314 413 introduction digital design using hardware design language describe module datapath aluop regdst memtoreg memread memwrite iord regwrite irwritepcwrite pcwritecond alusrca alusrcb pcsource opcode clock control inputs clock input 10 aluop alusrcb pcsource 2bit control signals input regdst memtoreg memread memwrite iord regwrite irwrite pcwrite pcwritecond alusrca clock 1bit control signals output 50 opcode opcode needed output control reg 310 pc memory 01023 mdrir aluout cpu state temporaries wire 310 absignextendoffset pcoffset aluresultout pcvalue jumpaddr writedata aluain alubinmemout signals derived registers wire 30 aluctl alu control lines wire zero zero signal alu wire40 writereg signal used communicate destination register initial pc 0 start pc 0combinational signals used datapath read using word address either aluout pc address sourceassign memout memread memoryiord aluout pc20 assign opcode ir3126 opcode shortcut get write register address one two elds depending regdstassign writereg regdst ir1511 ir2016 get write register data either aluout mdrassign writedata memtoreg mdr aluout signextend lower half ir loadstorebranch offsetsassign signextendoffset 16ir15ir150 signextend lower 16 bits branch offset also shifted make word offsetassign pcoffset signextendoffset 2 input alu either rs register pcassign aluain alusrca pc alu input pc compose jump addressassign jumpaddr pc3128 ir2502b00 jump addressfigure 4136 verilog version multicycle mips datapath appropriate synthesis datapath relies several units appendix b initial statements synth esize version used synthesis would incorpor ate reset signal th ect also note resetting r0 0 every clock best way ensure r0 stays 0 instead modifying register le module produce 0 whenever r0 read ignore writes r0 would mor cient solution continues next page 413 introduction digital design using hardware design language 41315 creates instance alu control unit see module de ned figure c516 page c38 input aluop controlunit set used describe instruction class chapter 4 input ir50 function code eld alu instruction output aluctl actual alu control bits chapter 4alucontrol alucontroller aluopir50aluctl alu control unit creates 3to1 multiplexor used select source next pc inputs aluresultout incremented pc aluout branch address jump target address pcsource selector input pcvalue multiplexor outputmult3to1 pcdatasrc aluresultoutaluoutjumpaddr pcsource pcvalue creates 4to1 multiplexor used select b input alu inputs register bconstant 4 signextended lower half ir signextended lower half ir 2 alusrcb selector input alubin multiplexor outputmult4to1 alubinput b32d4signextendoffsetpcoffsetalusrcbalubin creates mips alu inputs aluctl alu control alu value inputs aluain alubin outputs aluresultout 32bit output zero zero detection outputmipsalu alu aluctl aluain alubin aluresultoutzero alu creates mips register le inputs rs rt elds ir used specify registers read writereg write register number writedata data written regwrite indicates write clock outputs b registers read register le regs ir2521ir2016writeregwritedataregwriteabclock register le clocktriggered actions datapathalways posedge clock begin memwrite memoryaluout2 b write memorymust store aluout aluresultout save alu result use later clock cycle irwrite ir memout write ir instruction fetch mdr memout always save memory read value pc written conditionally controlled pcwrite unconditionally pcwrite pcwritecond zero pc pcvalue end endmodulefigure 4136 verilog version multicycle mips datapath appropriate synthesis 41316 413 introduction digital design using hardware design language describe module cpu clock parameter lw 6b100011 sw 6b101011 beq 6b000100 j 6d2 constants input clock reg 20 state wire 10 aluop alusrcb pcsource wire 50 opcode wire regdst memread memwrite iord regwrite irwrite pcwrite pcwritecond alusrca memoryop irwwrite mem2reg create instance mips datapath inputs control signals opcode outputdatapath mipsdp aluopregdstmem2reg memread memwrite iord regwrite irwrite pcwrite pcwritecond alusrca alusrcb pcsource opcode clock initial begin state 1 end start state machine state 1 de nitions control signalsassign irwrite state1assign mem2reg regdst assign memoryop opcodelwopcodesw memory operation assign aluop state1state2state3memoryop 2b00 add state3opcodebeq 2b01 2b10 subtract use function code assign regdst state4opcode0 1 0 assign memread state1 state4opcodelw assign memwrite state4opcodesw assign iord state1 0 state4 1 x assign regwrite state5 state4 opcode0 assign pcwrite state1 state3opcodej assign pcwritecond state3opcodebeq assign alusrca state1state2 0 1 assign alusrcb state1 state3opcodebeq 2b01 state2 2b11 state3memoryop 2b10 2b00 memory operation assign pcsource state1 2b00 opcodebeq 2b01 2b10 state machine sequence states always posedge clock begin state updates positive clock edge case state 1 state 2 unconditional next state 2 state 3 unconditional next state 3 third step jumps branches complete state opcodebeq opcodej 1 4 branch jump go back else next state 4 state opcodelw 5 1 rtype sw nish 5 state 1 go back endcase end endmodulefigure 4137 mips cpu using datapath figure 4136 413 introduction digital design using hardware design language 41317elaboration specifying control designers often take advantage knowledge control simplify shor cation cation figures 4136 4137 1 memtoreg set two cases always inverse regdst use inverse regdst2 irwrite set state 1 e alu operate every state unused safely anything 4 regdst 1 one case otherwise set 0 practice might better set explicitly needed otherwise set x iord first allows additional logic optimization possibilities exploitation dontcare terms see appendix b discussion examples second precise sp cation allows simulation closely model hardware possibly uncovering additional errors sp cation illustrations instruction execution hardware reduce cost book third edition moved sections gures used minority instructors online subsection recaptures thos gures readers would like supplemental material better understand pipelinin ese singleclockcycle pipeline diagrams take many gures illustrate execution sequence instructions e three examples respectively code hazards example forwarding pipelined implementation example bypassing pipelined implementation hazard illustrationson page 297 gave example code sequence lw 10 201 sub 11 2 3 add 12 3 4 lw 13 241 add 14 5 6 figures 443 444 showed multipleclockcycle pipeline diagrams twoinstruction sequence executing across six clock cycles figures 4138 41310 show corresponding singleclockcycle pipeline diagrams two instructions note order instruction ers two types diagrams newest instruction bottom right multiple clockcycle pipeline diagram singleclockcycle pipeline diagram 41318 413 introduction digital design using hardware design language describe instruction memory address 4 32 instruction ifid exmem memwb add add pc registers read data 1 read data 2 read register 1 read register 2 16 sign extend write register write data idex instruction decode lw 10201instruction fetch sub 1123instruction memory address 4 32 add add result shift left 2 shift left 2 instruction ifid exmem pc write data registers read data 1 read data 2 read register 1 read register 2 16 write register write data read data alu result alu zero add add result alu result alu zero idex instruction fetch lw 10201address data memory write data read data address data memory clock 1 clock 2 u x 0 1 u x 0 1 u x 0 1 u x 1 0 u x 1 0 u x 0 1 sign extend memwb figure 4138 singlecycle pipeline diagrams clock cycles 1 top diagram 2 bottom diagram style pipeline representation snapshot every instruction executing one clock cycle example two instructio ns two stages iden ed clock cycle normally stages occupied e highlighted portions datapath active clock cycle e load fetched clock cycle 1 decoded clock cycle 2 subtract fetched second clock cycle make gures easier understand pipeline stages empty normally instruction every pipeline stage 413 introduction digital design using hardware design language 41319instructionmemoryaddress432instructionifidexmemmemwb addaddregistersreaddata 1readdata 2readregister 1readregister 216signextendsignextendwrite registerwritedataidexmemorylw 10201executionsub 1123instructionmemoryaddress432addaddresultshiftleft 2addaddresultshiftleft 2instructionifidexmemmemwbpcpcwritedataregistersreaddata 1readdata 2readregister 1readregister 216writeregisterwritedatareaddataaluresultaluzeroaluresultaluzeroidexaddressdatamemorywritedatareaddataaddressdatamemoryclock 3clock 4mux01mux01mux01mux10mux10mux01instruction decodesub 1123executionlw 10201figure 4139 singlecycle pipeline diagrams clock cycles 3 top diagram 4 bottom diagram third clock cycle top diagram lw enters ex stage time sub enters id fourth clock cycle bottom datapath lw moves mem stage reading memory using address found exmem beginning clock cycle 4 time alu ubtracts places th erence exmem end clock cycle 41320 413 introduction digital design using hardware design language describe figure 41310 singlecycle pipeline diagrams clock cycles 5 top diagram 6 bottom diagram clock cycle 5 lw completes writing data memwb register 10 sub sends th erence exmem memwb next clock cycle sub writes value memwb register 11 instructionmemoryaddress432instructionifidexmemmemwbaddaddregistersreaddata 1readdata 2readregister 1readregister 216signextendwriteregisterwritedataidexinstructionmemoryaddress432addaddresultshiftleft 2shiftleft 2instructionifidexmemmemwb writedataregistersreaddata 1readdata 2readregister 1readregister 216writeregisterwritedatareaddataaluresultaluzeroaluresultaluzeroidexaddressdatamemorywritedatareaddataaddressdatamemoryclock 5clock 6mux01mux0 1mux01mux1 0mux0 1mux01memorysub 11 2 3write backlw 10 201write backsub 11 2 3signextendaddaddresultpcpc 413 introduction digital design using hardware design language 41321figure 41311 clock cycles 1 2 e phrase means ith instruction lw e lw instruction top datapath stage end clock cycle lw instruction ifid pipeline registers second clock cycle seen bottom datapath lw moves id stage sub enters stage note values instructio elds selected source registers shown id stage hence register 1 constant 20 operands lw written idex pipeline register e number 10 representing destination register number lw also placed idex bits 1511 0 use x show eld plays role given instructio e top idex pipeline register shows control values lw used remaining stag ese control values read lw row table figure 418 instruction20œ16memtoregaluopbranchregdstalusrc4instruction 15œ0alucontrolregwritememreadcontrolinstruction15œ11exmwbmwbwbinstructionifidexmemidexidbefore1ex before2mem before3wb before4memwbif lw 1020100000000000000000000000001pcwbexmmemtoregaluopbranchregdstalusrc4alucontrolregwritemwbwbinstructionifididlw 10201ex before1mem before2wb before3memwbif sub 11230101100010000000000000000pclwcontrolx1instruction20œ16instruction15œ0instruction15œ1120x110xmemwritememreadmemwriteclock 2clock 1mux01mux01mux10mux01mux01mux01mux0 1mux0addaddinstructionmemoryaddressinstructionmemoryaddressregistersreaddata 1readdata 2readregister 1readregister 2writeregisterregistersreaddata 1readdata 2readregister 1readregister 2writeregisterwritedatawritedatawritedatareaddataaluresultaluzeroaddressdatamemorywrite datareaddataaddressdatamemorysignextendsignextendx1020exmemidexaluresultaluzeroshiftleft 2addaddresultshiftleft 2addaddresult figure 41312 clock cycles 3 4 top diagram lw enters ex stage third clock cycle adding 1 20 form address exmem pipeline register e lw instruction written lw 10 upon reaching ex identity instruction operands needed ex subsequent stages version pipeline actions ex mem wb depend instruction destination register target address time sub enters id reading registers 2 3 instruction starts fourth clock cycle bottom datapath lw moves mem stage reading memory using value exmem address clock cycle alu subtracts 3 2 places th erence exmem reads registers 4 5 id instruction enters e two diagrams show control signals created id stage peeled used subsequent pipe stages instruction20œ16memtoregaluopbranchregdstalusrc4instruction15œ0shiftleft 2regwritememreadcontrolinstruction15œ11exmwbmwbwbinstructionifidexmemidexidsub 1123ex lw 10mem before1wb before2memwbif 124500010110001011000100000001pcwbexmmemtoregaluopbranchregdstalusrc4alucontrolalucontrolshiftleft 2regwritewbwbinstructionifidid 1245ex sub 11mem lw 10wb before1memwbif 13670001011000001010101110000pcandcontrol54instruction20œ16instruction15œ0instruction 15œ11x543 2x2010121011memwritememreadmemwriteclock 4clock 3mux01mux0 1mux10mux01mux0 1mux0 1mux01mux0addaddinstructionmemoryaddressinstructionmemoryaddressregistersreaddata 1readdata 2readregister 1readregister 2writeregisterregistersreaddata 1readdata 2readregister 1readregister 2writeregisterwritedatawritedataaddaddresultwritedatareaddataaluresultaluzeroaddaddresultaddressdatamemorywrite datareaddataaddressdatamemorysignextendsignextend12xxexmemidexaluresultaluzero2321 3xx11xx11m instruction20œ16memtoregaluopbranchregdstalusrc4instruction 15œ0shiftleft 2regwritememreadcontrolinstruction 15œ11exmwbmwbwbinstructionifidorexmemidexid 1367ex 12mem sub 11wb lw 10memwbif add 148900010110000010101010000111pcwbexmmemtoregaluopbranchregdstalusrc4alucontrolalucontrolshiftleft 2regwritemwbwbinstructionifididadd 1489ex 13mem 12wb sub 11memwbif after10001011000001010101000010pcaddcontrol9118instruction20œ16instruction15œ0instruction15œ11x987 6x111014112113memwritememreadmemwriteclock 6clock 5mux01mux01mux1 0mux0 1mux01mux01mux0 1mux0addaddinstructionmemoryaddressinstructionmemoryaddressregistersreaddata 1readdata 2readregister 1readregister 2writeregisterregistersreaddata 1readdata 2readregister 1readregister 2writeregisterwritedatawritedataaddaddresultwritedatareaddataaluresultaluzeroaddaddresultaddressdatamemorywrite datareaddataaddressdatamemorysignextendsignextend12xxexmemidexaluresultaluzero671064 57xx13xx1312 figure 41313 clock cycles 5 6 add th nal instruction example entering top datapath instructions engaged writing data memwb register 10 lw completes data register number memwb clock cycle sub sends erence exmem memwb rest instructions move forward next clock cycle sub selects value memwb write register number 11 found memwb e remaining instructions play followtheleader alu calculates 6 7 instruction ex stage registers 8 9 read id stage add instructio e instructions er add shown inactive emphasize occurs th instructions example e phrase eri means ith instruction er add 41324 413 introduction digital design using hardware design language describe instruction20œ16memtoregaluopbranchregdstalusrc4instruction 15œ0alucontrolshiftleft 2regwritememreadcontrolinstruction15œ11exmwbmwbwbinstructionifidexmemidexidafter1ex add 14mem 13wb 12memwbif after200000000000010101010000101pcwbexmmemtoregaluopbranchregdstalusrc4alucontrolshiftleft 2regwritemwbwbinstructionifididafter2ex after1mem add 14wb 13memwbifafter30000000000000000001000010pccontrol13instruction20œ16instruction 15œ0instruction 15œ113141memwritememreadmemwriteclock 8clock 7mux01mux01mux10mux01mux01mux01mux01mux0addaddinstructionmemoryaddressinstructionmemoryaddressregistersreaddata 1readdata 2readregister 1readregister 2writeregisterregistersreaddata 1readdata 2read register 1readregister 2writeregisterwritedataaddaddresultwritedatareaddataaluresultaluzeroaddaddresultaddressdatamemorywritedatareaddataaddressdatamemorysignextendsignextendexmemidexaluresultaluzero1289142131write datafigure 41314 clock cycles 7 8 top datapath add instruction brings rear adding values corresponding registers 8 9 ex stage e result instruction passed exmem memwb mem stage wb stage writes result instruction memwb register 12 note control signals deasserted set 0 id stage since instruction executed following clock cycle lower drawing wb stage writes result register 13 thereby completing mem stage passes sum add exmem memwb e instructions er add shown inactive pedagogical reasons 413 introduction digital design using hardware design language 41325wbexmmemtoregaluopbranch regdstalusrc4alucontrol shiftleft 2regwrite mwbwbinstruction ifididafter3ex after2mem after1wb add 14memwbifafter40000000000000000000000010pccontrol 14instruction 20œ16instruction 15œ0instruction 15œ1114memreadmemwrite clock 9 mux01mux01mux10mux01add instructionmemory addressregisters readdata 1readdata 2readregister 1readregister 2write registerwrite dataadd addresultwrite datareaddataaddressdatamemory signextend exmemidexaluresultaluzerofigure 41315 clock cycle 9 e wb stage writes sum memwb register 14 completing add th veinstruction sequence e instructions er add shown inactive pedagogical reasons examplesto understand pipeline control works lets consider thes instructions going pipeline lw 10 201 sub 11 2 3 12 4 5 13 6 7 add 14 8 9 figures 41311 41315 show instructions proceeding nine clock cycles takes complete execution highlighting active stage identifying instruction associated stage clock cycle examine carefully may notice figure 41313 see sequence destination register numbers fro right bottom pipeline register e numbers advance 41326 413 introduction digital design using hardware design language describe right clock cycle memwb pipeline register supplying number register written wb stage stage inactive values control lines deasserted shown 0 x dont care sequencing control embedded pipeline structure first instructions take number clock cycles special control instruction duration second control information computed instruction decode passed along pipeline registers forwarding illustrations use singleclockcycle pipeline diagrams show forwarding operates well control activates forwarding paths consider following code sequence dependences highlighted sub 2 1 3 4 2 5 4 4 2 add 9 4 2 figures 41316 41317 show events clock cycles 36 execution instructions clock cycle 4 forwarding unit sees writing sub instruction register 2 mem stage instruction ex stage reading register 2 e forwarding unit selects exmem pipeline register instead idex pipeline register upper input alu get proper value register 2 e following instruction reads register 4 written instruction register 2 written sub instruction us clock cycle 5 forwarding unit selects exmem pipeline register upper input alu memwb pipeline register lower input alu e following add instruction reads register 4 target instruction register 2 sub instruction already written notice prior two instructions write register 4 forwarding unit must pick immediately preceding one mem stage clock cycle 6 forwarding unit thus selects exmem pipeline register containing result instruction upper alu input uses nonforwarding register value lower input alu illustrating pipelines stalls forwarding use singleclockcycle pipeline diagrams show control stalls works figures 41318 41320 show singlecycle diagram clocks 2 7 following code sequence dependences highlighted 1w 2 201 4 25 4 42 add 9 42 pcinstructionmemory registers muxmuxmuxexmwbwbdatamemory muxforwarding unitinstruction ifidand 425sub 2 1 3idexbefore1 exmembefore2 memwbor 442clock 3 251010 2552413312control alumwbpcinstructionmemory registers muxmuxmuxexmwbdatamemory muxforwarding unitinstruction ifidor 442and 425idexsub 2exmembefore1 memwbadd 942clock 4 421010 10422442552 2 4control alumwbwbfigure 41316 clock cycles 3 4 instruction sequence page 41326 e bold lines active clock cycle italicized register numbers color indicate hazard e forwarding unit highlighted shading forwarding data alu e instructions sub shown inactive emphasize occurs four instructions example operand names used ex control forwarding thus included instruction label ex operand names n eeded mem wb used compare figures 41312 41315 show datapath without forwarding id last stage need operand information 413 introduction digital design using hardware design language 41327 41328 413 introduction digital design using hardware design language describe pcinstruction memory registerscontrolmuxdatamemory muxmuxmuxaluinstruction ifidadd 942or 442idexand 4exmemsub 2memwbafter1clock 5 422424 2 94242 41010 101 2 4after1after2add 942or 4exmemand 4memwbidexexwbmwbwbmforwarding unitpcinstruction memory registerscontrolmuxmu xmu xdatamemory mualuxinstruction ifidclock 6 44 2924101014 4exwbmwbwbmforwarding unitfigure 41317 clock cycles 5 6 instruction sequence page 41326 e forwarding unit highlighted forwarding data alu e two instructions er add shown inactive emphasize occurs four instructions example e bold lines active clock cycle italicized register numbers color indicate hazard registers instruction idex25control pcinstructionmemory pcinstructionmemory hazard detectionunit0muxifidwrite pcwrite ifidwrite pcwrite idexregisterrtbefore3 registers muxmuxexmwbmwbdatamemory muxinstruction ifidlw 2201idexbefore2 exmemmemwbclock 2 11xx111xx21control aluwblw 2201before1before2 442and 425 425clock 3 muxmuxmuxexmwbmwbdatamemory muxforwarding unitforwarding unitexmemmemwb0011 1xx12522 5542 aluwbhazard detectionunit0muxidexregisterrtbefore1 idexmemreadidexmemreadmuxifidfigure 41318 clock cycles 2 3 instruction sequence page 41326 load replacing sub e bold lines active clock cycle italicized register numbers color indicate hazard th place operands means identity information needed stage e values th cant control lines registers register numbers labeled th gures e instruction wants read value created lw instruction clock cycle 3 hazard detection unit stalls instructions hence hazard detection unit highlighted 413 introduction digital design using hardware design language 41329 41330 413 introduction digital design using hardware design language describe registersinstructionidex422controlpcinstructionmemorypcinstructionmemoryhazarddetectionunit0muxifidwritepcwriteifidwritepcwriteidexregisterrtbefore1registersmuxmuxexmwbmwbdatamemorymuxinstructionifidand 425idexlw 2 exmemmemwbclock 422551000 11255422554 22controlaluwband 425bubble lw 2add 942or 442 442clock 5muxmuxmuxexmwbmwbdatamemorymuxforwardingunitforwardingunitexmemmemwb1010 112 025544242 5242 aluwbhazarddetectionunit0muxidexregisterrtbubble idexmemreadidexmemreadmuxifidfigure 41319 clock cycles 4 5 instruction sequence page 41326 load replacing sub e bubble inserted pipeline clock cycle 4 instruction allowed proceed clock cyc e forwarding unit highlighted clock cycle 5 forwarding data lw alu note clock cycle 4 forwarding unit forwards address lw contents register 2 rendered harmless insertion bubble e bold lines active clock cycle italicized register numbers color indicate hazard 413 introduction digital design using hardware design language describe 413 31registers instruction idex4control pcinstructionmemory pcinstructionmemory hazard detectionunit0muxifidwrite pcwrite ifidwrite pcwrite idexregisterrtbubble registers muxmuxexmwbmwbdatamemory muxinstruction ifidadd 942idexand 4exmemmemwbclock 6 44221010 100422944224 44 control aluwbadd 942or 4and 4 after2after1 after1clock 7 muxmuxmuxexmwbmwbdatamemory muxforwarding unitforwarding unitexmemmemwb1010144 1042294 aluwbhazard detectionunit0muxidexregisterrtor 442idexmemreadidexmemreadmuxifidfigure 41320 clock cycles 6 7 instruction sequence page 41326 load replacing sub note unlike figure 41317 stall allows lw complete forwarding memwb clock cycle 6 register 4 add ex stage still depends result exmem forwarding unit passes result alu e bold lines show alu input lines active clock cycle italicized register numbers indicate hazard e instructions er add shown inactive pedagogical reasons 414 fallacies pitfalls 355 414 fallacies pitfalls fallacy pipelining easy books testify subtlety correct pipeline execution advanced book pipeline bug rst edition despite reviewed 100 people classtested 18 universit e bug uncovered someone tried build computer boo e fact verilog describe pipeline like intel core i7 many thousands lines indication complexity beware fallacy pipelining ideas implemented independent technology number transistors onchip speed transistors made vestage pipeline best solution delayed branch see elaboration page 255 simple solution control hazards longer pipelines superscalar execution dynamic branch prediction redundant early 1990s dynamic pipeline scheduling took many resources required high performance transistor budgets continued double due moores law logic became much faster memory multiple functional units dynamic pipelining made sense today concerns power leading less aggressive designs pitfall failure consider instruction set design adversely impact pipelining many th culties pipelining arise instruction set complications examples widely variable instruction lengths running times lead imbalance among pipeline stages severely complicate hazard detection design pipelined instruction set level problem overcome initially dec vax 8500 late 1980s using microoperations micropipelined scheme intel core i7 employs today course overhead translation maintaining correspondence micro operations actual instructions remains sophisticated addressing modes lead erent sorts problems addressing modes update registers complicate hazard detection addressing modes require multiple memory accesses substantially complicate pipeline control make cult keep pip owing smoothly perhaps best example dec alpha dec nvax comparable technology newer instruction set architecture alpha allowed implementation whose performance twice fast nvax another example bhandarkar clark 1991 compared mips m2000 dec vax 8700 counting clock cycles spec benchmarks concluded although mips m2000 executes 356 chapter 4 processor instructions vax average executes 27 times many clock cycles mips faster 415 concluding remarks seen chapter datapath control processor designed starting instruction set architecture understanding basic characteristics technology section 43 saw datapath mips processor could constructed based architecture decision build singlecycle implementation course underlying technology also ects many design decisions dictating components used datapath well whether singlecycle implementation even makes sense pipelining improves throughput inherent execution time instruction latency instructions instructions latency similar length singlecycle approach multiple instruction issue adds additional datapath hardware allow multiple instructions begin every clock cycle increas ective latency pipelining presented reducing clock cycle time simple singlecycle datapath multiple instruction issue comparison clearly focuses reducing clock cycles per instruction cpi pipelining multiple issue attempt exploit instructionlevel pa e presence data control dependences become hazards primary limitations much parallelism exploited scheduling speculation via prediction hardware ware primary techniques used reduce performance impact dependences showed unrolling dgemm loop four times exposed instructions could take advantage outoforder execution engine core i7 double performance e switch longer pipelines multiple instruction issue dynamic scheduling mid1990s helped sustain 60 per year processor performance increase started early 1980s mentioned chapter 1 microprocessors preserved sequential programming model eventually ran power wall us industry forced switch multiprocessors exploit parallelism much coarser levels subject chapt trend also caused designers reassess energy performance implications inventions since mid1990s resulting simp cation pipelines recent versions microarchitectures sustain advances processing performance via parallel processors amdahls law suggests another part system become bottleneck bottleneck topic next chapter memory hierarchy instruction latency e inherent execution time instruction ninetenths wisdom consists wise time american proverb 417 exercises 357 416 historical perspective reading section appears online discusses history th rst pipelined processors earliest superscalars development outoforder speculative techniques well important developments accompanying compiler technology 417 exercises41 consider following instruction instruction rdrsrtinterpretation regrd regrs regrt411 5 41 values control signals generated control figure 42 instruction 412 5 41 resources blocks perform useful function instruction 413 10 41 resources blocks produce outputs outputs used instruction resources produce outputs instruction 42 e basic singlecycle mips implementation figure 4 2 implement instructions new instructions added existing instruction set architecture isa decision whether depends among things cost complexity proposed addition introduces processor datapath control e rst three problems exercise refer new instruction instruction lwi rtrdrsinterpretation regrt memregrdregrs421 10 41 existing blocks used instruction 422 10 41 new functional blocks need instruction 423 10 41 new signals need control unit support instruction 416 358 chapter 4 processor 43 processor designers consider possible improvement processor datapath decision usually depends costperformance tradeo following three problems assume starting datapath figure 42 imem add mux alu regs dmem control blocks latencies 400 ps 100 ps 30 ps 120 ps 200 ps 350 ps 100 ps respectively costs 1000 30 10 100 200 2000 500 respectively consider addition multiplier alu addition add 300 ps latency alu add cost 600 alu e result 5 fewer instructions executed since longer need emulate mul instruction 431 10 41 clock cycle time without improvement 432 10 41 speedup achieved adding improvement 433 10 41 compare costperformance ratio without improvement 44 problems exercise assume logic blocks needed implement processors datapath following latencies imem addmuxaluregsdmemsignextendshiftleft2 200ps70ps20ps90ps90ps250ps15ps 10ps441 10 43 thing need processor fetch consecutive instructions figure 46 would cycle time 442 10 43 consider datapath similar one figure 411 processor one type instruction unconditional pcrelative branch would cycle time datapath 443 10 43 repeat 442 time need support conditional pcrelative branches e remaining three problems exercise refer datapath element 2444 10 43 kinds instructions require resource 445 20 43 kinds instructions resource critical path 446 10 43 assuming support beq add instructions discuss changes given latency resource ect cycle time processor assume latencies resources change 417 exercises 35945 problems exercise assume pipeline stalls breakdown executed instructions follows add addinotbeqlwsw 20200252510 451 10 43 fraction cycles data memory used 452 10 43 fraction cycles input signextend circuit needed circuit cycles input needed 46 silicon chips fabricated defects materials eg silicon manufacturing errors result defective circuits common defect one wire ect signal another called crosstalk fault special class crosstalk faults signal connected wire constant logical value eg power supply wire case stuckat0 stuck at1 fault ected signal always logical value 0 1 respectively e following problems refer bit 0 write register input regist le figure 424 461 10 43 44 let us assume processor testing done lling pc registers data instruction memories values choose values letting single instruction execute reading pc memories register ese values examined determine particular fault present design test values pc memories registers would determine stuckat0 fault signal 462 10 43 44 repeat 461 stuckat1 fault use single test stuckat0 stuckat1 yes explain explain 463 60 43 44 know processor stuckat1 fault signal processor still usable usable must able convert program executes normal mips processor program works processor assume enough free instruction memory data memory let make program longer store additional data hint processor usable every instruction broken fault replaced sequence working instructions achieve ect464 10 43 44 repeat 461 fault test whether memread control signal becomes 0 regdst control signal 0 fault otherwise 465 10 43 44 repeat 464 fault test whether jump control signal becomes 0 regdst control signal 0 fault otherwise 360 chapter 4 processor 47 exercise examine detail instruction executed singlecycle datapath problems exercise refer clock cycle processor fetches following instruction word 10101100011000100000000000010100assume data memory zeros processors registers following values beginning cycle instruction word fetched r0 r1r2r3r4r5r6r8r12r31 012341068216 471 5 44 outputs signextend jump 2 unit near top figure 424 instruction word 472 10 44 values alu control units inputs instruction 473 10 44 new pc address er instruction executed highlight path value determined 474 10 44 mux show values data output execution instruction register values 475 10 44 alu two add units data input values 476 10 44 values inputs registers unit 48 exercise examine pipelining ects clock cycle time processor problems exercise assume individual stages datapath following latencies ifidexmemwb250ps350ps150ps300ps200ps also assume instructions executed processor broken follows alu beqlw sw45202015 481 5 45 clock cycle time pipelined nonpipelined processor 482 10 45 total latency lw instruction pipelined nonpipelined processor 417 exercises 361483 10 45 split one stage pipelined datapath two new stages half latency original stage stage would split new clock cycle time processor 484 10 45 assuming stalls hazards utilization data memory 485 10 45 assuming stalls hazards utilization writeregister port registers unit 486 30 45 instead singlecycle organization use multicycle organization instruction takes multiple cycles one instruction nishes another fetched organization instruction goes stages actually needs eg st takes 4 cycles need wb stage compare clock cycle times execution times single cycle multicycle pipelined organization 49 exercise examine data dependences ect execution basic 5stage pipeline described section 45 problems exercise refer following sequence instructions r1r2r3or r2r1r4 r1r1r2also assume following cycle times options related forwarding without forwarding full forwardingwith alualu forwarding 250ps300ps290ps491 10 45 indicate dependences type 492 10 45 assume forwarding pipelined processor indicate hazards add nop instructions eliminate 493 10 45 assume full forwarding indicate hazards add nop instructions eliminate 494 10 45 total execution time instruction sequence without forwarding full forwarding speedup achieved adding full forwarding pipeline forwarding 495 10 45 add nop instructions code eliminate hazards alualu forwarding forwarding mem ex stage 496 10 45 total execution time instruction sequence alualu forwarding speedup noforwarding pipeline 362 chapter 4 processor 410 exercise examine resource hazards control hazards instruction set architecture isa design ect pipelined execution problems exercise refer following fragment mips code sw r1612r6 lw r168r6 beq r5r4label assume r5r4 add r5r1r4 slt r5r15r4assume individual pipeline stages following latencies idexmemwb 200ps120ps150ps190ps100ps 4101 10 45 problem assume branches perfectly predicted eliminates control hazards delay slots used one memory instructions data structural hazard every time need fetch instruction cycle another instruction accesses data guarantee forward progress hazard must always resolved favor instruction accesses data total execution time instruction sequence 5stage pipeline one memory seen data hazards eliminated adding nops code structural hazard 4102 20 45 problem assume branches perfectly predicted eliminates control hazards delay slots used change loadstore instructions use register without set address instructions longer need use alu result mem ex stages overlapped pipeline 4 stages change code accommodate changed isa assuming change ect clock cycle time speedup achieved instruction sequence 4103 10 45 assuming stallonbranch delay slots speedup achieved code branch outcomes determined id stage relative execution branch outcomes determined ex stage 4104 10 45 given pipeline stage latencies repeat speedup calculation 4102 take account possible change clock cycle time ex mem done single stage work done parallel result resulting exmem stage latency larger original two plus 20 ps needed work could done parallel 4105 10 45 given pipeline stage latencies repeat speedup calculation 4103 taking account possible change clock cycle time assume latency id stage increases 50 latency ex stage decreases 10ps branch outcome resolution moved ex id 417 exercises 3634106 10 45 assuming stallonbranch delay slots new clock cycle time execution time instruction sequence beq address computation moved mem stage speedup change assume latency ex stage reduced 20 ps latency mem stage unchanged branch outcome resolution moved ex mem411 consider following loop looplw r10r1 r1r1r2 lw r10r1 lw r10r1 beq r1r0loop assume perfect branch prediction used stalls due control hazards delay slots pipeline full forwarding support also assume many iterations loop executed loop exits 4111 10 46 show pipeline execution diagram third iteration loop cycle fetch th rst instruction iteration including cycle fetch th rst instruction next iteration show instructions pipeline cycles third iteration 4112 10 46 en percentage cycles cycle whic pipeline stages useful work 412 exercise intended help understand costcomplexity performance tradeo forwarding pipelined processor problems exercise refer pipelined datapaths figure 445 ese problems assume instructions executed processor following fraction instructions particular type raw data dependence e type raw data dependence iden ed stage produces result ex mem instruction consumes result 1st instruction follows one produces result 2nd instruction follows assume register write done th rst half clock cycle register reads done second half cycle ex 3rd mem 3rd dependences counted result data hazards also assume cpi processor 1 data hazards ex 1st onlymem 1st onlyex 2nd onlymem 2nd onlyex 1st mem 2ndother raw dependences5205101010 364 chapter 4 processor assume following latencies individual pipeline stages ex stage latencies given separately processor without forwarding processor erent kinds forwarding idex fwex full fwex fw exmem onlyex fw memwb onlymemwb 150 ps100 ps120 ps150 ps140 ps 130 ps120 ps100 ps 4121 10 47 use forwarding fraction cycles stalling due data hazards 4122 5 47 use full forwarding forward results forwarded fraction cycles staling due data hazards 4123 10 47 let us assume ord threeinput muxes needed full forwarding decide better forward exmem pipeline register nextcycle forwarding memwb pipeline register twocycle forwarding two options results fewer data stall cycles 4124 10 47 given hazard probabilities pipeline stage latencies speedup achieved adding full forwarding pipeline forwarding 4125 10 47 would additional speedup relative processor forwarding added timetravel forwarding eliminates data hazards assume yettobeinvented timetravel circuitry adds 100 ps latency fullforwarding ex stage 4126 20 47 repeat 4123 time determine two options results shorter time per instruction 413 exercise intended help understand relationship forwarding hazard detection isa design problems exercise refer following sequence instructions assume executed 5stage pipelined datapath add r5r2r1lw r34r5 lw r20r2 r3r5r3 sw r30r54131 5 47 forwarding hazard detection insert nops ensure correct execution 417 exercises 3654132 10 47 repeat 4131 use nops hazard avoided changing rearranging instructions assume register r7 used hold temporary values mo ed code 4133 10 47 processor forwarding forgot implement hazard detection unit happens code executes 4134 20 47 forwarding th rst cycles execution code specify signals asserted cycle hazard detection forwarding units figure 460 4135 10 47 forwarding new inputs output signals need hazard detection unit figure 460 using instruction sequence example explain signal needed 4136 20 47 new hazard detection unit 4135 specify output signals asserts th rs cycles execution code 414 exercise intended help understand relationship delay slots control hazards branch execution pipelined processor exercise assume following mips code executed pipelined processor 5stage pipeline full forwarding predicttaken branch predictor lw r20r1label1 beq r2r0label2 taken taken lw r30r2 beq r3r0label1 taken add r1r3r1label2 sw r10r24141 10 48 draw pipeline execution diagram code assuming delay slots branches execute ex stage 4142 10 48 repeat 4141 assume delay slots used given code instruction follows branch delay slot instruction branch 4143 20 48 one way move branch resolution one stage earlier need alu operation conditional branch e branch instructions would bez rdlabel bnez rdlabel would branch register zero value respectively change code use branch instructions instead beq assume register r8 available use temporary register seq set equal rtype instruction used 366 chapter 4 processor section 48 describes severity control hazards reduced moving branch execution id stage approach involves dedicated comparator id stage shown figure 462 however approach potentially adds latency id stage requires additional forwarding logic hazard detection 4144 10 48 using th rst branch instruction given code example describe hazard detection logic needed support branch execution id stage figure 462 type hazard new logic supposed detect 4145 10 48 given code speedup achieved moving branch execution id stage explain answer speedup calculation assume additional comparison id stage ect clock cycle time 4146 10 48 using th rst branch instruction given code example describe forwarding support must added support branch execution id stage compare complexity new forwarding unit complexity existing forwarding unit figure 462 415 e importance good branch predictor depends en conditional branches executed together branch predictor accuracy determine much time spent stalling due mispredicted branches exercise assume breakdown dynamic instructions various instruction categories follows rtypebeqjmplwsw 40255255 also assume following branch predictor accuracies alwaystaken alwaysnottaken2bit 4555854151 10 48 stall cycles due mispredicted branches increase cpi extra cpi due mispredicted branches alwaystaken predictor assume branch outcomes determined ex stage data hazards delay slots used 4152 10 48 repeat 4151 alwaysnottaken predictor 4153 10 48 repeat 4151 2bit predictor 4154 10 48 2bit predictor speedup would achieved could convert half branch instructions way replaces branch instruction alu instruction assume correctly incorrectly predicted instructions chance replaced 417 exercises 3674155 10 48 2bit predictor speedup would achieved could convert half branch instructions way replaced branch instruction two alu instructions assume correctly incorrectly predicted instructions chance replaced 4156 10 48 branch instructions much predictable others know 80 executed branch instructions easytopredict loopback branches always predicted correctly accuracy 2bit predictor remaining 20 branch instructions 416 exercise examines accuracy various branch predictors following repeating pattern eg loop branch outcomes nt nt4161 5 48 accuracy alwaystaken alwaysnottaken predictors sequence branch outcomes 4162 5 48 accuracy twobit predictor th rst 4 branches pattern assuming predictor starts botto state figure 463 predict taken 4163 10 48 accuracy twobit predictor pattern repeated forever 4164 30 48 design predictor would achieve perfect accuracy pattern repeated forever predictor sequential circuit one output provides prediction 1 taken 0 taken inputs clock control signal indicates instruction conditional branch 4165 10 48 accuracy predictor 4164 given repeating pattern exact opposite one 4166 20 48 repeat 4164 predictor able eventually er warmup period make wrong predictions start perfectly predicting pattern opposite predictor input tells real outcome hint input lets predictor determine two repeating patterns given 417 exercise explores exception handling ects pip e rst three problems exercise refer following two instructions instruction 1 instruction 2 bne r1 r2 label lw r1 0r1 4171 5 49 exceptions instructions trigger exceptions specify pipeline stage detected 368 chapter 4 processor 4172 10 49 separate handler address exception show pipeline organization must changed able handle exception assume addresses handlers known processor designed 4173 10 49 second instruction fetched right er th rst instruction describe happens pipeline th rst instruction causes th rst exception listed 4171 show pipeline execution diagram time th rst instruction fetched time th rst instruction exception handler completed 4174 20 49 vectored exception handling table exception handler addresses data memory know xed address change pipeline implement exception handling mechanism repeat 4173 using mo ed pipeline vectored exception handling 4175 15 49 want emulate vectored exception handling described 4174 machine xed handler address write code xed address hint code identify exception get right address exception vector table transfer execution handler 418 exercise compare performance 1issue 2issue processors taking account program transformations made optimize 2issue execution problems exercise refer following loop written c fori0iji2 biaiai1when writing mips code assume variables kept registers follows registers except indicated free used keep various variables used anything else jabc free r5r6r1r2r3r10 r11 r12 4181 10 410 translate c code mips instructions translation direct without rearranging instructions achieve better performance 4182 10 410 loop exits er executing two iterations draw pipeline diagram mips code 4181 executed 2issue processor shown figure 469 assume processor perfect branch prediction fetch two instructions consecutive instructions cycle 4183 10 410 rearrange code 4181 achieve better performance 2issue statically scheduled processor figure 469 417 exercises 3694184 10 410 repeat 4182 time use mips code 4183 4185 10 410 speedup going 1issue processor 2issue processor figure 469 use code 4181 1issue 2issue assume 1000000 iterations loop executed 4182 assume processor perfect branch predictions 2issue processor fetch two instructions cycle 4186 10 410 repeat 4185 time assume 2issue processor one instructions executed cycle kind must nonmemory instruction 419 exercise explores energ ciency relationship performance problems exercise assume following energy consumption activity instruction memory registers data memory assume components datapath spend negligible amount energy imem 1 register readregister writedmem readdmem write 140pj70pj60pj140pj120pjassume components datapath following latencies assume components datapath negligible latencies imemcontrolregister read writealudmem read write 200ps150ps 90ps90ps250ps4191 10 43 46 414 much energy spent execute add instruction singlecycle design 5stage pipelined design 4192 10 46 414 worstcase mips instruction terms energy consumption energy spent execute 4193 10 46 414 energy reduction paramount would change pipelined design percentage reduction energy spent lw instruction er change 4194 10 46 414 performance impact changes 41934195 10 46 414 eliminate memread control signal data memory read every cycle ie permanently memread1 explain processor still functions correctly er change ect change clock frequency energy consumption 4196 10 46 414 idle unit spends 10 power would spend active energy spent instruction memory cycle percentage overall energy spent instruction memory idle energy represent 370 chapter 4 processor 41 page 248 3 5 control datapath memory input output missing 42 page 251 false edgetriggered state elements make simultaneous reading writing possible unambiguous 43 page 257 ii c 44 page 272 yes branch aluop0 identical addition memtoreg regdst inverses one another dont need inverter simply use signal ip order inputs multiplexor 45 page 285 stall lw result 2 bypass th rst add result written t1 3 stall bypass required 46 page 298 statements 2 4 correct rest incorrect 48 page 324 1 predict taken 2 predict taken 3 dynamic prediction 49 page 332 e rst instruction since logically executed others 410 page 344 1 2 3 ware 4 hardware 5 hardware 6 hardware 7 8 hardware 9 411 page 353 first two false last two true answers check 5ideally one would desire inde nitely large memory capacity particular word would immediately available forced recognize possibility constructing hierarchy memories greater capacity preceding less quickly accessible w burks h h goldstine j von neumann preliminary discussion logical design electronic computing instrument 1946large fast exploiting memory hierarchy 51 introduction 37452 memory technologies 37853 basics caches 38354 measuring improving cache performance 39855 dependable memory hierarchy 41856 virtual machines 42457 virtual memory 427computer organization design doi 2013 elsevier inc rights reservedhttpdxdoiorg101016b97801240772630000112013 58 common framework memory hierarchy 45459 using finitestate machine control simple cache 461510 parallelism memory hierarchies cache coherence 466511 parallelism memory hierarchy redundant arrays inexpensive disks 470512 advanced material implementing cache controllers 470513 real stuff arm cortexa8 intel core i7 memory hierarchies 471514 going faster cache blocking matrix multiply 475515 fallacies pitfalls 478516 concluding remarks 482517 historical perspective reading 483518 exercises 483the five classic components computer 374 chapter 5 large fast exploiting memory hierarchy 51 introductionfrom earliest days computing programmers wanted unlimited amounts fast memory e topics chapter aid programmers creating illusion look creating illusion lets consider simple analogy illustrates key principles mechanisms use suppose student writing term paper important historical developments computer hardware sitting desk library collection books pulled shelves examining yo nd several important computers need write described books nothing edsa erefore go back shelves look additional book yo nd book early british computers covers edsac good selection books desk front good probability many topics need found may spend time using books desk without going back shelves several books desk front saves time compared one book constantly go back shelves return take another e principle allows us create illusion large memory access fast small memory need access books library equal probability program access code data equal probability otherwise would impossible make memory accesses fast still large memory computers would impossible library books desk still nd wanted quickly principle locality underlies way work library way programs operate e principle locality states programs access relatively small portion address space instant time accessed small portion librarys collectio ere tw erent types locality temporal locality locality time item referenced tend referenced soon recently brought book desk look probably need look soon spatial locality locality space item referenced items whose addresses close tend referenced soon example brought book early english computers nd edsac also noticed another book shelved next early mechanical computers also brought back book later found something useful book libraries put books topic together shelves increase spatial locality well see memory hierarchies use spatial locality little later chapter temporal locality e principle stating data location referenced tend referenced soon spatial locality e locality principle stating data location referenced data locations nearby addresses tend referenced soon 51 introduction 375just accesses books desk naturally exhibit locality locality programs arises simple natural program structures example programs contain loops instructions data likely accessed repeatedly showing high amounts temporal locality since instructions normally accessed sequentially programs also show high spatial locality accesses data also exhibit natural spatial locality example sequential accesses elements array record nat urally high degrees spatial locality take advantage principle locality implementing memory computer memory hierarchy memory hierarchy consists multiple levels memory erent speeds e faster memories expensive per bit slower memories thus smaller figure 51 shows faster memory close processor slower less expensive memory e goal present user much memory available cheapest technology providing access speed ered fastest memory e data similarly hierarchical level closer processor generally subset level away data stored lowest level analogy books desk form subset library working turn subset libraries campus furthermore move away processor levels take progressively longer access might encounter hierarchy campus libraries memory hierarchy consist multiple levels data copied two adjacent levels time focus attention two levels memory hierarchy structure uses multiple levels memories distance processor increases size memories access time increase speedfastestslowestsmallestbiggestsizecost bit currenttechnology highestlowestsramdrammagnetic diskprocessormemorymemorymemoryfigure 51 basic structure memory hierarchy implementing memory system hierarchy user illusion memory large largest level hierarchy accessed built fastest memory flash memory replaced disks many personal mobile devices may lead new level storage hierarchy desktop server computers see section 52 376 chapter 5 large fast exploiting memory hierarchy e upper levelthe one closer processoris smaller faster lower level since upper level uses technology expensive figure 52 shows minimum unit information either present present twolevel hierarchy called block line library analogy block information one book data requested processor appears block upper level called hit analogous yo nding information one books desk data found upper level request called miss e lower level hierarchy accessed retrieve block containing requested data continuing analogy go desk shelves nd desired boo e hit rate hit ratio fraction memory accesses found upper level en used measure performance memory hierarchy e miss rate 1hit rate fraction memory accesses found upper level since performance major reason memory hierarchy time service hits misses important hit time time access upper level memory hierarchy includes time needed determine whether access hit miss time needed look books th e miss penalty time replace block upper level corresponding block lower level plus time deliver block processor time get another book shelves place desk upper level smaller built using faster memory parts hit time much smaller time access next level hierarchy major component miss penalty e time examine books desk much smaller time get get new book shelves block line e minimum unit information either present present cache hit rate e fraction memory accesses found level memory hierarchy miss rate e fraction memory accesses found level memory hierarchy hit time e time required access level memory hierarchy including time needed determine whether access hit miss miss penalty e time required fetch block level memory hierarchy lower level including time access block transmit one level insert level experienced miss pass block requestor processordata transferredfigure 52 every pair levels memory hierarchy thought upper lower level within level unit information present called block line usually transfer entire block copy something levels 51 introduction 377as see chapter concepts used build memory systems ect many aspects computer including operating system manages memory io compilers generate code even applications use computer course programs spend much time accessing memory memory system necessarily major factor determining performance e reliance memory hierarchies achieve performance meant programmers used able think memory random access storage device need understand memory hierarchy get good performance show important understanding later examples figure 518 page 408 section 514 shows double matrix multiply performance since memory systems critical performance computer designers devote great deal attention systems develop sophisticated mechanisms improving performance memory system chapter discuss major conceptual ideas although use many simp cations abstractions keep material manageable length complexity programs exhibit temporal locality tendency reuse recently accessed data items spatial locality tendency reference data items close recently accessed items memory hierarchies take advantage temporal locality keeping recently accessed data items closer processor memory hierarchies take advantage spatial locality moving blocks consisting multiple contiguous words memory upper levels hierarchy figure 53 shows memory hierarchy uses smaller faster memory technologies close processor us accesses hit highest level hierarchy processed quickly accesses miss go lower levels hierarchy larger slower hit rate high enough memory hierarchy ective access time close highest fastest level size equal lowest largest level systems memory true hierarchy meaning data present level unless also present level 1the bigpicturewhich following statements generally true 1 memory hierarchies take advantage temporal locality 2 read value returned depends blocks cache 3 cost memory hierarchy highest level 4 capacity memory hierarchy lowest level check 378 chapter 5 large fast exploiting memory hierarchy 52 memory technologies ere four primary technologies used today memory hierarchies main memory implemented dram dynamic random access memory levels closer processor caches use sram static random access memory dram less costly per bit sram although substantially slower e pr erence arises dram us cantly less area per bit memory drams thus larger capacity amount silicon speed erence arises several factors described section b9 appendix b e third technolog ash memory nonvolatile memory secondary memory personal mobile de e fourth technology used implement largest slowest level hierarchy server e access time price per bit vary widely among technologies table shows using typical values 2012 memory technology typical access time per gib 2012sram semiconductor memory 0525 ns5001000dram semiconductor memory 5070 ns1020flash semiconductor memory 500050000 ns075100magnetic disk500000020000000 ns005010we describe memory technology remainder section cpulevel 1level 2level nincreasing distancefrom cpu inaccess timelevels thememory hierarchysize memory levelfigure 53 diagram shows structure memory hierarchy distance processor increases size structure appropriate operating mechanisms allows processor access time determined primarily level 1 hierarchy yet memory large level n maintaining illusion subject chapter although local disk normally bottom hierarchy systems use tape le server local area network next levels hierarchy 52 memory technologies 379sram technology srams simply integrated circuits memory arrays usually single access port provide either read write srams hav xed access time datum though read write access times er srams dont need refresh access time close cycle time srams typically use six eight transistors per bit prevent information disturbed read sram needs minimal power retain charge standby mode past pcs server systems used separate sram chips either primary secondary even tertiary caches today thanks moores law levels caches integrated onto processor chip market separate sram chips nearly evaporated dram technology sram long power applied value kep nitely dynamic ram dram value kept cell stored charge capacitor single transistor used access stored charge either read value overwrite charge stored drams use single transistor per bit storage much denser cheaper per bit sram drams store charge capacitor kep nitely must periodically refreshed memory structure called dynamic opposed static storage sram cell refresh cell merely read contents write bac e charge kept several milliseconds every bit read dram written back individually would constantly refreshing dram leaving time accessing fortunately drams use twolevel decoding structure allows us refresh entire row shares word line read cycle followed immediately write cycle figure 54 shows internal organization dram figure 55 shows density cost access time drams changed years e row organization helps refresh also helps performance improve performance drams bu er rows repeat e b er acts like sram changing address random bits accessed b er next ro capability improves th cantly since access time bits row much lower making chip wider also improves memory bandwidth chip row b er transferred successive addresses whatever width dram typically 4 8 16 bits specifying block transfer starting address within bu er improve interface processors drams added clocks properly called synchronous drams sd e advantage sdrams use clock eliminates time memory processor synchronize e speed advantage synchronous drams comes ability transfer bits burst without specify additional address bits 380 chapter 5 large fast exploiting memory hierarchy instead clock transfers successive bits burs e fastest version called double data rate ddr sd e name means data transfers rising falling edge clock thereby getting twice much bandwidth might expect based clock rate data widt e latest version technology called ddr4 ddr43200 dram 3200 million transfers per second means 1600 mhz clock sustaining much bandwidth requires clever organization inside dram instead faster row bu er dram internally organized read figure 55 dram size increased multiples four approximately every three years 1996 thereafter considerably slower e improvements access time slower continuous cost roughly tracks density improvements although cost en ected issues availability demand e cost per gibibyte adjusted fo ation year introducedchip size per gib total access time new rowcolumn average columnaccess time existing row 198064 kibibit1500000 250 ns150 ns1983256 kibibit500000185 ns100 ns 19851 mebibit200000135 ns40 ns 19894 mebibit50000110 ns40 ns 199216 mebibit1500090 ns30 ns 199664 mebibit1000060 ns12 ns 1998128 mebibit400060 ns10 ns 2000256 mebibit100055 ns7 ns 2004512 mebibit25050 ns5 ns 20071 gibibit5045 ns125 ns 20102 gibibit 4 gibibit3040 ns1 ns 2012135 ns08 nsfigure 54 internal organization dram modern drams organized banks typically four ddr3 bank consists series rows sending pre precharge command opens closes bank row address sent act activate causes row transfer bu er row b er transferred successive column addresses whatever width dram typically 4 8 16 bits ddr3 specifying block transfer starting address command well block transfers synchronized clock columnrdwr preactrow bank 52 memory technologies 381write multiple banks row b er sending address several banks permits read write simultaneously example four banks one access time accesses rotate four banks supply four times bandwidt rotating access scheme called address interleaving although personal mobile devices like ipad see chapter 1 use individual drams memory servers commonly sold small boards called dual inline memory modules dimms dimms typically contain 416 drams normally organized 8 bytes wide server systems dimm using ddr4 3200 sdrams could transfer 8 3200 25600 megabytes per second dimms named er bandwidth pc25600 since dimm many dram chips portion used particular transfer need term refer subset chips dimm share common address lines avoid confusion internal dram names row banks use term memory rank subset chips dimm elaboration one way measure performance memory system behind caches stream benchmark mccalpin 1995 measures performance long vector operations temporal locality access arrays larger cache computer testedflash memory flash memory type electrically erasable programmable readonly memory eeprom unlike disks dram like eeprom technologies writes wear ash memory bits cope limi ash products include controller spread writes remapping blocks written many times less trodden bloc technique called wear leveling wear leveling personal mobile devices unlikely exceed write limits th ash wear leveling lowers potential performance ash needed unless higher level ware monitors block wear flash controllers perform wear leveling also improve yield mapping memory cells manufactured incorrectly disk memory figure 56 shows magnetic hard disk consists collection platters rotate spindle 5400 15000 revolutions per minute e metal platters covered magnetic recording material sides similar material found cassette videotape read write information hard disk movable arm containing small electromagnetic coil called readwrite head located surface e entire drive permanently sealed control environment inside drive turn allows disk heads much closer drive surface disk surface divided concentric circles called tracks ere typically tens thousands tracks per surface track turn divided track one thousands concentric circles makes surface magnetic disk 382 chapter 5 large fast exploiting memory hierarchy sectors contain information track may thousands sectors sectors typically 512 4096 bytes size e sequence recorded magnetic media sector number gap information sector including error correction code see section 55 gap sector number next sector e disk heads surface connected together move conjunction every head track every surface e term cylinder used refer tracks heads given point surfaces figure 56 disk showing 10 disk platters readwrite heads e diameter todays disks 25 35 inches typically one two platters per drive today access data operating system must direct disk threestage pro e rst step position head proper trac operation called seek time move head desired track called seek time disk manufacturers report minimum seek time maximum seek time average seek time manu e rst two easy measure average open wide interpretation depends seek distance e industry calculates average seek time sum time possible seeks divided number possible seeks average seek times usually advertised 3 ms 13 ms depending application scheduling disk requests actual average seek time may 25 33 advertised number locality disk sector one segments make track magnetic disk sector smallest amount information read written diskseek e process positioning readwrite head proper track disk 53 basics caches 383refere locality arises successive accesses sa le operating system tries schedule accesses together head reached correct track must wait desired sector rotate readwrite head time called rotational latency rotational delay e average latency desired information halfway around disk disks rotate 5400 rpm e average rotational latency 5400 rpm average rotational latency05 rotation rpm05 rotati5400o rpmseconds minute 00056 seconds56 540060 ss e last component disk access transfer time time transfer block bi e transfer time function sector size rotation speed recording density track transfer rates 2012 100 200 mbsec one complication disk controllers builtin cache stores sectors passed transfer rates cache typically higher 750 mbsec 6 gbitsec 2012 alas block numbers located longer intuitive e assumptions sectortrackcylinder model nearby blocks track blocks cylinder take less time access since seek time tracks closer e reason change raising level disk interfaces speedup sequential transfers higher level interfaces organize disks like tapes like random access devices e logical blocks ordered serpentine fashion across single surface trying capture sectors recorded bit density try get best performance hence sequential blocks may erent tracks summary two primar erences magnetic disks semiconductor memory technologies disks slower access time mechanical de ash 1000 times fast dram 100000 times fastyet cheaper per bit high storage capacity modest costdisk 10 100 time cheaper magnetic disks nonvolatile lik ash unlike ash write wearout problem however ash much rugged hence better match jostling inherent personal mobile devices 53 basics caches library example desk acted cachea safe place store things books needed examine cache name chosen represent level memory hierarchy processor main memory th rst commercial computer extra level e memories datapath chapter 4 simply replaced caches today although remains dominant rotational latency also called rotational delay e time required desired sector disk rotate readwrite head usually assumed half rotation time cache safe place hiding storing things websters new world dictionary american language ird college edition 1988 384 chapter 5 large fast exploiting memory hierarchy use word cache term also used refer storage managed take advantage locality access cach rst appeared research computers early 1960s production computers later decade every general purpose computer built today servers lowpower embedded processors includes caches section begin looking simple cache processor requests one word blocks also consist single word readers already familiar cache basics may want skip section 54 figure 57 shows simple cache er requesting data item initially cache request cache contains collection recent references x1 x2 xn1 processor requests word x n cache request results miss word x n brought memory cache looking scenario figure 57 two questions answer know data item cache moreover w nd e answers related word go exactly one place cache straightforward nd word cache e simplest way assign location cache word memory assign cache location based address word memory cache structure called direct mapped since memory location mapped directly exactly one location cache e typical mapping addresses cache locations direct mapped cache usually simple example almost directmapped caches use mapping nd block block address modulo number blocks cache number entries cache power 2 modulo computed simply using loworder log 2 cache size blocks bits addr us 8block cache uses three lowest bits 8 23 block address example figure 58 shows memory addresses 1 ten 00001two 29 ten 11101two map locations 1 ten 001two 5 ten 101two directmapped cache eight words cache location contain contents number erent memory locations know whether data cache corresponds requested wor know whether requested word cache answer question adding set tags cache e tags contain address information required identify whether word cache corresponds requested word e tag needs contain upper portion address corresponding bits used index cache example figure 58 need upper 2 5 address bits tag since lower 3bi eld address selects block architects omit index bits redundant since b nition eld address cache block must block number also need way recognize cache block valid information instance processor starts cache good data ta elds meaningless even er executing many instructions directmapped cache cache structure memory location mapped exactly one location cache tag eld table used memory hierarchy contains address information required identify whether associated block hierarchy corresponds requested word 53 basics caches 385x4x1xn œ 2xn œ 1x2x3a reference x nx4x1xn œ 2xn œ 1x2x3b reference x nxnfigure 57 cache reference word xn initially cache reference causes miss forces cache fetch x n memory insert cache cachememory0000110001010100101111110000001011001010100101101 101011100111101 figure 58 directmapped cache eight entries showing addresses memory words 0 31 map cache locations eight words cache address x maps directmapped cache word x modu loworder log28 3 bits used cach us addresses 00001 two 01001two 10001two 11001 two map entry 001 two cache addresses 00101 two 01101two 10101two 11101 two map entry 101 two cache 386 chapter 5 large fast exploiting memory hierarchy cache entries may still empty figure 57 us need know tag ignored entr e common method add valid bit indicate whether entry contains valid address bit set match block rest section focus explaining cache deals reads general handling reads little simpler handling writes since reads change contents cache er seeing basics reads work cache misses handled well examine cache designs real computers detail caches handle writes valid bit eld tables memory hierarchy indicates associated block hierarchy contains valid data caching perhaps important example big idea prediction relies principle locality try nd desired data higher levels memory hierarchy provides mechanisms ensure prediction wrong nds uses proper data lower levels memory hierarchy e hit rates cache prediction modern computers en higher 95 see figure 547 bigpictureaccessing cachebelow sequence nine memory references empty eightblock cache including action reference figure 59 shows contents cache change miss since eight blocks cache loworder three bits address give block number decimal addressof referencebinary address referencehit missin cacheassigned cache blockwhere found placed2210110twomiss 56b10110two mod 8 110two2611010twomiss 56c11010two mod 8 010two2210110twohit10110two mod 8 110two2611010twohit11010two mod 8 010two1610000twomiss 56d10000two mod 8 000two300011twomiss 56e00011two mod 8 011two1610000twohit10000two mod 8 000two1810010twomiss 56f10010two mod 8 010two1610000twohit10000two mod 8 000twosince cache empty several th rst references misses caption figure 59 describes actions memory reference eighth reference 53 basics caches 387indexvtag dataindexvtag data000n 000n 001n001n 010n010n 011n011n 100n100n 101n101n 110n110y 10twomemory 10110 two111n 111n initial state cache poweronb handling miss address 10110twoindexvtag dataindexvtag data000n 000y 10twomemory 10000 two001n 001n 010y11twomemory 11010 two010y11 twomemory 11010 two011n011n 100n100n 101n101n 110y 10twomemory 10110 two110y10 twomemory 10110 two111n111n c handling miss address 11010twod handling miss address 10000twoindexvtag dataindexvtag data000y10 twomemory 10000 two000y10 twomemory 10000 two001n001n 010y11 twomemory 11010 two010y 10twomemory 10010 two011y 00twomemory 00011 two011y00 twomemory 00011 two100n100n 101n101n 110y 10twomemory 10110 two110y10 twomemory 10110 two111n111n e handling miss address 00011twof handling miss address 10010twofigure 59 cache contents shown reference request misses index tag ﬁ elds shown binary sequence addresses page 386 e cache initially empty valid bits v entry cache turned e processor requests following addresses 10110 two miss 11010two miss 10110two hit 11010 two hit 10000 two miss 00011two miss 10000two hit 10010 two miss 10000 two hi e gures show cache contents er miss sequence handled address 10010 two 18 referenced entry address 11010 two 26 must replaced reference 11010 two cause subsequen e ta eld contain upper portion addr e full address word contained cache block tag eld j cache j 8 equivalently concatenation ta eld j index example cache f index 010 two tag 10 two corresponds address 10010 two 388 chapter 5 large fast exploiting memory hierarchy con icting demands bloc e word address 18 10010 two brought cache block 2 010 two hence must replace word address 26 11010two already cache block 2 010 two behavior allows cache take advantage temporal locality recently referenced words replace less recently referenced words situation directly analogous needing book shelves space desksome book already desk must returned shelves directmapped cache one place put newly requested item hence one choice replace know look cache possible address loworder bits address used nd unique cache entry address could map figure 510 shows referenced address divided ag eld used compare value ta eld cache cache index used select block e index cache block together tag contents block uniquely sp es memory address word contained cache block th eld used address reference cache nbit eld 2 n values total number entries directmapped cache must power 2 mips architecture since words aligned multiples four bytes le cant two bits every address specify byte within word hence le cant two bits ignored selecting word block e total number bits needed cache function cache size address size cache includes storage data ta e size block one word normally several following situation 32bit addresses directmapped cache e cache size 2 n blocks n bits used index e block size 2 words 2 m2 bytes bits used word within block two bits used byte part address size ta eld 32 n 2 e total number bits directmapped cache 2n block size tag size eld size 53 basics caches 389since block size 2 words 2 m5 bits need 1 bit th eld number bits cache 2n 2m 32 32 n 2 1 2n 2m 32 31 n malthough actual size bits naming convention exclude size tag eld count size dat us cache figure 510 called 4 kib cache address showing bit positionsdatahitdatatagvalidtag 3220index012102310221021index2010byteoffset31 3013 12 112 1 0 figure 510 cache lower portion address used select cache entry consisting data word tag cache holds 1024 words 4 kib assume 32bit addresses chapter e tag cache compared upper portion address determine whether entry cache corresponds requested address cache 2 10 1024 words block size one word 10 bits used index cache leaving 32 10 2 20 bits compared tag tag upper 20 bits address equal valid bit request hits cache word supplied processor otherwise miss occurs 390 chapter 5 large fast exploiting memory hierarchy bits cachehow many total bits required directmapped cache 16 kib data 4word blocks assuming 32bit address know 16 kib 4096 2 12 words block size 4 words 2 2 1024 2 10 blocks block 4 32 128 bits data plus tag 32 10 2 2 bits plus valid bi us total cache size 210 4 32 32 10 2 2 1 210 147 147 kibibits 184 kib 16 kib cache cache total number bits cache 115 times many needed storage data mapping address multiword cache blockconsider cache 64 blocks block size 16 bytes block number byte address 1200 map saw formula pag e block given block address modulo number blocks cache address block byte address bytes per block notice block address block containing addresses byte address bytes per block bytes per block exampleanswerexampleanswer 53 basics caches 391andbyte address bytes per block bytes per blockbytes per block 1 us 16 bytes per block byte address 1200 block address 1200675which maps cache block number 75 modulo 64 11 fact block maps addresses 1200 1215 larger blocks exploit spatial locality lower miss rates figure 511 shows increasing block size usually decreases miss rate e miss rate may go eventually block size beco cant fraction cache size number blocks held cache become small great deal competition blocks result block bumped cache many words accessed stated alternatively spatial locality among words block decreases large block consequently ts miss rate become smaller serious problem associated increasing block size cost miss increas e miss penalty determined time required fetch 4k161016k64k256k503264128256missrateblock sizefigure 511 miss rate versus block size note miss rate actually goes block size large relative cache size line represents cache erent size gure independent associativity discussed soon unfortunately spec cpu2000 traces would take long block size included data based spec92 392 chapter 5 large fast exploiting memory hierarchy block next lower level hierarchy load cache e time fetch block two parts latency th rst word transfer time rest block clearly unless change memory system transfer timeand hence miss penaltywill likely increase block size increases furthermore improvement miss rate starts decrease blocks become larger e result increase miss penalty overwhelms decrease miss rate blocks large cache performance thus decreases course design memory transfer larger blocks ciently increase block size obtain improvements cache performance discuss topic next section elaboration although hard anything longer latency component miss penalty large blocks may able hide transfer time miss penalty effectively smaller simplest method called early restart simply resume execution soon requested word block returned rather wait entire block many processors use technique instruction access works best instruction accesses largely sequential memory system deliver word every clock cycle processor may able restart operation requested word returned memory system delivering new instruction words time technique usually less effective data caches likely words requested block less predictable way probability processor need another word different cache block transfer completes high processor access data cache transfer ongoing must stall even sophisticated scheme organize memory requested word transferred memor rst remainder block transferred starting address requested word wrapping around beginning block technique called requested word ﬁ rst critical word ﬁ rst slightly faster early restart limited properties limit early restart handling cache missesbefore look cache real system lets see control unit deals cache misses describe cache controller detail sectio e control unit must detect miss process miss fetching requested data memory shall see lowerlevel cache cache reports hit computer continues using data nothing happened modifying control processor handle hit trivial misses however require extra wo e cache miss handling done collaboration processor control unit separate controller initiates memory access r lls cache e processing cache miss creates pipeline stall chapter 4 opposed interrupt would require saving state registers cache miss stall th e entire processor essentially freezing contents temporary programmervisible registers wait cache miss request data cache b lled data present cache 53 basics caches 393for memory sophisticated outoforder processors allow execution instructions waiting cache miss well assume inorder processors stall cache misses section lets look little closely instruction misses handled approach easily extended handle data misses instruction access results miss content instruction register invalid get proper instruction cache must able instruct lower level memory hierarchy perform read since program counter incremented th rst clock cycle execution address instruction generates instruction cache miss equal value program counter minus 4 address need instruct main memory perform read wait memory respond since access take multiple clock cycles write words containing desired instruction cache ne steps taken instruction cache miss 1 send original pc value current pc 4 memory 2 instruct main memory perform read wait memory complete access 3 write cache entry putting data memory data portion entry writing upper bits address alu tag eld turning valid bit 4 restart instruction execution th rst step refetch instruction nding cache e control cache data access essentially identical miss simply stall processor memory responds data handling writeswrites work somewhat erently suppose store instruction wrote data data cache without changing main memory er write cache memory would hav erent value cache case cache memory said inconsistent e simplest way keep main memory cache consistent always write data memory cache scheme called writethrough e key aspect writes occurs write miss w rst fetch words block memory er block fetched placed cache overwrite word caused miss cache block also write word main memory using full address although design handles writes simply would provide good performance writethrough scheme every write causes data written main memory ese writes take long time likely least 100 processor clock cycles could slow processor considerably example suppose 10 instructions stores cpi without cache writethrough scheme writes always update cache next lower level memory hierarchy ensuring data always consistent two 394 chapter 5 large fast exploiting memory hierarchy misses 10 spending 100 extra cycles every write would lead cpi 10 100 10 11 reducing performance factor 10 one solution problem use write bu er write bu er stores data waiting written memory er writing data cache write bu er processor continue execution write main memory completes entry write b er freed write bu er full processor reaches write processor must stall empty position write bu er course rate memory complete writes less rate processor generating writes amount bu ering help writes generated faster memory system accept e rate writes generated may also less rate memory accept yet stalls may still occur happen writes occur bursts reduce occurrence stalls processors usually increase depth write b er beyond single entry e alternative writethrough scheme scheme called writeback writeback scheme write occurs new value written block cache e mo ed block written lower level hierarchy replaced writeback schemes improve performance especially processors generate writes fast faster writes handled main memory writeback scheme however complex implement writethrough rest section describe caches real processors examine handle reads writes section 58 describe handling writes detail elaboration writes introduce several complications caches present reads w cient implementation writes writeback cachesconsider miss writethrough cache common strategy allocate block cache called write allocate block fetched memory appropriate portion block overwritten alternative strategy update portion block memory put cache called write allocate motivation sometimes programs write entire blocks data operating system zeros page memory cases fetch associated initial write miss may unnecessary computers allow write allocation policy changed per page basis ciently cache uses writeback strategy complex writethrough cache writethrough cache write data cache read tag tag mismatches miss occurs cache writethrough overwriting block cache catastrophic since memory correct value writeback cache w rst write block back memor ed cache miss simply overwrote block store instruction knew whether store hit cache could writethrough cache would destroy contents block backed next lower level memory hierarchy write bu er queue holds data data waiting written memory writeback scheme handles writes updating values block cache writing mo ed block lower level hierarchy block replaced 53 basics caches 395in writeback cache overwrite block stores either require two cycles cycle check hit followed cycle actually perform write require write buffer hold dataeffectively allowing store take one cycle pipelining store buffer used processor cache lookup places data store buffer normal cache access cycle assuming cache hit new data written store buffer cache next unused cache access cycleby comparison writethrough cache writes always done one cycle read tag write data portion selected block tag matches address block written processor continue normally since correct block updated tag match processor generates write miss fetch rest block corresponding address many writeback caches also include write buffers used reduce miss ed block case ed block moved writeback buffer associated cache requested block read memory writeback buffer later written back memory assuming another miss occur immediately technique halves miss penalty dirty block must replacedan example cache intrinsity fastmath processor e intrinsity fastmath embedded microprocessor uses mips architecture simple cache implementation near end chapter examine complex cache designs arm intel microprocessors start simple yet real example pedagogical reasons figure 512 shows organization intrinsity fastmath data cache processor 12stage pipeline operating peak speed processor request instruction word data word every clock satisfy demands pipeline without stalling separate instruction data caches used cache 16 kib 4096 words 16word blocks read requests cache straightforward separate data instruction caches need separate control signals read write cache remember need update instruction cache miss occur us steps read request either cache follows 1 send address appropriate cache e address comes either pc instruction alu data 2 cache signals hit requested word available data lines since 16 words desired block need select right one bloc eld used control multiplexor shown bottom th gure selects requested word 16 words indexed block 396 chapter 5 large fast exploiting memory hierarchy 3 cache signals miss send address main memory memory returns data write cache read fu request writes intrinsity fastmath ers writethrough writeback leaving operating system decide strategy use application oneentry write bu er cache miss rates attained cache structure like used intrinsity fastmath figure 513 shows miss rates instruction data cach e combined miss rate th ective miss rate per reference program er accounting th ering frequency instruction data accesses address showing bit positionsdatahitdatatagvtag3218index188byteoffset3114 132 1 0 6 54block offset256entries512 bits18 bitsmux323232figure 512 16 kib caches intrinsity fastmath contain 256 blocks 16 words per block e tag eld 18 bits wide th eld 8 bits wide 4bi eld bits 52 used index block select word block using 16to1 multiplexor practice eliminate multiplexor caches use separate large ram data smal ler ram tags block set supplying extra address bits large data ram case large ram 32 bits wide must 16 times many words blocks cache 53 basics caches 397although miss rate important characteristic cache designs ultimate measure th ect memory system program execution time well see miss rate execution time related shortly elaboration combined cache total size equal sum two split caches usually better hit rate higher rate occurs combined cache rigidly divide number entries may used instructions may used data nonetheless almost processors today use split instruction data caches increase cache bandwidth match modern pipelines expect may also ict misses see section 58 miss rates caches size found intrinsity fastmath processor combined cache whose size equal sum two caches total cache size 32 kib split cache effective miss rate 324 combined cache miss rate 318the miss rate split cache slightly worse advantage doubling cache bandwidth supporting instruction data access simultaneously easily overcomes disadvantage slightly increased miss rate observation cautions us use miss rate sole measure cache performance section 54 shows summary began previous section examining simplest caches directmapped cache oneword block cache hits misses simple since word go exactly one location separate tag every word keep cache memory consistent writethrough scheme used every write cache also causes memory updated e alternative writethrough writeback scheme copies block back memory replaced well discuss scheme upcoming sections split cache scheme level memory hierarchy composed two independent caches operate parallel one handling instructions one handling data instruction miss ratedata miss rateeffective combined miss rate 0411432figure 513 approximate instruction data miss rates intrinsity fastmath processor spec cpu2000 benchmarks e combined miss rate th ective miss rate seen combination 16 kib instruction cache 16 kib data cache obtained weighting instruction data individual miss rates frequency instruction data references 398 chapter 5 large fast exploiting memory hierarchy take advantage spatial locality cache must block size larger one word e use larger block decreases miss rate improves ciency cache reducing amount tag storage relative amount data storage cache although larger block size decreases miss rate also increase miss penalty miss penalty increased linearly block size larger blocks could easily lead lower performance avoid performance loss bandwidth main memory increased transfer cache blocks mor ciently common methods increasing bandwidth external dram making memory wider interleaving dram designers steadily improved interface processor memory increase bandwidth burst mode transfers reduce cost larger cache block sizes e speed memory system ects designers decision size cache block following cache designer guidelines generally valid e shorter memory latency smaller cache block e shorter memory latency larger cache block e higher memory bandwidth smaller cache block e higher memory bandwidth larger cache block 54 measuring improving cache performance section begin examining ways measure analyze cache performance explore tw erent techniques improving cache performance one focuses reducing miss rate reducing probability tw erent memory blocks contend cache locatio e second technique reduces miss penalty adding additional level hierarchy technique called multilevel caching rst appeared highend computers selling 100000 1990 since become common personal mobile devices selling hundred dollars check 54 measuring improving cache performance 399cpu time divided clock cycles cpu spends executing program clock cycles cpu spends waiting memory system normally assume costs cache accesses hits part normal cpu execution cyc uscpu time cpu execution clock cycles memorystall clock cycles clock cycle time e memorystall clock cycles come primarily cache misses make assumption also restrict discussion simp ed model memory system real processors stalls generated reads writes quite complex accurate performance prediction usually requires detailed simulations processor memory system memorystall clock cycles b ned sum stall cycles coming reads plus coming writes memorystall clock cycles readstall cycles writestall cycles e readstall cycles ned terms number read accesses per program miss penalty clock cycles read read miss rate readstall cycles readsprogram read miss rateread miss pe nnaltywrites complicated writethrough scheme two sources stalls write misses usually require fetch block continuing write see elaboration page 394 details dealing writes write bu er stalls occur write b er full write occur us cycles stalled writes equals sum two writestall cycles writes program write miss ratewrite mis ss penalty stalls write bu er stalls depend proximity writes frequency possible give simple equation compute stalls fortunately systems reasonable write b er depth eg four words memory capable accepting writes rate cantly exceeds average write frequency programs eg factor 2 write bu er stalls small safely ignore system meet criteria would well designed stead designer used either deeper write bu er writeback organization 400 chapter 5 large fast exploiting memory hierarchy writeback schemes also potential additional stalls arising need write cache block back memory block replaced discuss section 58 writethrough cache organizations read write miss penalties time fetch block memory assume write bu er stalls negligible combine reads writes using single miss rate miss penalty memorystall clock cyclesmemory accessesprogram miss ratemiss penaltywe also factor memorystall clock cyclesinstructions program misses instru cction miss penaltylets consider simple example help us understand impact cache performance processor performance calculating cache performance assume miss rate instruction cache 2 miss rate data cache 4 processor cpi 2 without memory stalls miss penalty 100 cycles misses determine much faster processor would run perfect cache never missed assume frequency loads stores 36 e number memory miss cycles instructions terms instruction count instruction miss cycles 2 100 200 ias frequency loads stores 36 ca nd number memory miss cycles data references data miss cycles 36 4 100 144 iexampleanswer 54 measuring improving cache performance 401what happens processor made faster memory system e amount time spent memory stalls take increasing fraction execution time amdahls law examined chapter 1 reminds us fact simple examples show serious problem suppose speedup computer previous example reducing cpi 2 1 without changing clock rate might done improved pipeline e system cache misses would cpi 1 344 444 system perfect cache would 444 1444 times fast e amount execution time spent memory stalls would risen 344 544 63to344 444 77similarly increasing clock rate without changing memory system also increases performance lost due cache misses e previous examples equations assume hit time factor determining cache performance clearly hit time increases total time access word memory system crease possibly causing increase processor cycle time although see additional examples increase e total number memorystall cycles 200 144 three cycles memory stall per instruction accordingly total cpi including memory stalls 2 344 544 since change instruction count clock rate ratio cpu execution times cpu time stalls cpu time perfect cache icpi stall clock cycle icpiclock cycle cpi cpi 5perfect stall perfect 44 2 e performance perfect cache better 544 2272 402 chapter 5 large fast exploiting memory hierarchy hit time shortly one example increasing cache size larger cache could clearly longer access time desk library large say 3 square meters would take longer locate book desk increase hit time likely adds another stage pipeline since may take multiple cycles cache hit although complex calculate performance impact deeper pipeline point increase hit time larger cache could dominate improvement hit rate leading decrease processor performance capture fact time access data hits misses ects performance designers sometime use average memory access time amat way examine alternative cache designs average memory access time average time access memory considering hits misses frequency erent accesses equal following amat time hit miss rate miss penalty calculating average memory access time find amat processor 1 ns clock cycle time miss penalty 20 clock cycles miss rate 005 misses per instruction cache access time including hit detection 1 clock cycle assume read write miss penalties ignore write stalls e average memory access time per instruction amattime hitmiss ratemiss penalt y100520 2 clocck cyclesor 2 ns e next subsection discusses alternative cache organizations decrease miss rate may sometimes increase hit time additional examples appear section 515 fallacies pitfalls reducing cache misses flexible placement blocksso far place block cache used simple placement scheme block go exactly one place cache mentioned earlier called direct mapped direct mapping block address memory single location upper level hierarchy however actually whole range schemes placing blocks direct mapped block placed exactly one location one extreme exampleanswer 54 measuring improving cache performance 403at extreme scheme block placed location cache scheme called fully associative block memory may associated entry cache nd given block fully associative cache entries cache must searched block placed one make search practical done parallel comparator associated cache entry ese comparator cantly increase hardware ectively making fully associative placement practical caches small numbers blocks e middle range designs direct mapped fully associative called set associative setassociative cache ar xed number locations block placed setassociative cache n locations block called nway setassociative cache nway setassociative cache consists number sets consists n blocks block memory maps unique set cache given th eld block placed element us setassociative placement combines directmapped placement fully associative placement block directly mapped set blocks set searched match example figure 514 shows block 12 may placed cache eight blocks total according three block placement policies remember directmapped cache position memory block given block number modulo number blocks cache fully associative cache cache structure block placed location cache setassociative cache cache tha xed number locations least two block placed direct mapped2457 6013 block datatag search12set associative2013 set datatag search1 2fully associative datatag search1 2figure 514 location memory block whose address 12 cache eight blocks varies directmapped setassociative fully associative placement direct mapped placement one cache block memory block 12 found block given 12 modulo 8 4 twoway setassociative cache would four sets memory block 12 must set 12 mod 4 0 memory block could either element set fully associative placement memory block block address 12 appear eight cache blocks 404 chapter 5 large fast exploiting memory hierarchy setassociative cache set containing memory block given block number modulo number sets cache since block may placed element set tags elements set must searched fully associative cache block go anywhere tags blocks cache must searched also think block placement strategies variation set associativity figure 515 shows possible associativity structures eight block cache directmapped cache simply oneway setassociative cache cache entry holds one block set one element fully associative cache entries simply mway setassociative cache one set blocks entry reside block within set e advantage increasing degree associativity usually decreases miss rate next example sho e main disadvantage discuss detail shortly potential increase hit time eightway set associative fully associativetagtagdatadatatag tagdatadata tagtagdatadatatag tagdatadata tagtagdatadatatag tagdatadata setfourway set associativetagtagdatadata set01012301 2 3 4567twoway set associativetagdata blockoneway set associativedirect mappedfigure 515 eightblock cache conﬁ gured direct mapped twoway set associative fourway set associative fully associative e total size cache blocks equal number sets times associativity us fo xed cache size increasing associativity decreases number sets increasing number elements per set eight blocks eightway set associative cache fully associative cache 54 measuring improving cache performance 405misses associativity cachesassume three small caches consisting four oneword blocks one cache fully associative second twoway setassociative third directmapped find number misses cache organization given following sequence block addresses 0 8 0 6 8 e directmapped case easiest first lets determine cache block block address maps block addresscache block 00 modulo 4 066 modulo 4 288 modulo 4 0now ca cache contents er reference using blank entry mean block invalid colored text show new entry added cache associated reference plain text show old entry cache address memory block accessedhitor misscontents cache blocks reference01230missmemory0 8missmemory8 0missmemory0 6missmemory0 memory6 8missmemory8 memory6 e directmapped cache generat misses th accesses e setassociative cache two sets indices 0 1 two elements per set let rst determine set block address maps block addresscache set00 modulo 2 066 modulo 2 088 modulo 2 0because choice entry set replace miss need replacement rule setassociative caches usually replace least recently used block within set block used furthest past exampleanswer 406 chapter 5 large fast exploiting memory hierarchy replaced discuss replacement rules detail shortly using replacement rule contents setassociative cache er reference looks like address memory block accessedhitor misscontents cache blocks referenceset 0set 0set 1set 1 0missmemory0 8missmemory0 memory8 0hitmemory0memory8 6missmemory0 memory6 8missmemory8 memory6 notice block 6 referenced replaces block 8 since block 8 less recently referenced bloc e twoway setassociative cache four misses one less directmapped cache e fully associative cache four cache blocks single set memory block stored cache bloc e fully associative cache best performance three misses address memory block accessedhitor misscontents cache blocks referenceblock 0block 1block 2block 3 0missmemory0 8missmemory0 memory8 0hitmemory0memory8 6missmemory0memory8 memory6 8hitmemory0memory8memory6 series references three misses best three unique block addresses accessed notice eight blocks cache would replacements twoway setassociative cache check would number misses fully associative cache similarly 16 blocks 3 caches would number misses even trivial example shows cache size associativity independent determining cache performance much reduction miss rate achieved associativity figure 516 shows improvement 64 kib data cache 16word block associativity ranging direct mapped eightway going oneway twoway associativity decreases miss rate 15 little improvement going higher associativity 54 measuring improving cache performance 407locating block cachenow lets consider task nding block cache set associative directmapped cache block setassociative cache includes address tag gives block addr e tag every cache block within appropriate set checked see matches block address processor figure 517 decomposes addr e index value used select set containing address interest tags blocks set must searched speed essence tags selected set searched parallel fully associative cache sequential search would make hit time setassociative cache slow total cache size kept increasing associativity increases number blocks per set number simultaneous compares needed perform search parallel increase factor 2 associativity doubles number blocks per set halves number sets accordingly factorof2 increase associativity decreases size index 1 bit increases size tag 1 bit fully associative cache ther ectively one set blocks must checked parallel us index entire address excluding block set compared tag every block words search entire cache without indexing directmapped cache single comparator needed entry one block access cache simply indexing figure 518 shows fourway setassociative cache four comparators needed together 4to1 multiplexor choose among four potential members selected set e cache access consists indexing appropriate set searching tags e costs associative cache extra comparators delay imposed compare select among elements set associativitydata miss rate1103286483881figure 516 data cache miss rates organization like intrinsity fastmath processor spec cpu2000 benchmarks associativity varying oneway eightway ese results 10 spec cpu2000 programs hennessy patterson 2003 block offsettagindexfigure 517 three portions address setassociative directmapped cache e index used select set tag used choose block comparison blocks selected e block set address desired data within block 408 chapter 5 large fast exploiting memory hierarchy e choice among directmapped setassociative fully associative mapping memory hierarchy depend cost miss versus cost implementing associativity time extra hardware elaboration content addressable memory cam circuit combines comparison storage single device instead supplying address reading word like ram supply data cam looks see copy returns index matching row cams mean cache designers afford implement much higher set associativity needed build hardware srams comparators 2013 greater size power cam generally leads 2way 4way set associativity built standard srams comparators 8way built using cams addressdatatagvtag index22831 3012 11 10 9 83 2 1 0 4to1 multiplexorindex01 2253254255datavtag datavtag datavtag 2232datahitfigure 518 implementation fourway setassociative cache requires four comparators 4to1 multiplexor e comparators determine element selected set matches ta e output comparators used select data one four blocks indexed set using multiplexor decoded select signal implementations output enable signals data portions cache rams used select entry set drives outpu e output enable signal comes comparators causing element matches drive data outpu organization eliminates need multiplexor 54 measuring improving cache performance 409choosing block replacewhen miss occurs directmapped cache requested block go exactly one position block occupying position must replaced associative cache choice place requested block hence choice block replace fully associative cache blocks candidates replacement setassociative cache must choose among blocks selected set e commonly used scheme least recently used lru used previous example lru scheme block replaced one unused longest time e set associative example page 405 uses lru replaced memory0 instead memory6 lru replacement implemented keeping track element set used relative elements set twoway setassociative cache tracking two elements used implemented keeping single bit set setting bit indicate element whenever element referenced associativity increases implementing lru gets harder section 58 see alternative scheme replacement size tags versus set associativity increasing associativity requires comparators tag bits per cache block assuming cache 4096 blocks 4word block size 32bit addr nd total number sets total number tag bits caches direct mapped twoway fourway set associative fully associative since 16 24 bytes per block 32bit address yields 32 4 28 bits used index ta e directmapped cache number sets blocks hence 12 bits index since log 24096 12 hence total number 28 12 4096 16 4096 66 k tag bits degree associativity decreases number sets factor 2 thus decreases number bits used index cache 1 increases number bits tag b us twoway setassociative cache 2048 sets total number tag bits 28 11 2 2048 34 2048 70 kbits fourway setassociative cache total number sets 1024 total number 28 10 4 1024 72 1024 74 k tag bits fully associative cache one set 4096 blocks tag 28 bits leading 28 4096 1 115 k tag bits least recently used lru replacement scheme block replaced one unused longest time exampleanswer 410 chapter 5 large fast exploiting memory hierarchy reducing miss penalty using multilevel caches modern computers make use caches close gap fast clock rates modern processors increasingly long time required access drams microprocessors support additional level cachin secondlevel cache normally chip accessed whenever miss occurs primary cache secondlevel cache contains desired data miss penalty th rstlevel cache essentially access time secondlevel cache much less access time main memory neither primary secondary cache contains data main memory access required larger miss penalty incurred ho cant performance improvement use secondary cach e next example shows us performance multilevel caches suppose processor base cpi 10 assuming references hit primary cache clock rate 4 ghz assume main memory access time 100 ns including miss handling suppose miss rate per instruction primary cache 2 much faster processor add secondary cache 5 ns access time either hit miss large enough reduce miss rate main memory 05 e miss penalty main memory 100025 ns nsclock cycle 400 clock cycles e ective cpi one level caching given total cpi base cpi memorystall cycles per instruction processor one level caching total cpi 10 memorystall cycles per instruction 10 2 400 9with two levels caching miss primary rstlevel cache satis ed either secondary cache main memory e miss penalty access secondlevel cache 5025 ns nsclock cycle 20 clock cyclesexampleanswer 54 measuring improving cache performance 411if miss sa ed secondary cache entire miss penalty miss needs go main memory total miss penalty sum secondary cache access time main memory access time us twolevel cache total cpi sum stall cycles levels cache base cpi total cpi1primary stalls per instructionsecondary stall ss per instruction 1220054001042034 us processor secondary cache faster 903426alternatively could computed stall cycles summing stall cycles references hit secondary cache 2 05 20 ose references go main memory must include cost access secondary cache well main memory access time 05 20 400 e sum 10 03 21 34 e design considerations primary secondary cache ar cantly erent presence cache changes best choice versus singlelevel cache particular twolevel cache structure allows primary cache focus minimizing hit time yield shorter clock cycle fewer pipeline stages allowing secondary cache focus miss rate reduce penalty long memory access times e ect changes two caches seen comparing cache optimal design single level cache comparison single level cache primary cache multilevel cache en smaller furthermore primary cache may use smaller block size go smaller cache size also reduce miss penalty comparison secondary cache much larger singlelevel cache since access time secondary cache less critical larger total size secondary cache may use larger block size appropriate singlelevel cache en uses higher associativity primary cache given focus reducing miss rates sorting exhaustively analyzed nd better algorithms bubble sort quicksort radix sort figure 519a shows instructions executed item searched radix sort versus quicksort expected large arrays radix sort algorithmic advantage quicksort terms number operations figure 519b shows time per key instead instructions executed see lines start trajectory figure 519a radix sort line multilevel cache memory hierarchy multiple levels caches rather cache main memory understanding program performance 412 chapter 5 large fast exploiting memory hierarchy figure 519 comparing quicksort radix sort instructions executed per item sorted b time per item sorted c cache misses per item sorted data paper lamarca ladner 1996 due results new versions radix sort invented take memory hierarchy account regain algorithmic advantages see sectio e basic idea cache optimizations use data block repeatedly replaced miss radix sort quicksort size k items sort instructionsitem 0481632 200400 600 8001000 120064128256512 102420484096 aradix sort quicksort size k items sort clock cyclesitem 0481632 4008001200 1600200064128256512 102420484096 bradix sort quicksort size k items sort cache missesitem 0481632 1234564128256512 102420484096 c 54 measuring improving cache performance 413diverges data sort increases going figure 519c answers looking cache misses per item sorted quicksort consistently many fewer misses per item sorted alas standard algorithmic analysis en ignores impact memory hierarchy faster clock rates moores law allow architects squeeze performance stream instructions using memory hierarchy well critical high performance said introduction understanding behavior memory hierarchy critical understanding performance programs todays computers software optimization via blocking given importance memory hierarchy program performance surprisingly many ware optimizations invented dramatically improve performance reusing data within cache hence lower miss rates due improved temporal locality dealing arrays get good performance memory system store array memory accesses array sequential memory suppose dealing multiple arrays however arrays accessed rows columns storing arrays rowbyrow called row major order columnbycolumn column major order solve problem rows columns used every loop iteration instead operating entire rows columns array blocked algorithms operate submatrices blocks e goal maximize accesses data loaded cache data replaced improve temporal locality reduce cache misses example inner loops dgemm lines 4 9 figure 321 chapter 3 int j 0 j n j double cij cijn cij cij int k 0 k n k cij aikn bkjn cij aikbkj cijn cij cij cij reads nby n elements b reads n elements corresponds one row repeatedly writes corresponds one row n elements c e comments make rows columns matrices easier identify figure 520 gives snapshot accesses three arrays dark shade indicates recent access light shade indicates older access white means yet accessed 414 chapter 5 large fast exploiting memory hierarchy e number capacity misses clearly depends n size cache hold three nby n matrices well provided cache co icts purposely picked matrix size 32 32 dgemm chapters 3 4 would case matrix 32 32 1024 elements element 8 bytes three matrices occupy 24 kib comfortabl 32 kib data cache intel core i7 sandy bridge cache hold one nby n matrix one row n least ith row array b may stay cache less misses may occur b c worst case would 2 n3 n2 memory words accessed n3 operations ensure elements accessed ca cache original code changed compute submatrix hence essentially invoke version dgemm figure 480 chapter 4 repeatedly matrices size blocksize blocksize blocksize called blocking factor figure 521 shows blocked version e function do_block dgemm figure 321 three new parameters si sj sk specify starting position submatrix b c e two inner loops do_block compute steps size blocksize rather full length b c e gcc optimizer removes function call overhead inlining function inserts code directly avoid conventional parameter passing return address bookkeeping instructions figure 522 illustrates accesses three arrays using blocking looking capacity misses total number memory words accessed 2 n3 blocksize n2 total improvement factor blocksize hence blocking exploits combination spatial temporal locality since bene ts spatial locality b bene ts temporal locality figure 520 snapshot three arrays c b n 6 1 e age accesses array elements indicated shade wh ite means yet touched light means older accesses dark means newer accesses compared figure 521 elements b read repeatedly calculate new elements x e variables j k shown along rows columns used access arrays 01 2 345102345 xji0 1 2 345102345 yki0 1 2 345102345 zjk 54 measuring improving cache performance 415figure 521 cache blocked version dgemm figure 321 assume c initialized zero e do_block function basically dgemm chapter 3 new parameters specify starting positions submatrices blocksize e gcc optimizer remove function overhead instructions inlining do_block function figure 522 age accesses arrays c b blocksize 3 note contrast figure 520 fewer elements accessed 01 2 3 4 5102345 xji0 1 2 3 4 5102345 yki0 1 2 3 4 5102345 zjk1 define blocksize 32 2 void do_block int n int si int sj int sk double double 3 b double c 4 5 int si siblocksize 6 int j sj j sjblocksize j 7 8 double cij cijn cij cij 9 int k sk k skblocksize k 10 cij aikn bkjn cijaikbkj 11 cijn cij cij cij 12 13 14 void dgemm int n double double b double c 15 16 int sj 0 sj n sj blocksize 17 int si 0 si n si blocksize 18 int sk 0 sk n sk blocksize 19 do_blockn si sj sk b c 20 although aimed reducing cache misses blocking also used help register allocation taking small blocking size block held registers minimize number loads stores program also improves performance 416 chapter 5 large fast exploiting memory hierarchy figure 523 shows impact cache blocking performance unoptimized dgemm increase matrix size beyond three matr cache e unoptimized performance halved largest matr e cacheblocked version less 10 slower even matrices 960x960 900 times larger th trices chapters 3 4 elaboration multilevel caches create several complications first several different types misses corresponding miss rates example pages 410411 saw primary cache miss rate global miss ratethe fraction references missed cache levels also miss rate secondary cache ratio misses secondary cache divided number accesses miss rate called local miss rate secondary cache primar lters accesses especially good spatial temporal locality local miss rate secondary cache much higher global miss rate example pages 410411 compute local miss rate secondary cache 052 25 luckily global miss rate dictates often must access main memory elaboration outoforder processors see chapter 4 performance complex since execute instructions miss penalty instead instruction miss rates data miss rates use misses per instruction formula memorystall cycles instruction misses instruction total mi sss latencyoverlapped miss latency global miss rate e fraction references miss levels multilevel cache local miss rate e fraction references one level cache miss used multilevel hierarchies 1815 12 09 06gflops03œunoptimized 17151308171616 15blocked 32x32160x160480x480960x960 figure 523 performance unoptimized dgemm figure 321 versus cache blocked dgemm figure 521 matrix dimension varies 32x32 three matrices ﬁ cache 960x960 54 measuring improving cache performance 417there general way calculate overlapped miss latency evaluations memory hierarchies outoforder processors inevitably require simulation processor memory hierarchy seeing execution processor miss see processor stalls w nds work guideline processor often hides miss penalty l1 cache miss hits l2 cache rarely hides miss l2 cache elaboration performance challenge algorithms memory hierarchy varies different implementations architecture cache size associativity block size number caches cope variability recent numerical libraries parameterize algorithms search parameter space r nd best combination particular computer approach called autotuningwhich following generally true design multiple levels caches 1 firstlevel caches concerned hit time secondlevel caches concerned miss rate 2 firstlevel caches concerned miss rate secondlevel caches concerned hit time summary section focused four topics cache performance using associativity reduce miss rates use multilevel cache hierarchies reduce miss penalties ware optimizations improv ectiveness caches e memory syst cant ect program execution time e number memorystall cycles depends miss rate miss penalty e challenge see section 58 reduce one factors without cantly ecting critical factors memory hierarchy reduce miss rate examined use associative placement schemes schemes reduce miss rate cache allowing mor exible placement blocks within cache fully associative schemes allow blocks placed anywhere also require every block cache searched satisfy req e higher costs make large fully associative caches impractical set associative caches practical alternative since need search among elements unique set chosen indexing setassociative caches higher miss rates faster e amount associativity yields best performance depends technology details implementation looked multilevel caches technique reduce miss penalty allowing larger secondary cache handle misses primary cache second level caches become commonplace designer nd limited silicon goals high clock rates prevent primary caches becoming large e secondary cache en ten times larger primary cache handles many accesses miss primary cache cases miss penalty access time secondary cache typically 10 processor check 418 chapter 5 large fast exploiting memory hierarchy cycles versus access time memory typically 100 processor cycles associativity design tradeo size secondary cache access time depend number aspects implementation finally given importance memory hierarchy performance looked change algorithms improve cache behavior blocking important technique dealing large arrays 55 dependable memory hierarchy implicit prior discussion memory hierarchy doesnt forget fast undependable attractive learned chapter 1 one great idea dependability redundancy section wel rst go terms ne terms measures associated failure show redundancy make nearly unforgettable memories deﬁ ning failure start assumption sp cation proper service users see system alternating two states delivered service respect service sp cation 1 service accomplishment service delivered sp ed2 service interruption delivered serv erent sp ed service transitions state 1 state 2 caused failures transitions state 2 state 1 called restorations failures permanent intermitten e latter mor cult case harder diagnose problem system oscillates two states permanent failures far easier diagnose nition leads two related terms reliability availability reliability measure continuous service accomplishmentor equivalently time failurefrom reference point hence mean time failure mttf reliability measure related term annual failure rate afr percentage devices would expected fail year given mttf mttf gets large misleading afr leads better intuition mttf vs afr diskssome disks today quoted 1000000hour mttf 1000000 hours 1000000365 24 114 years would seem like practically never fail warehouse scale computers run internet services search might 50000 servers assume server 2 disks use afr calculate many disks would expect fail per year example 55 dependable memory hierarchy 419one year 365 24 8760 hours 1000000hour mttf means afr 87601000000 0876 100000 disks would expect 876 disks fail per year average 2 disk failures per day service interruption measured mean time repair mttr mean time failures mtbf simply sum mttf mttr although mtbf widely used mttf en appropriate term availability measure service accomplishment respect alternation two states accomplishment interruption availability statistically quan ed availabilitymttfmttfmttr note reliability availability actually quan able measures rather synonyms dependability shrinking mttr help availability much increasing mttf example tools fault detection diagnosis repair help reduce time repair faults thereby improve availability want availability high one shorthand quote number nines availability per year example good internet service today ers 4 5 nines availability given 365 days per year 365 24 60 526000 minutes shorthand decoded follows one nine 90 365 days repairyear two nines 99 365 days repairyear ree nines 999 526 minutes repairyear four nines 9999 526 minutes repairyear five nines 99999 526 minutes repairyear increase mttf improve quality components design systems continue operation presence components failed hence failure needs ned respect context failure component may lead failure system make distinction clear term fault used mean failure component three ways improve mttf 1 fault avoidanc e preventing fault occurrence construction 2 fault tolerance using redundancy allow service comply service sp cation despite faults occurring 3 fault forecasting predicting presence creation faults allowing component replaced fails answer 420 chapter 5 large fast exploiting memory hierarchy hamming single error correcting double error detecting code secdedrichard hamming invented popular redundancy scheme memory received turing award 1968 invent redundant codes helpful talk close correct bit patterns call hamming distance minimum number bits ar erent two correct bit patterns example distance 011011 001111 two happens minimum distance members codes two get onebit error turn valid pattern code invalid one us detect whether members code valid detect single bit errors say single bit error detection code hamming used parity code error detection parity code number 1s word counted word odd parity number 1s odd even otherwise word written memory parity bit also written 1 odd 0 ev parity n1 bit word always even en word read parity bit read checked parity memory word stored parity bit match error occurred calculate parity byte value 31 ten show pattern stored memory assume parity bit right suppose th cant bit inverted memory read back detect error happens tw cant bits inverted 31ten 00011111two whic 1s make parity even need write 1 parity bit 000111111 two th cant bit inverted read back would see 100111111 two seven 1s since expect even parity calculated odd parity would signal error two cant bits inverted would see 110111111 two eight 1s even parity would signal error 2 bits error 1bit parity scheme detect errors since parity match data two errors actually 1bit parity scheme detect odd number errors however probability 3 errors much lower probability two practice 1bit parity code limited detecting single bit error course parity code correct errors hamming wanted well detect used code minimum distance 3 single bit error would closer correct pattern valid pattern came easy understand mapping data distance 3 code call hamming error correction code ecc honor use extra error detection code code enables detection error data precise location hence correction error exampleanswer 55 dependable memory hierarchy 421parity bits allow position iden cation single error steps calculate hamming ecc 1 start numbering bits 1 th opposed traditional numbering rightmost bit 0 2 mark bit positions powers 2 parity bits positions 1 2 4 8 16 3 bit positions used data bits positions 3 5 6 7 9 10 11 12 13 14 15 e position parity bit determines sequence data bits checks figure 524 shows coverage graphically bit 1 0001 two checks bits 1357911 bits rightmost bit address 1 0001 two 0011two 0101two 0111two 1001two 1011two bit 2 0010 two checks bits 236710111415 bits second bit right address 1 bit 4 0100 two checks bits 47 1215 2023 bits third bit right address 1 bit 8 1000 two checks bits 815 2431 4047 bits fourth bit right address 1 note data bit covered two parity bits 5 set parity bits create even parity group bit positionencoded data bitsparitybitcoveragep1p1p2 p4 p8p2d1p4d2d3d4p8d5d6d7d8 xxxxxxxxxxxx xxxxxxxxxx123456789101112 figure 524 parity bits data bits eld coverage hamming ecc code eight data bits seems like magic trick determine whether bits incorrect looking parity bits using 12 bit code figure 524 value four parity calculations p8p4p2p1 0000 error however pattern say 1010 10 ten hamming ecc tells us bit 10 d6 error since number binary correct error inverting value bit 10 422 chapter 5 large fast exploiting memory hierarchy assume one byte data value 10011010 two first show hamming ecc code byte invert bit 10 show ecc co nds corrects single bit error leaving spaces parity bits 12 bit pattern _ _ 1 _ 0 0 1 _ 1 0 1 0 position 1 checks bits 13579 and11 highlight __ 1 _ 0 0 1 _ 1 0 1 0 make group even parity set bit 1 0 position 2 checks bits 23671011 0 _ 1 _ 0 0 1 _ 1 0 1 0 odd parity set position 2 1 position 4 checks bits 456712 0 1 1 _ 0 0 1 _ 1 0 1 set 1 position 8 checks bits 89101112 0 1 1 1 0 0 1 _ 1 0 1 0 set 0 e nal code word 011100101010 inverting bit 10 changes 011100101110 parity bit 1 0 011100101110 four 1s even parity group ok parity bit 2 1 0 1110010111 1s odd parity error somewhere parity bit 4 1 011 100101110 two 1s even parity group ok parity bit 8 1 0111001 01110 three 1s odd parity error somewhere parity bits 2 10 incorrect 2 8 10 bit 10 must wrong hence correct error inverting bit 10 011100101 010 voila hamming stop single bit error correction code cost one bit make minimum hamming distance code b means correct single bit errors detect double bit errors e idea add parity bit calculated whole word lets use fourbit data word example would need 7 bits single bit error detection hamming parity bits h p1 p2 p3 computed even parity usual plus even parity entire word p4 1 2 3 4 5 6 7 8 p1 p2 d1 p3 d2 d3 d4 p4 en algorithm correct one error detect two calculate parity ecc groups h plus one whole group p 4 ere four cases 1 h even p 4 even error occurred 2 h odd p 4 odd correctable single error occurred p 4 calculate odd parity one error occurred 3 h even p 4 odd single error occurred p 4 bit rest word correct p 4 bit exampleanswer 55 dependable memory hierarchy 4234 h odd p 4 even double error occurred p 4 calculate even parity two errors occurred single error correcting double error detecting secded common memory servers today conveniently eight byte data blocks get secded one byte many dimms 72 bits wide elaboration calculate many bits needed sec let p total number parity bits number data bits p bit word p error correction bits point error bit p cases plus one case indicate error exists need 2p p 1 bits thus p logp 1for example 8 bits data means 8 2p p 8 1 p 4 similarly p 5 16 bits data 6 32 bits 7 64 bits elaboration large systems possibility multiple errors well complete failure single wide memor cant ibm introduced chipkill solve problem many large systems use technology intel calls version sddc similar nature raid approach used disks see section 511 chipkill distributes data ecc information complete failure single memory chip handled supporting reconstruction missing data remaining memory chips assuming 10000processor cluster 4 gib per processor ibm calculated following rates unrecoverable memory errors three years operation parity onlyabout 90000 one unrecoverable undetected failure every 17 minutes secded onlyabout 3500 one undetected unrecoverable failure every 75 hours chipkill6 one undetected unrecoverable failure every 2 months hence chipkill requirement warehousescale computers elaboration single double bit errors typical memory systems networks bursts bit errors one solution called cyclic redundancy check block k bits transmitter generates nk bit frame check sequence transmits n bits exactly divisible number receiver divides frame number remainder assumes error receiver rejects message asks transmitter send might guess chapter 3 easy calculate division binary numbers shift register made crc codes popular even hardware precious going even reed elds correct multibit transmission errors data cients polynomials code space values polynomial reedsolomon calculation considerably complicated binary division 424 chapter 5 large fast exploiting memory hierarchy 56 virtual machines virtual machines vm wer rst developed mid1960s remained important part mainframe computing years although largely ignored single user pc era 1980s 1990s recently gained popularity due e increasing importance isolation security modern systems e failures security reliability standard operating systems e sharing single computer among many unrelated users particular cloud computing e dramatic increases raw speed processors decades makes overhead vms acceptable e br nition vms includes basically emulation methods provide standard ware interface java vm section interested vms provide complete systemlevel environment binary instruction set architecture isa level although vms r erent isas vm native hardware assume always match hardware vms called operating system virtual machines ibm vm370 virtualbox vmware esx server xen examples system virtual machines present illusion users entire computer including copy operating system single computer runs multiple vms support number erent operating systems oses conventional platform single os owns hardware resources vm multiple oses share hardware resources e ware supports vms called virtual machine monitor vmm hypervisor vmm heart virtual machine technology e underlying hardware platform called host resources shared among guest e vmm determines map virtual resources physical resources physical resource may timeshared partitioned even emulated ware e vmm much smaller traditional os isolation portion vmm perhaps 10000 lines code although interest vms improving protection vms provide two b ts commerciall cant 1 managing ware vms provide abstraction run complete ware stack even including old operating systems like dos typical deployment might vms running legacy oses many running current stable os release testing next os release 2 managing hardware one reason multiple servers application running compatible version operating system separate computers separation improve dependability vms 56 virtual machines 425allow separate ware stacks run independently yet share hardware thereby consolidating number servers another example vmms support migration running vm erent computer either balance load evacuate failing hardware amazon web services aws uses virtual machines cloud computing ering ec2 fo reasons 1 allows aws protect users sharing server 2 simp es ware distribution within warehouse scale computer customer installs virtual machine image co gured appropriate ware aws distributes instances customer wants use 3 customers aws reliably kill vm control resource usage customers complete work 4 virtual machines hide identity hardware customer running means aws keep using old servers introduce new cient servers e customer expects performance instances match ratings ec2 compute units aw nes provide equivalent cpu capacity 1012 ghz 2007 amd opteron 2007 intel xeon processor anks moores law newer servers clearly er ec2 compute units older ones aws keep renting old servers long economical 5 virtual machine monitors control rate vm uses processor network disk space allows aws er many price points instances erent types running underlying servers example 2012 aws ered 14 instance types small standard instances 008 per hour high io quadruple extra large instances 310 per hour general cost processor virtualization depends workload user level processorbound programs zero virtualization overhead os rarely invoked everything runs native speeds iointensive workloads generally also osintensive executing many system calls privileged instructions result high virtualization overhead hand iointensive workload also iobound cost processor virtualization completely hidden since processor en idle waiting io e overhead determined number instructions must emulated vmm much time takes emulate hence guest vms run isa host assume goal hardware software interface 426 chapter 5 large fast exploiting memory hierarchy architecture vmm run almost instructions directly native hardware requirements virtual machine monitor must vm monitor presents ware interface guest ware must isolate state guests must protect guest ware including guest os e qualitative requirements guest ware behave vm exactly running native hardware except performancerelated behavior limitations xed resources shared multiple vms guest ware able change allocation real system resources directly virtualize processor vmm must control everythingaccess privileged state io exceptions interruptseven though guest vm os currently running temporarily using example case timer interrupt vmm would suspend currently running guest vm save state handle interrupt determine guest vm run next load state guest vms rely timer interrupt provided virtual timer emulated timer interrupt vmmto charge vmm must higher privilege level guest vm generally runs user mode also ensures execution privileged instruction handled th e basic requirements system virtual least two processor modes system user privileged subset instructions available system mode resulting trap executed user mode system resources must controllable via instructions lack instruction set architecture support virtual machinesif vms planned design isa relatively easy reduce number instructions must executed vmm improve emulation speed architecture allows vm execute directly hardware earns title virtualizable ibm 370 architecture proudly bears label alas since vms considered pc server applications fairly recently instruction sets created without virtualization mind ese culprits include x86 risc architectures including armv7 mips 57 virtual memory 427because vmm must ensure guest system interacts virtual resources conventional guest os runs user mode program top en guest os attempts access modify information related hardware resources via privileged instructionfor example reading writing status bit enables interruptsit trap th e vmm ect appropriate changes corresponding real resources hence instruction tries read write sensitive information traps executed user mode vmm intercept support virtual version sensitive information guest os expects absence support measures must taken vmm must take special precautions locate problematic instructions ensure behave correctly executed guest os thereby increasing complexity vmm reducing performance running vm protection instruction set architecture protection join ort architecture operating systems architects modify awkward details existing instruction set architectures virtual memory became popular example x86 instruction popf loads th ag registers top stack memory one th ags interrupt enable ag run popf instruction user mode rather trap simply changes ags except ie system mode change ie since guest os runs user mode inside vm problem expects see changed ie historically ibm mainframe hardware vmm took three steps improve performance virtual machines 1 reduce cost processor virtualization 2 reduce interrupt overhead cost due virtualization 3 reduce interrupt cost steering interrupts proper vm without invoking vmm amd intel tried address th rst point 2006 reducing cost processor virtualization interesting see many generations architecture vmm mo cations take address three points long virtual machines 21st century b cient ibm mainframes vmms 1970s 57 virtual memory earlier sections saw caches provided fast access recently used portions programs code data similarly main memory act cache system devised make core drum combination appear programmer single level store requisite transfers taking place automatically kilburn et al onelevel storage system 1962 428 chapter 5 large fast exploiting memory hierarchy secondary storage usually im plemented wit technique called virtual memory historically two major motivations virtual memory allow cient safe sharing memory among multiple programs memory needed multiple virtual machines cloud computing remove programming burdens small limited amount main memory five decades er invention former reason reigns today course allow multiple virtual machines share memory must able protect virtual machines ensuring program read write portions main memory assigned main memory need contain active portions many virtual machines cache contains active portion one program us principle locality enables virtual memory well caches virtual memory allows us ciently share processor well main memory know virtual machines share memory virtual machines compile fact virtual machines sharing memory change dynamically virtual machines running dynamic interaction would like compile program address space separate range memory locations accessible program virtual memory implements translation programs address space physical addresses translation process enforces protection programs address space virtual machines e second motivation virtual memory allow single user program exceed size primary memory formerly program became large memory programmer make programmers divided programs pieces iden ed pieces mutually exclusive ese overlays loaded unloaded user program control execution programmer ensuring program never tried access overlay loaded overlays loaded never exceeded total size memory overlays traditionally organized modules containing code data calls procedur erent modules would lead overlaying one module another well imagine responsibility substantial burden programmers virtual memory invented relieve programmers th culty automatically manages two levels memory hierarchy represented main memory sometimes called physical memory distinguish virtual memory secondary storage although concepts work virtual memory caches th ering historical roots led use erent terminology virtual memory block called page virtual memory miss called page fault virtual memory processor produces virtual address translated combination hardware ware physical address turn used access main memory figure 525 shows virtually addressed memory pages mapped main memory process called address mapping virtual memory technique uses main memory cache secondary storage physical address address main memory protection set mechanisms ensuring multiple processes sharing processor memory io devices interfere intentionally unintentionally one another reading writing others data ese mechanisms also isolate operating system user process page fault event occurs accessed page present main memory virtual address address corresponds location virtual space translated address mapping physical address memory accessed 57 virtual memory 429address translation today two memory hierarchy levels controlled virtual memory usually drams ash memory personal mobile devices drams magnetic disks servers see section 52 return library analogy think virtual address title book physical address location book library might given library congress call number virtual memory also simp es loading program execution providing relocation relocation maps virtual addresses used program erent physical addresses addresses used access memory relocation allows us load program anywhere main memory furthermore virtual memory systems use today relocate program set xedsize blocks pages thereby eliminating need nd contiguous block memory allocate program instead operating system need onl cient number pages main memory virtual memory address broken virtual page number page set figure 526 shows translation virtual page number physical page number e physical page number constitutes upper portion physical address page set changed constitutes lower portio e number bits page eld determines page size e number pages addressable virtual address need match number pages addressable physical address larger number virtual pages physical pages basis illusion essentially unbounded amount virtual memory address translation also called address mapping e process virtual address mapped address used access memory virtual addressesphysical addressesaddress translationdisk addressesfigure 525 virtual memory blocks memory called pages mapped one set addresses called virtual addresses another set called physical addresses e processor generates virtual addresses memory accessed using physical addresses virtual memory physical memory broken pages virtual page mapped physical page course also possible virtual page absent main memory mapped physical address case page resides disk physical pages shared two virtual addresses point physical addr capability used allow tw erent programs share data code 430 chapter 5 large fast exploiting memory hierarchy many design choices virtual memory systems motivated high cost page fault page fault disk take millions clock cycles process e table page 378 shows main memory latency 100000 times quicker tha enormous miss penalty dominated time get rst word typical page sizes leads several key decisions designing virtual memory systems pages large enough try amortize high access time sizes 4 kib 16 kib typical today new desktop server systems developed support 32 kib 64 kib pages new embedded systems going direction 1 kib pages organizations reduce page fault rate attractive e primary technique used allow fully associative placement pages memory page faults handled ware overhead small compared disk access time addition ware ord use clever algorithms choosing place pages even small reductions miss rate pay cost algorithms writethrough work virtual memory since writes take long instead virtual memory systems use writeback virtual page numberpage offset31 30 29 28 273 2 1 015 14 13 12 11 10 9 8physical page numberpage offset29 28 273 2 1 015 14 13 12 11 10 9 8virtual addressphysical addresstranslationfigure 526 mapping virtual physical address e page size 2 12 4 kib e number physical pages allowed memory 2 18 since physical page number 18 bits us main memory 1 gib virtual address space 4 gib 57 virtual memory 431 e next subsections address factors virtual memory design elaboration present motivation virtual memory many virtual machines sharing memory virtual memory originally invented many programs could share computer part timesharing system since many readers today experience timesharing systems use virtual machines motivate sectionelaboration servers even pcs 32bit address processors problematic although normally think virtual addresses much larger physical addresses opposite occur processor address size small relative state memory technology single program vir collection programs virtual machines r swapped memory running parallel processors elaboration discussion virtual memory book focuses paging xedsize blocks also variablesize block scheme called segmentation segmentation address consists two parts segment number segment offset segment number mapped physical address offset added nd actual physical address segment vary size bounds check also needed make sure offset within segment major use segmentation support powerful methods protection sharing address space operating system textbooks contain extensive discussions segmentation compared paging use segmentation logically share address space major disadvantage segmentation splits address space logically separate pieces must manipulated twopart address segment number offset paging contrast makes boundary page number offset invisible programmers compilers segments also used method extend address space without changing word size computer attempts unsuccessful awkwardness performance penalties inherent twopart address programmers compilers must aware man xedsize blocks simplify protection betw ciency implementing paging although divisions often called segments mechanism much simpler variable block size segmentation visible user programs discuss detail shortly placing page finding incredibly high penalty fo r page fault designers reduce page fault frequency optimizing page placement allow virtual page mapped physical page operating system choose replace page wants page fault occurs example operating system use segmentation variablesize address mapping scheme address consists two parts segment number mapped physical address segment set 432 chapter 5 large fast exploiting memory hierarchy sophisticated algorithm complex data structures track page usage try choose page needed long time e ability use clever exible replacement scheme reduces page fault rate simp es use fully associative placement pages mentioned section 54 th culty using fully associative placement locating entry since anywhere upper level hierarchy full search impractical virtual memory systems locate pages using table indexes memory structure called page table resides memory page table indexed page number virtual address discover corresponding physical page number program page table maps virtual address space program main memory library analogy page table corresponds mapping book titles library locations card catalog may contain entries books another library campus rather local branch library see page table may contain entries pages present memory indicate location page table memory hardware includes register points start page table call page table register assume page tab xed contiguous area memory e page table together program counter registers sp es state virtual machine want allow another virtual machine use processor must save state later er restoring state virtual machine continue execution en refer state process e process considered active possession processor otherwise considered inactive e operating system make process active loading processs state including program counter initiate execution value saved program counter e processs address space hence data access memory ned page table resides memory rather save entire page table operating system simply loads page table register point page table process wants make active process page table erent processes use virtual address e operating system responsible allocating physical memory updating page tables virtual address spaces erent processes collide see shortly use separate page tables also provides protection one process another page table e table containing virtual physical address translations virtual memory syst e table stored memory typically indexed virtual page number entry table contains physical page number virtual page page currently memory hardware software interface 57 virtual memory 433figure 527 uses page table register virtual address indicated page table show hardware form physical address valid bit used page table entry cache bit page present main memory page fault occurs bit page memory entry contains physical page number page table contains mapping every possible virtual page tags required cache terminology index used access page table consists full block address virtual page number virtual page numberpage offset31 30 29 28 273 2 1 015 14 13 12 11 10 9 8physical page numberpage offset29 28 273 2 1 015 14 13 12 11 10 9 8virtual addressphysical addresspage table registerphysical page numbervalidpage tableif 0 page notpresent memory201218figure 527 page table indexed virtual page number obtain corresponding portion physical address assume 32bit addr e page table pointer gives starting address page table gure page size 2 12 bytes 4 kib e virtual address space 2 32 bytes 4 gib physical address space 2 30 bytes allows main memory 1 gib e number entries page table 2 20 1 million entr e valid bit entry indicates whether mapping legal page present memory although page table entry shown need 19 bits wide would typically rounded 32 bits ease indexin e extra bits would used store additional information needs kept perpage basis protection 434 chapter 5 large fast exploiting memory hierarchy page faults valid bit virtual page page fault occur e operating system must given control transfer done exception mechanism saw chapter 4 discuss later section operating system gets control mu nd page next level hierarchy usually ash memory magnetic disk de cide place requested page main memory e virtual address alone immediately tell us page disk returning library analogy canno nd location library book shelves knowing title instead go catalog look book obtaining address location shelves library congress call number likewise virtual memory system must keep track location disk page virtual address space know ahead time page memory replaced operating system usually creates space ash memory disk pages process creates pro space called swap space time also creates data structure record virtual page stored data structure may part page table may auxiliary data structure indexed way page table figure 528 shows organization single table holds either physical page number disk address e operating system also creates data structure tracks processes virtual addresses use physical page page fault occurs pages main memory use operating system must choose page replace want minimize number page faults operating systems try choose page hypothesize needed near future using past predict future operating systems follow least recently used lru replacement scheme mentioned section e operating system searches le ast recently used page assuming page used long time less likely needed recently accessed page e replaced pages written swap space disk case wondering operating system another process tables controlling memory memory details seeming contradiction explained shortly swap space e space disk reserved full virtual memory space process 57 virtual memory 435implementing completely accurate lru scheme expensive since requires updating data structure every memory reference stead operating systems approximate lru keeping track pages pages recently used help operating system estimate lru pages computers provide reference bit use bit set whenever page accessed e operating system periodically clears reference bits later records determine pages touched particular time period usage information operating system select page among least recently referenced detected reference bit bit provided hardware operating system mu nd another way estimate pages accessed hardware software interfacereference bit also called use bit eld set whenever page accessed used implement lru replacement schemes page tablephysical page ordisk addressphysical memoryvirtual pagenumberdisk storage111101 11 1100validfigure 528 page table maps page virtual memory either page main memory page stored disk next level hierarchy e virtual page number used index page table valid bit page table supplies physical page number ie starting address page memory corr esponding virtual page valid bit page currently resides disk sp ed disk address many syste ms table physical page addresses disk page addresses logically one tabl e stored two separate data structures dual tables ju ed part must keep disk addresses pages even currently main memory remember pages main memory pages disk size 436 chapter 5 large fast exploiting memory hierarchy elaboration 32bit virtual address 4 kib pages 4 bytes per page table entry compute total page table size number page table entries223220212size page table2 page table entries2 bytes page tabl 202e e entry 4 mibthat would need use 4 mib memory program execution time amount bad single process hundreds processes running page table handle 64bit addresses calculation would need 2 52 wordsa range techniques used reduce amount storage required page techniques aim reducing total maximum storage required well minimizing main memory dedicated page tables 1 simplest technique keep limit register restricts size page table given process virtual page number becomes larger contents limit register entries must added page table technique allows page table grow process consumes space thus page table large process using many pages virtual address space technique requires address space expand one direction 2 cient since languages require two areas whose size expandable one area holds stack area holds heap duality convenient divide page table let grow highest address well lowest address means two separate page tables two separate limits use two page tables breaks address space two segments highorder bit address usually determines segment thus es segment segment large onehalf address space es current size segment grows units pages type segmentation used many architectures including mips unlike type segmentation discussed third elaboration page 431 form segmentation invisible application program although operating system major disadvantage scheme work well address space used sparse fashion rather contiguous set virtual addresses 3 another approach reducing page table size apply hashing function virtual address page table need size number physical pages main memory structure called inverted page table course lookup process slightly complex inverted page table longer index page table 4 multiple levels page tables also used reduce total amount rst le xedsize blocks virtual address space perhaps 64 256 pages total large blocks sometimes called segments rstlevel mapping table sometimes called 57 virtual memory 437segment table though segments invisible user entry segment table indicates whether pages segment allocated points page table segment address translation happens b rst looking segment table using highestorder bits address segment address valid next set highorder bits used index page table indicated segment table entry scheme allows address space used sparse fashion multiple noncontiguous segments active without allocate entire page table schemes particularly useful large address spaces software systems require noncontiguous allocation primary disadvantage twolevel mapping complex process address translation5 reduce actual main memory tied page tables modern systems also allow page tables paged although sounds tricky works using basic ideas virtual memory simply allowing page tables reside virtual address space addition small critical problems neverending series page faults must avoided problems overcome detailed typically c brief problems avoided placing page tables address space operating system placing least page tables operating system portion main memory physically addressed always present thus never disk writes e erence access time cache main memory tens hundreds cycles writethrough schemes used although need write bu er hide latency write processor virtual memory system writes next level hierarchy disk take millions processor clock cycles therefore building write bu er allow system writethrough disk would completely impractical instead virtual memory systems must use writeback performing individual writes page memory copying page back disk replaced memory writeback scheme another major advantage virtual memory system disk transfer time small compared access time copying back entire page much e cient writing individual words back disk writeback operation although cient transferring individual words still costly us would like know whether page needs copied back choose replace track whether page written since read memory dirty bit added page table e dirty bit set word page written operating system chooses replace page dirty bit indicates whether page needs written location memory given another page hence mo ed page en called dirty page hardware software interface 438 chapter 5 large fast exploiting memory hierarchy making address translation fast tlb since page tables stored main memory every memory access program take least twice long one memory access obtain physical address second access get dat e key improving access performance rely locality reference page table translation virtual page number used probably needed near future references words page temporal spatial locality accordingly modern processors include special cache keeps track recently used translation special address translation cache traditionally referred translationlookaside bu er tlb although would accurate call translation cache e tlb corresponds little piece paper typically use record location set books look card catalog rather continually searching entire catalog record location several books use scrap paper cache library congress call numbers figure 529 shows tag entry tlb holds portion virtual page number data entry tlb holds physical page number translationlookaside bu er tlb cache keeps track recently used address mappings try avoid access page table 11 1 1 0 1 11110000 0 0 0 0 01110010 0 1 0 1 111100physical pageor disk addressvaliddirtyref page tablephysical memoryvirtual pagenumberdisk storage1111010110001 1 1 1 0 1physical pageaddressvaliddirtyref tlbtagfigure 529 tlb acts cache page table entries map physical pages e tlb contains subset virtualtophysical page mappings page table e tlb mappings shown color tlb cache must ta eld matching entry tlb page page table must examined e page table either supplies physical page number page us ed build tlb entry indicates page resides disk case page fault occurs since th e page table entry every virtual page ta eld needed words unlike tlb page table cache 57 virtual memory 439because access tlb instead page table every reference tlb need include status bits dirty reference bits every reference look virtual page number tlb get hit physical page number used form address corresponding reference bit turned processor performing write dirty bit also turned miss tlb occurs must determine whether page fault merely tlb miss page exis ts memory tlb miss indicates translation missing cases processor handle tlb miss loading translation page table tlb trying reference page present memory tlb miss indicates true page fault case proces sor invokes operating system using exception tlb many fewer entries number pages main memory tlb misses much frequent true page faults tlb misses handled either hardware ware practice care little performa erence two approaches basic operations either case er tlb miss occurs missing translation retrieved page table need select tlb entry replace reference dirty bits contained tlb entry need copy bits back page table entry replace entry ese bits portion tlb entry changed using writebackthat copying entries back miss time rather writtenis ver cient since expect tlb miss rate small systems use techniques approximate reference dirty bits eliminating need write tlb except load new table entry miss typical values tlb might tlb size 16512 entries block size 12 page table entries typically 48 bytes hit time 051 clock cycle miss penalty 10100 clock cycles miss rate 0011 designers used wide variety associativities tlbs systems use small fully associative tlbs fully associative mapping lower miss rate furthermore since tlb small cost fully associative mapping high systems use large tlbs en small associativity fully associative mapping choosing entry replace becomes tricky since implementing hardware lru scheme expensive furthermore since tlb misses much frequent page faults thus must handled cheaply ord expensive ware algorithm page faults result many systems provide support randomly choosing entry replace well examine replacement schemes little detail section 58 440 chapter 5 large fast exploiting memory hierarchy intrinsity fastmath tlb see ideas real processor lets take closer look tlb intrinsity fastma e memory system uses 4 kib pages 32bit address space thus virtual page number 20 bits long top figure 530 e physical address size virtual addr e tlb contains 16 entries fully associative shared instruction data references entry 64 bits wide contains 20bit tag virtual page number tlb entry corresponding physical page number also 20 bits valid bit dirty bit bookkeeping bits like mips systems uses ware handle tlb misses figure 530 shows tlb one caches figure 531 shows steps processing read write request tlb miss occurs mips hardware saves page number reference special register generates exceptio e exception invokes operating system handles miss ware nd physical address mi ssing page tlb miss routine indexes page table using page nu mber virtual address page table register indicates starting address active process page table using special set system instructions update tlb operating system places physical address page table tlb tlb miss takes 13 clock cycles assuming code page table entry instruction cache data cache respectively see mips tlb code page 449 true page fault occurs page table entry valid physical addr e hardware maintains index indicates recommended entry replace recommended entry chosen randomly ere extra complication write requests namely write access bit tlb must checked bit prevents program writing pages read access program attempts write write access bit exception generated e write access bit forms part protection mechanism discuss shortly integrating virtual memory tlbs caches virtual memory cache systems work together hierarchy data cache unless present main memory e operating system helps maintain hierarchy ushing contents page cache decides migrate page disk time os mo es page tables tlb attempt access data migrated page generate page fault best circumstances virtual address translated tlb sent cache appropriate data found retrieved sent back processor worst case reference miss three components memory hierarchy tlb page table cache e following example illustrates interactions detail 57 virtual memory 44120virtual page numberpage offsettagvaliddirty tlbphysical page numbertagvalidtlb hitcache hitdatadatabyteoffsetphysical page numberpage offsetphysical address tagcache index1220blockoffsetphysical address1832842128cache31 30 293 2 1 014 13 12 11 10 9virtual addressfigure 530 tlb cache implement process going virtual address data item intrinsity fastmath gure shows organization tlb data cache assuming 4 kib page size diagram focuses read figure 531 describes handle writes note unlike figure 512 tag data rams split addressing lo ng narrow data ram cache index concatenated block set select desired word block without 161 multiplexor cache direct mapped tlb fully associative implementing fully associative tlb requires every tlb tag c ompared virtual page number since entry interest anywhere tlb see content addressable memories elaboration page 408 valid bit matching entry access tlb hit bits physical page number togeth er bits page set form index used access cache 442 chapter 5 large fast exploiting memory hierarchy yes write access bit onnoyes cache hitnowrite data cache update dirty bit put data theaddress write buffer yes tlb hitvirtual address tlb accesstry read data cachenoyes write nocache miss stallwhile read block deliver data cpuwrite protection exception yes cache hitnotry write data cachecache miss stallwhile read block tlb missexception physical address figure 531 processing read writethrough intrinsity fastmath tlb cache tlb generates hit cache accessed resulting physical address read cache generates hit miss supplies ata causes stall data brought memory operation write portion cache entry overwritten hit data sent write bu er assume writethrough write miss like read miss except block mo ed er read memory writeback requires writes set dirty bit cache block write bu er loaded whole block read miss write miss block replaced dirty notice tlb hit cache hit independent events cache hit ly occur er tlb hit occurs means data must present memory e relationship tlb misses cache misses examined following example exercises end chapter 57 virtual memory 443overall operation memory hierarchy memory hierarchy like figure 530 includes tlb cache organized shown memory reference encounter thre erent types misses tlb miss page fault cache miss consider combinations three events one occurring seven possibilities possibility state whether event actually occur circumstances figure 532 shows combinations whether possible practice elaboration figure 532 assumes memory addresses translated physical addresses cache accessed organization cache physically indexed physically tagged cache index tag physical rather virtual addresses system amount time access memory assuming cache hit must accommodate tlb access cache access course accesses pipelinedalternatively processor index cache address completely partially virtual called virtually addressed cache uses tags virtual addresses hence cache virtually indexed virtually tagged caches address translation hardware tlb unused normal cache access since cache accessed virtual address translated physical address takes tlb critical path reducing cache latency cache miss occurs however processor needs translate address physical address fetch cache block main memory exampleanswervirtually addressed cache cache accessed virtual address rather physical address tlbpage tablecache possible circumstance hithitmisspossible although page table never really checked tlb hits misshithittlb misses entry found page table retry data found cache misshitmisstlb misses entry found page table retry data misses cache missmissmisstlb misses followed page fault retry data must miss cache hitmissmissimpossible translation tlb page present memory hitmisshitimpossible translation tlb page present memory missmisshitimpossible data allowed cache page memory figure 532 possible combinations events tlb virtual memory system cache ree combinations impossible one possible tlb hit virtual memory hit cache miss never detected 444 chapter 5 large fast exploiting memory hierarchy cache accessed virtual address pages shared processes may access different virtual addresses possibility aliasing aliasing occurs object two namesin case two virtual addresses page ambiguity creates problem word page may cached two different locations corresponding different virtual addresses ambiguity would allow one program write data without program aware data changed completely virtually addressed caches either introduce design limitations cache tlb reduce aliases require operating system possibly user take steps ensure aliases occur common compromise two design points caches virtually indexedsometimes using pageoffset portion address really physical address since translatedbut use physical tags designs virtually indexed physically tagged attempt achieve performance advantages virtually indexed caches architecturally simpler advantages physically addressed cache example alias problem case figure 530 assumed 4 kib page size really 16 kib intrinsity fastmath use trick pull must careful coordination minimum page size cache size associativity implementing protection virtual memory perhaps important function virtual memory today allow sharing single main memory multiple processes providing memory protection among processes operating syst e protection mechanism must ensure although multiple processes sharing main memory one renegade process write addres space another user process operating system either intentionally unintentionally e write access bit tlb protect page written without level protection computer viruses would even widespread enable operating system implement protection virtual memory system hardware must provide leas three basic capabilities summarized note th rst two requirements needed virtual machines section 56 1 support least two modes indicate whether running process user process operating system process variously called supervisor process kernel process executive process 2 provide portion processor state user process read write includes usersupervisor mode bit dictates whether processor user supervisor mode page table pointer aliasing situation two addresses access object occur virtual memory two virtual addresses physical page physically addressed cache cache addressed physical address hardware software interfacesupervisor mode also called kernel mode mode indicating running process operating system process 57 virtual memory 445tlb write elements operating system uses special instructions available supervisor mode 3 provide mechanisms whereby processor go user mode supervisor mode vice vers e rst direction typically accomplished system call exception implemented special instruction syscall mips instruction set transfers control dedicated location supervisor code space exception program counter point system call saved exception pc epc processor placed supervisor mode return user mode exception use return exception eret instruction resets user mode jumps address epc using mechanisms storing page tables operating systems address space operating system change page tables preventing user process changing ensuring user process access storage provided operating system also want prevent process reading data another process example wouldnt want student program read grades processors memory begin sharing main memory must provide ability process protect data reading writing another process otherwise sharing main memory mixed blessing remember process virtual address space us operating system keeps page tables organized independent virtual pages map disjoint physical pages one pr ocess able access anothers data course also requires user process unable change page table mappin e operating system assure safety prevents user process modifying page tables however operating system must able modify page tables placing page tables protected address space operating system sa es requirements processes want share information limited way operating system must assist since accessing infor mation another process requires changing page table accessing pro e write access bit used restrict sharing read sharing like rest page table bit changed operating system allow another process say p1 read page owned process p2 p2 would ask operating system create page table entry virtual page p1s address space points physical page p2 wants share e operating system could use write protection bit prevent p1 writing data p2s wish bits determine access rights page mu st included page table tlb page table accessed tlb miss system call special instruction transfers control user mode dedicated location supervisor code space invoking exception mechanism process 446 chapter 5 large fast exploiting memory hierarchy elaboration operating system decides change running process p1 running process p2 called context switch process switch must ensure p2 get access page tables p1 would compromise protection tlb ces change page table register point p2 page table rather p1s tlb must clear tlb entries belong p1both protect data p1 force tlb load entries p2 process switch rate high cient example p2 might load tlb entries operating system switched back p1 unfortunately nd tlb entries gone would pay tlb misses reload problem arises virtual addresses used p1 p2 must clear tlb avoid confusing addresses common alternative extend virtual address space adding process identiﬁ er task identiﬁ er intrinsity fastmath 8bit address space id asid eld pur es currently running process kept register loaded operating system switches processes process er concatenated tag portion tlb tlb hit occurs page number er match combination eliminates need clear tlb except rare occasions similar problems occur cache since process switch cache contain data running process problems arise different ways physically addressed virtually addressed caches variety different solutions ers used ensure process gets data handling tlb misses page faults although translation virtual physical addresses tlb straightforward get tlb hit saw earlier handling tlb misses page faults complex tlb miss occurs entry tlb matches virtual address recall tlb miss indicate one two possibilities e page present memory need create missing tlb entry e page present memory need transfer control operating system deal page fault mips traditionally handles tlb miss ware brings page table entry memory reexecutes instruction caused tlb miss upon reexecuting get tlb hit page table entry indicates page memory time get page fault exception handling tlb miss page fault requires using exception mechanism interrupt active process transferring control operating system later resuming execution interrupted process page fault recognized sometime clock cycle used access memory restart instruction er page fault handled program counter instruction caused page fault must saved chapter 4 exception program counter epc used hold value context switch changing internal state processor allow erent process use processor includes saving state needed return currently executing process 57 virtual memory 447in addition tlb miss page fault exception must asserted end clock cycle memory access occurs next clock cycle begin exception processing rather continue normal instruction execution page fault recognized clock cycle load instruction could overwrite register could disastrous try restart instruction example consider instruction lw 101 computer must able prevent write pipeline stage occurring otherwise could properly restart instruction since contents 1 would destroyed similar complication arises stores must prevent write memory actually completing page fault usually done deasserting write control line memory time begin executing exception handler operating system time operating system saved state process operating system particularly vulnerable example another exception occurred processing th rst exception operating system control unit would overwrite exception program counter making impossible return instruction caused page fault avoid disaster providing ability disable enable exceptions exceptio rst occurs processor sets bit disables exceptions could happen time processor sets supervisor mode bi e operating system save enough state allow recover another exception occurs namely exception program counter epc cause registers epc cause two special control registers help exceptions tlb misses page faults figure 533 shows r e operating system reenable exception ese steps make sure exceptions cause processor lose state thereby unable restart execution interrupting instruction operating system knows virtual address caused page fault must complete three steps 1 look page table entry using virtual address nd location referenced page disk 2 choose physical page replace chosen page dirty must written disk bring new virtual page physical page 3 start read bring referenced page disk chosen physical page hardware software interfaceexception enable also called interrupt enable signal action controls whether process responds exception necessary preventing occurrence exceptions intervals processor safely saved state needed restart 448 chapter 5 large fast exploiting memory hierarchy course last step take millions processor clock cycles second replaced page dirty accordingly operating system usually select another process execute th e processor disk access completes operating system saved state process freely give control processor another process read page disk complete operating system restore state process originally caused page fault execute instruction returns exceptio instruction reset processor kernel user mode well restore program counter e user process reexecutes instruction faulted accesses requested page successfully continues execution page fault exceptions data accesses ar cult implement properly processor combination three characteristics ey occur middle instructio ns unlike instruction page faults e instruction completed handling exception er handling exception instruction must restarted nothing occurred making instructions restartable exception handled instruction later continued relatively easy architecture like mips instruction writes one data item write occurs end instruction cycle simply prevent instruction completing writing restart instruction beginning lets look detail mips tlb miss occurs mips hardware saves page number reference special register called badvaddr generates exception restartable instruction instruction resume execution er exception resolved without exceptions ecting result instruction registercp0 register number descriptionepc14where restart exception cause13cause exceptionbadvaddr 8address caused exceptionindex0location tlb read writtenrandom1pseudorandom location tlbentrylo 2physical page address ßags entryhi 10virtual page address context4page table address page number figure 533 mips control registers ese considered coprocessor 0 hence read using mfc0 written using mtc0 57 virtual memory 449 e exception invokes operating system handles miss ware control transferred address 8000 0000 hex location tlb miss handler nd physical address missin g page tlb miss routine indexes page table using page number vi rtual address page table register indicates starting address active process page table make indexing fast mips hardware places everything need special context register upper 12 bits address base page table next 18 bits virtual address missing page page table entry one word last 2 bits ar us th rst two instructions copy context register kernel temporary register k1 load page table entry address k1 recall k0 k1 reserved operating system use without saving major reason convention make tlb miss handler fast mips code typical tlb miss handler tlbmissmfc0 k1context copy address pte temp k1 lw k10k1 put pte temp k1 mtc0 k1entrylo put pte special register entrylotlbwr put entrylo tlb entry randomeret return tlb miss exceptionas shown mips special set system instructions update tlb e instruction tlbwr copies control register entrylo tlb entry selected control register random random implements random replacement basically freerunning counter tlb miss takes dozen clock cycles note tlb miss handler check see page table entry valid exception tlb entry missing much frequent page fault operating system loads tlb page table without examining entry restarts instruction entry invalid another erent exception occurs operating system recognizes page fault method makes frequent case tlb miss fast slight performance penalty infrequent case page fault process generated page fault interrupted transfers control 8000 0180 hex erent address tlb miss handler general address exception tlb miss special entry point lower penalty fo e operating system uses exception cause register diagnose cause exception exception page fault operating system knows extensive processing required us unlike tlb miss saves entire state active pro state includes generalpurpose oatingpoint registers page table address register epc exception cause register since exception handlers usually use th oatingpoint registers general entry point save leaving handlers need handler name ware routine invoked handle exception interrupt 450 chapter 5 large fast exploiting memory hierarchy figure 534 sketches mips code exception handler note save restore state mips code taking care enable disable exceptions invoke c code handle particular exception e virtual address caused fault depends whether fault instruction data faul e address instruction generated fault epc instruction page fault epc contains virtual address faulting page otherwise faulting virtual address computed examining instruction whose address epc nd base register set eldelaboration ed version assumes stack pointer sp valid avoid problem page fault lowlevel exception code mips sets aside portion address space page faults called unmapped operating system places exception entry point code exception stack unmapped memory mips hardware translates virtual addresses 8000 0000 hex bfff ffffhex physical addresses simply ignoring upper bits virtual address thereby placing addresses low part physical memory thus operating system places exception entry points exception stacks unmapped memory elaboration code figure 534 shows mips32 exception return sequence older mipsi architecture uses rfe jr instead eretelaboration processors complex instructions touch many memory locations write many data items making instructions restartable much harder processing one instruction may generate number page faults middle instruction example x86 processors block move instructions touch thousands data words processors instructions often restarted beginning mips instructions instead instruction must interrupted later continued midstream execution resuming instruction middle execution usually requires saving special state processing exception restoring special state making work properly requires careful detailed coordination exceptionhandling code operating system hardware elaboration rather pay extra level indirection every memory access vmm maintains shadow page table maps directly guest virtual address space physical address space hardw cations guests page table vmm ensure shadow page table entries used hardware translations correspond guest os environment exception correct physical pages substituted real pages guest tables hence vmm must trap attempt guest os change page table access page table pointer commonly done write protecting guest page tables trapping access page table pointer guest os noted latter happens naturally accessing page table pointer privileged operationunmapped portion address space page faults 57 virtual memory 451save statesave gpr addi k1sp xcpsize save space stack state sw sp xct_spk1 save sp stack sw v0 xct_v0k1 save v0 stack save v1 ai si ti stack sw ra xct_rak1 save ra stack save hi lo mfhi v0 copy hi mßo v1 copy lo sw v0 xct_hik1 save hi value stack sw v1 xct_lok1 save lo value stack save exception registers mfc0 a0 cr copy cause register sw a0 xct_crk1 save cr value stack save v1 mfc0 a3 sr copy status register sw a3 xct_srk1 save sr stack set sp move sp k1 sp sp xcpsizeenable nested exceptions andi v0 a3 mask1 v0 sr mask1 enable exceptions mtc0 v0 sr sr value enables exceptions call c exception handlerset gp move gp gpinit set gp point heap area call c code move a0 sp arg1 pointer exception stack jal xcpt_deliver call c code handle exception restoring staterestore gpr hi lo move sp temporary value sp lw ra xct_raat restore ra stack restore t0 a1 lw a0 xct_a0k1 restore a0 stack restore status register lw v0 xct_srat load old sr stack li v1 mask2 mask disable exceptions v0 v0 v1 v0 sr mask2 disable exceptions mtc0 v0 sr set status register exception return restore sp rest gpr used temporary registers lw sp xct_spat restore sp stack lw v0 xct_v0at restore v0 stack lw v1 xct_v1at restore v1 stack lw k1 xct_epcat copy old epc stack lw xct_atat restore stack restore erc return mtc0 k1 epc restore epc eret ra return interrupted instruction figure 534 mips code save restore state exception 452 chapter 5 large fast exploiting memory hierarchy elaboration nal portion architecture virtualize io far cult part system virtualization increasing number io devices attached computer increasing diversity io device types culty sharing real device among multiple vms yet another comes supporting myriad device drivers required especially different guest oses supported vm system vm illusion maintained giving vm generic versions type io device driver leaving vmm handle real io elaboration addition virtualizing instruction set virtual machine another challenge virtualization virtual memory guest os every virtual machine manages set page tables make work vmm separates notions real physical memory often treated synonymously makes real memory separate intermediate level virtual memory physical memory use terms virtual memory physical memory machine memory name three levels guest os maps virtual memory real memory via page tables vmm page tables map guest real memory physical memory virtual memor ed either via page tables ibm vm370 x86 via tlb structure mips summary virtual memory name level memory hierarchy manages caching main memory secondary memory virtual memory allows single program expand address space beyond limits main memory importantly virtual memory supports sharing main memory among multiple simultaneously active processes protected manner managing memory hierarchy main memory disk challenging high cost page faults several techniques used reduce miss rate 1 pages made large take advantage spatial locality reduce miss rate e mapping virtual addresses physical addresses implemented page table made fully associative virtual page placed anywhere main memory e operating system uses techniques lru reference bit choose pages replace 57 virtual memory 453writes secondary memory expensive virtual memory uses writeback scheme also tracks whether page unchanged using dirty bit avoid writing unchanged pages e virtual memory mechanism provides address translation virtual address used program physical address space used accessing memory address translation allows protected sharing main memory provides several additional ts simplifying memory allocation ensuring processes protected requires operating system change address translations implemented preventing user programs changing page tables controlled sharing pages among processes implemented help operating system access bits page table indicate whether user program read write access page processor access page table resident memory translate every access virtual memory would expensive caches would pointless instead tlb acts cache translations page table addresses translated virtual physical using translations tlb caches virtual memory tlbs rely common set principles po e next section discusses common framework although virtual memory invented enable small memory act large one performa erence secondary memory main memory means program routinely accesses virtual memory physical memory run slowly program would continuously swapping pages memory disk called thrashing rashing disaster occurs rare program thrashes easiest solution run computer memory buy memory computer complex choice reexamine algorithm data structures see change locality thereby reduce number pages program uses simultaneously set popular pages informally called working set common performance problem tlb misses since tlb might handle 3264 page entries time program could easily see high tlb miss rate processor may access less quarter mebibyte directly 64 4 kib 025 mib example tlb misses en challenge radix sort try alleviate problem computer architectures support variable page sizes example addition standard 4 kib page mips hardware supports 16 kib 64 kib 256 kib 1 mib 4 mib 16 mib 64 mib 256 mib pages hence program uses large page sizes access memory directly without tlb misses e practical challenge getting operating system allow programs select larger page sizes complex solution reducing understanding program performance 454 chapter 5 large fast exploiting memory hierarchy tlb misses reexamine algorithm data structures reduce working set pages given importance memory accesses performance frequency tlb misses programs large working sets redesigned goal match th nitions right column terms th column 1 l1 cache cache cache 2 l2 cache b cache disks 3 main memoryc cache main memory 4 tlb cache page table entries 58 common framework memory hierarchy youve recognized th erent types memory hierarchies great deal common although many aspects memory hierarc er quantitatively many policies features determine hierarchy functions similar qualitatively figure 535 shows quantitative characteristics memory hierarchies ca er rest section discuss common operational alternatives memory hierarchies determine behavior examine policies series four questions apply two levels memory hierarchy although simplicity primarily use terminology caches check feature typical values l1 cachestypical values l2 cachestypical values paged memory typical values tlbtotal size blocks 250ð20002500ð25000 16000ð25000040ð1024total size kilobytes 16ð64125ð20001000000ð1000000000025ð16 block size bytes 16ð6464ð1284000ð640004ð32miss penalty clocks10ð25100ð100010000000ð10000000010ð1000 miss rates global l22ð5 01ð2000001ð00001001ð2figure 535 key quantitative design parameters characterize major elements memory hierarchy computer ese typical values levels 2012 although range values wide partially many th e values ed time related example caches become larger overcome larger miss penalties block sizes also grow shown server microprocessors today also l3 caches 2 8 mib contain many blocks l2 caches l 3 caches lower l2 miss penalty 30 40 clock cycles 58 common framework memory hierarchy 455question 1 block placedwe seen block placement upper level hierarchy use range schemes direct mapped set associative fully associative mentioned entire range schemes thought variations setassociative scheme number sets number blocks per set varies scheme namenumber setsblocks per setdirect mappednumber blocks cache 1set associativenumber blocks cache associativity associativity typically 216fully associative1number blocks cache e advantage increasing degree associativity usually decreases miss rate e improvement miss rate comes reducing misses compete location examine detail shortly first lets look much improvement gained figure 536 shows miss rates several cache sizes associativity varies direct mapped eightway set associative e largest gains obtained going direct mapped twoway set associative yields 20 30 reduction miss rate cache sizes grow relative improvement associativity increases associativitymiss rate 0onewaytwoway 36 912 15fourwayeightway 1 kib2 kib4 kib8 kib16 kib32 kib64 kib128 kibfigure 536 data cache miss rates eight cache sizes improve associativity increases b going oneway direct mapped twoway set associativ cant b ts associativity smaller eg 110 improvement going twoway fourway versus 2030 improvement going oneway twowa ere even less improvement going fourway eightway set associative turn comes close miss rates fully associative cache smaller caches obta cantly larger absolute associativity base miss rate small cache larger figure 516 explains data collected 456 chapter 5 large fast exploiting memory hierarchy slightly since overall miss rate larger cache lower opportunity improving miss rate decreases absolute improvement miss rate associativity shr cantly e potential disadvantages associativity mentioned earlier increased cost slower access time question 2 block found e choice locate block depends block placement scheme since dictates number possible locations summarize schemes follows associativitylocation methodcomparisons requireddirect mappedindex1set associativeindex set search among elements degree associativityfullsearch cache entriessize cacheseparate lookup table0 e choice among directmapped setassociative fully associative mapping memory hierarchy depend cost miss versus cost implementing associativity time extra hardware including l2 cache chip enables much higher associativity hit times critical designer rely standard sram chips building blocks fully associative caches prohibitive except small sizes cost comparators overwhelming absolute miss rate improvements greatest virtual memory systems separate mapping tablethe page tableis kept index memory addition storage required table using index table requires extra memor e choice full associativity page placement extra table motivated facts 1 full associativity b cial since misses expensive 2 full associativity allows ware use sophisticated replacement schemes designed reduce miss rate e full map easily indexed extra hardware searching required erefore virtual memory systems almost always use fully associative placement setassociative placement en used caches tlbs access combines indexing search small set systems used direct mapped caches advantage access time simplicity e advantage access time occurs becaus nding requested block depend comparison design choices depend many details 58 common framework memory hierarchy 457implementation whether cache onchip technology used implementing cache critical role cache access time determining processor cycle time question 3 block replaced cache misswhen miss occurs associative cache must decide block replace fully associative cache blocks candidates replacement cache set associative must choose among blocks set course replacement easy directmapped cache one candidate ere two primary strategies replacement setassociative fully associative caches random candidate blocks randomly selected possibly using hardware assistance example mips supports random replacement tlb misses least recently used lru e block replaced one unused longest time practice lru costly implement hierarchies small degree associativity two four typically since tracking usage information costly even fourway set associativity lru en approximatedfor example keeping track pair blocks lru requires 1 bit tracking block pair lru requires 1 bit per pair larger associativity either lru approximated random replacement used caches replacement algorithm hardware means scheme easy implement random replacement simple build hardware twoway setassociative cache random replacement miss rate 11 times higher lru replacement caches become larger miss rate replacement strategies falls absolut erence becomes small fact random replacement sometimes better simple lru approximations easily implemented hardware virtual memory form lru always approximated since even tiny reduction miss rate important cost miss enormous reference bits equivalent functionality en provided make easier operating system track set less recently used pages misses expensive relatively infrequent approximating information primarily ware acceptable question 4 happens writea key characteristic memory hierarchy deals writes already seen two basic options writethrough e information written block cache block lower level memory hierarchy main memory cach e caches section 53 used scheme 458 chapter 5 large fast exploiting memory hierarchy writeback e information written block cache e mo ed block written lower level hierarchy replaced virtual memory systems always use writeback reasons discussed section 57 writeback writethrough advantag e key advantages writeback following individual words written processor rate cache rather memory accept multiple writes within block require one write lower level hierarchy blocks written back system mak ective use high bandwidth transfer since entire block written writethrough advantages misses simpler cheaper never require block written back lower level writethrough easier implement writeback although practical writethrough cache w ill still need use write bu er caches tlbs virtual memory may initially look ver erent rely two principles locality understood answers four questions question 1where block placed answer one place direct mapped places set associative place fully associative question 2how block found answer ere four methods indexing directmapped cache limited search setassociative cache full search fully associative cache separate lookup table page table question 3what block replaced miss answer typically either least recently used random block question 4how writes handled answer level hierarchy use either writethrough writeback bigpicture 58 common framework memory hierarchy 459in virtual memory systems writeback policy practical long latency write lower level hierarchy e rate writes generated processor generally exceeds rate memory system process even allowing physically logically wider memories burst modes dram consequently today lowestlevel caches typically use writeback three cs intuitive model understanding behavior memory hierarchies subsection look model provides insight sources misses memory hierarchy misses ected changes hierarchy explain ideas terms caches although ideas carry directly level hierarchy model misses cl ed one three categories three cs compulsory misses ese cache misses caused th rst access block never cache ese also called coldstart misses capacity misses ese cache misses caused cache contain blocks needed execution program capacity misses occur blocks replaced later retrieved con ict misses ese cache misses occur setassociative directmapped caches multiple blocks compete set con ict misses misses directmapped setassociative cache eliminated fully associative cache size ese cache misses also called collision misses figure 537 shows miss rate divides three sour ese sources misses directly attacked changing aspect cache design since co ict misses arise directly contention cache block increasing associativity reduces co ict misses associativity however may slow access time leading lower overall performance capacity misses easily reduced enlarging cache indeed second level caches growing steadily larger many years course make cache larger must also careful increasing access time could lead lower overall performance us rstlevel caches growing slowly compulsory misses generated th rst reference block primary way cache system reduce number compulsory misses increase block size reduce number references required touch block program program consist fewer three cs model cache model cache misses cl ed one three categories compulsory misses capacity misses co ict misses compulsory miss also called coldstart miss cache miss caused th rst access block never cache capacity miss cache miss occurs cache even full associativity contain blocks needed satisfy request co ict miss also called collision miss cache miss occurs setassociative direct mapped cache multiple blocks compete set eliminated fully associative cache size 460 chapter 5 large fast exploiting memory hierarchy cache size kib miss rate per type083212 3 4 51285126 716642564capacity8 9101024oneway twoway fourway figure 537 miss rate broken three sources misses graph shows total miss rate components range cach data spec cpu2000 integer oatingpoint benchmarks source data figure 536 e compulsory miss component 0006 seen grap e next component capacity miss rate depends cache size e co ict portion depends associativity cache size shown range associativities oneway eightway case labeled section corresponds increase miss rate occurs associativity changed next higher degree labeled degree associativity example section labeled twoway indicates additional misses arising cache associativity two rather four us th erence miss rate incurred directmapped cache versus fully associative cache size given sum sections marked fourway twoway oneway e erence eightway fourway small cult see graph e challenge designing memory hierarchies every change potentially improves miss rate also negatively ect overall performance figure 538 summar combination positive negative ects makes design memory hierarchy interesting bigpicture 59 using finitestate machine control simple cache 461cache blocks mentioned increasing block size much negative ect performance increase miss penalty e decomposition misses three cs useful qualitative model real cache designs many design choices interact changing one cache characteristic en ect several components miss rate despite shortcomings model useful way gain insight performance cache designs following statements generally true ere way reduce compulsory misses 2 fully associative caches co ict misses 3 reducing misses associativity important capacity 59 using finitestate machine control simple cachewe implement control cache implemented control singlecycle pipelined datapaths chapt section starts nition simple cache description nitestate machines fsms nishes fsm controller simple cache section 512 goes depth showing cache controller new hardware description language simple cachewere going design controller simple cache key characteristics cache directmapped cache check design changeeffect miss rate possible negative performance effect increases cache sizedecreases capacity misses may increase access time increases associativitydecreases miss rate due conßict missesmay increase access time increases block sizedecreases miss rate wide range block sizes due spatial localityincreases miss penalty large block could increase miss ratefigure 538 memory hierarchy design challenges 462 chapter 5 large fast exploiting memory hierarchy writeback using write allocate block size 4 words 16 bytes 128 bits cache size 16 kib holds 1024 blocks 32byte addresses e cache includes valid bit dirty bit per block section 53 calculate th elds address cache cache index 10 bits block set 4 bits tag size 32 10 4 18 bits e signals processor cache 1bit read write signal 1bit valid signal saying whether cache operation 32bit address 32bit data processor cache 32bit data cache processor 1bit ready signal saying cache operation complete e interface memory cache sa elds processor cache except dat elds 128 bits wide e extra memory width generally found microprocessors today deal either 32bit 64bit words processor dram controller en 128 bits making cache block match width dram simp ed design signals 1bit read write signal 1bit valid signal saying whether memory operation 32bit address 128bit data cache memory 128bit data memory cache 1bit ready signal saying memory operation complete note interface memory xed number cycles assume memory controller notify cache via ready signal memory read writ nished describing cache controller need revie nitestate machines allow us control operation take multiple clock cycles 59 using finitestate machine control simple cache 463finitestate machines design control unit singlecycle datapath used set truth tables sp ed setting control signals based instruction class cache control complex operation series steps e control cache must specify signals set step next step sequence e common multistep control method based nitestate machines usually represented graphically nitestate machine consists set states directions change stat e directions ar ned nextstate function maps current state inputs new state us nitestate machine control state also sp es set outputs asserted machine state e implementation nitestate machine usually assumes outputs explicitly asserted deasserted similarly correct operation datapath depends fact signal explicitly asserted deasserted rather acting dont care multiplexor controls slightl erent since select one inputs whether 0 us th nitestate machine always specify setting multiplexor controls care implement th nitestate machine logic setting control 0 may default thus may require gates simple example nitestate machine appears appendix b unfamiliar concept nitestate machine may want examine appendix b proceeding nitestate machine implemented temporary register holds current state block combinational logic determines datapath signals asserted next state figure 539 shows implementation might look appendix describes detail th nitestate machine implemented using structure section b3 combinational control logic fo nitestate machine implemented either rom readonly memory pla programmable logic array also see appendix b description logic elements elaboration note simple design called blocking cache processor must w nished request section 512 describes alternative called nonblocking cacheelaboration nitestate machine book called moore machine edward moore identifying characteristic output depends current state moore machine box labeled combinational control logic split two pieces one piece control output state input nextstate outputan alternative style machine mealy machine named george mealy mealy machine allows input current state used determine output moore machines potential implementation advantages speed size control unit speed advantages arise control outputs nitestate machine sequential logic function consisting set inputs outputs nextstate function maps current state inputs new state output function maps current state possibly inputs set asserted outputs nextstate function combinational function given inputs current state determines next state nitestate machine 464 chapter 5 large fast exploiting memory hierarchy needed early clock cycle depend inputs current state appendix b nitestate machine taken logic gates size advantage clearly seen potential disadvantage moore machine may require additional states example situations onestate difference two sequences states mealy machine may unify states making outputs depend inputs fsm simple cache controllerfigure 540 shows four states simple cache controller idle state waits valid read write request processor moves fsm compare tag state compare tag name suggests state tests see requested read write hit e index portion address selects tag compared data cache block referred index portion address valid tag portion address matches tag hit either data read selected word load written selected word store e cache ready signal combinationalcontrol logic outputsinputsstate registernext state datapath control outputsinputs cachedatapathfigure 539 finitestate machine controllers typically implemented using block combinational logic register hold current state e outputs combinational logic nextstate number control signals asserted current state e inputs combinational logic current state inputs used determine next state notice nitestate machine used chapter outputs depend current state inpu e elaboration explains detail 59 using finitestate machine control simple cache 465set write dirty bit set 1 note write hit also sets valid bit ta eld seems unnecessary included tag single memory change dirty bit also need change valid ta elds hit block valid fsm returns idle state rst updates cache tag goes either writeback state block location dirty bit value 1 allocate state 0 writeback state writes 128bit block memory using address composed tag cache index remain state waiting ready signal memory memory write complete fsm goes allocate state allocate e new block fetched memory remain state waiting ready signal memory memory read complete fsm goes compare tag state although could gone new state complete operation instead reusing compare tag state good deal overlap including update appropriate word block access write cachemiss old block dirtycache missandold blockis cleanvalid cpu requestmark cache readyidlecache hitcompare tagif valid hit set valid settagif write set dirtymemory readymemory readymemorynotreadymemorynotreadywrite oldblock tomemorywritebackread new blockfrom memoryallocatefigure 540 four states simple controller 466 chapter 5 large fast exploiting memory hierarchy simple model could easily extended states try improve performance example compare tag state compare read write cache data single clock cycle en compare cache access done separate states try improve clock cycle time another optimization would add write bu er could save dirty block read new bloc rst processor doesnt wait two memory accesses dir e cache would write dirty block write bu er processor operating requested data section 512 goes detail fsm showing full controller hardware description language block diagram simple cache 510 parallelism memory hierarchy cache coherencegiven multicore multiprocessor means multiple processors single chip processors likely share common physical address space caching shared data introduces new problem view memory held tw erent processors individual caches without additional precautions could end seeing tw erent values figure 541 illustrates problem shows tw erent processors tw erent values locatio culty generally referred cache coherence problem informally could say memory system coherent read data item returns recently written value data nition although intuitively appealing vague simplistic reality much comp simp nition contains tw erent aspects memory system behavior critical writing correct shared memory programs e rst aspect called coherence nes values returned read e second aspect called consistency determines written value returned read lets look cohere rst memory system coherent 1 read processor p location x follows write p x writes x another processor occurring write read p always returns value written p us figure 541 cpu read x er time step 3 see value 1 2 read processor location x follows write another processor x returns written value read write ar ciently separated time writes x occur two access us figure 541 need mechanism value 0 cache cpu b replaced value 1 er cpu stores 1 memory address x time step 3 510 parallelism memory hierarchy cache coherence 4673 writes location serialized two writes location two processors seen order processors example cpu b stores 2 memory address x er time step 3 processors never read value location x 2 later read 1 e rst property simply preserves program orderwe certainly expect property true uniprocessors example e second proper nes notion means coherent view memory processor could continuously read old data value would clearly say memory incoherent e need write serialization subtle equally important suppose serialize writes processor p1 writes location x followed p2 writing location x serializing writes ensures every processor see write done p2 point serialize writes might case processor could see write rst see write p1 maintaining value written b nitely e simplest way avoid culties ensure writes location seen order call write serialization basic schemes enforcing coherencein cache coherent multiprocessor caches provide migration replication shared data items migration data item moved local cache used transparent fashion migration reduces latency access shared data item allocated remotely bandwidth demand shared memory time stepeventcache contents cpu acache contents cpu bmemory contents location x001cpu reads x00 2cpu b reads x000 3cpu stores 1 x101 figure 541 cache coherence problem single memory location x read written two processors b initially assume neither cache contains variable x value 0 also assume writethrough cache writeback cache adds additional similar complication er value x written cache memory contain new value bs cache b reads value x receive 0 468 chapter 5 large fast exploiting memory hierarchy replication shared data simultaneously read caches make copy data item local cache replication reduces latency access contention read shared data item supporting migration replication critical performance accessing shared data many multiprocessors introduce hardware protocol maintain coherent cach e protocols maintain coherence multiple processors called cache coherence protocols key implementing cache coherence protocol tracking state sharing data block e popular cache coherence protocol snooping every cache copy data block physical memory also copy sharing status block centralized state kep e caches accessible via broadcast medium bus network cache controllers monitor snoop medium determine whether copy block requested bus switch access following section explain snoopingbased cache coherence implemented shared bus communication medium broadcasts cache misses processors used implement snoopingbased coherence scheme broadcasting caches makes snooping protocols simple implement also limits scalability snooping protocolsone method enforcing coherence ensure processor exclusive access data item writes style protocol called write invalidate protocol invalidates copies caches write exclusive access ensures readable writable copies item exist write occurs cached copies item invalidated figure 542 shows example invalidation protocol snooping bus writeback caches action see protocol ensures coherence consider write followed read another processor since write requires exclusive access copy held reading processor must invalidated hence protocol na us read occurs misses cache cache forced fetch new copy data write require writing processor exclusive access preventing processor able write simultaneously two processors attempt write data simultaneously one wins race causing processors copy invalidated processor complete write must obtain new copy data must contain updated value erefore protocol also enforces write serialization 510 parallelism memory hierarchy cache coherence 469one insight block size plays important role cache coherency example take case snooping cache block size eight words single word alternatively written read two processors protocols exchange full blocks processors thereby increasing coherency bandwidth demands large blocks also cause called false sharing two unrelated shared variables located cache block full block exchanged processors even though processors accessin erent variables programmers compilers lay data carefully avoid false sharing elaboration although three proper cient ensure coherence question written value seen also important see observe require read x figure 541 instantaneously sees value written x processor example write x one processor precedes read x another processor shortly beforehand may impossible ensure read returns value data written since written data may even left processor point issue exactly written value must seen b ned memory consistency model hardware software interfacefalse sharing two unrelated shared variables located cache block full block exchanged processors even though processors accessin erent variables figure 542 example invalidation protocol working snooping bus single cache block x writeback caches assume neither cache initially holds x value x memor e cpu memory contents show value er processor bus activity completed blank indicates activity copy cached second miss b occurs cpu responds value canceling response memory addition contents bs cache memory contents x updated update memory occurs block becomes shared simp es protocol possible track ownership force writeback block replaced requires introduction additional state called owner indicates block may shared owning processor responsible updating processors memory changes block replaces processor activitybus activity contents cpu cache contents cpu bs cachecontents memory location x000xrofssimehcac xsdaeraupc cpu b reads xcache miss x 00001xrofnoitadilavnixot1asetirwaupc cpu b reads xcache miss x 111 470 chapter 5 large fast exploiting memory hierarchy make following two assumptions first write complete allow next write occur processors seen effect write second processor change order write respect memory access two conditions mean processor writes location x followed location processor sees new value must also see new value x restrictions allow processor reorder reads forces processor nish write program order elaboration since input change memory behind caches since output could need latest value write back cache also cache coherency problem io caches single processor well caches multiple processors cache coherence problem multiprocessors io see chapter 6 although similar origin different characteristics affect appropriate solution unlike io multiple data copies rare event one avoided whenever possible program running multiple processors normally copies data several caches elaboration addition snooping cache coherence protocol status shared blocks distributed directorybased cache coherence protocol keeps sharing status block physical memory one location called directory directorybased coherence slightly higher implementation overhead snooping c caches thus scale larger processor counts 511 parallelism memory hierarchy redundant arrays inexpensive disks online section describes using many disks conjunction er much higher throughput orginal inspiration redundant arrays inexpensive disks e real popularlity raid however due much greater dependability ered including modest number redundant e section explains th erences performance cost dependability th erent raid levels 512 advanced material implementing cache controllers online section shows implement control cache implemented control singlecycle pipelined datapaths chapter 4 section starts description nitestate machines implemention cache controller simple data cache including description cache controller hardware description language goes details example cache coherence protocol th culties implementing protocol parallelism memory hierarchy redundant arrays inexpensive disks amdahls law chapter 1 reminds us neglecting io parallel revolution foolhardy simple example demonstrates impact io system performance suppose benchmark executes 100 seconds elapsed time 90 seconds cpu time rest io time suppose number processors doubles every two years processors remain speed io time doesnt improve much faster program run end six years know elapsed timecpu timeio time io time io time 10090 10e econds e new cpu times resulting elapsed times computed following table n yearscpu timeio timeelapsed time io time 0 years90 seconds10 seconds100 seconds10 2 years 90245 seconds 10 seconds55 seconds18 4 years 45223 seconds 10 seconds33 seconds31 6 years 23211 seconds 10 seconds21 seconds47 e improvement cpu performance er six years 90118exampleanswer511 511 parallelism memory hierarchy redundant arrays inexpensive disks 5113however improvement elapsed time 1002147and io time increased 10 47 elapsed time hence parallel revolution needs come io well computation th ort spent parallelizing could squandered whenever programs io must accelerating io performance original motivation disk arrays late 1980s high performance storage choice large expensive disks e argument replacing fe w large disks many small disks performance would improve would read good match multiple processors well since many readwrite heads mean storage system could support many independent accesses well large transfers spread across many could get high ios per second high data transfer rates addition higher performance could advantages cost power oor space since smaller di sks generally cient per gigabyte larger disks e aw argument disk arrays could make reliability much worse ese smaller inexpensive drives lower mttf ratings large drives importantly replacing single drive say 50 small drives failure rate would go least factor 50 e solution add redundancy system could cope disk failures without losing information many small disks cost extra redundancy improve dependability small relative solutions larg us dependability ordable constructed redundant array inexpensive observation led name redundant arrays inexpensive disks abbreviated raid retrospect although invention motivated performance dependability key reason widespread popularity raid e parallel revolution resurfaced original performance side argument raid e rest section surveys options dependability impacts cost performance much redundancy need need extra information nd faults matter organize data extra check information thes e paper coined term gave evolutionary answer questions starting simplest expensive solution figure 5111 shows evolution example cost number extra check disks keep track evolution authors numbered stages raid still used today redundant arrays inexpensive disks raid organization disks uses array small inexpensive disks increase performance reliability 5114 511 parallelism memory hierarchy redundant arrays inexpensive disks redundancy raid 0simply spreading data multiple disks called striping automatically forces accesses several disks striping across et disks makes collection appear ware single large disk simp es storage management also improves performance large accesses since many disks operate videoediting systems example en stripe data may worry dependability much say databases raid 0 something misnomer redundancy however raid levels en operator set creating storage system raid 0 en listed one options hence term raid 0 become widely used striping allocation logically sequential blocks separate disks allow higher performance single disk deliver figure 5111 raid example four data disks showing extra check disks per raid level companies use level figures 5112 5113 explain th erence raid 3 raid 4 raid 5 raid 0no redundancy widely useddata disksraid 1 mirroring emc hptandem ibmraid 2 error detection correction code unused raid 3 bitinterleaved parity storage conceptsraid 4 blockinterleaving parity network applianceraid 5 distributed block interleaved parity widely usedraid 6p q redundancyrecently popularredundant check disks 511 parallelism memory hierarchy redundant arrays inexpensive disks 5115mirroring raid 1 traditional scheme tolerating disk failure called mirroring shadowing uses twice many disks raid 0 whenever data written one disk data also written redundant disk always two copies information disk fails system goes mirror reads contents get desired information mirroring expensive raid solution since requires disks error detecting correcting code raid 2 raid 2 borrows error detection correction scheme en used memories see section 55 since raid 2 fallen disuse well describe bitinterleaved parity raid 3 e cost higher availability reduced 1 n n number disks protection group rather complete copy original data disk need add enough redundant information restore lost information failure reads writes go disks group one extra disk hold check information case failure raid 3 popular applications large data sets multimedia scien c codes parity one scheme readers unfamiliar parity think redundant disk sum th e data disks disk fails subtract data good disks parity disk remaining information must missing information parity simply sum modulo two unlike raid 1 many disks must read determine missing dat e assumption behind technique taking longer recover failure spending less redundant storage good tradeo blockinterleaved parity raid 4 raid 4 uses ratio data disks check disks raid 3 access data erently e parity stored blocks associated set data blocks raid 3 every access went disks however applications prefer smaller accesses allowing independent accesses occur parallel purpose raid levels 4 7 since error detection information sector checked reads see data correct small reads disk occur independently long minimum access one sector raid context small access goes one disk protection group large access goes disks protection group writes another matter would seem small write would demand disks accessed read rest information needed recalculate new parity th figure 5112 small write would mirroring writing identical data multiple disks increase data availability protection group e group data disks blocks share common check disk block 5116 511 parallelism memory hierarchy redundant arrays inexpensive disks figure 5112 small write update raid 4 optimization small writes reduces number disk accesses well number disks occupied gure assumes four blocks data one block parity e naive raid 4 parity calculation th th gure reads blocks d1 d2 d3 adding block d0 calculate new parity p case wondering new data d0 comes directly cpu disks involved reading e raid 4 shortcut right reads old value d0 compares new value d0 see bits change read old parity p change corresponding bits e logical function exclusive exactly wan example replaces three disk reads d1 d2 d3 two disk writes d0 p involving disks two disk reads d0 p two disk writes d0 p involve two disks increasing size parity group increases savings shortcut raid 5 uses shortcut require reading old data old parity adding new information writing new parity parity disk new data data disk e key insight reduce overhead parity simply sum information watching bits change write new information need change correspo nding bits pari e right figure 5112 shows shortcut must read old data disk written compare old data new data see bits change read old parity change corresponding bits write new data new parity us small write involves four disk access es two disks instead accessing organization raid 4 distributed blockinterleaved parity raid 5 ciently supports mixture large reads large writes small reads plus allows small writes one drawback system parity disk must updated every write parity disk bottleneck backtoback writes x paritywrite bottleneck parity information spread throughout disks single bottleneck writ e distributed parity organization raid 5 figure 5113 shows data distributed raid 4 versus raid 5 organization right shows raid 5 parity associated row data blocks longer restricted sing organization allows multiple writes occur simultaneously long parity blocks located disk example write block 8 right must also access parity d0d0d1d2d3pd0d1d2d3pnew data1 read2 read3 read 4 write 5 write xord0d0d1d2d3pd0d1d2d3pnew data1 read2 read 3 write 4 wr itexorxor 511 parallelism memory hierarchy redundant arrays inexpensive disks 5117block p2 thereby occupying th rst third disks second write block 5 right implying update parity block p1 accesses second fourth disks thus could occur concurrently write bloc ose writes organization th result changes blocks p1 p2 th h disk bottleneck p q redundancy raid 6paritybased schemes protect single selfidentifying failure single failure correction cient parity generalized second calculation data another check disk informatio second check block allows recovery second failure us storage overhead twice e small write shortcut figure 5112 works well except six disk accesses instead four update p q information raid summary raid 1 raid 5 widely used servers one estimate 80 disks servers found raid organization one weakness raid systems repair first avoid making data unavailable repair array must designed allow failed disks replaced without turn system raids enough redundancy allow continuous operation hotswapping disks place demands physical electrical design array disk interfaces second another failure could occur repair repair time ects chances losing data longer repair time greater chances another failure hotswapping replacing hardware component system running figure 5113 blockinterleaved parity raid 4 versus distributed blockinterleaved parity raid 5 distributing parity blocks disks small writes performed parallel 048121620 159131721 2610141822 3711151923 p0p1p2p3p4p5 04812p420 159p31621 26p2131722 3p110141823 p07111519p5 raid 4raid 5 5118 511 parallelism memory hierarchy redundant arrays inexpensive disks lose data rather wait operator bring good disk systems include standby spares data reconstructed immediately upon discovery failure e operator replace failed disks leisurely fashion note human operator ultimately determines disks remove operators human occasionally remove good disk instead broken disk leading unrecoverable disk failure addition designing raid system repair questions disk technology changes time although disk manufacturers quote high mttf products numbers nominal conditions particular disk array subject temperature cycles due say failure air conditioning system shaking due poor rack design construction installation failure rates three six times higher see fallacy page e calculation raid reliability assumes independence disk failures disk failures could correlated damage due environment would likely happen disks array another concern since disk bandwidth growing slowly disk capacity time repair disk raid system increasing turn increases chances second failure example 3 tb disk could take almost nine hours read sequentially assuming interference given damaged raid likely continue serve data reconstruction could stretched considerably besides increasing time another concern reading much data reconstruction means increasing chance uncorrectable read media failure would result data loss arguments concern simultaneous multiple failures increasing number disks arrays use higher capacity disks hence trends led growing interest protecting one failure raid 6 increasingly ered option used th eldwhich following true raid levels 1 3 4 5 6 1 raid systems rely redundancy achieve high availability 2 raid 1 mirroring highest check disk overhead 3 small writes raid 3 bitinterleaved parity worst throughput 4 large writes raid 3 4 5 throughput elaboration one issue mirroring interacts striping suppose say four disks worth data store eight physical disks use would create four pairs diskseach organized raid 1and stripe data across four raid 1 pairs alternatively would create two sets four diskseach organized raid 0and mirror writes raid 0 sets raid terminology evolved call former raid 1 0 raid 10 striped mirrors latter raid 0 1 raid 01 mirrored stripes standby spares reserve hardware resources immediately take place failed component check 513 real stuff arm cortexa8 intel core i7 memory hierarchies 471 513 real stuff arm cortexa8 intel core i7 memory hierarchies section look memory hierarchy two microprocessors described chapter 4 arm cortexa8 intel cor section based section 26 computer architecture quantitative approach 5th edition figure 543 summarizes address sizes tlbs two processors note a8 two tlbs 32bit virtual address space 32bit physical address space e core i7 three tlbs 48bit virtual address 44bit physical address although 64bit registers core i7 could hold larger virtual address ware need large space 48bit virtual addresses shrinks page table memory footprint tlb hardware figure 544 shows caches keep mind a8 one processor core core i7 four identically organized 32 kib 4way set associative l1 instruction caches per core 64 byte bloc e a8 uses design data cache core i7 keeps everything except associativity increases 8way use 8way set associativ ed l2 cache per core 64 byte blocks although a8 varies size 128 kib 1 mib cor xed 256 kib core i7 used servers characteristicarm cortexa8 intel core i7virtual address 32 bits 48 bitsphysical address32 bits44 bits page sizevariable 4 16 64 kib 1 16 mibvariable 4 kib 24 mib tlb organization1 tlb instructions 1 tlb databoth tlbs fully associativewith 32 entries round robin replacementtlb misses handled hardware1 tlb instructions 1 tlb fordata per coreboth l1 tlbs fourway setassociative lru replacementl1 itlb 128 entries smallpages 7 per thread large pagesl1 dtlb 64 entries small pages 32 large pagesthe l2 tlb fourway set associativelru replacementthe l2 tlb 512 entries tlb misses handled hardwarefigure 543 address translation tlb hardware arm cortexa8 intel core i7 920 processors provide support large pages used things like operating system mapping frame bu er e largepage scheme avoids using large number entries map single object always present 472 chapter 5 large fast exploiting memory hierarchy also ers l3 cache shared cores chip size varies depending number cores four cores case size 8 mib cant challenge facing cache designers support processors like a8 core i7 execute one memory instruction per clock cycle popular technique break cache banks allow multiple independent parallel accesses provided accesses erent ba e technique similar interleaved dram banks see section 52 e core i7 additional optimizations allow reduce miss penalty e rst return requested wor rst miss also continues execute instructions access data cache cache miss designers attempting hide cache miss latency commonly use technique called nonblocking cache building outoforder processors ey implement tw avors nonblocking hit miss allows additional cache hits miss miss miss allows multiple outstanding cache misses e aim th rst two hiding miss latency work aim second overlapping latency tw erent misses overlapping large fraction miss times multiple outstanding misses requires highbandwidth memory system capable handling multiple misses parallel personal mobile device memory may able take limited nonblocking cache cache allows processor make references cache cache handling earlier miss characteristicarm cortexa8intel nehaleml1 cache organizationsplit instruction data cachessplit instruction data caches l1 cache size32 kib instructionsdata 32 kib instructionsdata per corel1 cache associativityy4way 4way set associative4way 8way set associative l1 replacementrandom approximated lru l1 block size64 bytes 64 bytesl1 write policywriteback writeallocate writeback nowriteallocatel1 hit time loaduse1 clock cycle 4 clock cycles pipelinedl2 cache organizationunified instruction data unified instruction data per corel2 cache size128 kib 1 mib 256 kib 025 mibl2 cache associativity8way set associative 8way set associativel2 replacementrandom approximated lru l2 block size64 bytes 64 bytesl2 write policywriteback writeallocate writeback writeallocatel2 hit time11 clock cycles10 clock cyclesl3 cache organization unified instruction data8 mib sharedl3 cache sizel3 cache associativity16way set associativel3 replacementapproximated lrul3 block size64 bytes l3 write policywriteback writeallocatel3 hit time35 clock cyclesfigure 544 caches arm cortexa8 intel core i7 920 513 real stuff arm cortexa8 intel core i7 memory hierarchies 473advantage capability large servers multiprocessors en memory systems capable handling one outstanding miss parallel e core i7 prefetch mechanism data accesses looks pattern data misses use information try predict next address start fetching data miss occurs techniques generally work best accessing arrays loops e sophisticated memory hierarchies chips large fraction dies dedicated caches tlbs show th cant ort expended try close gap processor cycle times memory latency performance a8 core i7 memory hierarchies e memory hierarchy cortexa8 simulated 1 mib eightway set associative l2 cache using integer minnespec benchmarks mentioned chapter 4 minnespec set benchmarks consisting spec2000 benchmarks wit erent inputs reduce running times several orders magnitude although use smaller inputs change instruction mix ect cache behavior example mcf memoryintensive spec2000 integer benchmark minnespec miss rate 32 kib cache 65 miss rate full spec2000 version 1 mib cache th erence factor six reason one compare minnespec benchmarks spec2000 benchmarks much less even larger spec2006 benchmarks used core i7 figure 547 instead data useful looking relative impact l1 l2 misses overall cpi used chapter 4 e a8 instruction cache miss rates benchmarks also full spec2000 versions minnespec based small even l1 close zero 1 th low rate probably results computationally intensive nature spec programs fourway set associative cache eliminates co ict misses figure 545 shows data cache results a8 hav cant l1 l2 miss rat e l1 miss penalty 1 ghz cortexa8 11 clock cycles l2 miss penalty assumed 60 clock cycles using miss penalties figure 546 shows average miss penalty per data access figure 547 shows miss rates caches core i7 using spec2006 benchmar e l1 instruction cache miss rate varies 01 18 averaging ov rate keeping studies instruction cache behavior speccpu2006 benchmarks show low instruction cache miss rates l1 data cache miss rates running 5 10 sometimes higher importance l2 l3 caches obvious since cost miss memory 100 cycles average data miss rate l2 4 l3 obviously critical assuming ha lf instructions loads stores without l3 l2 cache misses could add two cycles per instruction cpi comparison average l3 data miss rate 1 cant four times lower l2 miss rate six times less l1 miss rate 250200 150miss rate1005000twolf bzip2gzipparsergapperlbmk gcccrafty vprvortex conmcfl1 data miss ratel2 data miss ratefigure 545 data cache miss rates arm cortexa8 running minnespec small version spec2000 applications larger memory footprints tend higher miss rates l1 l2 note l2 rate global miss rate counting references including hit l1 see elaboration section 54 mcf known cache buster note gure systems benchmarks figure 476 chapter 4 figure 546 average memory access penalty clock cycles per data memory reference coming l1 l2 shown arm processor running minnespec although miss rates l1 ar cantly higher l2 miss penalty times higher means l2 misses contribut cantly 0051152253354455gzipvpr gccmcfcraftyparsereonperlbmkgapvortexbzip2 l1 data average memory penaltyl2 data average memory penaltymiss penalty per data reference 514 going faster cache blocking matrix multiply 4752520 15 105 0libquantumh264refhummerperlbench bzip2xalancbmksjenggpbmlastargccomnetppmcfl1 data miss ratel2 data miss rate l3 data miss ratefigure 547 l1 l2 l3 data cache miss rates intel core i7 920 running full integer speccpu2006 benchmarks elaboration speculation may sometimes wrong see chapter 4 references l1 data cache correspond loads stores eventually complete execution data figure 545 measured data requests including cancelled miss rate measured completed data accesses 16 times higher average 95 versus 59 l1 dcache misses 514 going faster cache blocking matrix multiplyour next step continuing saga improving performance dgemm tailoring underlying hardware add cache blocking subword parallelism instruction level parallelism optimizations chapters 3 4 figure 548 shows blocked version dgemm figur e changes made earlier going unoptimized dgemm figure 321 blocked dgemm figure 521 time taking unrolled version dgemm chapter 4 invoke many times submatrices 476 chapter 5 large fast exploiting memory hierarchy include x86intrinhdefine unroll 4 define blocksize 32 void do_block int n int si int sj int sk double double b double c int si siblocksize iunroll4 int j sj j sjblocksize j __m256d c4 int x 0 x unroll x cx _mm256_load_pdcix4jn cx cij int k sk k skblocksize k __m256d b _mm256_broadcast_sdbkjn b bkj int x 0 x unroll x cx _mm256_add_pdcx cxaikb _mm256_mul_pd_mm256_load_pdankx4i b int x 0 x unroll x _mm256_store_pdcix4jn cx cij cx void dgemm int n double double b double c int sj 0 sj n sj blocksize int si 0 si n si blocksize int sk 0 sk n sk blocksize do_blockn si sj sk b c 1 2 3 4 5 6 7 8 910 11 12 13 14 15 16 17 18 19 20 21 22 23 242526 27 28 29 30 31 32 33 34figure 548 optimized c version dgemm figure 480 using cache blocking ese changes ones found figur e assembly language produced compiler do_block function nearly identical figure 481 overhead call do_block compiler inlines function call b c indeed lines 28 34 lines 7 8 figure 548 identical lines 14 20 lines 5 6 figure 521 exception incrementing loop line 7 amount unrolled unlike earlier chapters show resulting x86 code inner loop code nearly identical figure 481 blocking ect computation order accesses data memory change bookkeeping integer instructions implement loops expands 14 instructions inner loop 8 er loop figure 480 40 28 instructions respectively bookkeeping code generated figure 548 nevertheless extra instructions executed pale comparison performance improvement reducing cache misses figure 549 compares unoptimzed optimizations subword parallelism instruction level parallelism caches blocking improves performance unrolled avx code factors 2 25 larger matrices compare unoptimized code code three optimizations performance improvement factors 8 15 largest increase largest matrix 32x32160x160480x480960x960 1601208040unoptimizedavxavx unrollavx unroll blocked œ1715130864352325146664751136127117120gflopsfigure 549 performance four versions dgemm matrix dimensions 32x32 960x960 e fully optimized code largest matrix almost 15 times fast unoptimized version figure 321 chapter 3 elaboration mentioned elaboration section 38 results turbo mode turned chapters 3 4 turn improve results temporary increase clock rate 3326 127 turbo mode works particularly well case using single core eight core chip however want run fast use cores well see chapter 6 514 going faster cache blocking matrix multiply 477 478 chapter 5 large fast exploiting memory hierarchy 515 fallacies pitfalls one naturally quantitative aspects computer architecture memory hierarchy would seem less vulnerable fallacies pitfalls many fallacies propagated pitfalls encountered led major negative outcomes start pitfall en traps students exercises exams pitfall ignoring memory system behavior writing programs generating code compiler could easily rewritten fallacy programmers ignore memory hierarchies writing code e evaluation sort figure 519 cache blocking section 514 demonstrate programmers easily double performance factor behavior memory system design algorithms pitfall forgetting account byte addressing cache block size simulating cache simulating cache hand computer need make sure account th ect byte addressing multiword blocks determining cache block given address maps example 32byte direct mapped cache block size 4 bytes byte address 36 maps block 1 cache since byte address 36 block address 9 9 modulo 8 1 hand address 36 word address maps block 36 mod 8 4 make sure problem clearly states base address like fashion must account block size suppose cache 256 bytes block size 32 bytes block byte address 300 fall break address 300 int elds see answer 313029 11109876543210 000 000100101100 cache block numberblock offsetblock addressbyte address 300 block address 300329 e number blocks cache 256328block number 9 falls cache block number 9 modulo 8 1 515 fallacies pitfalls 479 mistake catches many people including authors earlier dra instructors forget whether intended addresses words bytes block numbers remember pitfall tackle exercises pitfall less set associativity shared cache number cores threads sharing cache without extra care parallel program running 2 n processors threads easily allocate data structures addresses would map set shared l2 cache cache least 2 nway associative accidental co icts hidden hardware program programmers could face apparently mysterious performance bugsactually due l2 co ict misses migrating say 16core design 32core design use 16way associative l2 caches pitfall using average memory access time evaluate memory hierarchy outoforder processor processor stalls cache miss separately calculate memorystall time processor execution time hence evaluate memory hierarchy independently using average memory access time see page 399 processor continues execute instructions may even sustain cache misses cache miss accurate assessment memory hierarchy simulate outoforder processor along memory hierarchy pitfall extending address space adding segments top unsegmented address space 1970s many programs grew large code data could addressed 16bit address computers revised er 32 bit addresses either unsegmented 32bit address space also called address space adding 16 bits segment existing 16bit address marketing point view adding segments programmervisible forced programmer compiler decompose programs segments could solve addressing problem unfortunately trouble time programming language wants address larger one segment indices large arrays unrestricted pointers reference parameters moreover adding segments turn every address two wordsone segment number one segment setcausing problems use addresses registers fallacy disk failure rates th eld match speci cations two recent studies evaluated large collections disks check relationship results th eld compared sp cations one study almost 100000 disks quoted mttf 1000000 1500000 hours afr 06 ey found afrs 2 4 common en three times higher sp ed rates schroeder gibson 2007 second study 100000 disks google quoted afr 15 saw failure rates 17 drives th rst year rise 86 drives third year abou six times sp ed rate pinheiro weber barroso 2007 480 chapter 5 large fast exploiting memory hierarchy fallacy operating systems best place schedule disk accesses mentioned section 52 higherlevel disk interfaces er logical block addresses host operating system given highlevel abstraction best os try help performance sort logical block addresses increasing order however since disk knows actual mapping logical addresses onto physical geometry sectors tracks surfaces reduce rotational seek latencies rescheduling example suppose workload four reads anderson 2003 operationstarting lbalength read 724 8read 100 16read9987 1read 26128 e host might reorder four reads logical block order operationstarting lbalength read 26128read 100 16read 724 8read9987 1depending relative location data disk reordering could make worse figure 550 sho e diskscheduled reads complete three quarters disk revolution osscheduled reads take three revolutions hostordered queuedriveordered queue724100269987figure 550 example showing os versus disk schedule accesses labeled hostordered versus driveordered e former takes three revolutions complete four reads latter completes threefourths revolution anderson 2003 figure 551 summary 18 x86 instructions cause problems virtualization robin irvine 2000 e rst instructions top group allow program user mode read control register descriptor table registers without causing trap e po ags instruction mo es control register sensitive information fails silently user mode e protection checking segmented architecture x86 downfall bottom group instructions checks privilege level implicitly part instruction execution reading control register e checking assumes os must highest privilege level case guest vms move segment register tries modify control state protection checking foils well problem category problem x86 instructions access sensitive registers without trapping running user mode store global descriptor table register sgdt store local descriptor table register sldt store interrupt descriptor table register sidt store machine status word smsw push ßags pushf pushfd pop ßags popf popfd accessing virtual memory mechanisms user mode instructions fail x86 protection checksload access rights segment descriptor lar load segment limit segment descriptor lsl verify segment descriptor readable verr verify segment descriptor writable verw pop segment register pop cs pop ss push segment register push cs push ss far call different privilege level call far return different privilege level ret far jump different privilege level jmp software interrupt int store segment selector register str move tofrom segment registers move pitfall implementing virtual machine monitor instruction set architecture wasnt designed virtualizable many architects 1970s 1980s werent careful make sure instructions reading writing information related hardware resource information privileged laissezfaire attitude causes problems vmms architectures including x86 use example figure 551 describes 18 instructions cause problems virtualization robin irvine e two broad classes instructions read control registers user mode reveals guest operating system running virtual machine popf mentioned earlier check protection required segmented architecture assume operating system running highest privilege level simplify implementations vmms x86 amd intel proposed extensions architecture via new mode intels vtx provides new execution mode running vms architecte nition vm 515 fallacies pitfalls 481 482 chapter 5 large fast exploiting memory hierarchy state instructions swap vms rapidly large set parameters select circumstances vmm must invoked altogether vtx adds 11 new instructions x86 amds p ca makes similar proposals alternative modifying hardware make small mo cations operating system avoid using troublesome pieces architecture technique called paravirtualization open source xen vmm good example e xen vmm provides guest os virtual machine abstraction uses easytovirtualize parts physical x86 hardware vmm runs 516 concluding remarks e culty building memory system keep pace faster processors underscored fact raw material main memory drams essentially fastest computers slowest cheapest principle locality gives us chance overcome long latency memory accessand soundness strategy demonstrated levels memory hierarchy although levels hierarchy look quit erent quantitative terms follow similar strategies operation exploit properties locality multilevel caches make possible use cache optimizations easily two reasons first design parameters lowerlevel cache ar erent fro rstlevel cache example lowerlevel cache much larger possible use larger block sizes second lowerlevel cache constantly used processor rstlevel cach allows us consider lowerlevel cache something idle may useful preventing future misses another trend seek ware help ciently managing memory hierarchy using variety program transformations hardware facilities major focus compiler enhancements tw erent ideas explored one idea reorganize program en hance spatial temporal locality approach focuses looporiented programs use large arrays major data structure large linear algebra problems typical example dgemm restructuring loops access arrays substantially improved localityand therefore cache performancecan obtained another approach prefetching prefetching block data brought cache actually referenced many microprocessors use hardware prefetching try predict accesses may b cult ware notice third approach special cacheaware instructions optimize memory transfer example microprocessors section 610 chapter 6 use optimization fetch contents block memory write miss program going write full bloc optimization cantly reduces memory tra c one kernel prefetching technique data blocks needed future brought cache early use special instructions specify address block see chapter 6 memory systems central design issue parallel processor e growing importance memory hierarchy determining system performance means important area continue focus designers researchers years come 517 historical perspective reading section appears online gives overview memory technologies mercury delay lines dram invention memory hierarchy protection mechanisms virtual machines concludes brief history operating systems including ctss multics unix bsd unix msdos windows linux 518 exercises51 exercise look memory locality properties matrix computation e following code written c elements within row stored contiguously assume word 32bit integer i0 i8 j0 j8000 j aijbi0aji511 5 51 many 32bit integers stored 16byte cache block 512 5 51 references variables exhibit temporal locality 513 5 51 references variables exhibit spatial locality locality ected reference order data layou e computation also written matlab whic ers c storing matrix elements within column contiguously memory i18 j18000 aijbi0aji end end 518 exercises 483 484 chapter 5 large fast exploiting memory hierarchy 514 10 51 many 16byte cache blocks needed store 32bit matrix elements referenced 515 5 51 references variables exhibit temporal locality 516 5 51 references variables exhibit spatial locality 52 caches important providing highperformance memory hierarchy processors list 32bit memory address references given word addresses 3 180 43 2 191 88 190 14 181 44 186 253 521 10 53 references identify binary address tag index given directmapped cache 16 oneword blocks also list reference hit miss assuming cache initially empty 522 10 53 references identify binary address tag index given directmapped cache twoword blocks total size 8 blocks also list reference hit miss assuming cache initially empty 523 20 53 54 asked optimize cache design given refere ere three directmapped cache designs possible total 8 words data c1 1word blocks c2 2word blocks c3 4word blocks terms miss rate cache design best miss stall time 25 cycles c1 access time 2 cycles c2 takes 3 cycles c3 takes 5 cycles best cache design ere man erent design parameters important caches overall performance listed parameters fo erent directmapped cache designs cache data size 32 kib cache block size 2 words cache access time 1 cycle 524 15 53 calculate total number bits required cache listed assuming 32bit address given total size nd total size closest directmapped cache 16word blocks equal size greater explain second cache despite larger data size might provide slower performance rst cache 525 20 53 54 generate series read requests lower miss rate 2 kib 2way set associative cache cache listed identify one possible solution would make cache listed equal lower miss rate 2 kib cache discuss advantages disadvantages solution 526 15 e formula shown section 53 shows typical method index directmapped cache sp cally block address modulo number blocks cache assuming 32bit address 1024 blocks cache con erent indexing function sp cally block address3127 xor block address2622 possible use index directmapped cache explain discuss changes might need made cache possible explain 53 directmapped cache design 32bit address following bits address used access cache tagindexoffset 31109ð540531 5 53 cache block size words 532 5 53 many entries cache 533 5 53 ratio total bits required cache implementation data storage bits starting power following byteaddressed cache references recorded address041613223216010243014031001802180 534 10 53 many blocks replaced 535 10 53 hit ratio 536 20 53 list th nal state cache valid entry represented record index tag data 54 recall two write policies write allocation policies combinations implemented either l1 l2 cache assume following choices l1 l2 caches l1l2 write nonwrite allocate write back write allocate 541 5 53 58 b ers employed betw erent levels memory hierarchy reduce access latency given co guration list possible bu ers needed l1 l2 caches well l2 cache memory 542 20 53 58 describe procedure handling l1 writemiss considering component involved possibility replacing dirty block 543 20 53 58 multilevel exclusive cache block reside one l1 l2 caches co guration describe procedure handling l1 writemiss considering component involved possibility replacing dirty block 518 exercises 485 486 chapter 5 large fast exploiting memory hierarchy consider following program cache behaviors data reads per 1000 instructions data writes per 1000 instructions instruction cache miss ratedata cache miss rateblock size byte 250100030264544 5 53 58 writethrough writeallocate cache minimum read write bandwidths measured byte per cycle needed achieve cpi 2 545 5 53 58 writeback writeallocate cache assuming 30 replaced data cache blocks dirty minimal read write bandwidths needed cpi 2 546 5 53 58 minimal bandwidths needed achieve performance cpi15 55 media applications play audio les part class workloads called streaming workloads ie bring large amounts data reuse much consider video streaming wo rkload accesses 512 kib working set sequentially following address stream 0 2 4 6 8 10 12 14 16 551 5 54 58 assume 64 kib directmapped cache 32byte block miss rate address stream miss rate sensitive size cache working set would categorize misses workload experiencing based 3c model 552 5 51 58 recompute miss rate cache block size 16 bytes 64 bytes 128 bytes kind locality workload exploiting 553 10 513prefetching technique leverages predictable address patterns speculatively bring additional cache blocks particular cache block accessed one example prefetching stream b er prefetches sequentially adjacent cache blocks separate bu er particular cache block brought data found prefetch b er considered hit moved cache next cache block prefetched assume twoentry stream b er assume cache latency cache block loaded computation previous cache block completed miss rate address stream cache block size b ect miss rate miss latency assuming 1cpi machine average 135 references instruction data per instruction hel nd optimal block size given following miss rates various block sizes 8 416 332 264 15128 1 554 10 53 optimal block size miss latency 20b cycles 555 10 53 optimal block size miss latency 24b cycles 556 10 53 constant miss latency optimal block size 56 exercise look th erent ways capacity ects overall performance general cache access time proportional capacity assume main memory accesses take 70 ns memory accesses 36 instructions e following table shows data l1 caches attached two processors p1 p2 l1 sizel1 miss ratel1 hit time p12 kib80066 nsp24 kib60090 ns561 5 54 assuming l1 hit time determines cycle times p1 p2 respective clock rates 562 5 54 average memory access time p1 p2 563 5 54 assuming base cpi 10 without memory stalls total cpi p1 p2 processor faster next three problems consider addition l2 cache p1 presumably make limited l1 cache capacity use l1 cache capacities hit times previous table solving problem e l2 miss rate indicated local miss rate l2 sizel2 miss ratel2 hit time 1 mib95562 ns564 10 54 amat p1 addition l2 cache amat better worse l2 cache 565 5 54 assuming base cpi 10 without memory stalls total cpi p1 addition l2 cache 566 10 54 processor faster p1 l2 cache p1 faster miss rate would p2 need l1 cache match p1s performance p2 faster miss rate would p1 need l1 cache match p2s performance 57 exercise examines impact erent cache designs sp cally comparing associative caches directmapped caches section 54 exercises refer address stream shown exercise 52 571 10 54 using sequence references exercise 52 show th nal cache contents threeway set associative cache twoword blocks total size 24 words use lru replacement reference identify index bits tag bits block set bits hit miss 572 10 54 using references exercise 52 show th nal cache contents fully associative cache oneword blocks total size 8 words use lru replacement reference identify index bits tag bits hit miss 518 exercises 487 488 chapter 5 large fast exploiting memory hierarchy 573 15 54 using references exercise 52 miss rate fully associative cache twoword blocks total size 8 words using lru replacement miss rate using mru recently used replacement finally best possible miss rate cache given replacement policy multilevel caching important technique overcome limited amount space tha rst level cache provide still maintaining speed consider processor following parameters base cpi memory stallsprocessor speedmain memory access time first level cache missrate per instruction second level cache directmapped speedglobal miss rate second level cache directmappedsecond level cache eightway set associative speedglobal miss rate second level cache eightway set associative152 ghz100 ns712 cycles3528 cycles15574 10 54 calculate cpi processor table using 1 rst level cache 2 second level directmapped cache 3 second level eightway set associative cache numbers change main memory access time doubled cut half 575 10 54 possible even greater cache hierarchy two levels given processor second level directmapped cache designer wants add third level cache takes 50 cycles access reduce global miss rate 13 would provide better performance general advantages disadvantages adding third level cache 576 20 54 older processors intel pentium alpha 21264 second level cache external located erent chip main processor th rst level cache allowed large second level caches latency access cache much higher bandwidth typically lower second level cache ran lower frequency assume 512 kib chip second level cache global miss rate 4 additional 512 kib cache lowered global miss rates 07 cache total access time 50 cycles big would cache match performance second level directmapped cache listed eightway set associative cache 58 mean time failures mtbf mean time replacement mttr mean time failure mttf useful metrics evaluating reliability availability storage resource explore concepts answering questions devices following metrics mttfmttr3 years 1 day 581 5 55 calculate mtbf devices table 582 5 55 calculate availability devices table 583 5 55 happens availability mttr approaches 0 realistic situation 584 5 55 happens availability mttr gets high ie de cult repair imply device low availability 59 exercise examines single error correcting double error detecting sec ded hamming code 591 5 55 minimum number parity bits required protect 128bit word using secded code 592 5 55 section 55 states modern server memory modules dimms employ secded ecc protect 64 bits 8 parity bits compute cost performance ratio code code 591 case cost relative number parity bits needed performance relative number errors corrected better 593 consider sec code protects 8 bit words 4 parity bits read value 0x375 error correct error 510 highperformance system btree index database page size determined mainly data size disk performance assume average btree index page 70 full wit xsized entr e utility page btree depth calculated log 2entr e following table shows 16byte entries 10yearold disk 10 ms latency 10 mbs transfer rate optimal page size 16k page size kib page utility btree depth number disk accesses saved index page access cost msutilitycost 2649 log2204816071020644749104072 8849108079 16949116082 321049132079 641149164070 1281249228055 2561349356038 5101 10 57 best page size entries become 128 bytes 5102 10 57 based 5101 best page size pages half full 5103 20 57 based 5102 best page size using modern disk 3 ms latency 100 mbs transfer rate explain future servers likely larger pages 518 exercises 489 490 chapter 5 large fast exploiting memory hierarchy keeping frequently used hot pages dram save disk accesses determine exact meaning frequently used given system data engineers use cost ratio dram disk access quantify reuse time threshold hot pag e cost disk access diskaccesses_per_sec cost keep page dram dram_mibpage_size e typical dram disk costs typical database page sizes several time points listed year dram cost mibpage size kibdisk cost diskdisk access rate accesssec19875000115000151997158200064 2007005648083 5104 10 51 57 reuse time thresholds three technology generations 5105 10 57 reuse time thresholds keep using 4k page size whats trend 5106 20 57 factors changed keep using page size thus avoiding ware rewrite discuss likeliness current technology cost trends 511 described section 57 virtual memory uses page table track mapping virtual addresses physical address exercise shows table must updated addresses accessed e following data constitutes stream virtual addresses seen system assume 4 kib pages 4entry fully associative tlb true lru replacement pages must brought disk increment next largest page number 4669 2227 13916 34587 48870 12608 49225 tlbvalid tag physical page number1111 2174 136 049 page table validphysical page disk 150disk 0disk 16 19 111 0disk 14 0disk 0disk 13 112 5111 10 57 given address stream shown initial tlb page table states provided show th nal state system also list reference hit tlb hit page table page fault 5112 15 57 repeat 5111 time use 16 kib pages instead 4 kib pages would advantages larger page size disadvantages 5113 15 54 57 show th nal contents tlb 2way set associative also show contents tlb direct mapped discuss importance tlb high performance would virtual memory accesses handled tlb ere several parameters impact overall size page table listed key page table parameters virtual address size page size page table entry size 32 bits8 kib4 bytes 5114 5 57 given parameters shown calculate total page table size system running 5 applications utilize half memory available 5115 10 57 given parameters shown calculate total page table size system running 5 applications utilize half memory available given two level page table approach 256 entries assume entry main page table 6 bytes calculate minimum maximum amount memory required 5116 10 57 cache designer wants increase size 4 kib virtually indexed physically tagged cache given page size shown possible make 16 kib directmapped cache assuming 2 words per block would designer increase data size cache 518 exercises 491 492 chapter 5 large fast exploiting memory hierarchy 512 exercise examine spacetime optimizations page tab e following list provides parameters virtual memory system virtual address bits physical dram installedpage sizepte size byte 4316 gib4 kib45121 10 57 singlelevel page table many page table entries ptes needed much physical memory needed storing page table 5122 10 57 using multilevel page table reduce physical memory consumption page tables keeping active ptes physical memory many levels page tables needed case many memory references needed addres translation missing tlb 5123 15 57 inverted page table used optimize space time many ptes needed store page table assuming hash table implementation common case worst case numbers memory references needed servicing tlb miss e following table shows contents 4entry tlb entryidvalidva pagemodiﬁ edprotectionpa page 111401rw 3020400rx34312001ro 32412800rw 315124 5 57 scenarios would entry 2s valid bit set zero 5125 5 57 happens instruction writes va page 30 would ware managed tlb faster hardware managed tlb 5126 5 57 happens instruction writes va page 200 513 exercise examine replacement policies impact miss rate assume 2way set associative cache 4 blocks solve problems exercise nd helpful draw table like one demonstrated address sequence 0 1 2 3 4 address memory block accessedhit miss evicted blockcontents cache blocks referenceset 0set 0set 1set 1 0missmem01missmem0mem12missmem0mem2mem1 3missmem0mem2mem1mem3 4miss0mem4mem2mem1mem3 consider following address sequence 0 2 4 8 10 12 14 16 0 5131 5 54 58 assuming lru replacement policy many hits address sequence exhibit 5132 5 54 58 assuming mru recently used replacement policy many hits address sequence exhibit 5133 5 54 58 simulate random replacement policy b ipping coin example heads means evict th rst block set tails means evict second block set many hits address sequence exhibit 5134 10 54 58 address evicted replacement maximize number hits many hits address sequence exhibit follow optimal policy 5135 10 54 58 describe cult implement cache replacement policy optimal address sequences 5136 10 54 58 assume could make decision upon memory reference whether want requested address cached impact could miss rate 514 support multiple virtual machines two levels memory virtualization needed virtual machine still controls mapping virtual address va physical address pa hypervisor maps physical address pa virtual machine actual machine address accelerate mappings ware approach called shadow paging duplicates virtual machines page tables hypervisor intercepts va pa mapping changes keep copies consistent remove complexity shadow page tables hardware approach called nested page table npt explicitly supports two classes page tables va pa pa walk tables purely hardware consider following sequence operations 1 create process 2 tlb miss 3 page fault 4 context switch 5141 10 56 57 would happen given operation sequence shadow page table nested page table respectively 5142 10 56 57 assuming x86based 4level page table guest nested page table many memory references needed service tlb miss native vs nested page table 5143 15 56 57 among tlb miss rate tlb miss latency page fault rate page fault handler latency metrics important shadow page table important nested page table 518 exercises 493 494 chapter 5 large fast exploiting memory hierarchy assume following parameters shadow paging system tlb misses per 1000 instructions npt tlb miss latencypage faults per 1000 instructions shadowing page fault overhead 02200 cycles000130000 cycles5144 10 56 benchmark native execution cpi 1 cpi numbers using shadow page tables vs npt ssuming page table virtualization overhead 5145 10 56 techniques used reduce page table shadowing induced overhead 5146 10 56 techniques used reduce npt induced overhead 515 one biggest impediments widespread use virtual machines performance overhead incurred running virtual machine listed various performance parameters application behavior base cpipriviliged os accesses per 10000 instructions performance impact trap guest osperformance impact trap vmmio access per 10000 instructions io access time includes time trap guest os1512015 cycles175 cycles30 1100 cycles5151 10 56 calculate cpi system listed assuming accesses io cpi vmm performance impact doubles cut half virtual machine ware company wishes obtain 10 performance degradation longest possible penalty trap vmm 5152 10 56 io accesses en large impact overall system performance calculate cpi machine using performance characteristics assuming nonvirtualized system calculate cpi time using virtualized system cpis change system half io accesses explain io bound applications smaller impact virtualization 5153 30 56 57 compare contrast ideas virtual memory virtual machines goals compare pros cons list cases virtual memory desired cases virtual machines desired 5154 20 56 section 56 discusses virtualization assumption virtualized system running isa underlying hardware however one possible use virtualization emulate nonnative isas example qemu emulates variety isas mips sparc powerpc th culties involved kind virtualization possible emulated system run faster native isa 516 exercise explore control unit cache controller processor write bu er use th nite state machine found figure 540 starting point designing ow nite state machines assume cache controller simple directmapped cache described page 465 figure 540 section 59 add write bu er capacity one block recall purpose write bu er serve temporary storage processor doesnt wait two memory accesses dirty miss rather writing back dirty block reading new block b ers dirty block immediately begins reading new bloc e dirty block written main memory processor working 5161 10 58 59 happen processor issues request hits cache block written back main memory write bu er5162 10 58 59 happen processor issues request misses cache block written back main memory write bu er5163 30 58 59 nite state machine enable use write bu er 517 cache coherence concerns views multiple processors given cache bloc e following data shows two processors readwrite operations two erent words cache block x initially x0 x1 0 assume size integers 32 bits p1p2x0 x1 3x0 5 x1 25171 15 510 list possible values given cache block correct cache coherence protocol implementation list least one possible value block protocol doesnt ensure cache coherency 5172 15 510 snooping protocol list valid operation sequence processorcache nish readwrite operations 5173 10 510 bestcase worstcase numbers cache misses needed execute listed readwrite instructions memory consistency concerns views multiple data item e following data shows two processors readwrite operations erent cache blocks b initially 0 p1p2a 1 b 2 a2 bc b 518 exercises 495 496 chapter 5 large fast exploiting memory hierarchy 5174 15 510 list possible values c implementation ensures consistency assumptions page 470 5175 15 510 list least one possible pair values c assumptions maintained 5176 15 53 510 various combinations write policies write allocation policies combinations make protocol implementation simpler 518 chip multiprocessors cmps multiple cores caches single chip cmp onchip l2 cache design interesting tradeo e following table shows miss rates hit latencies two benchmarks private vs shared l2 cache designs assume l1 cache misses every 32 instructions privateshared benchmark missesperinstruction030012 benchmark b missesperinstruction006003 assume following hit latencies private cacheshared cache memory 5201805181 15 513 cache design better benchmarks use data support conclusion 5182 15 513 shared cache latency increases cmp size choose best design shared cache latency doub chip bandwidth becomes bottleneck number cmp cores increases choose best design chip memory latency doubles 5183 10 513 discuss pros cons shared vs private l2 caches singlethreaded multithreaded multiprogrammed workloads reconsider onchip l3 caches 5184 15 513 assume benchmarks base cpi 1 ideal l2 cache nonblocking cache improves average number concurrent l2 misses 1 2 much performance improvement provide shared l2 cache much improvement achieved private l2 5185 10 513 assume new generations processors double number cores every 18 months maintain level percore performance much chip memory bandwidth needed processor released three years 5186 15 513 consider entire memory hierarchy kinds optimizations improve number concurrent misses 519 exercise show th nition web server log examine code optimizations improve log processing speed e data structure th ned follows struct entry int srcip remote ip addresschar url128 request url eg get indexhtml long long reftime reference time int status connection status char browser64 client browser name log num_entriesassume following processing function log topk_sourceip int hour5191 5 515 whic elds log entry accessed given log processing function assuming 64byte cache blocks prefetching many cache misses per entry given function incur average 5192 10 515 reorganize data structure improve cache utilization access locality show structur nition code 5193 10 515 give example another log processing function would pref erent data structure layout functions important would rewrite program improve overall performance supplement discussion code snippet data problems use data cache performance spec cpu2000 benchmarks httpwwwcswiscedumultifacetmiscspec2000cachedata pairs benchmarks shown following table amesa gccbmcf swim5194 10 515 64 kib data caches varying set associativities miss rates broken miss types cold capacity co ict misses benchmark 5195 10 515 select set associativity used 64 kib l1 data cache shared benchmarks l1 cache directly mapped select set associativity 1 mib l2 cache 5196 20 515 give example miss rate table higher set associativity actually increases miss rate construct cache co guration reference stream demonstrate 518 exercises 497 498 chapter 5 large fast exploiting memory hierarchy 51 page 377 1 4 3 false cost memory hierarchy varies per computer 2013 highest cost usually dram 53 page 398 1 4 lower miss penalty enable smaller blocks since dont much latency amortize yet higher memory bandwidth usually leads larger blocks since miss penalty slightly larger 54 page 417 1 57 page 454 1a 2c 3b 4d 58 page 461 2 large block sizes prefetching may reduce compulsory misses 1 false answers check 6i swing big everything ive got hit big miss big like live big babe ruthamerican baseball player parallel processors client cloud61 introduction 50262 difﬁ culty creating parallel processing programs 50463 sisd mimd simd spmd vector 50964 hardware multithreading 51665 multicore shared memory multiprocessors 51966 introduction graphics processing units 524computer organization design doi 2013 elsevier inc rights reservedhttpdxdoiorg101016b97801240772630000112013 67 clusters warehouse scale computers message passing multiprocessors 53168 introduction multiprocessor network topologies 53669 communicating outside world cluster networking 539610 multiprocessor benchmarks performance models 540611 real stuff benchmarking intel core i7 versus nvidia tesla gpu 550612 going faster multiple processors matrix multiply 555613 fallacies pitfalls 558614 concluding remarks 560615 historical perspective reading 563616 exercises 563computercomputercomputer computernetworkmultiprocessor cluster organization 502 chapter 6 parallel processors client cloud 61 introductioncomputer architects long sought e city gold el dorado computer design create powerful computers simply connecting many existing smaller golden vision fountainhead multiprocessors ideally customers order many processors ord receive commensurate amount performance us multiprocessor ware must designed work variable number processors mentioned chapter 1 energy become overriding issue microprocessors datacenters replacing larg cient processors many smaller cient processors deliver better performance per joule large small ware ciently use th us improved energ ciency joins scalable performance case multiprocessors since multiprocessor ware scale designs support operation presence broken hardware single processor fails multiprocessor n processors system would continue provide service n 1 processors hence multiprocessors also improve availability see chapter 5 high performance mean high throughput independent tasks called tasklevel parallelism processlevel parallelism ese tasks independent singlethreaded applications important popular use multiple processor approach contrast running single job multiple processors use term parallel processing program refer single program runs multiple processors simultaneously ere long scien c problems needed much faster computers class problems used justify many novel parallel computers decades problems handled simply today using cluster composed microprocessors housed many independent servers see section 67 addition clusters serve equally demanding applications outside sciences search engines web servers email servers databases described chapter 1 multiprocessors shoved spotlight energy problem means future increases performance primarily come explicit hardware parallelism rather much higher clock rates vastly improved cpi said chapter 1 called mountains moon valley shadow ride boldly ride shade replied seek el dorado edgar allan poe el dorado stanza 4 1849 multiprocessor computer system least two processor computer contrast uniprocessor one increasingly hard nd today tasklevel parallelism processlevel parallelism utilizing multiple processors running independent programs simultaneously parallel processing program single program runs multiple processors simultaneously cluster set computers connected local area network function single large multiprocessor 61 introduction 503multicore microprocessors instead multiprocessor microprocessors presumably avoid redundancy naming hence processors en called cores multicore chip e number cores expected increase moores law ese multicores almost always shared memory processors smps usually share single physical address space well see smps section 65 e state technology today means programmers care performance must become parallel programmers sequential code means slow code e tall challenge facing industry create hardware ware make easy write correct parallel processing programs execute ciently performance energy number cores per chip scales abrupt microprocessor design caught many guard great deal confusion terminology means figure 61 tries clarify terms serial parallel sequential concurren e columns gure represent ware either inherently sequential concurren e rows gure represent hardware either serial parallel example programmers compilers think sequential programs steps include parsing code generation optimization contrast programmers operating systems normally think concurrent programs cooperating processes handling io events due independent jobs running computer e point two axes figure 61 concurrent ware run serial hardware operating systems intel pentium 4 uniprocessor parallel hardware os recent intel cor e true sequential ware example matlab programmer writes matrix multiply thinking sequentially could run serially pentium 4 parallel intel core i7 might guess challenge parallel revolutio guring make naturally sequential ware high performance parallel hardware also make concurrent programs high performance multiprocessors number processors increases distinction made rest chapter use parallel processing program parallel ware mean either sequential concurrent ware running parallel hardware e next section chapter describes hard create cient parallel processing programs software sequentialconcurrent hardware serialmatrix multiply written matlabrunning intel pentium 4 windows vista operating system running intel pentium 4 parallel matrix multiply written matlab running intel core i7 windows vista operating system running intel core i7 figure 61 hardwaresoftware categorization examples application perspective concurrency versus hardware perspective parallelism multicore microprocessor microprocessor containing multiple processors cores single integrated circuit virtually microprocessors today desktops servers multicore shared memory multiprocessor smp parallel processor single physical address space 504 chapter 6 parallel processors client cloud proceeding path parallelism forget initial incursions earlier chapters chapter 2 section 211 parallelism instructions synchronization chapter 3 section 36 parallelism computer arithmetic subword parallelism chapter 4 section 410 parallelism via instructions chapter 5 section 510 parallelism memory hierarchy cache coherence true false b multiprocessor application must concurrent 62 difﬁ culty creating parallel processing programs e culty parallelism hardware important application programs rewritten complete tasks sooner multiprocessors cult write ware uses multiple processors complete one task faster problem gets worse number processors increases parallel processing programs much harder develop sequential programs e rst reason must get better performance better energy ciency parallel processing program multiprocessor otherwise would use sequential program uniprocessor sequential programming simpler fact uniprocessor design techniques superscalar outof order execution take advantage instructionlevel parallelism see chapter 4 normally without involvement programmer innovations reduced demand rewriting programs multiprocessors since programmers could nothing yet sequential programs would run faster new computers cult write parallel processin g programs fast especially number processors increases chapter 1 used analogy eight reporters trying write single story hopes work eight times faster succeed task must broken eight equalsized pieces otherwise reporters would idle waiting ones larger pieces nish another speedup obstacle could reporters would spend much time communicating instead writing pieces story analogy parallel programming challenges include scheduling partitioning work parallel pieces balancing load evenly workers time synchronize check overhead communication part e challenge er reporters newspaper story processors parallel programming discussion chapter 1 reveals another obstacle namely amdahl law reminds us even small parts program must parallelized program make good use many cores speedup challengesuppose want achieve speedup 90 times faster 100 processors percentage original computation sequential amdahl law chapter 1 says execution time imp rovement execution time b yy improvement amount improvement execution time c ted reformulate amdahl law terms speedup versus original execution time speedup execution time execution time beforeexecu tion time aected execution time amount impr ovement formula usually rewritten assuming execution time 1 unit time execution time ected improvement considered fraction original execution time speedup 11fraction time aected fraction time ae dd amount improvement substituting 90 speedup 100 amount improvement formula 90 11fraction time aected fraction time aected 100exampleanswer 62 difﬁ culty creating parallel processing programs 505 506 chapter 6 parallel processors client cloud en simplifying formula solving fraction time ected 901099fraction ti a1 9090099fraction ime1 9090099fraction time fractio n n time 898910999 us achieve speedup 90 100 processors sequential percentage 01 yet applications plenty parallelism shall see next speedup challenge bigger problemsuppose want perform two sums one sum 10 scalar variables one matrix sum pair twodimensional arrays dimensions 10 10 lets assume matrix sum parallelizable well see soon parallelize scalar sums speedup get 10 versus 40 processors next calculate speedups assuming matrices grow 20 20 assume performance function time addition 10 additions b parallel processors 100 additions time single processor 110 execution time 10 processors execution timeer improvement execution time b yy improvement amount improvement execution time c ted execution timeer improvement 10010ttt1020 speedup 10 processors 110 t20t e execution time 40 processors execution time imp rovement 10040ttt10125 speedup 40 processors 110 t125t us problem size get 55 potential speedup 10 processors 22 40 exampleanswer look happens increase matr e sequential program takes 10 400t e execution time 10 processors execution time improvement 40010ttt1050 speedup 10 processors 410 t50t e execution time 40 processors execution time improvement 40040ttt1020 speedup 40 processors 410 t20t us larger problem size get 82 potential speedup 10 processors 51 40 ese examples show getting good speedup multiprocessor keeping prob xed harder getting good speedup increasing size prob insight allows us introduce two terms describe ways scale strong scaling means measuring speedup keeping prob xed weak scaling means problem size grows proportionally increase number processors lets assume size problem working set main memory p processor en memory per processor strong scaling approximately mp weak scaling approximately note memory hierarchy interfere conventional wisdom weak scaling easier strong scaling example weakly scaled dataset long ts last level cache multicore microprocessor resulting performance could much worse using strong scaling depending application argue either scaling approach example tpcc debitcredit database benchmark requires scale number customer accounts proportion higher transactions per minute e argument nonsensical think given customer base suddenly going start using atms 100 times day bank gets faster computer instead going demonstrate system perform 100 times numbers transactions per minute run experiment 100 times many customers bigger problems en need data argument weak scaling nal example shows importance load balancing speedup challenge balancing loadto achieve speedup 205 previous larger problem 40 processors assumed load perfectly balanced 40 strong scaling speed achieved multiprocessor without increasing size problem weak scaling speed achieved multiprocessor increasing size problem proportionally increase number processors example 62 difﬁ culty creating parallel processing programs 507 508 chapter 6 parallel processors client cloud processors 25 work instead show impact speedup one processor load higher rest calculate twice load 5 times load 125 hardest working processor well utilized rest processors one processor 5 parallel load must 5 400 20 additions 39 share remaining 380 since operating simultaneously calculate execution time maximum execution time imp rovementmax 38039201tt110tt30 e speedup drops 205 410 t30t e remaining 39 processors utilized less half time waiting 20t hardest working processor nish compute 380 t39 97t one processor 125 load must perform 50 addition e formula execution time imp rovementmax 35039501tt110tt60 e speedup drops even 410 t60t e rest processors utilized less 20 time 9 t50t example demonstrates importance balancing load single processor twice load others cuts speedup third times load one processor reduces speedup almost factor three better understand goals challenges parallel processing give overview rest chapter e next section 63 describes much older cl cation scheme figure 61 addition describes two styles instruction set architectures support running sequential applications parallel hardware namely simd vector section 64 describes multithreading term en confused multiprocessing part relies upon similar concurrency programs section 65 describes rst two alternatives fundamental parallel hardware characteristic whether processors systems rely upon single physical address space mentioned two popular versions alternatives called shared memory multiprocessors smps clusters section covers former section 66 describes relatively new style computer graphics hardware community called graphicsprocessing unit gpu also assumes single physical address appendix c describes gpus even detail section 67 describes clusters popular example computer multiple physical address spaces section 68 shows typical topologies used connect many processors together either server nodes cluster cores microprocessor section 69 describes hardware ware communicating answer nodes cluster using ethernet shows optimize performance using custom ware hardware next discuss th culty nding parallel benchmarks sectio section also includes simple yet insightful performance model helps design applications well architectures use model well parallel benchmarks section 611 compare multicore computer gpu section 612 divulges th nal largest step journey accelerating matrix multiply matrices cache parallel processing uses 16 cores improve performance factor 14 close fallacies pitfalls conclusions parallelism next section introduce acronyms probably already seen identify erent types parallel computers true false strong scaling bound amdahl law 63 sisd mimd simd spmd vector one categorization parallel hardware proposed 1960s still used today based number instruction streams number data streams figure 62 shows categor us conventional uniprocessor single instruction stream single data stream conventional multiprocessor multiple instruction streams multiple data stream ese two categories abbreviated sisd mimd respectively possible write separate programs run erent processors mimd computer yet work together grander coordinated goal programmers normally write single program runs processors mimd computer relying conditional statements wh erent processors execut erent sections code style called single program multiple data spmd normal way program mimd computer e closest come multiple instruction streams single data stream misd processor might stream processor would perform series computations single data stream pipelined fashion parse input network decrypt data decompress search match e inverse misd much popular simd computers operate vectors check sisd single instruction stream single data stream uniprocessor mimd multiple instruction streams multiple data streams multiprocessor spmd single program multiple data streams e conventional mimd programming model single program runs across processors simd single instruction stream multiple data streams e instruction applied many data streams vector processor figure 62 hardware categorization examples based number instruction streams data streams sisd simd misd mimd data streams singlemultipleinstruction streamssinglesisd intel pentium 4 simd sse instructions x86 multiplemisd examples today mimd intel core i7 63 sisd mimd simd spmd vector 509 510 chapter 6 parallel processors client cloud data example single simd instruction might add 64 numbers sending 64 data streams 64 alus form 64 sums within single clock cycle e subword parallel instructions saw sections 36 37 another example simd indeed middle letter intels sse acronym stands simd e virtues simd parallel execution units synchronized respond single instruction emanates single program counter pc programmer perspective close already familiar sisd although every unit executing instruction execution unit address registers unit hav erent data address us terms figure 61 sequential application might compiled run serial hardware organized sisd parallel hardware organized simd e original motivation behind simd amortize cost control unit dozens execution units another advantage reduced instruction bandwidth space simd needs one copy code simultaneously executed messagepassing mimds may need copy every processor shared memory mimd need multiple instruction caches simd works best dealing arrays loops hence parallelism work simd must great deal identically structured data called datalevel parallelism simd weakest case switch statements execution unit must perfor erent operation data depending data execution units wrong data must disabled units proper data may continue n cases situations simd processors essentially run 1 nth peak performance e socalled array processors inspired simd category faded history see section 615 online two current interpretations simd remain active today simd x86 multimedia extensionsas described chapter 3 subword parallelism narrow integer data original inspiration multimedia extension mmx instructions x86 1996 moores law continued instructions added leadin rst streaming simd extensions sse advanced vector extensions avx avx supports simultaneous execution four 64bi oatingpoint numbers e width operation registers encoded opcode multimedia instructions data width registers operations grew number opcodes multimedia instructions exploded hundreds sse avx instructions see chapter 3 vector older shall see elegant interpretation simd called vector architecture closely iden ed computers designed seymour cray starting 1970s also great match problems lots datalevel parallelism rather 64 alus perform 64 additions simultaneously like old array processors vector architectures pipelined alu get good performance low e basic philosophy vector architecture collect datalevel parallelism parallelism achieved performing operation independent data data elements memory put order large set registers operate sequentially registers using pipelined execution units write results back memory key feature vector architectures set vector register us vector architecture might 32 vector registers 64 64bit elements comparing vector conventional code suppose extend mips instruction set architecture vector instructions vector registers vector operations use names mips operations letter v appended example addvd adds two doubleprecision vector e vector instructions take input either pair vector registers addvd vector register scalar register addvsd latter case value scalar register used input operations operation addvsd add contents scalar register element vector register e names lv sv denote vector load vector store load store entire vector doubleprecision data one operand vector register loaded stored operand mips generalpurpose register starting address vector memory given short description show conventional mips code versus vector mips code yaxy x vectors 64 double precisio oatingpoint numbers initially resident memory scalar double precision variable example socalled daxpy loop forms inner loop linpack benchmark daxpy stands double precision x plus assume starting addresses x s0 s1 respectively conventional mips code daxpy ld f0asp load scalar addiu t0s0512 upper bound load loop ld f20s0 load xi muld f2f2f0 x xi ld f40s1 load yi addd f4f4f2 x xi yi sd f40s1 store yi addiu s0s08 increment index x addiu s1s18 increment index subu t1t0s0 compute bound bne t1zeroloop check done vector mips code daxpy exampleanswer 63 sisd mimd simd spmd vector 511 512 chapter 6 parallel processors client cloud ld f0asp load scalar lv v10s0 load vector x mulvsd v2v1f0 vectorscalar multiply lv v30s1 load vector addvd v4v2v3 add product sv v40s1 store result ere interesting comparisons two code segments example e dramatic vector processor greatly reduces dynamic instruction bandwidth executing 6 instructions versus almost 600 traditional mips architecture reduction occurs vector operations work 64 elements time overhead instructions constitute nearly half loop mips present vector code might expect reduction instructions fetched executed saves energy another importan erence frequency pipeline hazards chapter 4 straightforward mips code every addd must wait muld every sd must wait addd every addd muld must wait ld vector processor vector instruction stall th rst element vector subsequent elemen ow smoothly pipeline us pipeline stalls required per vector operation rather per vector element example pipeline stall frequency mips 64 times higher vector version e pipeline stalls reduced mips using loop unrolling see chapter 4 however large erence instruction bandwidth reduced since vector elements independent operated parallel much like subword parallelism avx instructions modern vector computers vector functional units multiple parallel pipelines called vector lanes see figures 62 63 produce two results per clock cycle elaboration loop example exactly matched vector length loops shorter vector architectures use register reduces length vector operations loops larger add bookkeeping code iterate fulllength vector operations handle leftovers latter process called strip miningvector versus scalar vector instructions several important properties compared conventional instruction set architectures called scalar architectures context single vector instruction sp es great deal work equivalent executing entire loop e instruction fetch decode bandwidth needed dramatically reduced using vector instruction compiler programmer indicates computation result vector independent computation results vector hardware check data hazards within vector instruction vector architectures compilers reputation making much easier using mimd multiprocessors writ cient applications contain datalevel parallelism hardware need check data hazards two vector instructions per vector operand every element within vectors reduced checking save energy well time vector instructions access memory known access pattern vector elements adjacent fetching vector set heavily interleaved memory banks works well us cost latency main memory seen entire vector rather word vector entire loop replaced vector instruction whose behavior predetermined control hazards would normally arise loop branch nonexistent e savings instruction bandwidth hazard checking plus th cient use memory bandwidth give vector architectures advantages power energy versus scalar architectures reasons vector operations made faster sequence scalar operations number data items designers motivated include vector units application domain en use vector versus multimedia extensions like multimedia extensions found x86 avx instructions vector instruction sp es multiple operations however multimedia extensions typically specify operations vector sp es dozens operations unlike multimedia extensions number elements vector operation opcode separate register distinction mean erent versions vector architecture implemented wit erent number elements changing contents register hence retain binary compatibility contrast new large set opcodes added time vector length changes multimedia extension architecture x86 mmx sse sse2 avx avx2 also unlike multimedia extensions data transfers need contiguous vectors support strided accesses hardware loads every nth data element memory indexed accesses hardware nds addresses items loaded vector register indexed accesses also called gather scatter indexed loads gather elements main memory contiguous vector elements indexed stores scatter vector elements across main memory like multimedia extensions vector architectures easily capture th exibility data widths easy make vector operation work 32 64bit data elements 64 32bit data elements 128 16bit data elements 256 8bit data elemen e parallel semantics vector instruction allows implementation execute operations using deeply pipelined functional unit array parallel functional units combination parallel pipelined functional units figure 63 illustrates improve vector performance using parallel pipelines execute vector add instruction vector arithmetic instructions usually allow element n one vector register take part operations element n vector register 63 sisd mimd simd spmd vector 513 514 chapter 6 parallel processors client cloud dramatically simp es construction highly parallel vector unit structured multiple parallel vector lanes tra c highway increase peak throughput vector unit adding lanes figure 64 shows structure fourlane vector uni us going four lanes one lane reduces number clocks per vector instruction roughly factor four multiple lanes advantageous applications architecture must support long vectors otherwise execute quickly youll run instructions requiring instruction level parallel techniques like chapter 4 supply enough vector instructions generally vector architectures cient way execute data parallel processing programs better matches compiler technology multimedia extensions easier evolve time multimedia extensions x86 architecture given classic categories next see exploit parallel streams instructions improve performance single processor reuse multiple processors true false exemp ed x86 multimedia extensions thought vector architecture short vectors supports contiguous vector data transfers vector lane one vector functional units portion vector regist le inspired lanes highways increase tra c speed multiple lanes execute vector operations simultaneously check a9a8a7a6a5a4a3a2a1b9b8b7b6b5b4b3b2b1c0c0c1c2c3a8a4b8b4a9a5b9b5a6b6a7b7abelement group figure 63 using multiple functional units improve performance single vector add instruction c b e vector processor th single add pipeline complete one addition per cycle e vector processor b right four add pipelines lanes complete four additions per cycle e elements within single vector add instruction interleaved across four lanes elaboration given advantages vector arent popular outside highperformance computing concerns larger state vector register culty handling page faults vector loads stores simd instructions achie ts vector instructions addition long advances instruction level parallelism could deliver performance promise moores law little reason take chance changing architecture styleselaboration another advantage vector multimedia extensions relatively easy extend scalar instruction set architecture instructions improve performance data parallel operations elaboration haswellgeneration x86 processors intel support avx2 gather operation scatter operationlane 0lane 1lane 2lane 3fp addpipe 0fp mul pipe 0vector registerselements048fp addpipe 1fp mul pipe 1vector registerselements159fp addpipe 2fp mul pipe 2vector registerselements2610fp addpipe 3fp mul pipe 3vector registerselements3711vector load store unit figure 64 structure vector unit containing four lanes e vectorregister storage divided across lanes lane holding every fourth element vector register e gure shows three vector functional units fp add fp multiply loadstore unit vector arithmetic units contains four execution pipelines one per lane acts concert complete single vector instruction note section vectorregist le needs provide enough read write ports see chapter 4 functional units local lane 63 sisd mimd simd spmd vector 515 516 chapter 6 parallel processors client cloud 64 hardware multithreading related concept mimd especially programmers perspective hardware multithreading mimd relies multiple processes threads try keep multiple processors busy hardware multithreading allows multiple threads share functional units single processor overlapping fashion try utilize hardware resour ciently permit sharing processor must duplicate independent state thread example thread would separate copy regist le program counter e memory shared virtual memory mechanisms already support multiprogramming addition hardware must support ability change erent thread relatively quickly particular thread switch much cient process switch typically requires hundreds thousands processor cycles thread switch instantaneous ere two main approaches hardware multithreading finegrained multithreading switches threads instruction resulting interleaved execution multiple thre interleaving en done roundrobin fashion skipping threads stalled clock cycle make negrained multithreading practical processor must able switch threads every clock cycle one advantage negrained multithreading hide throughput losses arise short long stalls since instructions threads executed one thread st e primary disadvantage negrained multithreading slows execution individual threads since thread ready execute without stalls delayed instructions threads coarsegrained multithreading invented alternative negrained multithreading coarsegrained multithreading switches threads costly stalls lastlevel cache miss change relieves need thread switching extremely fast much less likely slow execution individual thread since instructions threads issued thread encounters costly stall coarsegrained multithreadin ers however major drawback limited ability overcome throughput losses especially shorter st limitation arises pipeline startup costs coarsegrained multithreading cause processor coarsegrained multithreading issues instructions single thread stall occurs pipeline must emptied fro e new thread begins executing er stall mu pipeline instructions able complete due startup overhead coarsegrained multithreading much useful reducing penalty highcost stalls pipeline r negligible compared stall time hardware multithreading increasing utilization processor switching another thread one thread stalled thread thread includes program counter register state stack lightweight process whereas threads commonly share single address space processes dont process process includes one threads address space operating system state hence process switch usually invokes operating system thread switch negrained multithreading version hardware multithreading implies switching threads er every instruction coarsegrained multithreading version hardware multithreading implies switching threads er cant events lastlevel cache miss simultaneous multithreading smt variation hardware multithreading uses resources multipleissue dynamically scheduled pipelined processor exploit threadlevel parallelism time exploits instruction level parallelism see chapt e key insight motivates smt multipleissue processors en functional unit parallelism available single threads ca ectively use furthermore register renaming dynamic scheduling see chapter 4 multiple instructions independent threads issued without regard dependences among resolution dependences handled dynamic scheduling capability since smt relies existing dynamic mechanisms switch resources every cycle instead smt always executing instructions multiple threads leaving hardware associate instruction slots renamed registers proper threads figure 65 conceptually illustrates th erences processor ability exploit superscalar resources following processor co gurations e top portion shows simultaneous multithreading smt version multithreading lowers cost multithreading utilizing resources needed multiple issue dynamically scheduled microarchitecture figure 65 four threads use issue slots superscalar processor different approaches e four threads top show would execute running alone standard superscalar processor without multithreading suppor e three examples bottom show would execute running together three multithreading option e horizontal dimension represents instruction issue capability clock cycle e vertical dimension represents sequence clock cycles empty white box indicates corresponding issue slot unused clock cycle e shades gray color correspond fo erent threads multithreading processor e additional pipeline startu ects coarse multithreading illustrated th gure would lead loss throughput coarse multithreading issue slotsthread cthread thread athread b timetimesmtcoarse mtfine mt issue slots 64 hardware multithreading 517 518 chapter 6 parallel processors client cloud four threads would execute independently superscalar multithreading suppor e bottom portion shows four threads could combined execute processor ciently using three multithreading options superscalar coarsegrained multithreading superscalar wi negrained multithreading superscalar simultaneous multithreading superscalar without hardware multithreading support use issue slots limited lack instructionlevel parallelism addition major stall instruction cache miss leave entire processor idle coarsegrained multithreaded superscalar long stalls partially hidden switching another thread uses resources processor although reduces number completely idle clock cycles pipeline startup overhead still leads idle cycles limitations ilp means issue slots used th negrained case interleaving threads mostly eliminates idle clock cycles single thread issues instructions given clock cycle however limitations instructionlevel parallelism still lead idle slots within clock cycles 200175150125100075i7 smt performance energy efficiency ratioblackscholesbodytrackcannealferretfluidanimateraytracestreamclusterswaptions264energy efficiencyspeedupfacesimvipsfigure 66 speedup using multithreading one core i7 processor averages 131 parsec benchmarks see section 69 energy efﬁ ciency improvement 107 data collected analyzed esmaeilzadeh et al 2011 smt case threadlevel parallelism instructionlevel parallelism exploited multiple threads using issue slots single clock cycle ideally issue slot usage limited imbalances resource needs resource availability multiple threads practice factors restrict many slots used although figure 65 greatly simp es real operation processors illustrate potential performance advantages multithreading general smt particular figure 66 plots performance energy ts multithreading single processors intel core i7 960 hardware support two thre e average speedup 131 bad given modest extra resources hardware multithreadin e average improvement energy ciency 107 excellent general youd happy performance speedup energy neutral seen multiple threads utilize resources single processor ectively next show use exploit multiple processors 1 true false multithreading multicore rely parallelism get ciency chip 2 true false simultaneous multithreading smt uses threads improve resource utilization dynamically scheduled outoforder processor 65 multicore shared memory multiprocessors hardware multithreading improved th ciency processors modest cost big challenge last decade deliver performance potential moores law ciently programming increasing number processors per chip given th culty rewriting old programs run well parallel hardware natural question computer designers simplify task one answer provide single physical address space processors share programs need concern data merely programs may executed parallel approach variables program made available time processor e alternative separate address space per processor requires sharing must explicit well describe option section 67 physical address space common hardware typically provides cache coherence give consistent view shared memory see section 58 mentioned shared memory multiprocessor smp one ers programmer single physical address space across processors check 65 multicore shared memory multiprocessors 519 520 chapter 6 parallel processors client cloud nearly always case multicore chips although accurate term would shared address multiprocessor processors communicate shared variables memory processors capable accessing memory location via loads stores figure 67 shows classic organization smp note systems still run independent jobs virtual address spaces even share physical address space single address space multiprocessors come two styles th rst style latency word memory depend processor asks machines called uniform memory access uma multiprocessors second style memory accesses much faster others depending processor asks word typically main memory divided attached erent microprocessors erent memory controllers chip machines called nonuniform memory access numa multiprocessors might expect programming challenges harder numa multiprocessor uma multiprocessor numa machines scale larger sizes numas lower latency nearby memory processors operating parallel normally share data also need coordinate operating shared data otherwise one processor could start working data anot nished coordination called synchronization saw chapter 2 sharing supported single address space must separate mechanism synchronization one approach uses lock shared variable one processor time acquire lock processors interested shared data must wait original processor unlocks variable section 211 chapter 2 describes instructions locking mips instruction set uniform memory access uma multiprocessor latency word main memory matter processor requests access nonuniform memory access numa type single address space multiprocessor memory accesses much faster others depending processor asks word synchronization e process coordinating behavior two processes may running erent processors lock synchronization device allows access data one processor time figure 67 classic organization shared memory multiprocessor processormemoryioprocessorprocessorcachecachecacheinterconnection network simple parallel processing program shared address space suppose want sum 64000 numbers shared memory multiprocessor computer uniform memory access time let assume 64 processors e rst step ensure balanced load per processor split set numbers subsets size allocate subsets erent memory space since single memory space machine give di erent starting addresses processor pn number iden es processor 0 63 processors start program running loop sums subset numbers sumpn 0 1000pn 1000pn1 1 sumpn ai sum assigned areasnote c code 1 shorter way say 1 e next step add 64 partial sum step called reduction divide conquer half processors add pairs partial sums quarter add pairs new partial sums single nal sum figure 68 illustrates hierarchical nature reduction example two processors must synchronize consumer processor tries read result memory location written producer processor otherwise consumer may read old value exampleanswerreduction function processes data structure returns single value 001012301234567half 1half 2 half 4figure 68 last four levels reduction sums results processor bottom top processors whose number less half add sum produced processor number half sum 65 multicore shared memory multiprocessors 521 522 chapter 6 parallel processors client cloud data want processor version loop counter variable must indicate private variable code half private also half 64 64 processors multiprocessor synch wait partial sum completion half2 0 pn 0 sum0 sumhalf1 conditional sum needed half odd processor0 gets missing element half half2 dividing line sums pn half sumpn sumpnhalf half 1 exit final sum sum0 given longterm interest parallel programming hundreds attempts build parallel programming systems limited popular example openmp application programmer interface api along set compiler directives environment variables runtime library routines extend standard programming languages ers portable scalable simple programming model shared memory multiprocessors primary goal parallelize loops perform reductions c compilers already support openmp e command uses openmp api unix c compiler cc fopenmp foocopenmp extends c using pragmas commands c macro preprocessor like define include set number processors want use 64 wanted example use command define p 64 define constant well use times pragma omp parallel num_threadsp runtime libraries use 64 parallel threads turn sequential loop parallel loop divides work equally threads told use write assuming sum initialized 0 pragma omp parallel pn 0 pn p pn 1 0 1000pn 1000pn1 1 sumpn ai sum assigned areashardware software interfaceopenmp api shared memory multiprocessing c c fortran runs unix microso platforms includes compiler directives library runtime directives perform reduction use another command tells openmp reduction operator variable need use place result reduction pragma omp parallel reduction finalsumfor 0 p 1 finalsum sumi reduce single number note openmp library nd cient code sum 64 number ciently using 64 processors openmp makes easy write simple parallel code helpful debugging many parallel programmers use sophisticated parallel programming systems openmp many programmers today use productive languages c given tour classic mimd hardware ware next path exotic tour type mimd architecture erent heritage thus erent perspective parallel programming challenge true false shared memory multiprocessors take advantage tasklevel parallelism elaboration writers repurposed acronym smp mean symmetric multiprocessor indicate latency processor memory processors shift done contrast largescale numa multiprocessors classes used single address space clusters proved much popular largescale numa multiprocessors book restore smp original meaning use contrast use multiple address spaces clusters elaboration alternative sharing physical address space would separate physical address spaces share common virtual address space leaving operating system handle communication approach tried high overhead offer practical shared memory abstraction performanceoriented programmer check 65 multicore shared memory multiprocessors 523 524 chapter 6 parallel processors client cloud 66 introduction graphics processing units e original ju cation adding simd instructions existing architectures many microprocessors connected graphics displays pcs workstations increasing fraction processing time used graphics moores law increased number transistors available microprocessors therefore made sense improve graphics processing major driving force improving graphics processing computer game industry pcs dedicated game consoles sony playstation e rapidly growing game market encouraged many companies make increasing investments developing faster graphics hardware positive feedback loop led graphics processing improve faster rate generalpurpose processing mainstream microprocessors given graphics game communi erent goals microprocessor development community evolved style processing terminology graphics processors increased power earned name graphics processing units gpus distinguish cpus hundred dollars anyone buy gpu today hundreds parallel oatingpoint units makes highperformance computing accessible e interest gpu computing blossomed potential combined programming language made gpus easier program hence many programmers scien c multimedia applications today pondering whether use gpus cpus section concentrates using gpus computing see gpu computing combines traditional role graphics acceleration see appendix c key characteristics gpus vary cpus gpus accelerators supplement cpu need able perform tasks cpu role allows dedicate resources graphics ne gpus perform tasks poorly given system cpu gpu cpu needed e gpu problems sizes typically hundreds megabytes gigabytes hundreds gigabytes terabytes ese erences led erent styles architecture perhaps bigg erence gpus rely multilevel caches overcome long latency memory cpus instead gpus rely hardware multithreading section 64 hide latency memory time memory request time data arrives gpu executes hundreds thousands threads independent request e gpu memory thus oriented toward bandwidth rather latency ere even special graphics dram chips gpus wider higher bandwidth dram chips cpus addition gpu memories traditionally smaller main memories conventional microprocessors 2013 gpus typically 4 6 gib less cpus 32 256 gib finally keep mind generalpurpose computation must include time transfer data cpu memory gpu memory since gpu coprocessor given reliance many threads deliver good memory bandwidth gpus accommodate many parallel processors mimd well many threads hence gpu processor highly multithreaded typical cpu plus processors although gpus designed narrower set applications programmers wondered could specify applications form would let tap high potential performance gpu er tiring trying specify problems using graphics apis languages developed cinspired programming languages allow write programs directly gpus example nvidia cuda compute u ed device architecture enables programmer write c programs execute gpus albeit restrictions appendix c gives examples cuda code opencl multi company initiative develop portable programming language provides many ts cuda nvidia decided unifying theme forms parallelism cud read using lowest level parallelism programming primitive compiler hardware gang thousands cud reads together utilize various styles parallelism within gpu multithreading mimd simd instructionlevel pa ese threads blocked together executed groups 32 time multithreaded processor inside gpu executes blocks threads gpu consists 8 32 multithreaded processors introduction nvidia gpu architecturewe use nvidia systems example representative gpu architectures sp cally follow terminology cuda parallel programming language use fermi architecture example like vector architectures gpus work well datalevel parallel problems styles gatherscatter data transfers gpu processors even hardware software interface 66 introduction graphics processing units 525 526 chapter 6 parallel processors client cloud registers vector processors unlike vector architectures gpus also rely hardware multithreading within single multithreaded simd processor hide memory latency see section 64 multithreaded simd processor similar vector processor former many parallel functional units instead deeply pipelined latter mentioned gpu contains collection multithreaded simd processors gpu mimd composed multithreaded simd processors example nvidia four implementations fermi architecture erent price points 7 11 14 15 multithreaded simd processors provide transparent scalability across models gpus wit ering number multithreaded simd processors th read block scheduler hardware assigns blocks threads multithreaded simd processors figure 69 shows simp ed block diagram multithreaded simd processor dropping one level detail machine object hardware creates manages schedules executes thread simd instructions also call simd thread traditional thread contains exclusively simd instruction ese simd threads program counters run multithreaded simd processor e read scheduler includes controller lets know threads simd instructions ready run sends dispatch unit run multithreaded figure 69 simpliﬁ ed block diagram datapath multithreaded simd processor 16 simd la e read scheduler many independent simd threads chooses run processor instruction register registers1k32loadstoreunitloadstoreunitloadstoreunitloadstoreunitaddress coalescing unitinterconnection network local memory 64kib global memory loadstoreunitloadstoreunitloadstoreunitloadstoreunitload storeunitloadstoreunitloadstoreunitloadstoreunitloadstoreunitloadstoreunitloadstoreunitloadstoreunitreg 1k32reg 1k32reg 1k32reg 1k32reg 1k32reg 1k32reg 1k32reg 1k32reg 1k32reg 1k32reg 1k32reg 1k32reg 1k32reg 1k32reg 1k32simd lanesthreadprocessors simd processor identical hardware thread scheduler traditional multithreaded processor see section 64 except scheduling threads simd instruction us gpu hardware two levels hardware schedulers e read block scheduler assigns blocks threads multithreaded simd processors 2 read scheduler within simd processor schedules simd threads run e simd instructions threads 32 wide thread simd instructions would compute 32 elements computation since thread consists simd instructions simd processor must parallel functional units perform operation call simd lanes quite similar vector lanes section 63 elaboration number lanes per simd processor varies across gpu generations fermi 32wide thread simd instructions mapped 16 simd lanes simd instruction thread simd instructions takes two clock cycles complete thread simd instructions executed lock step staying analogy simd processor vector processor could say 16 lanes vector length would 32 wide shallow nature use term simd processor instead vector processor intuitive since b nition threads simd instructions independent simd thread scheduler pick whatever thread simd instructions ready need stick next simd instruction sequence within single thread thus using terminology section 64 negrained multithreading hold memory elements fermi simd processor impressive 32768 32bit registers like vector processor registers divided logically across vector lanes case simd lanes simd thread limited 64 registers might think simd thread 64 vector registers vector register 32 elements element 32 bits wide since fermi 16 simd lanes contains 2048 registers cuda thread gets one element vector registers note cuda thread vertical cut thread simd instructions corresponding one element executed one simd lane beware cuda threads different posix threads cant make arbitrary system calls synchronize arbitrarily cuda thread nvidia gpu memory structures figure 610 shows memory structures nvidia gpu call chip memory local multithreaded simd processor local memory shared simd lanes within multithreaded simd processor memory shared multithreaded simd processors call chip dram shared whole gpu thread blocks gpu memory rather rely large caches contain whole working sets application gpus traditionally use smaller streaming caches rely extensive multithreading threads simd instructions hide long latency dram 66 introduction graphics processing units 527 528 chapter 6 parallel processors client cloud since working sets hundreds megabyt us last level cache multicore microprocessor given use hardware multithreading hide dram latency chip area used caches system processors spent instead computing resources large number registers hold state many threads simd instructions elaboration hiding memory latency underlying philosophy note latest gpus vector processors added caches example recent fermi architecture added caches thought either band lters reduce demands gpu memory accelerators variables whose latency hidden multithreading local memory stack frames function calls register spilling good match caches since latency matters calling function caches also save energy since onchip cache accesses take much less energy accesses multiple external dram chips cuda thread thread block perblock local memory grid 0 grid 1 gpu memory sequenceintergrid synchronization percuda thread private memoryfigure 610 gpu memory structures gpu memory shared vectorized loops threads simd instructions within thread block share local memory putting gpus perspective high level multicore computers simd instruction extensions share similarities gpus figure 611 summarizes similarities erences mimds whose processors use multiple simd lanes although gpus processors many lanes use hardware multithreading improve processor utilization although gpus hardware support many threads use caches although gpus use smaller streaming caches multicore computers use large multilevel caches try contain whole working sets completely use 64bit address space although physical main memory much smaller gpus gpus support memory protection page level yet support demand paging simd processors also similar vector processor e multiple simd processors gpus act independent mimd cores many vector computers multiple vector processor view would consider fermi gtx 580 16core machine hardware support multithreading core 16 la e bigg erence multithreading fundamental gpus missing vector processors gpus cpus go back computer architecture genealogy common ancestor missing link explains result uncommon heritage gpus used terms common computer architecture community led confusion gpus work help resolve confusion figure 612 fro right lists descriptive term used section closest term mainstream computing cial nvidia gpu term case interested short description ter gpu rosetta stone may help relate section ideas conventional gpu descriptions found appendix c gpus moving toward mainstream computing abandon responsibility continue excel grap us design gpus may featuremulticore simdgpu simd processorssimd lanesprocessor multithreading hardware support simd threads largest cache size size memory address size main memory memory protection level page demand pagingcache coherent4 88 168 1616 322 42 48 mib075 mib8 gib 256 gib4 gib 6 gib 64bit64bityes yes nonoyes yes figure 611 similarities differences multicore multimedia simd extensions recent gpus 66 introduction graphics processing units 529 530 chapter 6 parallel processors client cloud make sense architects ask given hardware invested graphics well supplement improve performance wider range applications covered tw erent styles mimd shared address space next introduce parallel processors processor private address space makes much easier build much larger system e internet services use every day depend large scale systems typemore descriptivenamevectorizable loopbody ofvectorized loopbody stripmined vectorized loopthread blocksequence simd laneoperationsone iteration ofa scalar loopcuda threada thread simdinstructionsthread vectorinstructionswarpsimdinstructionvector instructionptx instructionmultithreadedsimdprocessormultithreaded vector processorstreamingmultiprocessorthread block schedulerscalar processorgiga thread enginesimd thread schedulerthread scheduler multithreaded cpuwarp schedulersimd lanevector lanethread processor gpu memorymain memoryglobal memory local memorylocal memoryshared memory simd laneregistersvector lane registersthread processor registersa vectorized loop executed multithreaded simd processor made one threads simd instructions communicate via local memoryprogram abstractionsmachine objectprocessing hardwarememory hardwarea vertical cut thread simd instructions corresponding one element executed one simd lane result stored depending maskand predicate registera traditional thread contains simdinstructions executed multithreaded simd processor results stored depending perelement maska single simd instruction executed across simdlanesa multithreaded simd processor executesthreads simd instructions independent simd processorsassigns multiple thread blocks bodies ofvectorized loop multithreaded simdprocessorshardware unit schedules issues threadsof simd instructions ready execute includes scoreboard track simd thread executiona simd lane executes operations thread simd instructions single element results stored depending maskdram memory accessible multithreaded simd processors gpufast local sram one multithreaded simdprocessor unavailable simd processorsregisters single simd lane allocated acrossa full thread block body vectorized loopvectorizable loopgrid vectorizable loop executed gpu made one thread blocks bodies vectorized loop execute parallelclosest old term outside gpusofficial cuda nvidia gpu termbook definitionfigure 612 quick guide gpu terms use th rst column hardware terms four groups cluster 12 terms top bottom program abstractions machine objects processing hardware memory hardware elaboration gpu introduced separate memory cpu amd intel announced fused products combine gpus cpus share single memory challenge maintain high bandwidth memory fused architecture foundation gpus true false gpus rely graphics dram chips reduce memory latency thereby increase performance graphics applications 67 clusters warehouse scale computers messagepassing multiprocessors e alternative approach sharing address space processors private physical address space figure 613 shows classic organization multiprocessor multiple private addr alternative multiprocessor must communicate via explicit message passing traditionally name style computers provided system routines send receive messages coordination built message passing since one processor knows message sent receiving processor knows message arrives sender needs co rmation message arrived receiving processor send acknowledgment message back sender ere several attempts build largescale computers based highperformance messagepassing networks er better absolute check message passing communicating multiple processors explicitly sending receiving information send message routine routine used processor machines private memories pass message another processor receive message routine routine used processor machines private memories accept message another processor cachecachecachememorymemorymemoryinterconnection network processorprocessorprocessor figure 613 classic organization multiprocessor multiple private address spaces traditionally called messagepassing multiprocessor note unlike smp figure 67 interconnection network caches memory instead processormemory nodes 67 clusters warehouse scale computers messagepassing multiprocessors 531 532 chapter 6 parallel processors client cloud communication performance clusters built using local area networks indeed many supercomputers today use custom networ e problem much expensive local area networks like ethernet applications today outside high performance computing justify higher communication performance given much higher costs computers rely message passing communication rather cache coherent shared memory much easier hardware designers build see sectio ere advantage programmers well communication explicit means fewer performance surprises implicit communication cachecoherent shared memory computer e downside programmers harder port sequential program message passing computer since every communication must iden ed advance program work cachecoherent shared memory allows hardware gure data needs communicated makes porting easier ere ar erences opinion shortest path high performance given pros cons implicit communication confusion marketplace today multicore microprocessors use shared physical memory nodes cluster communicate using message passing concurrent applications run well parallel hardware independent whether ers shared addresses message passing particular tasklevel parallelism applications little communication like web search mail servers le servers require shared addressing run well result clusters become widespread example today messagepassing parallel computer given separate memories node cluster runs distinct copy operating system contrast cores inside microprocessor connected using highspeed network inside chip multichip shared memory system uses memory interconnect communicatio e memory interconnect higher bandwidth lower latency allowing much better communication performance shared memory multiprocessors e weakness separate memories user memory parallel programming perspective turns strength system dependability see section 55 since cluster consists independent computers co nnected local area network much easier replace computer without bringing system cluster shared memory multiprocessor fundamentally shared address means di cult isolate processor replace without heroic work operating system physical design server also easy clusters scale gracefully server fails thereby improving dependability since cluster ware layer runs top local operating systems running computer much easier disconnect replace broken computer hardware software interfaceclusters collections computers connected via io standard network switches form messagepassing multiprocessor given clusters constructed whole computers independent scalable networks isolation also makes easier expand system without bringing application runs top cluster eir lower cost higher availability rapid incremental expandability make clusters attractive service internet providers despite poorer communication performance compared largescale shared memory multiprocessor e search engines hundreds millions us use every day depend upon technology amazon facebook google microso others multiple datacenters clusters tens thousands servers clearly use multiple processors internet service companies hugely successful warehousescale computers internet services described necessitated construction new buildings house power cool 100000 servers although may cl ed large clusters architecture operation sophisticated ey act one giant computer cost order 150m building electrical cooling infrastructure servers networking equipment connects houses 50000 100000 servers consider new class computer called warehousescale computers wsc e popular framework batch processing wsc mapreduce dean 2008 opensource twin hadoop inspired lisp functions name rst applies programmersupplied function logical input record map runs thousands servers produce intermediate result key value pairs reduce collects output distributed tasks collapses using another programmer ned function appropriate ware support highly parallel yet easy understand use within 30 minutes novice programmer run mapreduce task thousands servers example one mapreduce program calculates number occurrences every english word large collection documents simp ed version program shows inner loop assumes one occurrence english words found document hardware software interface 67 clusters warehouse scale computers messagepassing multiprocessors 533anyone build fast cpu e trick build fast system seymour cray considered father supercomputer mapstring key string value key document name value document contents word w valueemitintermediatew 1 produce list words reducestring key iterator values key word values list counts int result 0 v values result parseintv get integer keyvalue pair emitasstringresult 534 chapter 6 parallel processors client cloud e function emitintermediate used map function emits word document value one en reduce function sums values per word document using parseint get number occurrences per word documen e mapreduce runtime environment schedules map tasks reduce tasks servers wsc extreme scale requires innovation power distribution cooling monitoring operations wsc modern descendant 1970s supercomputersmaking seymour cray godfather todays wsc architects extreme computers handled computations could done nowhere else expensive companies could ord time target providing information technology world instead high performance computing scientists engineers hence wscs surely play important societal role today crays supercomputers past share common goals servers wscs three major distinctions 1 ample easy parallelism concern server architect whether applications targeted marketplace enough parallelism justify amount parallel hardware whether cost high fo cient communication hardware exploit parallelism wsc architect concern first batch applications like mapreduce b large number independent data sets need independent processing billions web pages web crawl second interactive internet service applications also known ware service saas b millions independent users interactive internet services reads writes rarely dependent saas saas rarely needs synchronize example search uses readonly index email normally reading writing independent information call type easy parallelism requestlevel parallelism many independen orts proceed parallel naturally little need communication synchronization 2 operational costs count traditionally server architects design systems peak performance within cost budget worry energy make sure dont exceed cooling capacity enclosure ey usually ignored operational costs server assuming pale comparison purchase costs wsc longer lifetimesthe building electrical cooling infrastructure en amortized 10 yearsso operational costs add energy power distribution cooling represent 30 costs wsc 10 years 3 scale opportunitiesproblems associated scale construct single wsc must purchase 100000 servers along supporting infrastructure means volume discounts hence wscs massive ware service saas rather selling ware installed run customers computers ware run remote site made available internet typically via web interface customers saas customers charged based use versus ownership internally get economy scale even many wscs ese economies scale led cloud computing lower per unit costs wsc meant cloud companies could rent servers pro table rate still costs outsiders themselv e ip side economic opportunity scale need cope failure frequency scale even server mean time failure amazing 25 years 200000 hours wsc architect would need design 5 server failures every day section 515 mentioned annualized disk failure rate afr measured google 2 4 4 disks per server annual failure rate 2 wsc architect expect see one disk fail every hour us fault tolerance even important wsc architect server architect e economies scale uncovered wsc realized long dreamed goal computing utility cloud computing means anyone anywhere good ideas business model credit card tap thousands servers deliver vision almost instantly around world course important obstacles could limit growth cloud computingsuch security privacy standards rate growth internet bandwidthbut foresee addressed wscs cloud computing ca ourish put growth rate cloud computing perspective 2012 amazon web services announced adds enough new server capacity every day support amazons global infrastructure 2003 amazon 52bn annual revenue enterprise 6000 employees understand importance messagepassing multiprocessors especially cloud computing next cover ways connect nodes wsc together anks moores law increasing number cores per chip need networks inside chip well topologies important small well large elaboration mapreduce framewor es sorts keyvalue pairs end map phase produce groups share key groups passed reduce phaseelaboration another form large scale computing grid computing computers spread across large areas programs run across must communicate via long haul networks popular unique form grid computing pioneered setihome project millions pcs idle one time nothing useful could harvested put good uses someone developed software could run computers gave pc independent piece problem wor rst example search extraterrestrial intelligence seti launched uc berkeley 1999 5 million computer users 200 countries signed setihome 50 outside us end 2011 average performance setihome grid 35 petaflops 67 clusters warehouse scale computers messagepassing multiprocessors 535 536 chapter 6 parallel processors client cloud 1 true false like smps messagepassing computers rely locks synchronization 2 true false clusters separate memories thus need many copies operating system 68 introduction multiprocessor network topologies multicore chips require onchip networks connect cores together clusters require local area networks connect servers together section reviews pros cons erent interconnection network topologies network costs include number switches number links switch connect network width number bits per link length links network mapped silicon example cores servers may adjacent others may side chip side datacenter network performance multifaceted well includes latency unloaded network send receive message throughput terms maximum number messages transmitted given time period delays caused contention portion network variable performance depending pattern communication another obligation network may fault tolerance since systems may required operate presence broken components finally era energylimited systems energy ciency erent organizations may trump concerns networks normally drawn graphs edge graph representing link communication network th gures section processor memory node shown black square switch shown colored circle assume links bidirectional information ca ow either direction networks consist switches whose links go processor memory nodes switch e rst network connects sequence nodes together topology called ring since nodes directly connected messages hop along intermediate nodes arrive th nal destination unlike busa shared set wires allows broadcasting connected devicesa ring capable many simultaneous transfers check numerous topologies choose performance metrics needed distinguish designs two popular e rst total network bandwidth bandwidth link multiplied number links represents peak bandwidth ring network p processors total network bandwidth would p times bandwidth one link total network bandwidth bus bandwidth bus balance best bandwidth case include another metric closer worst case bisection bandwidth metric calculated dividing machine two halv en sum bandwidth links cross imaginary dividing line e bisection bandwidth ring two times link bandwidth one times link bandwidth bus single link fast bus ring twice fast bus worst case p times faster best case since network topologies symmetric question arises draw imaginary line bisecting machine bisection bandwidth worstcase metric answer choose division yields pessimistic network performance stated alternatively calculate possible bisection bandwidths pick smallest take pessimistic view parallel programs en limited weakest link communication chain extreme ring fully connected network every processor bidirectional link every processor fully connected networks total network bandwidth p p 12 bisection bandwidth p22 e tremendous improvement performa nce fully connected networks set tremendous increas consequence inspires engineers invent new topologies cost rings performance fully connected networ e evaluation success depends large part nature communication workload parallel programs run computer e number erent topologies discussed publications would cult count used commercial parallel processors figure 614 illustrates two popular topologies alternative placing processor every node network leave switch e switches smaller processormemory switch nodes thus may packed densely thereby lessening distance increasing performance networks frequently called multistage networks ect multiple steps message may travel types multistage networks numerous singlestage networks figure 615 illustrates two popular multistage organizations fully connected crossbar network allows node communicate node one pass network omega network uses less hardware crossbar network 2 n log2 n versus n2 switches contention occur messages depending pattern network bandwidth informally peak transfer rate network refer speed single link collective transfer rate links network bisection bandwidth e bandwidth two equal parts multiprocessor measure worst case split multiprocessor fully connected network network connects processor memory nodes supplying dedicated communication link every node multistage network network supplies small switch node crossbar network network allows node communicate node one pass network 68 introduction multiprocessor network topologies 537 538 chapter 6 parallel processors client cloud communication example omega network figure 615 send message p 0 p 6 time sends message p 1 p 4implementing network topologies simple analysis networks section ignores important practical considerations construction networ e distance link ects cost communicating high clock rate generally longer distance expensive run high clock rate shorter distances also make easier assign wires link power drive many wires less wires short shorter wires also cheaper longer wires another practical limitation threedimensional drawings must mapped onto chips essentially twodimensio e nal concern energy energy concerns may force multicore chips rely simple grid topologies example e bottom line topologies appear elegant sketched blackboard may impractical constructed silicon datacenter understand importance clusters seen topologies follow connect together next look hardware ware interface network processor true false ring p nodes ratio total network bandwidth bisection bandwidth p2 check 2d grid mesh 16 nodesb ncube tree 8 nodes 8 23 n 3figure 614 network topologies appeared commercial parallel processors e colored circles represent switches black squares represent processormemory nodes even though switch many links generally one goes processor e boolean ncube topology ndimensional interconnect 2n nodes requiring n links per switch plus one processor thus n nearestneighbor nodes frequently basic topologies supplemented extra arcs improve performance reliability 5969 communicating outside world cluster networking online section describes networking hardware ware used connect nodes cluster together e example 10 gigabitsecond ethernet connected computer using peripheral component interconnect express pcie shows ware hardware optimizations improve network performance including zero copy messaging user space communication using polling instead io interrupts hardware calculation checksums example networking techniques section apply storage controllers io devices well crossbarb omega networkc omega network switch boxcda bp0p1p2p3p4p5p6p7p0p1p2p3p4p5p6p7figure 615 popular multistage network topologies eight nodes e switches drawings simpler earlier drawings links unidirectional data comes th exits righ e switch box c pass c b b c e crossbar uses n 2 switches n number processors omega network uses 2n log 2n large switch boxes logically composed four smaller switches case crossbar uses 64 switches versus 12 switch boxes 48 switches omega networ e crossbar however support combination messages processors omega network 69 communicating outside world cluster networking 539 communicating outside world cluster networking online section describes networking hardware ware used connect nodes cluster together whole books courses networking section introduces main terms concepts example networking techniques describe apply storage controllers io devices well ethernet dominated local area networks decades surprising clusters primarily rely ethernet cluster interconnect became commercially popular 10 megabits per second link speed 1980s today 1 gigabit per second ethernet standard 10 gigabit per second deployed datacenters figure 691 shows network interface card nic 10 gigabit ethernet computers er highspeed links plug fast io devices like nic used separate chips connect microprocessor memory highspeed io devices thanks moores law functions absorbed main chip recent erings like intels sandy bridge popular high speed link today pcie stands peripheral component interconnect express called link basic building block called serial lane consists four wires two receiving data two transmitting data small number contrasts earlier version pci consisted 64 5969figure 691 netfpga 10gigabit ethernet card see httpnetfpgaorg connects four 10gigabitsec ethernet links fpgabased open platform network research classroom experimentation e dma engine four mac chips figure 692 portions xilinx virtex fpga middle board e four phy chips figure 692 four black squares right four white rectangles th edge board ethernet cables plugged 69 communicating outside world cluster networking 693wires called parallel bus pcie allows anywhere 1 32 lanes used connect io devices depending nic uses pci 11 lane transfers 2 gigabitssecond e nic figure 691 connects host computer 8lane pcie link ers 16 gigabitssecond directions communicate nic must send transmit messages receive en abbreviated tx rx respectively nic 10g link uses separate transmit receive queues store two fulllength ethernet packets used ethernet links nic figure 692 block diagram nic showing tx rx q e nic also two 32entry queues transmitting receiving host computer nic give command nic processor must able address device supply one command words memorymapped io portions address space assigned io devices initialization boot time pcie devices request assigned address region sp ed length subsequent processor reads writes address region forwarded pcie device reads writes addresses interpreted commands io device example write operation used send data network interface data interpreted command processor issues address data memory system ignores operation address indicates portion memory space used io e nic however sees operation records data user programs prevented issuing io operations directly os provide access address space assigned io devices thus addresses protected address translation memorymapped io also used transmit data writing reading select address e device uses address determine type command data may provided write obtained read event address encodes device identity type transmission processor device memorymapped io io scheme portions address space assigned io devices reads writes addresses interpreted commands io device pcietxrxdmamac mac mac mac phyphyphyphyport 0 port 1 port 2 port 3 controldatafigure 692 block diagram netfpga ethernet card figure 691 showing control paths data paths e control path allows dma engine read status queues empty vs onempty content next available queue entry e dma engine also controls port multiplexin e data path simply passes dma block txrx queues main memory e mac chips described e phy chips refer physical layer connect mac chips physical networking medium copper wire opt ber 694 69 communicating outside world cluster networking processor could transfer data user space io space overhead transferring data highspeed network could intolerable since could consume large fraction processor us computer designers long ago invented mechanism oading processor device controller transfer data directly memory without involving processor mechanism called direct memory access dma dma implemented specialized controller transfers data network interface memory independent processor case dma engine inside nic notify operating system eventually application receive packet transfer complete dma sends io interrupt io interrupt like exceptions saw chapters 4 5 two important distinctions 1 io interrupt asynchronous respect instruction execution interrupt associated instruction prevent instruction completion ver erent either page fault exceptions exceptions arithmetic ow control unit needs check pending io interrupt time starts new instruction 2 addition fact io interrupt occurred would like convey information identity device generating interrupt furthermore interrupts represent devices may erent priorities whose interrupt requests hav erent urgencies associated communicate information processor identity device raising interrupt system use either vectored interrupts exception iden cation register called cause register mips see section 49 processor recognizes interrupt device send either vector address stat eld place cause register result os gets control knows identity device caused interrupt immediately interrogate device interrupt mechanism eliminates need processor keep checking device instead allows processor focus executing programs role operating system networking e operating system acts interface hardware program requests io e network responsibilities operating system arise three characteristics networks 1 multiple programs using processor share network 2 networks en use interrupts communicate information operations interrupts cause transfer kernel supervisor mode must handled operating system os direct memory access dma mechanism provides device controller ability transfer data directly memory without involving processor interruptdriven io io scheme employs interrupts indicate processor io device needs attention 69 communicating outside world cluster networking 69 5 e lowlevel control network complex requires managing set concurrent events requirements correct device control en detailed ese three characteristics networks sp cally io systems general lead sev erent functions os must provide e os guarantees users program accesses portions io device user rights example os must allow program read writ le disk owner th le granted access program system shared io devices protection could provided user programs could perform io directly e os provides abstractions accessing devices supplying routines handle lowlevel device operations e os handles interrupts generated io devices handles exceptions generated program e os tries provide equitable access shared io resources well schedule accesses enhance system throughput e ware inside operating system interfaces sp c io device like nic called device driver e driver nic follo steps transmitting receiving message figure 693 shows relationship steps ethernet packet sent one node cluster received another node cluster first transmit steps e driv rst prepares packet bu er host memory copies packet user address space b er allocates operating system address space 2 next talks ni e driver writes io descriptor appropriate nic register gives address b er length e dma nic next copies outgoing ethernet packet host bu er pcie 4 transmission complete dma interrupts processor notify processor packet successfully transmitted 5 finally driver deallocates transmit bu er hardware software interfacedevice driver program controls io device attached computer 696 69 communicating outside world cluster networking next receive steps 1 first driver prepares packet b er host memory allocating new bu er place received packet 2 next talks ni e driver writes io descriptor appropriate nic register gives address b er length e dma nic next copies incoming ethernet packet pcie allocated host b er 4 transmission complete dma interrupts processor notify host newly received packet size 5 finally driver copies received packet user address space see figure 693 th rst three steps time critical transmitting packet since last two occur er packet sent last three steps time critical receiving packet since th rst two occur packet arrives however noncritical steps must completed individual nodes run resources memory space failure negatively ects network performance sourcestep 1step 2step 3step 3niccpuramstep 2step 1step 4step 5destinationethernet step 4step 5ramcpunicpciepciefigure 693 relationship ﬁ steps driver transmitting ethernet packet one node receiving packet another node 69 communicating outside world cluster networking 697improving network performance e importance networking clusters means certainly worthwhile try improve performance show ware hardware techniques starting ware optimizations one performance target reducing number times packet copied may noticed happening repeatedly th steps driver e zerocopy optimization allows dma engine get message directly user program data space transmission placed user wants message received rather go intermediary bu ers operating system along way second ware optimization cut operating system almost entirely moving communication user address space invoking operating system causing context switch reduce ware overhead considerably radical scenario third step would drop interrupts one reason modern processors normally go lower power mode waiting interrupt takes time come low power service interrupt well disruption pipeline increases latency e alternative interrupts processor periodically check status bits see io operation complete called polling hence require user program poll nic continuously see dma unit delivered message ect processor go low power mode looking hardware optimizations one potential target improvement calculating values th elds ethernet pack e 48bit ethernet address called media access control address mac address unique number assigned ethernet nic improve performance mac chipactually portion fpga niccalculates value preamb elds cr eld see sectio e driv placing mac destination address mac source address message type data payload padding needed ethernet requires minimum packet including header cr elds preamble 64 bytes note even least expensive ethernet nics crc calculation hardware today second hardware optimization available recent intel processors ivy bridge improves performance nic respect memory hierarchy direct data io ddio allowing 10 last level cache used fast scratchpad dma engine data copied directly last level cache rather dram dma written dram upon eviction cache optimization helps latency also bandwidth memory regions used control might written nic repeatedly writes longer need go dr us ddio ers ts similar write back cache versus write cache chapter 5 lets look object store follows clientserver architecture uses optimizations zero copy messaging user space communication polling instead interrupts hardware calculation preamble cr e driver polling e process periodically checking status io device determine need service device 698 69 communicating outside world cluster networking operates user address space library application invokes grants application exclusive direct access nic io register space nic mapped application driver state kept application e os kernel doesnt even see nic avoids overheads context switching standard kernel network ware stack interrupts figure 694 shows time send object one node another varies 95 125 microseconds depending size object time step microseconds 07 client driver library make request driver tx figure 694 64 87 nic hardware transmit clients request pcie bus ethernet depending size object nic tx 002 send object 10 g ethernet time fligh e time ight limited speed light 5 ns per meter e threemeter cables used measurement mean time ight 15 ns small clearly visible th gure 02468101214064128192 256 3203844485125766407047688328969601024108811521216128013441408latency microseconds object size b driver rx nic rx time flight nic tx driver tx figure 694 time send object broken transmit driver nic hardware time vs receive driver nic hardware time nic transmit time much larger nic receive time transmit requires pcie roundtri e nic pcie reads read descriptor data receive nic pcie writes data length data interrupt pcie reads incur round trip latency nic waits reply pcie writes require response pcie reliable pcie writes sent backtoback 69 communicating outside world cluster networking 69918 25 nic hardware receive object depen ding size nic rx 06 server driver transmit message requested object app driver rx seen measure performance network low level detail lets raise perspective see benchmark multiprocessors kinds much higher level programs elaboration three versions pcie nic uses pcie 11 transfers 2 gigabits per second per lane nic transfers 16 gigabits per second direction pcie 20 found pc motherboards today doubles lane bandwidth 4 gigabits per second pcie 30 doubles 8 gigabits per second starting found motherboards applaud standard committees logical rate bandwidth improvement 2 version number gigabitssecond limitations virtex 5 fpga prevented nic using faster versions pcie elaboration ethernet foundation cluster communication clusters commonly use higherlevel protocols reliable communication transmission control protocol internet protocol tcpip although invented planetwide communication often used inside warehouse scale computer due part dependability ip makes deliver guarantees protocol tcp sender keeps packet sent gets acknowledgment message back received correctly receiver receiver knows message corrupted along way eld ensure ip delivers right destination ip header includes checksum make sure destination number remains unchanged success internet due large part elegance popularity tcpip allows independent local area networks communicate dependably given importance internet clusters many accelerated tcpip using techniques like listed section regnier 2004 elaboration adding dma another path memory systemone go address translation mechanism cache hierarchy difference generates problems virtual memory caches problems usually solved combination hardware techniques software support culties dma virtual memory system arise pages physical virtual address dma also creates problems systems caches two copies data item one cache one memory dma issues memory requests directly memory rather processor cache value memory location seen dma unit processor may differ consider read nic dma unit places directly memory locations dma writes cache processor receive old value read similarly cache write back dma may read value directly memory newer value 6910 69 communicating outside world cluster networking cache value written back called stale data problem coherence problem see chapter 5 similar solutions coherence used dmaelaboration virtual machine support clearly negatively impact networking performance result microprocessor designers adding hardware reduce performance overhead virtual machines networking particular io general intel offers virtualization technology directed io vtd help virtualize io io memory management unit enables guest virtual machines directly use io devices ethernet supports dma remapping allows dma read write data directly io buffers guest virtual machine rather host io buffers copy guest io buffers also supports interrupt remapping lets virtual machine monitor route interrupt requests directly proper virtual machine two options networking using interrupts polling using dma using processor via load store instructions 1 want lowest latency small packets combination likely best 2 want lowest latency large packets combination likely best check 540 chapter 6 parallel processors client cloud er covering performance network low level detail online section next section shows benchmark multiprocessors kinds much higherlevel programs 610 multiprocessor benchmarks performance models saw chapter 1 benchmarking systems always sensitive topic highly visible way try determine system better e results ect sales commercial systems also reputation designers systems hence participants want win competition also want sure someone else wins deserve win genuinely better syst desire leads rules ensure benchmark results simply engineering tricks benchmark instead advances improve performance real applications avoid possible tricks typical rule change benchmark e source code data sets ar xed single proper answer deviation rules makes results invalid many multiprocessor benchmarks follow traditions common exception able increase size problem run benchmark systems widel erent number processor many benchmarks allow weak scaling rather require strong scaling even though must take care comparing results programs runnin erent problem sizes figure 616 gives summary several parallel benchmarks also described linpack collection linear algebra routines routines performing gaussian elimination constitute known linpack benchmar e dgemm routine example page 215 represents small fraction source code linpack benchmark accounts execution time benchmark allows weak scaling letting user pick size problem moreover allows user rewrite linpack almost form language long computes proper result performs number oating point operations given problem size twice year 500 computers fastest linpack performance published wwwtop500org e rst list considered press world fastest computer specrate throughput metric based spec cpu benchmarks spec cpu 2006 see chapter 1 rather report performance individual programs specrate runs many copies program simultaneously us measures tasklevel parallelism communication tasks run many copies programs want form weak scaling splash splash 2 stanford parallel applications shared memory e orts researchers stanford university 1990s put together parallel benchmark suite similar goals spec cpu benchmark suite includes kernels applications including many highperformance computing community benchmark requires strong scaling although comes two data sets benchmarkscalingreprogram descriptionlinpackweak yesdense matrix linear algebra dongarra 1979 specrateweak noindependent job parallelism henning 2007 stanford parallel applications shared memory splash 2 woo et al 1995 strong although offers two problem sizesnocomplex 1d fftblocked lu decomposition blocked sparse cholesky factorization integer radix sort barneshut adaptive fast multipole ocean simulation hierarchical radiosity ray tracer volume renderer water simulation spatial data structure water simulation without spatial data structure nas parallel benchmarks bailey et al 1991weak yes c fortran ep embarrassingly parallel mg simpliþed multigridcg unstructured grid conjugate gradient method ft 3d partial differential equation solution using ffts large integer sort parsec benchmark suite bienia et al 2008weak noblackscholesñoption pricing blackscholes pdebodytrackñbody tracking person cannealñsimulated cacheaware annealing optimize routing dedupñnextgeneration compression data deduplication facesimñsimulates motions human face ferretñcontent similarity search server fluidanimateñfluid dynamics animation sph methodfreqmineñfrequent itemset mining streamclusterñonline clustering input streamswaptionsñpricing portfolio swaptions vipsñimage processing x264ñh264 video encodingberkeley design patterns asanovic et al 2006strong weak yes finitestate machine combinational logicgraph traversal structured grid dense matrix sparse matrix spectral methods fftdynamic programmingnbodymapreduce backtrackbranch boundgraphical model inferenceunstructured grid figure 616 examples parallel benchmarks 610 multiprocessor benchmarks performance models 541 542 chapter 6 parallel processors client cloud e nas nasa advanced supercomputing parallel benchmarks another attempt 1990s benchmark multiprocessors taken computatio uid dynamics consist ker ey allow weak scaling ning data sets like linpack benchmarks rewritten rules require programming language c fortran e recent parsec princeton application repository shared memory computers benchmark suite consists multithreaded programs use pthreads posix threads openmp open multiprocessing see sectio ey focus emerging computational domains consist nine applications three kernels eight rely data parallelism three rely pipelined parallelism e unstructured parallelism cloud front goal yahoo cloud serving benchmark ycsb compare performance cloud data services ers framework makes easy client benchmark new data services using cassandra hbase representative examples cooper 2010 e downside traditional restrictions benchmarks innovation c limited architecture compiler better data structures algorithms programming languages en used since would give misleading resul e system could win say algorithm hardware compiler guidelines understandable foundations computing relatively stable 1990s th rst half decade undesirable programming revolution revolution succeed need encourage innovation levels researchers university california berkeley advocated one approac ey iden ed 13 design patterns claim part applications future frameworks kernels implement design patterns examples sparse matrices structured gr nitestate machines map reduce graph traversal keeping th nitions high level hope encourage innovations level syst us system fastest sparse matrix solver welcome use data structure algorithm programming language addition novel architectures compilers performance models topic related benchmarks performance models seen increasing architectural diversity chaptermultithreading simd gpus would especially helpful simple model ered insights performance erent architectures need perfect insightful e 3cs cache performance chapter 5 example performance model perfect performance model since ignores potentially important pthreads unix api creating manipulating threads structured library factors like block size block allocation policy block replacement policy moreover quirks example miss ascribed due capacity one design co ict miss another cache size yet 3cs model popular 25 years ers insight behavior programs helping architects programmers improve creations based insights model nd model parallel computers let start small kernels like 13 berkeley design patterns figure 616 versions erent data types ker oating point popular several implementations hence pe oatingpoint performance limit speed kernels given computer multicore chips pe oatingpoint performance collective peak performance cores chip multiple microprocessors system would multiply peak per chip total number chips e demands memory system estimated dividing peak oatingpoint performance average number oatingpoint operations per byte accessed floatingpoint operationssec floatingpoint operationsby ttebytessec e ratio oatingpoint operations per byte memory accessed called arithmetic intensity calculated taking total number oating point operations program divided total number data bytes transferred main memory program execution figure 617 shows arithmetic intensity several berkeley design patterns figure 616 arithmetic intensity e ratio oating point operations program number data bytes accessed program main memory r h e c n e n ologn o1 sparsematrix spmvstructured grids stencils pdesstructured grids lattice methodsspectral methods fftsdense matrix blas3nbody particle methodsfigure 617 arithmetic intensity speciﬁ ed number ﬂ oatpoint operations run program divided number bytes accessed main memory williams waterman patterson 2009 kernels arithmetic intensity scales problem size dense matrix many kernels arithmetic intensities independent problem size kernels former case weak scaling lead erent results since puts much less demand memory system 610 multiprocessor benchmarks performance models 543 544 chapter 6 parallel processors client cloud rooﬂ ine model simple mo oatingpoint performance arithmetic intensity memory performance together twodimensional graph williams waterman patterson 2009 pe oatingpoint performance found using hardware sp cations mentioned e working sets kernels consider onchip caches peak memory performance may b ned memory system behind caches one way nd peak memory performance stream benchmark see elaboration page 381 chapter 5 figure 618 shows model done computer ker e vertical yaxis achievab oatingpoint performance 05 640 gflopssecond e horizontal xaxis arithmetic intensity varying 18 flopsdram byte accessed 16 flopsdram byte accessed note graph loglog scale given kernel ca nd point xaxis based arithmetic intensity draw vertical line point performance kernel computer must lie somewhere along line plot horizontal line showing peak oatingpoint performance computer obviously actual oatingpoint performance higher horizontal line since hardware limit arithmetic intensity flopsbyte ratioattainable gflopssecond0510204080160 320 640181412124816 peak floatingpoint performancepeak memory bw streamkernel 1memory bandwidth limited kernel 2 computation limitedfigure 618 rooﬂ ine model williams waterman patterson 2009 example peak oatingpoint performance 16 gflopssec peak memory bandwidth 16 gbsec stream benchmark since stream actually four measurements line average four e dotted vertical line color th represents kernel 1 arithmetic intensity 05 flops byte limited memory bandwidth 8 gflopssec optero e dotted vertical line right represents kernel 2 arithmetic intensity 4 flopsbyte limited computationally 16 gflo data based amd opteron x2 revision f using dual cores running 2 ghz dual socket system could plot peak memory performance measured bytes second since xaxis flopsbyte yaxis flopssecond bytessecond diagonal line 45degree angle gure hence plot third line gives maxim oatingpoint performance memory system computer support given arithmetic intensity express limits formula plot line graph figure 618 attainable gflop ssecmi n peak memory bwa rithmetic inte nnsity peak floatingpoint performance e horizontal diagonal lines give simple model name indicate value e ro ine sets upper bound performance kernel depending arithmetic intensity given roo ine computer apply repeatedly since vary kernel think arithmetic intensity pole hits roof either hits slanted part roof means performance ultimately limited memory bandwidth hits th part roof means performance computationally limited figure 618 kernel 1 example former kernel 2 example latter note ridge point diagonal horizontal roofs meet ers interesting insight computer far right kernels high arithmetic intensity achieve maximum performance computer far th almost kernel potentially hit maximum performance comparing two generations opterons e amd opteron x4 barcelona four cores successor opteron x2 two cores simplify board design use socket hence dram channels thus peak memory bandwidth addition doubling number cores opteron x4 also twice peak oatingpoint performance per core opteron x4 cores issue tw oatingpoint sse2 instructions per clock cycle opteron x2 cores issue one two systems comparing similar clock rates 22 ghz opteron x2 versus 23 ghz opteron x4 opteron x4 four times peak oatingpoint performance opteron x2 dram bandwidth e opteron x4 also 2mib l3 cache found opteron x2 figure 619 roo ine models systems compared would expect ridge point moves right 1 opteron x2 5 opteron x4 hence see performance gain next generation kernels need arithmetic intensity higher 1 working sets mu caches opteron x4 e roo ine model gives upper bound performance suppose program far bound optimizations perform order 610 multiprocessor benchmarks performance models 545 546 chapter 6 parallel processors client cloud reduce computational bottlenecks following two optimizations help almost kernel 1 floatingpoint operation mix pe oatingpoint performance computer typically requires equal number nearly simultaneous additions multiplication balance necessary either computer supports fused multiplyadd instruction see elaboration page 220 chapter 3 th oatingpoint unit equal number oatingpoint adders oatingpoint multiplier e best performance also requires tha cant fraction instructio oating point operations integer instructions 2 improve instructionlevel parallelism apply simd modern archi tectures highest performance comes fetching executing committing three four instructions per clock cycle see sectio e goal step improve code compiler increase ilp one way unrolling loops saw section 412 x86 architectures single avx instruction operate four double precision operands used whenever possible see sections 37 38 reduce memory bottlenecks following two optimizations help 1 ware prefetching usually highest performance requires keeping many memory operation ight easier performing predicting accesses via ware prefetch instructions rather waiting data required computation actual flopbyte ratioattainable gflops1280640320 160804020100518141216842 1opteron x4 barcelonaopteron x2figure 619 rooﬂ ine models two generations opterons e opteron x2 roo ine figure 618 black opteron x4 roo ine color e bigger ridge point opteron x4 means kernels computationally bound opteron x2 could memory performance bound opteron x4 2 memory nity microprocessors today include memory controller chip microprocessor improves performance memory hierarchy system multiple chips means addresses go dram local one chip rest require accesses chip interconnect access dram local another chip split results nonuniform memory accesses described section 65 accessing memory another chip lowers performance second optimization tries allocate data threads tasked operate data memoryprocessor pair processors rarely access memory chips e roo ine model help decide two optimizations perform order perform think optimizations ceiling appropriate roo ine meaning break ceiling without performing associated optimization e computational roo ine found manuals memory ro ine found running stream benchmar e computational ceilings suc oatingpoint balance also come manuals computer memory ceiling memory nity requires running experiments computer determine gap th e good news process need done per computer someone characterizes computer ceilings everyone use results prioritize optimizations computer figure 620 adds ceilings roo ine model figure 618 showing computational ceilings top graph memory bandwidth ceilings bottom graph although higher ceilings labeled optimizations implied gure break highest ceiling need already broken ones e width gap ceiling next higher limit reward trying optimizatio us figure 620 suggests optimization 2 improves ilp large b improving computation computer optimization 4 improves memory nity large b improving memory bandwidth computer figure 621 combines ceilings figure 620 single grap e arithmetic intensity kernel determines optimization region turn suggests optimizations try note computational optimizations memory bandwidth optimizations overlap much arithmetic intensity ree regions ar erently figure 621 indicate th erent optimization strategies example kernel 2 falls blue trapezoid right suggests working computational optimizations kernel 1 falls bluegray parallelogram middle suggests trying types optimizations moreover suggests starting optimizations 2 4 note kernel 1 vertical lines fall th oatingpoint imbalance optimization optimization 1 may unnecessary kernel fell gray triangle low would suggest trying memory optimizations 610 multiprocessor benchmarks performance models 547 548 chapter 6 parallel processors client cloud 0510204080160320640181412124816 peak floatingpoint performance1 fl pt imbalance2 without ilp simdamd opteronpeak memory bw streamarithmetic intensity flopsbyte ratioattainable gflopssecond0510204080160 320 640181412124816 amd opteronpeak memory bw streamarithmetic intensity flopsbyte ratioattainable gflopssecond3 wout sw prefetching4 wout memory affinitypeak floatingpoint performancefigure 620 rooﬂ ine model ceilings e top graph shows computational ceilings 8 gflopssec th oatingpoint operation mix imbalanced 2 gflopssec optimizations increase ilp simd also missin e bottom graph shows memory bandwidth ceilings 11 gb sec without ware prefetching 48 gbsec memory nity optimizations also missing us far assuming arithmetic intensit xed really case first kernels arithmetic intensity increases problem size dense matrix nbody problems see figure 617 indeed reason programmers success weak scaling strong scaling second th ectiveness memory hierarchy ects number accesses go memory optimizations improve cache performance also improve arithmetic intensity one example improving temporal locality unrolling loops grouping together statements similar addresses many computers special cache instructions allocate data cache rst data memory address since soon overwritten optimizations reduce memory tra c thereby moving arithmetic intensity pole right factor say right could put ker erent optimization region examples show help programmers improve performance architects also use model decide optimize hardware improve performance kernels think important e next section uses roo ine model demonstrate performance erence multicore microprocessor gpu see whether thes erences r ect performance real programs 0510204080160320640124816 peak memory bw stream arithmetic intensity flopsbyte ratio attainable gflopssecond kernel 1kernel 2 2 without ilp simd4 wout memory affinity1 fl pt imbalance3 wout sw prefetchingpeak floatingpoint performance181412figure 621 rooﬂ ine model ceilings overlapping areas shaded two kernels figure 618 kernels whose arithmetic intensity land blue trapezoid right focus computation optimizations kernels whose arithmetic intensity land gray triangle lower focus memory bandwidth optimization ose land bluegray parallelogram middle need worry kernel 1 falls parallelogram middle try optimizing ilp simd memory nity ware prefetching kernel 2 falls trapezoid right try optimizing ilp simd balance oatingpoint operations 610 multiprocessor benchmarks performance models 549 550 chapter 6 parallel processors client cloud elaboration ceilings ordered lower ceilings easier optimize clearly programmer optimize order following sequence reduces chances wasting effor due constraints like 3cs model ine model delivers insights model assumptions may prove optimistic example ine assumes load balanced processors elaboration alternative stream benchmark use raw dram band ine raw band nitely hard upper bound actual memory performance often far boundary useful program go close bound downside using stream careful programming may exceed stream results memor ine may ine stick stream programmers able deliver memory bandwidth stream discovers elaboration ine model shown multicore processors clearly would work uniprocessor well true fals e main drawback conventional approaches benchmarks parallel computers rules ensure fairness also slow ware innovation 611 real stuff benchmarking rooﬂ ines intel core i7 960 nvidia tesla gpu group intel researchers published paper lee et al 2010 comparing quadcore intel core i7 960 multimedia simd extensions previous generation gpu nvidia tesla gtx 280 figure 622 lists characteristics two systems products purchased f e core i7 intel 45nanometer semiconductor technology gpu tsmc 65nanometer technology although might fairer comparison neutral party interested parties purpose section determine much faster one product another try understand relative value features two contrasting architecture styles e roo ines core i7 960 gtx 280 figure 623 illustrate erences computers gtx 280 much higher memory bandwidth doubleprecisio oatingpoint performance also doubleprecision ridge point considerably th e doubleprecision ridge point 06 gtx 280 versus 31 core i7 mentioned much easier hit peak computational performance ridge point check roo ine th singleprecision performance ridge point moves far right computers much harder hit roof single precision performance note arithmetic intensity kernel based bytes go main memory bytes go cache memory us mentioned caching change arithmetic intensity kernel particular computer references really go cache note also bandwidth unitstride accesses architectures real gatherscatter addresses slower gtx 280 core i7 shall see e researchers selected benchmark programs analyzing computational memory characteristics four recently proposed benchmark suites formulated set throughput computing kernels capture characteristics figure 624 shows performance results larger numbers meaning faster e roo ines help explain relative performance case study given raw performance sp cations gtx 280 vary 25 slower clock rate 75 faster cores per chip performance varies core i7960number processing elements cores smsclock frequency ghz die size technology power chip module transistors memory brandwith gbytessec singleprecision simd width doubleprecision simd width peak singleprecision scalar flops gflopsec peak singleprecision simd flops gflopsec sp 1 add multiply sp 1 instruction fused multiplyadds rare sp dual issue fused multiplyadd multiply peal doubleprecision simd flops gflopsec432263intel 45 nm130700 m324 226102na na na513013576tsmc 65 nm1301400 m1418 1117311 933311 622 933781514520tsmc 40 nm1673030 m17732 16 63515 13445151344na5157504122 16 10 20 44 20 05 4630ð9130 61 91153804420 10 13 44 55 80 80 2566ð13166131ð101gtx 280gtx 480 ratio280i7ratio480i7figure 622 intel core i7960 nvidia gtx 280 gtx 480 speciﬁ cations e rightmost columns show ratios tesla gtx 280 fermi gtx 480 core i7 although case study tesla 280 i7 include fermi 4 80 show relationship tesla 280 since described chapter note memory bandwidths higher figure 623 dram pin bandwidths figure 623 processors measured benchmark program table 2 lee et al 2010 611 real stuff benchmarking rooﬂ ines intel core i7 960 nvidia tesla gpu 551 552 chapter 6 parallel processors client cloud figure 623 rooﬂ ine model williams waterman patterson 2009 ese roo ines show doubleprecisio oatingpoint performance top row singleprecision performance bottom row e dp fp performance ceiling also bottom row give perspective e core i7 960 th peak dp fp performance 512 gflopsec sp fp peak 1024 gflopsec peak memory bandwidth 164 gbytess e nvidia gtx 280 dp fp peak 78 gflopsec sp fp peak 624 gflopsec 127 gbytessec memory bandwidt e dashed vertical line th represents arithmetic intensity 05 flopbyte limited memory bandwidth 8 dp gflopsec 8 sp gflopsec cor e dashed vertical line right arithmetic intensity 4 flopbyte limited computationally 512 dp gflopsec 1024 sp gflopsec core i7 78 dp gflop sec 512 dp gflopsec gtx 280 hit highest computation rate core i7 need use 4 cores sse instructions equal number multiplies adds gtx 280 need use fused multiplyadd instructions multithrea ded simd processors 1286432168 4211286432168 421core i7 960nehalem102451225612864 32 16812arithmetic intensity481632 181412 12arithmetic intensity481632 181412 12arithmetic intensity481632 32181412 12arithmetic intensity4816 181412 core i7 960nehalemnvidia gtx2801024512256 128643281644nvidia gtx280gflopsgflopsgflopsgflops512 gfsdouble precisionstream 164 gbsstream127gbs peak 78gfs double precision78gfs double precisionstream127gbs 624gfs single precisionstream 164 gbs1024 gfssingle precision512 gfsdouble precision 20 slower solv 152 faster gjk intel researchers decided nd reasons th erences memory bandwidth e gpu 44 memory bandwidth helps explain lbm saxpy run 50 53 faster working sets hundreds megabytes hence core i7 cache access memory intensively purposely use cache blocking chapter 5 hence slope roo ines explains performance spmv also large working set runs 19 faster double precisio oating point gtx 280 15 faster core i7 compute bandwidth five remaining kernels compute bound sgemm conv fft mc bila e gtx faster 39 28 30 18 57 respectively e rst three use singleprecisio oatingpoint arithmetic gtx 280 single precision 3 6 faster mc uses double precision explains 18 faster since dp performance 15 faster bilat uses transcendental functions gtx 280 supports directly e core i7 spends twothirds time calculating transcendental functions bilat gtx 280 57 faster observation helps point value hardware support operations occur workload doubleprecisio oating point perhaps even transcendentals kernelunitscore i7960gtx 280 gtx 280i7960million pixelssec sgemmgflopsec billion pathssecmcmillion pixelssec conv gflopsecfftgbytessecsaxpymillion lookupsseclbmframessec solvgflopsecspmvframessec gjkmillion elementssecsort framessec rcmillion queriessec searchmillion pixelssec 83940812507141688510349672505501517395718283053500519152081618173644751435002138884265291102019881902583histbilatfigure 624 raw relative performance measured two platforms study saxpy used measure memory bandwidth right unit gbytessec gflopsec based table 3 lee et al 2010 611 real stuff benchmarking rooﬂ ines intel core i7 960 nvidia tesla gpu 553 554 chapter 6 parallel processors client cloud cache ben ts ray casting rc 16 faster gtx cache blocking core i7 caches prevents becoming memory bandwidth bound see sections 54 514 gpus cache blocking help search index trees small cache core i7 twice fast larger index trees make memory bandwidth bound overall gtx 280 runs search 18 faster cache blocking also helps sort programmers run sort simd processor written 1bit sort primitive called split however split algorithm executes many instructions scalar sort result core i7 runs 125 fast gtx 280 note caches also help kernels core i7 since cache blocking allows sgemm fft spmv become compute bound observation emphasizes importance cache blocking optimizations chapter 5 gatherscatter e multimedia simd extensions little help data scattered throughout main memory optimal performance comes accesses data aligned 16byte boundar us gjk gets little b simd core i7 mentioned gpus er gatherscatter addressing found vector architecture omitted simd extension e memory controller even batches accesses dram page together see sectio combination means gtx 280 runs gjk startling 152 fast core i7 larger single physical parameter figure 622 observation reinforces importance gather scatter vector gpu architectures missing simd extensions synchronization e performance synchronization limited atomic updates responsible 28 total runtime core i7 despite hardware fetchandincrement instructio us hist 17 faster gtx 280 solv solves batch independent constraints small amount computation followed barrier synchronizatio e core i7 ts atomic instructions memory consistency model ensures right results even previous accesses memory hierarchy completed without memory consistency model gtx 280 version launches batches system processor leads gtx 280 running 05 fast core observation points synchronization performance important data parallel problems striking en weaknesses tesla gtx 280 uncovered kernels selected intel researchers already addressed successor architecture tesla fermi faster doubleprecisio oatingpoint performance faster atomic operations caches also interesting gatherscatter support vector architectures predate simd instructions decades important th ective usefulness simd extensions predicted compariso e intel researchers noted 6 14 kernels would exploit simd better mor cient gatherscatter support core study certainly establishes importance cache blocking well seen wide range results benchmarkin erent multiprocessors lets return dgemm example see detail much change c code exploit multiple processors 612 going faster multiple processors matrix multiply section th nal largest step incremental performance journey adapting dgemm underlying hardware intel core i7 sandy bridge core i7 8 cores computer using 2 core i7s us 16 cores run dgemm figure 625 shows openmp version dgemm utilizes cores note line 30 single line added figure 548 make code run multiple processors openmp pragma tells compiler use multiple threads outermost loop tells computer spread work outermost loop across threads figure 626 plots classic multiprocessor speedup graph showing performance improvement versus single thread number threads increase graph makes easy see challenges strong scaling versus weak scaling everythin ts th rst level data cache case 32 32 matrices adding threads actually hurts performance e 16threaded version dgemm almost half fast singlethreaded version case contrast two largest matrices get 14 speedup 16 threads hence classic two right lines figure 626 figure 627 shows absolute performance increase increase number threads 1 16 dgemm operates operates 174 glops 960 960 matrices unoptimized c version dgemm figure 321 ran code 08 gfops optimizations chapters 3 6 tailor code underlying hardware result speedup 200 times next warnings fallacies pitfalls multiprocessin e computer architecture graveyar lled parallel processing projects ignored elaboration results turbo mode turned using dual chip system system surprisingly get full turbo speedup 3326 127 either 1 thread 1 core one chips 2 threads 1 core per chip increase number threads hence number active cores turbo mode decreases less power budget spend active cores 4 threads average turbo speedup 123 8 113 16 111 612 going faster multiple processors matrix multiply 555 556 chapter 6 parallel processors client cloud include x86intrinhdefine unroll 4 define blocksize 32 void do_block int n int si int sj int sk double double b double c int si siblocksize iunroll4 int j sj j sjblocksize j __m256d c4 int x 0 x unroll x cx _mm256_load_pdcix4jn cx cij int k sk k skblocksize k __m256d b _mm256_broadcast_sdbkjn b bkj int x 0 x unroll x cx _mm256_add_pdcx cxaikb _mm256_mul_pd_mm256_load_pdankx4i b int x 0 x unroll x _mm256_store_pdcix4jn cx cij cx void dgemm int n double double b double c pragma omp parallel int sj 0 sj n sj blocksize int si 0 si n si blocksize int sk 0 sk n sk blocksize do_blockn si sj sk b c 1 2 3 4 5 6 7 8 910 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 323334 35figure 625 openmp version dgemm figure 548 line 30 openmp code making outermost loop operate parallel line erence figure 548 elaboration although sandy bridge supports two hardware threads per core get performance 32 threads reason single avx hardware shared two threads multiplexed onto one core assigning two threads per core actually hurts performance due multiplexing overhead œ1234567 8 9101112 1314048threads1216speedup relative 1 core960 x 960480 x 480160 x 16032 x 32figure 626 performance improvements relative single thread number threads increase e honest way present graphs make performance relative best version single processor program plot relative performance code figure 548 without including openmp pragmas 14 12 11 11 8 13 20 31 61 60 12 22 43 85 169 12 23 44 87 174 5010015020012481 6gflopsthreads32x32160x160480x480960x960 figure 627 dgemm performance versus number threads four matrix sizes e performance improvement compared unoptimized code figure 321 th 960 matrix 16 threads astounding 212 times faster 612 going faster multiple processors matrix multiply 557 558 chapter 6 parallel processors client cloud 613 fallacies pitfalls e many assaults parallel processing uncovered numerous fallacies pitfalls cover four fallacy amdahls law doesnt apply parallel computers 1987 head research organization claimed multiprocessor machine broken amdahls law try understand basis media reports let see quote gave us amdahl law 1967 p 483 fairly obvious conclusion drawn point th ort expended achieving high parallel processing rates wasted unless accompanied achievements sequential processing rates nearly magnitude statement must still true neglected portion program must limit performance one interpretation law leads following lemma portions every program must sequential must economic upper bound number processors say 100 showing linear speedup 1000 processors lemma disproved hence claim amdahl law broken e approach researchers use weak scaling rather going 1000 times faster data set computed 1000 times work comparable time algorithm sequential portion program constant independent size input rest fully parallel hence linear speedup 1000 processors amdahl law obviously applies parallel processors research point one main uses faster computers run larger problems sure users really care problems versus ju cation buying expensive computer b nding problem keeps lots processors busy fallacy peak performance tracks observed performance e supercomputer industry used metric marketing fallacy exacerbated parallel machines marketers using nearly unattainable peak performance uniprocessor node also multiplying total number processors assuming perfect speedup amdahl law suggests ho cult reach either peak multiplying two together multiplies sin e roo ine model helps put peak performance perspective pitfall developing ware take advantage optimize multiprocessor architecture ere long history parallel ware lagging behind parallel hardware possibly ware problems much harder give one example show subtlety issues many examples could choose decade prophets voiced contention organization single computer reached limits truly signi cant advances made interconnection multiplicity computers manner permit cooperative solution demonstration made continued validity single processor approach gene amdahl validity single processor approach achieving large scale computing capabilities spring joint computer conference 1967 one frequently encountered problem occurs ware designed uniprocessor adapted multiprocessor environment example silicon graphics operating system originally protected page table single lock assuming page allocation infrequent uniprocessor represent performance problem multiprocessor become major performance bottleneck programs consider program uses large number pages initialized startup unix statically allocated pages suppose program parallelized multiple processes allocate pages page allocation requires use page table locked whenever use even os kernel allows multiple threads os serialized processes try allocate pages exactly might expect initialization time page table serialization eliminat es parallelism initialization cant impact overall parallel performance performance bottleneck persists even tasklevel parallelism example suppose split parallel processing program apart separate jobs run one job per processor sharing th exactly one user since reasonably believed performance problem due unintended sharing interference application unfortunately lock still serializes jobs even independent job performance poor pitfall indicates kind subtle bu cant performance bugs arise ware runs multiprocessors like many key ware components os algorithms data structures must rethought multiprocessor context placing locks smaller portions page table ectively eliminated problem fallacy get good vector performance without providing memory bandwidth saw roo ine model memory bandwidth quite important architectures daxpy requires 15 memory references p oatingpoint operation ratio typical many scien c codes even th oatingpoint operations took time cray1 could increase daxpy performance vector sequence used since memory limited e cray1 performance linpack jumped compiler used blocking change computation values could kept vector register approach lowered number memory references per flop improved performance nearly factor tw us memory bandwidth cray1 beca cient loop formerly required bandwidth roo ine model would predict 613 fallacies pitfalls 559 560 chapter 6 parallel processors client cloud 614 concluding remarks e dream building computers simply aggregating processors around since earliest days computing progress building usin ective cient parallel processors however slow rate progress limited b cult ware problems well long process evolving architecture multiprocessors enhance usability improv ciency discussed many ware challenges chapter including culty writing programs obtain good speedup due amdahl law e wide variety erent architectural approaches limited success short life many parallel architectures past compounded ware culties discuss history development multiprocessors online section 615 go even greater depth topics chapter see chapter 4 computer architecture quantitative approach fi h edition gpus comparisons gpus cpus chapter 6 wscs said chapter 1 despite long checkered past information technology industry tied future parallel computing although easy make case e ort fail like many past reasons hopeful clearly ware service saas growing importance clusters proven successful way deliver services providing redundancy higherlevel including geographically distributed datacenters services delivered 24 7 365 availability customers around world believe warehousescale computers changing goals principles server design needs mobile clients changing goals principles microprocessor design revolutionizing ware industry well performance per dollar performance per joule drive mobile client hardware wsc hardware parallelism key delivering sets goals simd vector operations good match multimedia applications playing larger role p ey share advantage easier programmer classic parallel mimd programming energy cient mimd put perspective importance simd versus mimd figure 628 plots number cores mimd versus number 32bit 64bit operations per clock cycle simd mode x86 computers time x86 computers expect see two additional cores per chip every two years simd width double every four years given assumptions next decade potential speedup simd parallelism twice dedicating future product development multicore designs believe key ection point industry race sea change computing paul otellini intel president intel developers forum 2004 mimd parallelism given th ectiveness simd multimedia increasing importance postpc era emphasis may appropriate hence least important understand simd parallelism mimd parallelism even though latter received much attention e use parallel processing domains scien c engineering computation popular application domain almost limitless thirst computation also many applications lots natural concurrency clusters dominate application area example using 2012 top 500 report clusters responsible 80 500 fastest linpack results desktop server microprocessor manufacturers building multiprocessors achieve higher performance unlike past easy path higher performance sequential applications said earlier sequential programs slow programs hence programmers need higher performance must parallelize codes write new parallel processing programs 2003110100potential parallel speedup 100020072011201520192023 mimdsimd 32b simd 32b mimdsimd 64b mimdsimd 64b figure 628 potential speedup via parallelism mimd simd mimd simd time x86 computers gure assumes two cores per chip mimd added every two years number operations simd double every four years 614 concluding remarks 561 562 chapter 6 parallel processors client cloud past microprocessors multiprocessors subject erent nitions success scaling uniprocessor performance microprocessor architects happy single thread performance went square root increased silicon us happy sublinear performance terms resources multiprocessor success used b ned linear speedup function number processors assuming cost purchase cost administration n processors n times much one processor parallelism happening chip via multicore use traditional microprocessor metric successful sublinear performance improvement e success justintime runtime co mpilation autotuning makes feasible think ware adapting take advantage increasing number cores per chip prov exibility available limited static compilers unlike past open source movement become critical portion ware industry movement meritocracy better engineering solutions win mind share developers legacy concerns also embraces innovation inviting change old ware welcoming new languages ware products open culture could extremely helpful time rapid change motivate readers embrace revolution demonstrated potential parallelism concretely matrix multiply intel core i7 sandy bridge going faster sections chapters 3 6 datalevel parallelism chapter 3 improved performance factor 385 executing four 64bit oatingpoint operations parallel using 256 bit operands avx instructions demonstrating value simd instructionlevel parallelism chapter 4 pushed performance another factor 23 unrolling loops 4 times give outoforder execution hardware instructions schedule cache optimizations chapter 5 improved performance matrices l1 data cache another factor 20 25 using cache blocking reduce cache misses readlevel parallelism chapter improved performance matrices single l1 data cache another factor 4 14 utilizing 16 cores multicore chips demonstrating value mimd adding single line using openmp pragma using ideas book tailoring ware computer added 24 lines code dgemm matrix sizes 32x32 160x160 480x480 960x960 overall performance speedup ideas realized two dozen lines code factors 8 39 129 212 parallel revolution hardwareso ware interface perhaps greatest challenge facing th eld last 60 years also think greatest opportunity going faster sections demonstrate revolution provide many new research business prospects inside outside eld companies dominate multicore era may ones dominated uniprocesso er understanding underlying hardware trends learning adapt ware perhaps one innovators seize opportunities certain appear uncertain times ahead look forward b ting inventions 59615 historical perspective reading section online gives rich en disastrous history multiprocessors last 50 years referencesg regnier makineni r illikkal r iyer minturn r huggahalli newell l cline foong tcp onloading data center servers ieee computer 37114858 2004b f cooper silberstein e tam r ramakrishnan r sears benchmarking cloud serving systems ycsb proceedings 1st acm symposium cloud computing june 1011 2010 indianapolis indiana usa doi10114518071281807152 616 exercises61 first write list daily activities typically weekday instance might get bed take shower get dressed eat breakfast dry hair brush teeth make sure break list minimum 10 activities 611 5 62 consider activities already exploiting form parallelism eg brushing multiple teeth time versus one time carrying one book time school versus loading 616 exercises 563 564 chapter 6 parallel processors client cloud backpack carry parallel activities discuss already working parallel 612 5 62 next consider activities could carried concurrently eg eating breakfast listening news activities describe activity could paired activity 613 5 62 612 could change current systems eg showers clothes tvs cars could perform tasks parallel 614 5 62 estimate much shorter time would take carry activities tried carry many tasks parallel possible 62 trying bake 3 blueberry pound cakes cake ingredients follows 1 cup butter ened1 cup sugar 4 large eggs 1 teaspoon vanilla extract 12 teaspoon salt 14 teaspoon nutmeg 1 12 cu 1 cup blueberries e recipe single cake follows step 1 preheat oven 325f 160c grease cake pan step 2 large bowl beat together mixer butter sugar medium speed light add eggs vanilla salt nutmeg beat thoroughly blended reduce mixer speed low 12 cup time beating blended step 3 gently fold blueberries spread evenly prepared baking pan bake 60 minutes 621 5 62 job cook 3 cak ciently possible assuming one oven large enough hold one cake one large bowl one cake pan one mixer come schedule make three cakes quickly possible identify bottlenecks completing task 622 5 62 assume three bowls 3 cake pans 3 mixers much faster process additional resources 623 5 62 assume two friends help cook large oven accommodate three cakes change schedule arrived exercise 621 624 5 62 compare cakemaking task computing 3 iterations loop parallel computer identify datalevel parallelism tasklevel parallelism cakemaking loop 63 many computer applications involve searching set data sorting data number cient searching sorting algorithms devised order reduce runtime tedious tasks problem consider best parallelize tasks 631 10 62 consider following binary search algorithm classic divide conquer algorithm searches value x sorted nelement array returns index matched entry binarysearcha0n1 x low 0high n 1 low high mid low high 2 amid x high mid 1else amid x low mid 1else return mid found return 1 foundassume cores multicore processor run binarysearch assuming much smaller n express speedup factor might expect obtain values n plot graph 632 5 62 next assume equal n would ect conclusions previous answer tasked obtaining best speedup factor possible ie strong scaling explain might change code obtain 64 consider following piece c code j2j1000j dj dj1dj2 616 exercises 565 566 chapter 6 parallel processors client cloud e mips code corresponding fragment addiu s2zero7992 addiu s1zero16 loop ld f0 16s1 ld f2 8s1 addd f4 f0 f2 sd f4 0s1 addiu s1 s1 8 bne s1 s2 loopinstructions following associated latencies cycles adddldsdaddiu 4612 641 10 62 many cycles take instructions single iteration loop execute 642 10 62 instruction later iteration loop depends upon data value produced earlier iteration loop say loop carried dependence iterations loop identify loopcarried dependences code identify dependent program variable assemblylevel registers ignore loop induction variable j643 10 62 loop unrolling described chapter 4 apply loop unrolling loop consider running code 2node distributed memory message passing system assume going use message passing described section 67 introduce new operation send x sends node x value operation receive waits value sent assume send operations take cycle issue ie later instructions node proceed next cycle take 10 cycles received receiving node receive instructions stall execution node executed receive message produce schedule two nodes assuming unroll factor 4 loop body ie loop body appear 4 times compute number cycles take loop run message passing system 644 e latency interconnect network plays large role th ciency message passing systems fast interconnect need order obtain speedup using distributed system described exercise 643 65 consider following recursive mergesort algorithm another classic divide conquer algorithm mergesor rst described john von neumann e basic idea divide unsorted list x elements two sublists half size original list peat operation sublist continue lists size 1 lengt en starting sublists length 1 merge two sublists single sorted list mergesortmvar list left right resultreturn melsevar middle lengthm 2for x middleadd x leftfor x middleadd x rightleft mergesortleftright mergesortright result mergeleft right return result e merge step carried following code mergeleftrightvar list resultwhile lengthleft 0 lengthright 0append firstleft resultleft restleftelseappend firstright result right restrightif lengthleft 0append restleft resultif lengthright 0append restright resultreturn result651 10 62 assume cores multicore processor run mergesort assuming much smaller lengthm express speedup factor might expect obtain values lengthm plot graph 652 10 62 next assume equal length would ect conclusions previous answer tasked obtaining best speedup factor possible ie strong scaling explain might change code obtain 616 exercises 567 568 chapter 6 parallel processors client cloud 66 matrix multiplication plays important role number applications two matrices multiplied number columns th rst matrix equal number rows second lets assume n matrix want multiply n p matrix b express product p matrix denoted ab b assign c ab cij denotes entry c position j element j im jp want see parallelize computation c assume matrices laid memory sequentially follows 11 a21 a31 a41 etc 661 10 65 assume going compute c single core shared memory machine 4core sharedmemory machine compute speedup would expect obtain 4core machine ignoring memory issues662 10 65 repeat exercise 661 assuming updates c incur cache miss due false sharing consecutive elements row ie index updated 663 10 65 would yo x false sharing issue occur 67 consider following portions tw erent programs running time four processors symmetric multicore processor smp assume code run x 0 core 1 x 2core 2 2core 3 w x 1core 4 z x 671 10 65 possible resulting values w x z possible outcome explain might arrive values need examine possible interleavings instructions 672 5 65 could make execution deterministic one set values possible 68 e dining philosophers problem classic problem synchronization concurrency e general problem stated philosophers sitting round table one two things eating thinking eating thinking thinking eating ere bowl pasta center fork placed philosopher e result philosopher one fork one fork right given nature eating pasta philosopher needs two ks eat use forks immediat righ e philosophers speak one another 681 10 67 describe scenario none philosophers ever eats ie starvation sequence events happen lead problem 682 10 67 describe solve problem introducing concept priority guarantee treat philosophers fairly explain assume hire waiter charge assigning forks philosophers nobody pick fork waiter says ca e waiter global knowledge forks impose policy philosophers always request pick th fork requesting pick right fork guarantee avoid deadlock 683 10 67 implement requests waiter either queue requests periodic retry request queue requests handled order received e problem using queue may always able service philosopher whose request head queue due unavailability resources describe scenario 5 philosophers queue provided service granted even though forks available another philosopher whose request deeper queue eat 684 10 67 implement requests waiter periodically repeating request resources become available solve problem described exercise 683 explain 69 consider following three cpu organizations cpu ss 2core superscalar microprocessor provides outoforder issue capabilities 2 function units fus single thread run core time cpu mt negrained multithreaded processor allows instructions 2 threads run concurrently ie two functional units though instructions single thread issued cycle cpu smt smt processor allows instructions 2 threads run concurrently ie two functional units instructions either threads issued run cycle assume two threads x run cpus include following operations thread xthread ya1 takes 3 cycles execute b1 take 2 cycles execute a2 dependences icts functional unit b1 icts functional unit a1b3 depends result b2 a4 depends result a3b4 dependences takes 2 cycles execute 616 exercises 569 570 chapter 6 parallel processors client cloud assume instructions take single cycle execute unless noted otherwise encounter hazard 691 10 64 assume 1 ss cpu many cycles take execute two threads many issue slots wasted due hazards 692 10 64 assume 2 ss cpus many cycles take execute two threads many issue slots wasted due hazards 693 10 64 assume 1 mt cpu many cycles take execute two threads many issue slots wasted due hazards 610 virtualization ware aggressively deployed reduce costs managing todays high performance servers companies like vmware microso ibm developed range virtualization produc e general concept described chapter 5 hypervisor layer introduced hardware operating system allow multiple operating systems share physical hardware e hypervisor layer responsible allocating cpu memory resources well handling services typically handled operating system eg io virtualization provides abstract view underlying hardware hosted operating system application ware require us rethink multicore multiprocessor systems designed future support sharing cpus memories number operating systems concurrently 6101 30 64 select two hypervisors market today compare contrast virtualize manage underlying hardware cpus memory 6102 15 64 discuss changes may necessary future multicore cpu platforms order better match resource demands placed systems instance multithreading play ective role alleviating competition computing resources 611 would like execute loop belo ciently possible tw erent machines mimd machine simd machine i0 2000 j0 j3000 jx_arrayij y_arrayji 2006111 10 63 4 cpu mimd machine show sequence mips instructions would execute cpu speedup mimd machine 6112 20 63 8wide simd machine ie 8 parallel simd functional units write assembly program using simd extensions mips execute loop compare number instructions executed simd machine mimd machine 612 systolic array example misd machine systolic array pipeline network wavefront data processing elements elements need program counter since execution triggered arrival data clocked systolic arrays compute lockstep processor undertaking alternate compute communication phases 6121 10 63 consider proposed implementations systolic array ca nd internet technical publication en attempt program loop provided exercise 611 using misd model discuss culties encounter 6122 10 63 discuss similarities erences misd simd machine answer question terms datalevel parallelism 613 assume want execute daxpy loop show page 511 mips assembly nvidia 8800 gtx gpu described chapter problem assume math operations performed singleprecisio oating point numbers rename loop saxpy assume instructions take following number cycles execute loadsstoresaddsmults5234 6131 20 66 describe constructs warps saxpy loop exploit 8 cores provided single multiprocessor 614 download cuda toolkit sdk httpwwwnvidiacomobject cuda_gethtml make sure use emurelease emulation mode version code need actual nvidia hardware assignment build example programs provided sdk co rm run emulator 6141 90 66 using template sdk sample starting point write cuda program perform following vector operations 1 b vectorvector subtraction 2 b vector dot product e dot product two vectors a1 a2 b b1 b2 bn ned ab 1122 abababab ininni1submit code program demonstrates operation ver es correctness results 6142 90 66 gpu hardware available complete performance analysis program examining computation time gpu cpu version program range vector sizes explain results see 616 exercises 571 572 chapter 6 parallel processors client cloud 615 amd recently announced integrating graphics processing unit x86 cores single package though wit erent clocks cor example heterogeneous multiprocessor system expect see produced commericially near future one key design points allow fast data communication cpu gpu presently communications must performed discrete cpu gpu chips changing amds fusion architecture presently plan use multiple least 16 pci express channels facilitate intercommunication intel also jumping arena larrabee chip intel considering use quickpath interconnect technology 6151 25 66 compare bandwidth latency associated two interconnect technologies 616 refer figure 614b shows ncube interconnect topology order 3 interconnects 8 nodes one attractive feature ncube interconnection network topology ability sustain broken links still provide connectivity 6161 10 68 develop equation computes many links ncube n order cube fail still guarantee unbroken link exist connect node ncube 6162 10 68 compare resiliency failure ncube fully connected interconnection network plot comparison reliability function added number links two topologies 617 benchmarking eld study involves identifying representative workloads run sp c computing platforms order able objectively compare performance one system another exercise compare two classes benchmarks whetstone cpu benchmark parsec benchmark suite select one program parsec programs freely available internet consider running multiple copies whetstone versus running parsec benchmark systems described section 611 6171 60 610 inherentl erent two classes workload run multicore systems 6172 60 610 terms roo ine model dependent results obtain running benchmarks amount sharing synchronization present workload used 618 performing computations sparse matrices latency memory hierarchy becomes much factor sparse matrices lack spatial locality data stream typically found matrix operations result new matrix representations proposed one earliest sparse matrix representations yale sparse matrix format stores initial sparse n matrix row form using three onedimensional arrays let r number nonzero entries construct array length r contains nonzero entries toright toptobottom order also construct second array ia length 1 ie one entry per row plus one iai contains index th rst nonzero element row row original matrix extends aiai aiai e third array ja contains column index element also length r6181 15 610 consider sparse matrix x write c code would store code yale sparse matrix format row 1 1 2 0 0 0 0 row 2 0 0 1 1 0 0 row 3 0 0 0 0 9 0 row 4 2 0 0 0 0 2 row 5 0 0 3 3 0 7 row 6 1 3 0 0 0 16182 10 610 terms storage space assuming element matrix x single precisio oating point compute amount storage used store matrix yale sparse matrix format 6183 15 610 perform matrix multiplication matrix x matrix shown 2 4 1 99 7 2put computation loop time execution make sure increase number times loop executed get good resolution timing measurement compare runtime using naïve representation matrix yale sparse matrix format 6184 15 610 yo nd cient sparse matrix representation terms space computational overhead 619 future systems expect see heterogeneous computing platforms constructed heterogeneous cpus begun see appear embedded processing market systems contain oating point dsps microcontroller cpus multichip module package assume three classes cpu cpu aa moderate speed multicore cpu wit oating point unit execute multiple instructions per cycle cpu ba fast singlecore integer cpu ie oating point unit execute single instruction per cycle cpu ca slow vector cpu wit oating point capability execute multiple copies instruction per cycle 616 exercises 573 574 chapter 6 parallel processors client cloud assume processors run following frequencies cpu acpu bcpu c 1 ghz3 ghz250 mhz cpu execute 2 instructions per cycle cpu b execute 1 instruction per cycle cpu c execute 8 instructions though instruction per cycle assume operations complete execution single cycle latency without hazards three cpus ability perform integer arithmetic though cpu b perfor oating point arithmetic cpu b instruction set similar mips processor cpu c perfor oating point add subtract operations well memory loads stores assume cpus access shared memory synchronization zero cost e task hand compare two matrices x contain 1024 1024 oating point elemen e output count number indices value x larger equal value 6191 10 611 describe would partition problem 3 erent cpus obtain best performance 6192 10 611 kind instruction would add vector cpu c obtain better performance 620 assume quadcore computer system process database queries steady state rate requests per second also assume transaction takes average xed amount time pro e following table shows pairs transaction latency processing rate average transaction latencymaximum transaction processing rate 1 ms5000sec2 ms5000sec1 ms10000sec2 ms10000secfor pairs table answer following questions 6201 10 611 average many requests processed given instant 6202 10 611 move 8core system ideally happen system throughput ie many queriessecond computer process 6203 10 611 discuss rarely obtain kind speedup simply increasing number cores 61 page 504 false tasklevel parallelism help sequential applications sequential applications made run parallel hardware although challenging 62 page 509 false weak scaling compensate serial portion program would otherwise limit scalability strong scaling 63 page 514 true missing useful vector features like gatherscatter vector length registers improve th ciency vector architectures elaboration section mentions avx2 simd extensions ers indexed loads via gather operation scatter indexed stor e haswell generation x86 microprocessor th rst support avx2 64 page 519 1 true 2 true 65 page 523 false since shared address physical address multiple tasks virtual address spaces run well shared memory multiprocessor 66 page 531 false graphics dram chips prized higher bandwidth 67 page 536 1 false sending receiving message implicit synchronization well way share data 2 true 68 page 538 true 610 page 550 true likely need innovation levels hardware ware stack parallel computing succeed answers check 616 exercises 575 afear serious injury alone justify suppression free speech assembly louis brandeiswhitney v california 1927assemblers linkers spim simulatorjames r larus microso research microso appendix a1 introduction a3 a2 assemblers a10 a3 linkers a18 a4 loading a19 a5 memory usage a20 a6 procedure call convention a22 a7 exceptions interrupts a33 a8 input output a38 a9 spim a40 a10 mips r2000 assembly language a45 a11 concluding remarks a81 a12 exercises a82 a1 introductionencoding instructions binary numbers natural cient computers humans however great deal culty understanding manipulating numbers people read write symbols words much better long sequences digits chapter 2 showed need choose numbers words computer instructions represented many ways humans write read symbols computers execute equivalent binary number appendix describes process humanreadable program translated form computer execute provides hints writing assembly programs explains run programs spim simulator executes mips programs unix windows mac os x versions spim simulator available cd assembly language symbolic representation computers binary encodingthe machine language assembly language readable machine language uses symbols instead bi e symbols assembly language name commonly occurr bit patterns opcodes register sp ers people read remember addition assembly language machine language binary representation used communication within computer system a4 appendix assemblers linkers spim simulator figure a11 process produces executable ﬁ le assembler translat le assembly language objec le linked ot les libraries executab le objectfilesourcefileassembler linker assembler assembler program library objectfileobjectfilesourcefilesourcefileexecutable filepermits programmers use labels identify name particular memory words hold instructions data tool called assembler translates assembly language binary instructions assemblers provide friendlier representation computers 0s 1s sim p es writing reading programs symbolic names operations loca tions one facet representation another facet programming facilities increase programs clarity example macros discussed section a2 enable programmer extend assembly language b ning new operations assembler reads single assembly language source le produces obje le containing machine instructions bookkeeping information helps combine several objec les program figure a11 illustrates program built programs consist sev lesalso called modules written compiled assembled independently program may also use prewritten routines supplied program library module typically contains ref erences subroutines dat ned modules librar e code module executed contains unresolved references labels objec les libraries another tool called linker combines collection object librar les executab le computer run see advantage assembly language consider following sequence gures contain short subroutine computes prints sum squares integers 0 100 figure a12 shows machine language mips computer executes considerab ort could use opcode instruction format tables chapter 2 translate instructions symbolic program similar shown figure a13 form routine much easier read operations operands written symbols rather assembler program translates symbolic version instruction binary ver sion macro pattern matching replacement facility pro vides simple mechanism name frequently used sequence instructions unresolved reference reference requires information outside source complete linker also called link editor systems program combines independently assembled machine language programs resolves ned labels executab le a1 introduction 5than bit patterns however assembly language cult follow memory locations named address rather symbolic label figure a14 shows assembly language labels memory addresses mne monic names programmers prefer read write form names begin period example data globl assembler directives tell assembler translate program produce machine instructions names followed colon str main labels name next memory locatio program readable assembly language programs except glaring lack comments cult follow many simple operations required accomplish simple tasks assembly languages lack contro ow constructs provides hints programs operation contrast c routine figure a15 shorter clearer since vari ables mnemonic names loop explicit rather constructed branches fact c routine one wrote e forms program produced c compiler assembler general assembly language plays two roles see figure a16 e rst role output language compilers compiler translates program written highlevel language c pascal equivalent program machine assembler directive operation tells assembler translate program produce machine instruc tions always begins period 0010011110111101111111111110000010101111101111110000000000010100 10101111101001000000000000100000 10101111101001010000000000100100 10101111101000000000000000011000 10101111101000000000000000011100 10001111101011100000000000011100 10001111101110000000000000011000 00000001110011100000000000011001 00100101110010000000000000000001 00101001000000010000000001100101 10101111101010000000000000011100 00000000000000000111100000010010 00000011000011111100100000100001 00010100001000001111111111110111 10101111101110010000000000011000 00111100000001000001000000000000 10001111101001010000000000011000 00001100000100000000000011101100 00100100100001000000010000110000 10001111101111110000000000010100 00100111101111010000000000100000 00000011111000000000000000001000 00000000000000000001000000100001figure a12 mips machine language code routine compute print sum squares integers 0 100 a6 appendix assemblers linkers spim simulator assembly language e highlevel language called source language compilers output target language assembly languages role language write program role used dominant one today however larger main memo ries better compilers programmers write highlevel language rarely ever see instructions computer executes nevertheless assembly language still important write programs speed size critical exploit hardware features analogues highlevel languages although appendix focuses mips assembly language assembly pro gramming machines similar e additional instructions address modes cisc machines vax make assembly pro grams shorter change process assembling program provide assembly language advantages highlevel languages typechecking structured contro ow source language e highlevel language pro gram originally written addiu 29 29 32 sw 31 2029 sw 4 3229 sw 5 3629 sw 0 2429 sw 0 2829 lw 14 2829 lw 24 2429 multu 14 14 addiu 8 14 1 slti 1 8 101 sw 8 2829 mflo 15addu 25 24 15 bne 1 0 9 sw 25 2429 lui 4 4096 lw 5 2429 jal 1048812 addiu 4 4 1072 lw 31 2029 addiu 29 29 32 jr 31move 2 0 figure a13 routine figure a12 written assembly language however code routine label registers memory locations include comments a1 introduction 7when use assembly language e primary reason program assembly language opposed available highlevel language speed size program critically important example consider computer controls piece machinery cars brakes computer incorporated another device car called embedded computer type computer needs respond rapidly predictably events outside world compiler introduces figure a14 routine figure a12 written assembly language labels com ments e commands start periods assembler directives see pages a4749 text indicates succeeding lines contain instructions data indicates contain data align n indicates items succ eeding lines aligned 2 n byte boundary hence align 2 means next item word boundary globl main declares main global symbol visible code stored ot les finally asciiz stores nullterminated string memory a8 appendix assemblers linkers spim simulator uncertainty time cost operations programmers nd cult ensure highlevel language program responds wit nite time intervalsay 1 millisecond er sensor detects tire skidding assembly language programmer hand tight control instruc tions execute addition embedded applications reducing programs size ts fewer memory chips reduces cost embedded computer hybrid approach program written highlevel lan guage timecritical sections written assembly language builds strengths languages programs typically spend time execut ing small fraction programs source code observation prin ciple locality underlies caches see section 51 chapter 5 program pro ling measures program spends time ca nd timecritical parts program many cases portion program made faster better data structures algorithms sometimes however sig cant performance improvements come recoding critical portion program assembly language include stdiohintmain int argc char argv int int sum 0 0 100 1 sum sum printf sum 0 100 dn sum figure a15 routine figure a12 written c programming language figure a16 assembly language either written programmer output compiler linker compilerassembler computerhighlevel language program assembly language program program a1 introduction 9 improvement necessarily indication highlevel languages compiler failed compilers typically better programmers produc ing uniformly highquality machine code across entire program pro grammers however understand programs algorithms behavior deeper level compiler expend considerab ort ingenuity improving small sections program particular programmers en consider several proce dures simultaneously writing code compilers typically compile procedure isolation must follow strict conventions governing use registers procedure boundaries retaining commonly used values regis ters even across procedure boundaries programmers make program run faster another major advantage assembly language ability exploit special ized instructionsfor example string copy patternmatching instructions compilers cases determine program loop replaced single instruction however programmer wrote loop replace easily single instruction currently programmers advantage compiler beco cult maintain compilation techniques improve machines pipelines increase complexity chapter 4 e nal reason use assembly language highlevel language available particular computer many older specialized computers compiler programmers alternative assembly language drawbacks assembly language assembly language many disadvantages strongly argue wide spread use perhaps major disadvantage programs written assembly language inherently machinespe c must totally rewritten run another computer architecture e rapid evolution computers discussed chapter 1 means architectures become obsolete assembly language pro gram remains tightly bound original archi tecture even er computer eclipsed new faster ective machines another disadvantage assembly language programs longer equivalent programs written highlevel language example c program figure a15 11 lines long assembly program figure a14 31 lines long complex programs ratio assembly highlevel lan guage expansion factor much larger factor three exam ple unfortunately empirical studies shown programmers write roughly number lines code per day assembly highlevel languag means programmers roughly x times productive highlevel language x assembly language expansion factor a10 appendix assemblers linkers spim simulator compound problem longer programs cult read understand contain bugs assembly language exacerbates prob lem complete lack structure common programming idioms ifthen statements loops must built branches jum e resulting programs hard read reader must reconstruct every higherlevel construct pieces instance statement may slightly erent example look figure a14 answer questions type loop used lower upper bounds elaboration compilers produce machine language directly instead relying assembler compilers typically execute much faster invoke assembler part compilation however compiler generates machine lan guage must perform many tasks assembler normally handles resolv ing addresses encoding instructions binary numbers tradeoff compilation speed compiler simplicity elaboration despite considerations embedded applications writ ten highlevel language many applications large complex pro grams must extremely reliable assembly language programs longer cult write read highlevel language programs greatly increases cost writing assembly language program makes extremely dif cult verify correctness type program fact considerations led us department defense pays many complex embedded systems develop ada new highlevel language writing embedded systems a2 assemblers assembler translat le assembly language statements le binary machine instructions binary dat e translation process two major par e rst step nd memory locations labels relationship symbolic names addresses known instructions trans lated e second step translate assembly statement combining numeric equivalents opcodes register sp ers labels legal instruc tion shown figure a11 assembler produces outpu le called obje le contains machine instructions data bookkeeping infor mation ob le typically executed references procedures data ot les label external also called global labeled object external label also called global label label referring object referenced les one ned referenced les one ned label local object used within th le ned assem blers labels local default must explicitly declared global subrou tines global variables require external labels since referenced many les program local labels hide names visible modulesfor example static functions c called functions sa le addition compilergenerated namesfor example name instruction beginning loopare local compiler need produce unique names ever le local global labelsconsider program figure a14 e subroutine external global label main also contains two local labels loop strthat visible assembly language le finally routine also contains unresolved reference external label printf library routine prints values labels figure a14 could referenced anot leonly global labels visible ou le label could referenced anot le mainsince assembler processes le program individually isola tion knows addresses local labe e assembler depends another tool linker combine collection objec les libraries executable le resolving external labe e assembler assists lin ker pro viding lists labels unresolved references however even local labels present interesting challenge assembler unlike names highlevel languages assembly labels may used ar ned example figure a14 label str used la instruction ned e possibility forward reference like one forces assembler translate program two st rst nd labels produce instructions example assembler sees la instruction know word labeled str located even whether str labels instruction datum local label label referring object used within th le ned exampleanswerforward reference label used ned a2 assemblers a11 a12 appendix assemblers linkers spim simulator assemblers rst pass reads line assembly le breaks component p ese pieces called lexemes individual words numbers punctuation characters example line ble t0 100 loop contains six lexemes opcode ble register sp er t0 comma number 100 comma symbol loopif line begins label assembler records symbol table name label address memory word instruction occupies e assembler calculates many words memory instruction current line occupy keeping track instructions sizes assembler determine next instruction goes compute size variable length instruction like vax assembler examine detail however xedlength instructions like mips require cursory examinatio e assembler performs similar calculation compute space required data statements assembler reaches end assembly le symbol table records location labe ned th le e assembler uses information symbol table second pass th le actually produces machine code e assembler exam ines line th le line contains instruction assembler com bines binary representations opcode operands register sp ers memory address legal instructio e process similar one used section 25 chapter 2 instructions data words reference external symbol ned anot le completely assembled unre solved since symbols address symbol table assembler complain unresolved references since corresponding label likely b ned anot le assembly language programming language princi erence highlevel languages basic java c assembly lan guage provides simple types data contro ow assembly language programs specify type value held variable instead programmer must apply appropriate operations eg integer oatingpoint addition value addition assem bly language programs must implement contro ow go factors make assembly language programming machinemips x86more cult errorprone writing highlevel language symbol table table matches names labels addresses memory words instructions occupy bigpicture elaboration assemblers speed important twostep process done one pass le technique known backpatching pass le assembler builds possibly incomplete binary representation every instruction instr ned assembler records label instr ned nd instructions contain forward reference label assembler goes back corrects binary representation incorpo rate address label backpatching speeds assembly assembler reads input however requires assembler hold entire binary rep resentation program memory instructions backpatched require ment limit size programs assembled process com plicated machines several types branches span different ranges instructions rst sees unresolved label branch instruction must either use largest possible branch risk go back readjust many instructions make room larger branch object file format assemblers produce objec les objec le unix contains six distinct sections see figure a21 e obje le header describes size position pieces th le e text segment contains machine language code routines sour le ese routines may unexecutable unresolved references e data segment contains binary representation data source le e data also may incomplete unresolved references labels ot les e relocation information iden es instructions data words depend absolute addresses ese references must change portions program moved memory e symbol table associates addresses external labels sour le lists unresolved references e debugging information contains concise description way program compiled debugger ca nd instruction addresses correspond lines sour le print data structures readable form e assembler produces objec le contains binary representation program data additional information help link pieces program backpatching method translating assembly lan guage machine instructions assembler builds possibly incomplete binary representation every instruc tion one pass program returns previ ously ned labels text segment e segment unix ob le contains machine language code rou tines sour le data segment e segment unix object executab le contains binary represen tation initialized data used program relocation information e segment unix ob le iden es instructions data words depend absolute addresses absolute address variables routines actual address memory a2 assemblers a13 a14 appendix assemblers linkers spim simulator relocation information necessary assembler know memory locations procedure piece data occupy er linked rest program procedures data le stored con tiguous piece memory assembler know mem ory located e assembler also passes symbol table entries linker particular assembler must record external symbols ar le unresolved references occ le elaboration convenience assembler le starts address example location 0 expectation linker relocate code data assigned locations memory assembler produces relocation information contains entry describing instr le references absolute address mips subroutine call load store instructions reference absolute addresses instructions use pc relative addressing branches need relocated additional facilities assemblers provide variety convenience features help make assembler programs shorter easier write fundamentally change assembly language example data layout directives allow programmer describe data concise natural manner binary representation figure a14 directive asciiz sum 0 100 dnstores characters string memory contrast line alternative writing character ascii value figure 215 chapter 2 describes ascii encoding characters byte 84 104 101 32 115 117 109 32byte 102 114 111 109 32 48 32 46 byte 46 32 49 48 48 32 105 115 byte 32 37 100 10 0 e asciiz directive easier read represents characters letters binary numbers assembler translate characters binary repre sentation much faster accurately human data layout directives figure a21 object ﬁ le unix assembler produces objec le six distinct sections object fileheadertext segmentdatasegmentrelocationinformation symboltable debugging information specify data humanreadable form assembler translates binary layout directives described section a10 string directivede ne sequence bytes produced directive asciiz quick brown fox jumps lazy dogbyte 84 104 101 32 113 117 105 99 byte 107 32 98 114 111 119 110 32 byte 102 111 120 32 106 117 109 112 byte 115 32 111 118 101 114 32 116 byte 104 101 32 108 97 122 121 32 byte 100 111 103 0macro patternmatching replacement facility provides simple mechanism name frequently used sequence instructions instead repeat edly typing instructions every time used programmer invokes macro assembler replaces macro call corresponding sequence instructions macros like subroutines permit programmer create name new abstraction common operation unlike subroutines ever macros cause subroutine call return program runs since macro call replaced macros body program assembled er replacement resulting assembly indistinguishable equiv alent program written without macros macrosas example suppose programmer needs print many number e library routine printf accepts format string one values print arguments programmer could print integer register 7 following instructions dataint_str asciizd text la a0 int_str load string address first argexampleanswerexample a2 assemblers a15 a16 appendix assemblers linkers spim simulator mov a1 7 load value second arg jal printf call printf routine e data directive tells assembler store string programs data segment text directive tells assembler store instruc tions text segment however printing many numbers fashion tedious produces verbose program tha cult understand alternative introduce macro print_int print integer data int_strasciiz text macro print_intarg la a0 int_str load string address first arg mov a1 arg load macros parameter arg second arg jal printf call printf routine end_macro print_int7 e macro formal parameter arg names argument macro macro expanded argument call substituted formal parameter throughout macros body en assembler replaces call macros newly expanded body th rst call print_int argument 7 macro expands code la a0 int_strmov a1 7 jal printfin second call print_int say print_intt0 argument t0 macro expands la a0 int_str mov a1 t0 jal printfwhat call print_inta0 expand formal parameter variable argument proce dure macro replaced argument macro expanded la a0 int_str mov a1 a0 jal printf example illustrates drawback macros programmer uses macro must aware print_int uses register a0 correctly print value register assemblers also implement pseudoinstructions instructions pro vided assembler implemented hardware chapter 2 contains many examples mips assembler synthesizes pseudoinstructions addressing modes spartan mips hardware instruction set example section 27 chapter 2 describes assembler synthesizes blt instruc tion two instructions slt bne extending instruction set mips assembler makes assembly language programming easier without complicating hardware many pseudoinstructions could also simulated macros mips assembler generate better code instructions use dedicated register able optimize generated code elaboration assemblers conditionally assemble pieces code permits programmer include exclude groups instructions program assembled feature particularly useful several versions program differ small amount rather k leswhich greatly complicates xing bugs common codeprogrammers typically merge versions sin le code particular one version conditionally assembled excluded versions program assembled macros conditional assembly useful assemblers unix systems rarely ever provide one reason programmers systems write programs higherlevel languages like c assembly code produced compilers nd con ne macros another reason tools unixsuch cpp c preprocessor m4 general macro processorcan provide macros conditional assembly assembly language programsanswerhardware software interface a2 assemblers a17 a18 appendix assemblers linkers spim simulator a3 linkers separate compilation permits program split pieces stored erent les eac le contains logically related collection subroutines data structures form module larger progra le compiled assembled independently ot les changes one module require recompiling entire program discussed separate compila tion necessitates additional step linking combine objec les separate modules xing unresolved references e tool merges thes les linker see figure a31 performs three tasks searches program libraries nd library routines used program determines memory locations code module occupy relocates instructions adjusting absolute references resolves references amon lesa linker rst task ensure program contains ned labe e linker matches external symbols unresolved references pro grams les external symbol le resolves reference anot le refer label name unmatched references mean symbol used ned anywhere program unresolved references stage linking process necessarily mean programmer made mistake e program could referenced library routine whose code objec les passed linker er matching symbols program linker searches systems program librar ies nd pr ned subroutines data structures program refer e basic libraries contain routines read write data allocate deallo cate memory perform numeric operations libraries contain routines access database manipulate terminal windows program references unresolved symbol library erroneous linked program uses library routine linker extracts routines code library incorporates program text segmen new rou tine turn may depend library routines linker continues fetch library routines external references unresolved rou tine found external references resolved linker next determines memory locations module occupy since th les assembled isolation separate compilation split ting program across many les com piled without knowledge ot les assembler could know modules instructions data would placed relative modules linker places module memory abso lute references must relocated ect true location since linker relocation information iden es relocatable references ca ciently nd backpatch references e linker produces executab le run computer typically le format ob le except contains unresolved references relocation information a4 loadinga program links without error run run program r le secondary storage disk unix systems operating figure a31 linker searches collection object ﬁ les program libraries ﬁ nd nonlocal routines used program combines single executable ﬁ le resolves references routines different ﬁ les a4 loading 19 a20 appendix assemblers linkers spim simulator system kernel brings program memory starts running start program operating system performs following steps 1 reads executab les header determine size text data segments 2 creates new address space progra address space large enough hold text data segments along stack segment see section a5 3 copies instructions data executab le new address space 4 copies arguments passed program onto stack 5 initializes machine registers general registers cleared stack pointer must assigned address th rst free stack location see section a5 6 jumps startup routine copies programs arguments stack registers calls programs main routine main routine returns startup routine terminates program exit system call a5 memory usage e next sections elaborate description mips architecture presented earlier book earlier chapters focused primarily hardware relationship lowlevel ware ese sections focus primarily assembly language programmers use mips hardware ese sections describe set conventions followed many mips systems part hardware impose conventions instead represent agreement among programmers follow set rules ware written erent people work together mak ective use mips hardware systems based mips processors typically divide memory three parts see figure a51 e rst part near bottom address space starting address 400000 hex text segment holds programs instructions e second part text segment data segment divided two parts static data starting address 10000000 hex contains objects whose size known compiler whose lifetimethe interval dur ing program access themis programs entire execution example c global variables statically allocated since referenced static data e portion memory contains data whose size known com piler whose lifetime programs entire execution figure a51 layout memory dynamic datastatic datareserved stack segment data segmenttext segment 7fffffffhex10000000hex400000hexbecause data segment begins far program address 10000000 hex load store instructions directly reference data objects 16bit set elds see section 25 chapter 2 example load word data segment address 10010020 hex register v0 requires two instructions lui s0 0x1001 0x1001 means 1001 base 16 lw v0 0x0020s0 0x10010000 0x0020 0x10010020 e 0x number means hexadecimal value example 0x8000 8000hex 32768 ten avoid repeating lui instruction every load store mips systems typically dedicate register gp global pointer static data segmen register contains address 10008000 hex load store instructions use signed 16bit set elds access th rst 64 kb static data segment global pointer rewrite example single instruction lw v0 0x8020gpof course global pointer register makes addressing locations 10000000 hex10010000hex faster heap location e mips compiler usually stores global variables area variables hav xed locations bet ter global data arrays hardware software interface a5 memory usage a21anytime programs executio e linker assigns static objects locations data segment resolves references objects immediately static data dynamic data data name implies allocated program executes c programs malloc library rou tine a22 appendix assemblers linkers spim simulator nds returns new block memory since compiler predict much memory program allocate operating system expands dynamic data area meet demand upward arrow th gure indicates malloc expands dynamic area sbrk system call causes operating system add pages programs virtual address space see section 57 chapter 5 immediately dynamic data segment e third part program stack segment resides top virtual address space starting addr f hex like dynamic data maximum size programs stack known advance program pushes values stack operating system expands stack segment toward data segment threepart division memory possible one however two important characteristics two dynamically expandable segments far apart possible grow use programs entire address space a6 procedure call convention conventions governing use registers necessary procedures program compiled separately compile particular procedure compiler must know registers may use registers reserved procedures rules using registers called register use procedure call conventions name implies rules part conventions fol lowed ware rather rules enforced hardware however com pilers programmers try hard follow conventions violat ing causes insidious bugs e calling convention described section one used gcc com piler e native mips compiler uses complex convention slightly faster e mips cpu contains 32 generalpurpose registers numbered 031 register 0 always contains hardwired value 0 registers 1 k0 26 k1 27 reserved assembler operating system used user programs compilers registers a0a3 47 used pass th rst four arguments rou tines remaining arguments passed stack registers v0 v1 2 3 used return values functions stack segment e portion memory used program hold procedure call frames register use convention also called procedure call convention ware proto col governing use registers procedures registers t0t9 815 24 25 callersaved registers used hold temporary quantities need preserved across calls see section 28 chapter 2 registers s0s7 1623 calleesaved registers hold longlived values preserved across calls register gp 28 global pointer points middle 64k block memory static data segment register sp 29 stack pointer points last location stack register fp 30 frame pointer e jal instruction writes register ra 31 return address procedure call ese two regis ters explained next section e twoletter abbreviations names registersfor example sp stack pointerre ect registers intended uses procedure call convention describing convention use names instead regis ter numbers figure a61 lists registers describes intended uses procedure calls section describes steps occur one procedure caller invokes another procedure callee programmers write highlevel language like c pascal never see details one procedure calls another compiler takes care lowlevel bookkeeping however assembly language programmers must explicitly implement every procedure call return bookkeeping associated call centered around block memory called procedure call frame memory used variety purposes hold values passed procedure arguments save registers procedure may modify procedures caller want changed provide space variables local procedure programming languages procedure calls returns follow strict rstout lifo order memory allocated deallocated stack blocks memory sometimes called stack frames figure a62 shows typical stack frame e frame consists memory frame pointer fp points th rst word frame stack pointer sp points last word frame e stack grows higher memory addresses frame pointer points callersaved register regis ter saved routine called calleesaved register regis ter saved routine making procedure call procedure call frame block memory used hold values passed procedure arguments save registers procedure may modify procedures caller want changed pro vide space variables local procedure a6 procedure call convention a23 a24 appendix assemblers linkers spim simulator stack pointer e executing procedure uses frame pointer quickly access values stack frame example argument stack frame loaded register v0 instruction lw v0 0fp register namenumber usagezero0constant 0 at1reserved assembler v02expression evaluation results function v13expression evaluation results function a04argument 1 a15argument 2 a26argument 3 a37argument 4 t08temporary preserved across call t19temporary preserved across call t210temporary preserved across call t311temporary preserved across call t412temporary preserved across call t513temporary preserved across call t614temporary preserved across call t715temporary preserved across call s016saved temporary preserved across call s117saved temporary preserved across call s218saved temporary preserved across call s319saved temporary preserved across call s420saved temporary preserved across call s521saved temporary preserved across call s622saved temporary preserved across call s723saved temporary preserved across call t824temporary preserved across call t925temporary preserved across call k026reserved os kernel k127reserved os kernel gp28pointer global area sp29stack pointer fp30frame pointer ra31return address used function call figure a61 mips registers usage convention stack frame may built man erent ways however caller callee must agree sequence st e steps describe calling convention used mips mac convention comes play three points procedure call immediately caller invokes callee callee starts executing immediately callee returns caller th rst part caller puts procedure call arguments stan dard places invokes callee following 1 pass arguments convention th rst four arguments passed regis ters a0a3 remaining arguments pushed stack appear beginning called procedures stack frame 2 save callersaved register e called procedure use registers a0a3 t0t9 withou rst saving value caller expects use one registers er call must save value call 3 execute jal instruction see section 28 chapter 2 jumps callees rst instruction saves return address register rafigure a62 layout stack frame e frame pointer fp points th rst word currently executing procedures stack frame e stack pointer sp points last word frame e rst four arguments passed registers th h argument th rst one stored stack a6 procedure call convention a25argument 6argument 5saved registers local variables higher memory addresses lower memory addresses stack grows fpsp a26 appendix assemblers linkers spim simulator called routine starts running must take following steps set stack frame 1 allocate memory frame subtracting frames size stack pointer 2 save calleesaved registers frame callee must save values registers s0s7 fp ra altering since caller expects nd registers unchanged er call register fp saved every procedure allocates new stack frame however register ra needs saved callee makes call e callee saved registers used also must saved 3 establish frame pointer adding stack frames size minus 4 sp storing sum register fp e mips register use convention provides callee callersaved registers types registers advantageo erent circumstances callee saved registers better used hold longlived values variables users progra ese registers saved procedure call callee expects use register hand callersaved registers bet ter used hold shortlived quantities persist across call immediate values address calculation call callee also use registers shortlived temporaries finally callee returns caller executing following steps 1 callee function returns value place returned value register v02 restore calleesaved registers saved upon procedure entry 3 pop stack frame adding frame size sp4 return jumping address register raelaboration programming language permit recursive procedures procedures call either directly indirectly chain callsneed allocate frames stack nonrecursive language procedures frame may statically allocated since one invocation procedure active time older versions fortran prohibited recursion statically allocated frames produced faster code older machines however load store architec tures like mips stack frames may fast frame pointer register points directly hardware software interfacerecursive procedures procedures call either directly indirectly chain calls active stack frame permits single load store instruc tion access values frame addition recursion valuable programming technique procedure call exampleas example consider c routine main printf factorial 10 dn fact 10 int fact int n n 1 return 1 else return n fact n 1 computes prints 10 factorial 10 10 10 9 1 fact recursive routine computes n multiplying n times n e assembly code routine illustrates programs manipulate stack frames upon entry routine main creates stack frame saves two callee saved registers modify fp ra e frame larger required two register calling convention requires minimum size stack frame 24 byt minimum frame hold four argument registers a0a3 return address ra padded doubleword boundary 24 bytes since main also needs save fp stack frame must two words larger remember stack pointer kept doubleword aligned text globl main main subu spsp32 stack frame 32 bytes long sw ra20sp save return address sw fp16sp save old frame pointer addiu fpsp28 set frame pointer e routine main calls factorial routine passes single argument er fact returns main calls library routine printf passes format string result returned fact a6 procedure call convention a27 a28 appendix assemblers linkers spim simulator li a010 put argument 10 a0 jal fact call factorial function la a0lc put format string a0 move a1v0 move fact result a1 jal printf call print function finally er printing factorial main returns bu rst must restore registers saved pop stack frame lw ra20sp restore return address lw fp16sp restore frame pointer addiu spsp32 pop stack frame jr ra return caller rdata lc ascii factorial 10 dn000 e factorial routine similar structure main first creates stack frame saves calleesaved registers use addition saving ra fp fact also saves argument a0 use recursive call text fact subu spsp32 stack frame 32 bytes long sw ra20sp save return address sw fp16sp save frame pointer addiu fpsp28 set frame pointer sw a00fp save argument n e heart fact routine performs computation c program tests whether argument greater 0 routine returns value 1 argument greater 0 routine recursively calls compute factn1 multiplies value times n lw v00fp load n bgtz v0l2 branch n 0 li v01 return 1 jr l1 jump code return l2 lw v10fp load n subu v0v11 compute n 1 move a0v0 move value a0 jal fact call factorial function lw v10fp load n mul v0v0v1 compute factn1 n finally factorial routine restores calleesaved registers returns value register v0 l1 result v0 lw ra 20sp restore ra lw fp 16sp restore fp addiu sp sp 32 pop stack jr ra return callerstack recursive procedure figure a63 shows stack call fact7 main runs rst frame deepest stack main calls fact10 whose stack frame next stack invocation recursively invokes fact compute nextlowest factorial e stack frames parallel lifo order calls stack look like call fact10 returns example a6 procedure call convention a29figure a63 stack frames call fact7 mainfact 10 fact 9 fact 8 fact 7 stack stack grows old ra old fpold a0old ra old fpold a0old ra old fpold a0old ra old fpold a0old ra old fp a30 appendix assemblers linkers spim simulator answerelaboration difference mips compiler gcc compiler mips compiler usually use frame pointer register available another calleesaved register s8 change saves couple instructions procedure call return sequence however complicates code generation procedure must access stack frame sp whose value change procedures execution values pushed stack another procedure call exampleas another example consider following routine computes tak func tion widely used benchmark created ikuo takeuchi function compute anything useful heavily recursive program illustrates mips calling convention int tak int x int int z x return 1 tak tak x 1 z tak 1 z x tak z 1 x else return z int main tak18 12 6 e assembly code program shown e tak function rst saves return address stack frame arguments calleesaved regis ters since routine may make calls need use registers a0a2 ra e function uses calleesaved registers since hold values persist mainstack stack grows old ra old fp lifetime function includes several calls could potentially modify registers text globl tak tak subu sp sp 40 sw ra 32sp sw s0 16sp x move s0 a0 sw s1 20sp move s1 a1 sw s2 24sp z move s2 a2 sw s3 28sp temporary e routine begins execution testing x branches label l1 shown bge s1 s0 l1 x x executes body routine contains four recursive e rst call uses almost arguments parent addiu a0 s0 1 move a1 s1 move a2 s2 jal tak tak x 1 z move s3 v0 note result rst recursive call saved register s3 used later e function prepares arguments second recursive call addiu a0 s1 1 move a1 s2 move a2 s0 jal tak tak 1 z xin instructions result recursive call saved register s0 rst need read last time saved value th rst argu ment register a6 procedure call convention a31 a32 appendix assemblers linkers spim simulator addiu a0 s2 1 move a1 s0 move a2 s1 move s0 v0 jal tak tak z 1 x er three inner recursive calls ready th nal recursive call er call functions result v0 control jumps functions epilogue move a0 s3 move a1 s0 move a2 v0 jal tak tak tak tak takaddiu v0 v0 1 j l2 code label l1 consequent ifthenelse statement moves value argument z return register falls function epilogue l1 move v0 s2 e code function epilogue restores saved registers returns functions result caller l2 lw ra 32sp lw s0 16sp lw s1 20sp lw s2 24sp lw s3 28sp addiu sp sp 40 jr ra e main routine calls tak function initial arguments takes computed result 7 prints using spims system call printing integers globl main main subu sp sp 24 sw ra 16sp li a0 18 li a1 12 li a2 6 jal tak tak18 12 6 move a0 v0 li v0 1 print_int syscall syscall lw ra 16sp addiu sp sp 24 jr ra a7 exceptions interrupts section 49 chapter 4 describes mips exception facility responds exceptions caused errors instructions execution external interrupts caused io de section describes exception interrupt handling detail 1 mips processors part cpu called coprocessor 0 records information ware needs handle excep tions interrupts e mips simulator spim implement copro cessor 0s registers since many useful simulator part memory system spim implement however spim provide following coprocessor 0 registers registernameregisternumberusage badvaddr 8 memory address offending memory reference occurred count 9 timer compare 11value compared timer causes interrupt match status 12interrupt mask enable bits cause13exception type pending interrupt bits epc14address instruction caused exception g16 guration machine section discusses exceptions mips32 architecture spim imple ments version 70 later earlier versions spim implemented mips1 architecture handled exceptions slightl erently converting programs versions run mips32 cult changes limited status cause regist elds replacement rfe instruction eret instruction interrupt handler piece code run result exception interrupt a7 exceptions interrupts a33 a34 appendix assemblers linkers spim simulator ese seven registers part coprocessor 0s register ey accessed mfc0 mtc0 instruction er exception register epc contains address instruction executing exception occurred exception caused external interrupt instruction started executing exceptions caused execution instruc tion epc except ending instruction delay slot branch jump case epc points branch jump instruction bd bit set cause register bit set exception handler must look epc 4 ending instruction however either case excep tion handler properly resumes program returning instruction epc instruction caused exception made memory access register badvaddr contains referenced memory locations address e count register timer increments xed rate default every 10 milliseconds spim running value count register equals value compare register hardware interrupt priority level 5 occurs figure a71 shows subset status regist elds implemented mips simulator sp e interrupt mask eld contains bit six hardware two ware interrupt levels mask bit 1 allows inter rupts level interrupt processor mask bit 0 disables inter rupts level interrupt arrives sets interrupt pending bit cause register even mask bit disabled interrupt pending interrupt processor mask bit subsequently enabled e user mode bit 0 processor running kernel mode 1 running user mode spim bit xed 1 since spim processor implement kernel mode e exception level bit normally 0 set 1 er exception occurs bit 1 interrupts disabled epc updated another exception occur bit prevents exception handler disturbed interrupt exception reset ha nishes interrupt enable bit 1 interrupts allowed 0 disabled figure a72 shows subset cause regist elds spim implements e branch delay bit 1 last exception occurred instruction executed delay slot branc e interrupt pending bits become 1 inter rupt raised given hardware ware level e exception code register describes cause exception following codes numbername cause exception0intinterrupt hardware 4adeladdress error exception load instruction fetch 5adesaddress error exception store 6ibebus error instruction fetch 7dbebus error data load store 8syssyscall exception 9bpbreakpoint exception 10rireserved instruction exception 11cpucoprocessor unimplemented 12ovarithmetic ow exception 13trtrap 15fpe oating point exceptions interrupts cause mips processor jump piece code address 80000180 hex kernel user address space called exception handler code examines exceptions cause jumps appropriate point operating syst e operating system responds exception either terminating process caused exception performing action process causes error executing unimplemented instruction killed operating system hand exceptions page figure a71 status register 158410 interrupt maskusermodeexceptionlevel interrupt enable figure a72 cause register 1531862 pending interrupts branch delay exceptioncode a7 exceptions interrupts a35 a36 appendix assemblers linkers spim simulator faults requests process operating system perform service bringing page fro e operating system processes requests resumes pro e nal type exceptions interrupts external de ese generally cause operating system move data io device resume interrupted process e code example simple exception handler invokes routine print message exception interrup code similar exception handler exceptionss used spim simulator exception handler e exception ha rst saves register used pseudo instructions handler code saves a0 a1 later uses pass argumen e exception handler store old values registers stack would ordinary routine cause exception might memory reference used bad value 0 stack pointer instead exception handler stores registers exception handler register k1 since cant access memory without using two memory locations save0 save1 exception routine could interrupted two locations would enough since second exception would overwrite values saved th rst exception however simple exception ha nishes running enables interrupts problem arise ktext 0x80000180mov k1 save register sw a0 save0 handler reentrant cant use sw a1 save1 stack save a0 a1 dont need save k0k1 e exception handler moves cause epc registers cpu register e cause epc registers part cpu register set stead registers coprocessor 0 part cpu han dles exception e instruction mfc0 k0 13 moves coprocessor 0s register 13 cause register cpu register k0 note exception handler need save registers k0 k1 user programs supposed use register e exception handler uses value cause reg ister test whether exception caused interrupt see preceding ta ble exception ignored exception interrupt handler calls print_excp print message example mfc0 k0 13 move cause k0 srl a0 k0 2 extract exccode field andi a0 a0 oxf bgtz a0 done branch exccode int 0 mov a0 k0 move cause a0 mfco a1 14 move epc a1 jal print_excp print exception error message returning exception handler clears cause register resets status register enable interrupts clear exl bit allows subse quent exceptions change epc register restores registers a0 a1 executes eret exception return instruction returns instruction pointed b exception handler returns instruction following one caused exception reexecute faulting instruction cause exception done mfc0 k0 14 bump epc addiu k0 k0 4 reexecute faulting instruction mtc0 k0 14 epc mtc0 0 13 clear cause register mfc0 k0 12 fix status register andi k0 oxfffd clear exl bit ori k0 ox1 enable interrupts mtc0 k0 12 lw a0 save0 restore registers lw a1 save1 mov k1 eret return epc kdatasave0 word 0 save1 word 0 a7 exceptions interrupts a37 a38 appendix assemblers linkers spim simulator elaboration real mips processors return exception handler complex exception handler always jump instruction following epc example instruction caused exception branch instructions delay slot see chapter 4 next instruction execute may following instruction memory a8 input output spim simulates one io device memorymapped console program read write characters program running spim connects terminal separate console window xwindow version xspim windows version pcspim processor mips program running spim read characters type addition mips program writes characters terminal appear spims terminal console win dow one exception rule controlc character passed program instead causes spim stop return command mode program stops running example typed controlc program hit breakpoint terminal reconnected spim type spim commands use memorymapped io see spim xspim must started mapped_io ag pcspim enable memorymapped io comman ag settings dialog e terminal device consists two independent units receiver trans mitter e receiver reads characters keyboard e transmitter displays characters console e two units completely independen means example characters typed keyboard automatically echoed display instead program echoes character reading receiver writing transmitter program controls terminal four memorymapped device registers shown figure a81 memorymapped means register appears special memory locatio e receiver control register location 0000hex two bits actually used bit 0 called ready 1 means character arrived keyboard yet read receiver data register e ready bit readonly writes ignored e ready bit changes 0 1 character typed keyboard changes 1 0 character read receiver data register bit 1 receiver control register keyboard interrupt enable bit may read written progra e interrupt enable initially 0 set 1 program terminal requests interrupt hardware level 1 whenever character typed ready bit becomes 1 however inter rupt ect processor interrupts must also enabled status register see section a7 bits receiver control register unused e second terminal device register receiver data register address 0004hex e loworder eight bits register contain last character typed keyboard bits conta register readonly changes new character typed keyboard reading receiver data register resets ready bit receiver control register e value regist ned receiver control register 0 e third terminal device register transmitter control register address 0008hex loworder two bits register used ey behave much like corresponding bits receiver control register bit 0 called ready figure a81 terminal controlled four device registers appears memory location given address bits registers actually used e others always read 0s ignored writes 1interrupt enable ready1unused receiver control 0xffff00008received byteunusedreceiver data 0xffff00041interruptenableready1unusedtransmitter control 0xffff0008transmitter data 0xffff000c8transmitted byteunused a8 input output a39 a40 appendix assemblers linkers spim simulator readonly bit 1 transmitter ready accept new character output 0 transmitter still busy writing previous character bit 1 interrupt enable readable writable bit set 1 terminal requests interrupt hardware level 0 whenever transmitter ready new character ready bit becomes 1 e nal device register transmitter data register addr 000chex value written location loworder eight bits ie ascii character figure 215 chapter 2 sent console trans mitter data register written ready bit transmitter control register reset bit stays 0 enough time elapsed transmit character terminal ready bit becomes 1 aga e trans mitter data register written ready bit transmitter control register 1 transmitter ready writes transmitter data register ignored write appears succeed character output real computers require time send characters console terminal ese time lags simulated spim example er transmitter starts write character transmitters ready bit becomes 0 spim measures time instructions executed real clock time means transmitter become ready processor execut xed number instructions stop machine look ready bit change however let machine run bit eventually changes back 1 a9 spimspim ware simulator runs assembly language programs written processors implement mips32 architecture sp cally release 1 architecture xed memory mapping caches coprocessors 0 1 2 spims name mips spelled backwards spim read immedi ately execute assembly languag les spim selfcontained system running 2 earlier versions spim 70 implemented mips1 architecture used origi nal mips r2000 processor architecture almost proper subset mips32 architec ture th erence manner exceptions handled mips32 also introduced approximately 60 new instructions supported spim programs ran earlier versions spim use exceptions run unmo ed newer ver sions spim programs used exceptions require minor changes mips programs contains debugger provides operating systemlike services spim much slower real computer 100 times ever low cost wide availability matched real hardware obvious question use simulator people pcs contain processors r cantly faster spim one reason processors pcs intel 80 86s whose architecture far less regular far complex understand program mips processor e mips architecture may epitome simple clean risc machine addition simulators provide better environment assembly pro gramming actual machine detect errors provide better interface actual computer finally simulators useful tools studying computers programs run implemented ware silicon simulators examined easily mo ed add new instructions build new systems multiprocessors simply collect data simulation virtual machine e basic mips architecture cult program directly delayed branches delayed loads restricted address mo culty tolerable since computers designed programmed highlevel languages present interface designed compilers rather assembly language programmers good part programming complexity results delayed instructions delayed branch requires two cycles execute see elabora tions pages 284 322 chapter 4 second cycle instruction imme diately following branch execut instruction perform useful work normally would done branch also nop operation nothing similarly delayed loads require two cycles bring value memory instruction immediately following load use value see section 42 chapter 4 mips wisely chose hide complexity assembler implement virtual machine virtual computer appears nondelayed branches loads richer instruction set actual hardware e assembler reorga nizes rearranges instructions delay slo e virtual computer also provides pseudoinstructions appear real instructions assembly lan guage program e hardware however knows nothing pseudoinstruc tions assembler must translate equivalent sequences actual machine instructions example mips hardware provides instructions branch register equal equal 0 conditional branches one branches one register greater another synthesized comparing two registers branching result comparison true nonzero virtual machine virtual computer appears nondelayed branches loads richer instruction set actual hardware a9 spim 41 a42 appendix assemblers linkers spim simulator default spim simulates richer virtual machine since machine programmer nd useful however spim also simulate delayed branches loads actual hardware describe virtual machine mention passing features belong actual hardware follow convention mips assembly language pro grammers compilers routinely use extended machine implemented silicon getting started spim e rest appendix introduces spim mips r2000 assembly lan guage many details never concern however sheer volume information sometimes obscure fact spim simple easytouse progra section starts quick tutorial using spim enable load debug run simple mips programs spim co erent versions fo erent types computer system e one constant simplest version called spim commandlinedriven pro gram runs console window operates like programs type type line text hit return key spim executes command despite lack fancy interface spim everything fancy cousins ere two fancy cousins spim e version runs xwindows environment unix linux system called xspim xspim easier pro gram learn use spim commands always visible screen continually displays machines registers memory e fancy version called pcspim runs microso windo e unix windows versions spim available online publishers companion web site book tutorials xspim pcspim spim spim commandline options also online going run spim pc running microso windows rst look tutorial pcspim companion web site going run spim computer running unix lin ux read tutorial xspim surprising features although spim faithfully simulates mips computer spim simulator certain things identical actual computer e obviou er ences instruction timing memory systems identical spim simulate caches memory latency accurately r ect oatingpoint operation multiply divide instruction delays addition th oatingpoint instructions detect many error conditions would cause exceptions real machine another surprise occurs real machine well pseudo instruction expands several machine instructions singlestep exam ine memory instructions see ar erent source progra e correspondence two sets instructions fairly simple since spim reorganize instructions slots byte orderprocessors number bytes within word byte lowest number either th rightmost one e convention used machine called byte order mips processors operate either bigendian littleendian byte order example bigendian machine directive byte 0 1 2 3 would result memory word containing byte 0123while littleendian machine word would contain byte 3210spim operates byte orders spims byte order byte order underlying machine runs simulator example intel 80x86 spim littleendian macintosh sun sparc spim big endian system calls spim provides small set operating systemlike services system call syscall instruction request service program loads system call code see figure a91 register v0 arguments registers a0a3 f12 fo oatingpoint values system calls return values put results register v0 f0 fo oatingpoint results example follow ing code prints answer 5 data str asciiz answer text a9 spim 43 a44 appendix assemblers linkers spim simulator li v0 4 system call code print_str la a0 str address string print syscall print string li v0 1 system call code print_int li a0 5 integer print syscall print e print_int system call passed integer prints console print_float prints sing oatingpoint number print_double prints double precision number print_string passed pointer null terminated string writes console e system calls read_int read_float read_double read entire line input including newline characters following number ignored read_string semantics unix library routine fgets reads n 1 characters b er terminates string null byte fewer n 1 characters current line read_string reads including newline nullterminates string servicesystem call code argumentsresultprint_int1a0 integerprint_float2f12 oat print_double3f12 doubleprint_string4a0 stringread_int5integer v0 read_float6 oat f0 read_double7double f0 read_string8a0 buffer a1 lengthsbrk9a0 amountaddress v0 exit10print_char11a0 charread_char12char v0open13a0 lename string a1 ags a2 mode le descriptor a0read14a0 le descriptor a1 buffer a2 length num chars read a0write15a0 le descriptor a1 buffer a2 length num chars written a0close16a0 le descriptor exit217a0 resultfigure a91 system services warning programs use syscalls read terminal use memorymapped io see section a8 sbrk returns pointer block memory containing n additional bytes exit stops program spim running exit2 terminates spim pro gram argument exit2 becomes value returned spim simulator terminates print_char read_char write read single character open read write close standard unix library calls a10 mips r2000 assembly language mips processor consists integer processing unit cpu collec tion coprocessors perform ancillary tasks operate types data oatingpoint numbers see figure a101 spim simulates two coproces sors coprocessor 0 handles exceptions interrupts coprocessor 1 oatingpoint unit spim simulates aspects unit addressing modesmips load store architecture means load store instruc tions access memory computation instructions operate values regis ter e bare machine provides one memoryaddressing mode crx uses sum immediate c register rx addr e virtual machine provides following addressing modes load store instructions format address computationregistercontents register immimmediate imm registerimmediate contents register labeladdress label label immaddress label immediate label imm registeraddress label immediate contents register load store instructions operate aligned data quantity aligned memory address multiple size byt erefore half word a10 mips r2000 assembly language a45 a46 appendix assemblers linkers spim simulator object must stored even addresses full word object must stored addresses multiple four however mips provides instructions manipulate unaligned data lwl lwr swl swrelaboration mips assembler spim synthesizes complex addressing modes producing one instructions load store compute complex address example suppose label table referred memory loca tion 0x10000004 program contained instruction ld a0 table 4a1the assembler would translate instruction instructions figure a101 mips r2000 cpu fpu cpuregisters031arithmetic unitmultiplydividelohicoprocessor 1 fpuregisters031arithmetic unitregistersbadvaddr coprocessor 0 traps memory statuscauseepcmemory lui 4096addu a1 lw a0 8at rst instruction loads upper bits labels address register register assembler reserves use second instruction adds contents register a1 labels partial address finally load instruction uses hardware address mode add sum lower bits labels address offset original instruction value register atassembler syntaxcomments assemb les begin sharp sign everything sharp sign end line ignored iden ers sequence alphanumeric characters underbars _ dots begin number instruction opcodes reserved words used iden ers labels declared putting beginning line followed colon example dataitem word 1 text globl main must global main lw t0 item numbers base 10 default preceded 0x interpreted hexadecimal hence 256 0x100 denote value strings enclosed double quotes special characters strings follow c convention newline n tab quote spim supports subset mips assembler directives align n align next datum 2 n byte boundary example align 2 aligns next value word boundary align 0 turns automatic alignment half word float double directives next data kdata directive ascii str store string str memory null terminate a10 mips r2000 assembly language a47 a48 appendix assemblers linkers spim simulator asciiz str store string str memory null terminate byte b1 bn store n values successive bytes memory data addr subsequent items stored data segment optional argument addr present subse quent items stored starting address addr double d1 dn store n oatingpoint double preci sion numbers successive memory locations extern sym size declare datum stored sym size bytes large global label directive enables assembler store datum portion data segment tha ciently accessed via register gpfloat f1 fn store n oatingpoint single precision num bers successive memory locations globl sym declare label sym global refer enced ot leshalf h1 hn store n 16bit quantities successive mem ory halfwords kdata addr subsequent data items stored kernel data segment optional argument addr present subsequent items stored starting address addr ktext addr subsequent items put kernel text seg ment spim items may instruc tions words see word directive optional argument addr present subse quent items stored starting address addr set noat set e rst directive prevents spim complain ing subsequent instructions use regis ter e second directive reenables warning since pseudoinstructions expand code uses register programmers must care ful leaving values register space n allocates n bytes space current segment must data segment spim text addr subsequent items put user text seg ment spim items may instruc tions words see word directive optional argument addr present subse quent items stored starting address addr word w1 wn store n 32bit quantities successive mem ory words spim distinguish various parts data segment data rdata sdataencoding mips instructions figure a102 explains mips instruction encoded binary number column contains instruction encodings fo eld contiguous group bits instructio e numbers th margin values fo eld example j opcode value 2 opco eld e text top column na eld sp es bits occupies instruction example op eld contained bits 2631 instructio eld encodes instructions however groups instructions use additional elds distinguish related instructions example th eren oatingpoint instructions sp ed bi e arrows th rst column show opcodes use addition eldsinstruction format e rest appendix describes instructions implemented actual mips hardware pseudoinstructions provided mips assembler e two types instructions easily distinguished actual instructions depict elds binary representation example addition overﬂ owadd rd rs rt0rsrtrd00x20 655556 add instruction consists elds elds size bits small num ber th eld instruction begins six bits 0s register sp ers begin r th eld 5bit register sp er called rs register second argument symbolic assembly th line another common eld imm16 16bit immediate number a10 mips r2000 assembly language a49 a50 appendix assemblers linkers spim simulator figure a102 mips opcode map e values eld shown e rst column shows values base 10 second shows base 16 op eld bits 31 26 third col op eld completely sp es mips operation except six op values 0 1 16 17 18 ese operations determined ot elds iden ed pointer eld funct uses f mean rs 16 op 17 rs 17 op e seco eld rs uses z mean 0 1 2 3 op 16 17 18 19 respectively rs 16 operation sp ed elsewhere z 0 operations sp ed fourth eld bits 4 0 z 1 operations th eld f rs 17 z 1 operations th eld f 10012 3 4 56 7 8910 11 121314151617181920 2122232425 26272829303132 3334353637 3839 4041 42 434445 46 4748495051 52535455565758 5960 6162 6310012 3 4 56 7 8910 11 121314151617181920 2122232425 26272829303132 3334353637 3839 4041 42 434445 46 4748495051 52535455565758 5960 6162 6310012 3 4 56 7 8910 11 121314 151617181920 2122232425 26272829303132 3334353637 3839 4041 42 434445 46 4748495051 52535455565758 5960 6162 630 12 34 5 67 8910111213141516 17 181920 21 22 232425 26 2728 2930 310 12 34 5 67 8910111213141516 17 181920 21 22 232425 26 2728 2930 310 12 34 5 67 8910111213141516 17 181920 21 22 232425 26 2728 2930 3116 000102 03 04 0506 07 08090a0b0c0d 0e0f1011121314 1516171819 1a1b1c1d1e1f20 2122232425 2627 2829 2a 2b2c2d 2e2f30 313233 3435363738393a 3b3c3d 3e3f rs 2521 mfczcfczmtczctczcopzcopz1716bczfbcztbczflbcztltlbrtlbwitlbwrtlbperetderetrt2016bltz bgezbltzl bgezltgeitgeiu tltitltiutegitnei bltzal bgezal bltzall bgczallcvts fcvtdfcvtw fcf fcunfceqfcueqfcoltfcultf cole f cule fcsf fcngle fcseqf cnglfcltfcnge fcle fcngtffunct50funct50sllsrlsra sllvsrlv srav jrjalrmovz movn syscall breaksyncmfhimthimflomtlomult multu divdivuaddaddu subsubu andor xornorsltsltutgetgeu tlt tltuteqtneif z 1f dif z 1f sif z 0if z 1 z 20123funct40sub faddfmul fdiv fsqrt fabs fmov fnegfroundwftruncwfcellwffloor wfmovz fmovn fclzclofunct50maddmaddumul msubmsubu 1616movf movt 0 11616 movf fmovt f01op3126jjalbeq bne blez bgtz addiaddiusltisltiuandi ori xori luiz 0z 1z 2beqlbnelblezlbgtzllblh lwllw lbu lhu lwrsbsh swl swswr cache lllwc1lwc2prefldc1ldc2scswc1 swc2 sdc1sdc2 pseudoinstructions follow roughly conventions omit instruction encoding information example multiply without overﬂ owmul rdest rsrc1 src2pseudoinstruction pseudoinstructions rdest rsrc1 registers src2 either regis ter immediate value general assembler spim translate general form instruction eg add v1 a0 0x55 specialized form eg addi v1 a0 0x55arithmetic logical instructions absolute valueabs rdest rsrcpseudoinstruction put absolute value register rsrc register rdestaddition overﬂ owadd rd rs rt0rsrtrd00x20 655556 addition without overﬂ owaddu rd rs rt0rsrtrd00x21 655556 put sum registers rs rt register rdaddition immediate overﬂ owaddi rt rs imm8rsrtimm 6551 6addition immediate without overﬂ owaddiu rt rs imm9rsrtimm 65516 put sum register rs signextended immediate register rt a10 mips r2000 assembly language a51 a52 appendix assemblers linkers spim simulator andand rd rs rt0rsrtrd00x24 655556 put logical registers rs rt register rdand immediateandi rt rs imm0xcrsrtimm 65516 put logical register rs zeroextended immediate reg ister rtcount leading onesclo rd rs0x1crs0rd0 0x21655556 count leading zerosclz rd rs0x1crs0rd0 0x20655556 count number leading ones zeros word register rs put result register rd word ones zeros result 32 divide overﬂ owdiv rs rt0rsrt0 0x1a655106 divide without overﬂ owdivu rs rt0rsrt0 0x1b655106 divide register rs register rt leave quotient register lo remain der register hi note operand negative remainder unsp ed mips architecture depends convention machine spim run divide overﬂ owdiv rdest rsrc1 src2pseudoinstruction divide without overﬂ owdivu rdest rsrc1 src2pseudoinstruction put quotient register rsrc1 src2 register rdestmultiplymult rs rt0rsrt0 0x18655106 unsigned multiplymultu rs rt0rsrt0 0x19655106 multiply registers rs rt leave loworder word product register lo highorder word register himultiply without overﬂ owmul rd rs rt0x1crsrtrd02 655556 put loworder 32 bits product rs rt register rdmultiply overﬂ owmulo rdest rsrc1 src2pseudoinstruction unsigned multiply overﬂ owmulou rdest rsrc1 src2pseudoinstruction put loworder 32 bits product register rsrc1 src2 register rdest a10 mips r2000 assembly language a53 a54 appendix assemblers linkers spim simulator multiply addmadd rs rt0x1crsrt00 655106 unsigned multiply addmaddu rs rt0x1crsrt01 655106 multiply registers rs rt add resulting 64bit product 64bit value concatenated registers lo himultiply subtractmsub rs rt0x1crsrt04 655106 unsigned multiply subtractmsub rs rt0x1crsrt05 655106 multiply registers rs rt subtract resulting 64bit product 64 bit value concatenated registers lo hinegate value overﬂ owneg rdest rsrcpseudoinstruction negate value without overﬂ ownegu rdest rsrcpseudoinstruction put negative register rsrc register rdestnornor rd rs rt0rsrtrd00x27 655556 put logical registers rs rt register rd notnot rdest rsrcpseudoinstruction put bitwise logical negation register rsrc register rdestoror rd rs rt0rsrtrd00x25 655556 put logical registers rs rt register rdor immediateori rt rs imm0xdrsrtimm 65516 put logical register rs zeroextended immediate register rtremainderrem rdest rsrc1 rsrc2pseudoinstruction unsigned remainderremu rdest rsrc1 rsrc2pseudoinstruction put remainder register rsrc1 divided register rsrc2 register rdest note operand negative remainder unsp ed mips architecture depends convention machine spim run shift left logicalsll rd rt shamt0rsrtrdshamt0 655556 shift left logical variablesllv rd rt rs0rsrtrd04 655556 a10 mips r2000 assembly language a55 a56 appendix assemblers linkers spim simulator shift right arithmeticsra rd rt shamt0rsrtrdshamt3 655556 shift right arithmetic variablesrav rd rt rs0rsrtrd07 655556 shift right logicalsrl rd rt shamt0rsrtrdshamt2 655556 shift right logical variablesrlv rd rt rs0rsrtrd06 655556 register rt right distance indicated immediate shamt register rs put result register rd note argument rs ignored sll sra srlrotate leftrol rdest rsrc1 rsrc2pseudoinstruction rotate rightror rdest rsrc1 rsrc2pseudoinstruction rotate register rsrc1 right distance indicated rsrc2 put result register rdestsubtract overﬂ owsub rd rs rt0rsrtrd00x22 655556 subtract without overﬂ owsubu rd rs rt0rsrtrd00x23 655556 put th erence registers rs rt register rdexclusive orxor rd rs rt0rsrtrd00x26 655556 put logical xor registers rs rt register rdxor immediatexori rt rs imm0xersrtimm 65516 put logical xor register rs zeroextended immediate reg ister rtconstantmanipulating instructions load upper immediatelui rt imm0xfortimm 65516 load lower halfword immediate imm upper halfword reg ister rt e lower bits register set 0 load immediateli rdest immpseudoinstruction move immediate imm register rdestcomparison instructions set less thanslt rd rs rt0rsrtrd00x2a 655556 a10 mips r2000 assembly language a57 a58 appendix assemblers linkers spim simulator set less unsignedsltu rd rs rt0rsrtrd00x2b 655556 set register rd 1 register rs less rt 0 otherwise set less immediateslti rt rs imm0xarsrtimm 65516 set less unsigned immediatesltiu rt rs imm0xbrsrtimm 65516 set register rt 1 register rs less signextended immediate 0 otherwise set equalseq rdest rsrc1 rsrc2pseudoinstruction set register rdest 1 register rsrc1 equals rsrc2 0 otherwise set greater equalsge rdest rsrc1 rsrc2pseudoinstruction set greater equal unsignedsgeu rdest rsrc1 rsrc2pseudoinstruction set register rdest 1 register rsrc1 greater equal rsrc2 0 otherwise set greater thansgt rdest rsrc1 rsrc2pseudoinstruction set greater unsignedsgtu rdest rsrc1 rsrc2pseudoinstruction set register rdest 1 register rsrc1 greater rsrc2 0 otherwise set less equalsle rdest rsrc1 rsrc2pseudoinstruction set less equal unsignedsleu rdest rsrc1 rsrc2pseudoinstruction set register rdest 1 register rsrc1 less equal rsrc2 0 otherwise set equalsne rdest rsrc1 rsrc2pseudoinstruction set register rdest 1 register rsrc1 equal rsrc2 0 otherwise branch instructions branch instructions use signed 16bit instruction set eld hence jump 2 15 1 instructions bytes forward 2 15 instructions backward e jump instruction contains 26bit addr eld actual mips processors branch instructions delayed branches transfer control instruction following branch delay slot executed see chapter 4 delayed branches ect set calculation since must computed relative address delay slot instruction pc 4 branch occurs spim simulate delay slot unless bare delayed_branch ags sp ed assembly code sets usually sp ed numbers instead instructions branch label assembler computes distance branch target instructions mips32 actual pseudo conditional branch instructions likely variant example beqs likely variant beql execute instruction branchs delay slot branch taken use a10 mips r2000 assembly language a59 a60 appendix assemblers linkers spim simulator instructions may removed subsequent versions architec ture spim implements instructions described branch instruction b labelpseudoinstruction unconditionally branch instruction label branch coprocessor falsebclf cc label0x118 cc0offset 653216 branch coprocessor true bclt cc label0x118 cc1offset 653216 conditionally branch number instructions sp ed set oatingpoint coprocessors conditio ag numbered cc false true cc omitted instruction condition co ag 0 assumed branch equalbeq rs rt label4rsrtoffset 65516 conditionally branch number instructions sp ed set register rs equals rtbranch greater equal zerobgez rs label1rs1offset 65516 conditionally branch number instructions sp ed set register rs greater equal 0 branch greater equal zero linkbgezal rs label1rs0x11offset 65516 conditionally branch number instructions sp ed set register rs greater equal 0 save address next instruction reg ister 31 branch greater zerobgtz rs label7rs0offset 65516 conditionally branch number instructions sp ed set register rs greater 0 branch less equal zeroblez rs label6rs0offset 65516 conditionally branch number instructions sp ed set register rs less equal 0 branch less linkbltzal rs label1rs0x10offset 65516 conditionally branch number instructions sp ed set register rs less 0 save address next instruction register 31 branch less zerobltz rs label 1rs0offset 65516 conditionally branch number instructions sp ed set register rs less 0 a10 mips r2000 assembly language a61 a62 appendix assemblers linkers spim simulator branch equalbne rs rt label5rsrtoffset 65516 conditionally branch number instructions sp ed set register rs equal rtbranch equal zerobeqz rsrc labelpseudoinstruction conditionally branch instruction label rsrc equals 0 branch greater equalbge rsrc1 rsrc2 labelpseudoinstruction branch greater equal unsignedbgeu rsrc1 rsrc2 labelpseudoinstruction conditionally branch instruction label register rsrc1 greater equal rsrc2branch greater thanbgt rsrc1 src2 labelpseudoinstruction branch greater unsignedbgtu rsrc1 src2 labelpseudoinstruction conditionally branch instruction label register rsrc1 greater src2branch less equalble rsrc1 src2 labelpseudoinstruction branch less equal unsignedbleu rsrc1 src2 labelpseudoinstruction conditionally branch instruction label register rsrc1 less equal src2branch less thanblt rsrc1 rsrc2 labelpseudoinstruction branch less unsignedbltu rsrc1 rsrc2 labelpseudoinstruction conditionally branch instruction label register rsrc1 less rsrc2branch equal zerobnez rsrc labelpseudoinstruction conditionally branch instruction label register rsrc equal 0 jump instructions jumpj target2target 626 unconditionally jump instruction target jump linkjal target3target 626 unconditionally jump instruction target save address next instruction register ra a10 mips r2000 assembly language a63 a64 appendix assemblers linkers spim simulator jump link registerjalr rs rd0rs0rd09 655556 unconditionally jump instruction whose address register rs save address next instruction register rd defaults 31 jump registerjr rs0rs0 86515 6unconditionally jump instruction whose address register rstrap instructions trap equal teq rs rt0rsrt0 0x34655106 register rs equal register rt raise trap exception trap equal immediate teqi rs imm1rs0xcimm 65516 register rs equal signextended value imm raise trap exception trap equal teq rs rt0rsrt0 0x36655106 register rs equal register rt raise trap exception trap equal immediate teqi rs imm1rs0xeimm 65516 register rs equal signextended value imm raise trap exception trap greater equal tge rs rt0rsrt0 0x30655106 unsigned trap greater equaltgeu rs rt0rsrt0 0x31655106 register rs greater equal register rt raise trap exception trap greater equal immediate tgei rs imm1rs8imm 65516 unsigned trap greater equal immediatetgeiu rs imm1rs9imm 65516 register rs greater equal signextended value imm raise trap exception trap less tlt rs rt0rsrt0 0x32655106 unsigned trap less thantltu rs rt0rsrt0 0x33655106 register rs less register rt raise trap exception trap less immediate tlti rs imm1rsaimm 65516 a10 mips r2000 assembly language a65 a66 appendix assemblers linkers spim simulator unsigned trap less immediatetltiu rs imm1rsbimm 65516 register rs less signextended value imm raise trap exception load instructions load addressla rdest addresspseudoinstruction load computed address contents locationinto register rdestload byte lb rt address0x20rsrtoffset 65516 load unsigned byte lbu rt address0x24rsrtoffset 65516 load byte address register rt e byte signextended lb lbuload halfwordlh rt address0x21rsrtoffset 65516 load unsigned halfwordlhu rt address0x25rsrtoffset 65516 load 16bit quantity halfword address register rt e halfword signextended lh lhu load wordlw rt address0x23rsrtoffset 65516 load 32bit quantity word address register rtload word coprocessor 1lwcl ft address0x31rsrtoffset 65516 load word address register ft th oatingpoint unit load word leftlwl rt address0x22rsrtoffset 65516 load word rightlwr rt address0x26rsrtoffset 65516 load th right bytes word possibly unaligned address register rtload doubleword ld rdest addresspseudoinstruction load 64bit quantity address registers rdest rdest 1unaligned load halfwordulh rdest addresspseudoinstruction a10 mips r2000 assembly language a67 a68 appendix assemblers linkers spim simulator unaligned load halfword unsignedulhu rdest addresspseudoinstruction load 16bit quantity halfword possibly unaligned address register rdest e halfword signextended ulh ulhuunaligned load wordulw rdest addresspseudoinstruction load 32bit quantity word possibly unaligned address register rdestload linkedll rt address0x30rsrtoffset 65516 load 32bit quantity word address register rt start atomic readmodifywrite operatio operation completed store conditional sc instruction fail another processor writes block contain ing loaded word since spim simulate multiple processors store conditional operation always succeeds store instructions store byte sb rt address0x28rsrtoffset 65516 store low byte register rt address store halfwordsh rt address0x29rsrtoffset 65516 store low halfword register rt address store wordsw rt address0x2brsrtoffset 65516 store word register rt address store word coprocessor 1swcl ft address0x31rsftoffset 65516 store th oatingpoint value register ft oatingpoint coprocessor address store double coprocessor 1sdcl ft address0x3drsftoffset 65516 store doubleword oatingpoint value registers ft ft l oating point coprocessor address register ft must even numbered store word leftswl rt address0x2arsrtoffset 65516 store word rightswr rt address0x2ersrtoffset 65516 store th right bytes register rt possibly unaligned address store doubleword sd rsrc addresspseudoinstruction store 64bit quantity registers rsrc rsrc 1 address a10 mips r2000 assembly language a69 a70 appendix assemblers linkers spim simulator unaligned store halfwordush rsrc addresspseudoinstruction store low halfword register rsrc possibly unaligned address unaligned store wordusw rsrc addresspseudoinstruction store word register rsrc possibly unaligned address store conditionalsc rt address0x38rsrtoffset 65516 store 32bit quantity word register rt memory address com plete atomic readmodifywrite operation atomic operation success ful memory word mo ed register rt set 1 atomic operation fails another processor wrote location block contain ing addressed word instruction modify memory writes 0 register rt since spim simulate multiple processors instruc tion always succeeds data movement instructions move move rdest rsrcpseudoinstruction move register rsrc rdestmove hi mfhi rd00 rd00x10 610556 move lo mflo rd00 rd00x12 610556 e multiply divide unit produces result two additional registers hi lo ese instructions move values register e multiply divide remainder pseudoinstructions make unit appear operate general registers move result er computatio nishesmove hi lo register register rdmove hi mthi rs0rs0 0x116515 6move lo mtlo rs0rs0 0x136515 6move register rs hi lo register move coprocessor 0 mfc0 rt rd0x100rtrd0 655511 move coprocessor 1 mfcl rt fs0x110rtfs0 655511 coprocessors register ese instructions move values registers cpus registers move register rd coprocessor register fs fpu cpu register rt e oatingpoint unit coprocessor 1 a10 mips r2000 assembly language a71 a72 appendix assemblers linkers spim simulator move double coprocessor 1 mfc1d rdest frsrc1pseudoinstruction move oatingpoint registers frsrc1 frsrc1 1 cpu registers rdest rdest 1move coprocessor 0 mtc0 rd rt0x104rtrd0 655511 move coprocessor 1 mtc1 rd fs0x114rtfs0 655511 move cpu register rt register rd coprocessor register fs fpu move conditional zero movn rd rs rt0rsrtrd0xb 655511 move register rs register rd register rt 0 move conditional zero movz rd rs rt0rsrtrd0xa 655511 move register rs register rd register rt 0move conditional fp false movf rd rs cc0rs cc0rd01 6532556 move cpu register rs register rd fpu condition co ag number cc 0 cc omitted instruction condition co ag 0 assumed move conditional fp true movt rd rs cc0rs cc1rd01 6532556 move cpu register rs register rd fpu condition co ag number cc 1 cc omitted instruction condition code bit 0 assumed floatingpoint instructions oatingpoint coprocessor numbered 1 operates single precision 32bit double precision 64bi oatingpoint number coprocessor registers numbered f0f31 registers 32 bits wide two required hold doubles oatingpoint registers even numbers hold double precision val e oatingpoint coprocessor also eight condition code cc ags numbered 07 set compare instructions tested branch bclf bclt conditional move instructions values moved registers one word 32 bits time lwc1 swc1 mtc1 mfc1 instructions one double 64 bits time ldcl sdcl described ls ld ss sd pseudoinstructions described actual instructions bits 2126 0 single precision 1 double precision pseudoinstructions fdest oatingpoint register eg f2floatingpoint absolute value doubleabsd fd fs0x1110fsfd5 655556 floatingpoint absolute value singleabss fd fs0x1100fsfd5 compute absolute value th oatingpoint double single register fs put register fdfloatingpoint addition doubleaddd fd fs ft0x110x11ftfsfd0 655556 a10 mips r2000 assembly language a73 a74 appendix assemblers linkers spim simulator floatingpoint addition singleadds fd fs ft0x110x10ftfsfd0 655556 compute sum th oatingpoint doubles singles registers fs ft put register fdfloatingpoint ceiling wordceilwd fd fs0x110x110fsfd0xe 655556 ceilws fd fs0x110x100fsfd0xe compute ceiling th oatingpoint double single register fs convert 32bi xedpoint value put resulting word register fdcompare equal doubleceqd cc fs ft0x110x11ftfs cc0fc2 65553224 compare equal singleceqs cc fs ft0x110x10ftfs cc0fc2 65553224 compare th oatingpoint double single register fs one ft set th oatingpoint conditio ag cc 1 equal cc omitted condition co ag 0 assumed compare less equal doublecled cc fs ft0x110x11ftfs cc0fc0xe 65553224 compare less equal singlecles cc fs ft0x110x10ftfs cc0fc0xe 65553224 compare th oatingpoint double single register fs one ft set th oatingpoint conditio ag cc 1 th rst less equal second cc omitted condition co ag 0 assumed compare less doublecltd cc fs ft0x110x11ftfs cc0fc0xc 65553224 compare less singleclts cc fs ft0x110x10ftfs cc0fc0xc 65553224 compare th oatingpoint double single register fs one ft set conditio ag cc 1 th rst less second cc omitted condition co ag 0 assumed convert single double cvtds fd fs0x110x100fsfd0x21 655556 convert integer double cvtdw fd fs0x110x140fsfd0x21 655556 convert single precisio oatingpoint number integer register fs double single precision number put register fdconvert double single cvtsd fd fs0x110x110fsfd0x20 655556 convert integer single cvtsw fd fs0x110x140fsfd0x20 655556 convert double precisio oatingpoint number integer register fs single precision number put register fd a10 mips r2000 assembly language a75 a76 appendix assemblers linkers spim simulator convert double integer cvtwd fd fs0x110x110fsfd0x24 655556 convert single integer cvtws fd fs0x110x100fsfd0x24 655556 convert double single precisio oatingpoint number register fs integer put register fdfloatingpoint divide doubledivd fd fs ft0x110x11ftfsfd3 655556 floatingpoint divide singledivs fd fs ft0x110x10ftfsfd3 655556 compute quotient th oatingpoint doubles singles registers fs ft put register fdfloatingpoint ﬂ oor word floorwd fd fs0x110x110fsfd0xf 655556 floorws fd fs0x110x100fsfd0xf compute th oor th oatingpoint double single register fs put resulting word register fdload ﬂ oatingpoint double ld fdest addresspseudoinstruction load ﬂ oatingpoint single ls fdest addresspseudoinstruction load th oatingpoint double single address register fdestmove ﬂ oatingpoint double movd fd fs0x110x110fsfd6 655556 move ﬂ oatingpoint single movs fd fs0x110x100fsfd6 655556 move th oatingpoint double single register fs register fdmove conditional ﬂ oatingpoint double false movfd fd fs cc0x110x11 cc0fsfd0x11 6532556 move conditional ﬂ oatingpoint single false movfs fd fs cc0x110x10 cc0fsfd0x11 6532556 move th oatingpoint double single register fs register fd condi tion co ag cc 0 cc omitted condition co ag 0 assumed move conditional ﬂ oatingpoint double true movtd fd fs cc0x110x11 cc1fsfd0x11 6532556 move conditional ﬂ oatingpoint single true movts fd fs cc0x110x10 cc1fsfd0x11 6532556 a10 mips r2000 assembly language a77 a78 appendix assemblers linkers spim simulator move th oatingpoint double single register fs register fd condi tion co ag cc 1 cc omitted condition co ag 0 assumed move conditional ﬂ oatingpoint double zero movnd fd fs rt0x110x11rtfsfd0x13 655556 move conditional ﬂ oatingpoint single zero movns fd fs rt0x110x10rtfsfd0x13 655556 move th oatingpoint double single register fs register fd proces sor register rt 0 move conditional ﬂ oatingpoint double zero movzd fd fs rt0x110x11rtfsfd0x12 655556 move conditional ﬂ oatingpoint single zero movzs fd fs rt0x110x10rtfsfd0x12 655556 move th oatingpoint double single register fs register fd proces sor register rt 0floatingpoint multiply doublemuld fd fs ft0x110x11ftfsfd2 655556 floatingpoint multiply singlemuls fd fs ft0x110x10ftfsfd2 655556 compute product th oatingpoint doubles singles registers fs ft put register fdnegate doublenegd fd fs0x110x110fsfd7 655556 negate singlenegs fd fs0x110x100fsfd7 655556 negate th oatingpoint double single register fs put register fdfloatingpoint round wordroundwd fd fs0x110x110fsfd0xc 655556 roundws fd fs0x110x100fsfd0xc round th oatingpoint double single value register fs convert 32bit xedpoint value put resulting word register fdsquare root doublesqrtd fd fs0x110x110fsfd4 655556 square root singlesqrts fd fs0x110x100fsfd4 655556 compute square root th oatingpoint double single register fs put register fdstore ﬂ oatingpoint double sd fdest addresspseudoinstruction store ﬂ oatingpoint single ss fdest addresspseudoinstruction store th oatingpoint double single register fdest address floatingpoint subtract doublesubd fd fs ft0x110x11ftfsfd1 655556 a10 mips r2000 assembly language a79 a80 appendix assemblers linkers spim simulator floatingpoint subtract singlesubs fd fs ft0x110x10ftfsfd1 655556 compute th erence th oatingpoint doubles singles registers fs ft put register fdfloatingpoint truncate word truncwd fd fs0x110x110fsfd0xd 655556 truncws fd fs0x110x100fsfd0xd truncate th oatingpoint double single value register fs convert 32bit xedpoint value put resulting word register fdexception interrupt instructions exception return eret0x101 00x1861 196set exl bit coprocessor 0s status register 0 return instruction pointed coprocessor 0s epc register system call syscall000xc6206 register v0 contains number system call see figure a91 provided spim breakbreak code0code0xd6206 cause exception code exception 1 reserved debugger operationnop000000 655556 nothing a11 concluding remarks programming assembly language requires programmer trade helpful fea tures highlevel languagessuch data structures type checking control constructsfor complete control instructions computer executes external constraints applications response time program size require programmer pay close attention every instruction however cost level attention assembly language programs longer timeconsuming write mor cult maintain highlevel language programs moreover three trends reducing need write programs assembly language e rst trend toward improvement compilers modern com pilers produce code typically comparable best handwritten code sometimes better e second trend introduction new processors faster case processors execute multiple instruc tions simultaneously also mor cult program hand addition rapid evolution modern computer favors highlevel language programs tied single architecture finally witness trend toward increasingly complex applications characterized complex graphic interfaces many features predecessors large applications written teams programmers require modularity semantic checking features pro vided highlevel languages reading aho r sethi j ullman 1985 compilers principles techniques tools reading addison wesley slightly dated lacking coverage modern architectures still standard reference compilers sweetman 1999 see mips run san francisco ca morgan kaufmann publishers complete detailed engaging introduction mips instruction set assembly language program ming machines detailed documentation mips32 architecture available web mips32 architecture programmers volume introduction mips32 architecture httpmipscomcontentdocumentationmipsdocumentationprocessorarchitecture architectureprogrammingpublicationsformips32md000822bmips32intafp0200pdf getdownload mips32 architecture programmers vol e mips32 instruction set httpmipscomcontentdocumentationmipsdocumentationprocessorarchitecture architectureprogrammingpublic ationsformips32md000862bmips32bisafp0200pdfgetdownload mips32 architecture programmers vol e mips32 privileged resource architecture httpmipscomcontentdocumentationmipsdocumentationprocessorarchitecture architectureprogrammingpublicat ionsformips32md000902bmips32praafp0200pdfgetdownload a11 concluding remarks a81 a82 appendix assemblers linkers spim simulator a12 exercisesa1 5 a5 section a5 described memory partitioned mips systems propose another way dividing memory meets goals a2 20 a6 rewrite code fact use fewer instructions a3 5 a7 ever safe user program use registers k0 k1a4 25 a7 section a7 contains code simple exception handler one serious problem handler disables interrupts long time means interrupts fast io device may lost write better exception handler interruptable enables interrupts quickly possible a5 e simple exception handler always jumps back instruc tion following exceptio wo ne unless instruction causes exception delay slot branch case next instruction target branch write better handler uses epc register determine instruction executed er exception a6 5 a9 using spim write test adding machine program repeatedly reads integers adds runnin e program stop gets input 0 printing sum point use spim system calls described pages a43 a45 a7 5 a9 using spim write test program reads three integers prints sum largest two three use spim system calls described pages a43 a45 break ties arbitrarily a8 5 a9 using spim write test program reads positive inte ger using spim system calls integer positive program terminate message invalid entry otherwise program print names digits integers delimited exactly one space example user entered 728 output would seven two eight a9 25 a9 write test mips assembly language program compute print th rst 100 prime numbers number n prime numbers except 1 n divide evenly implement two routines test_prime n return 1 n prime 0 n prime main iterate integers testing prime print th rst 100 numbers prime test programs running spim a10 10 a6 a9 using spim write test recursive program solv ing classic mathematical recreation towers hanoi puzzle require use stack frames support recursio e puzzle consists three pegs 1 2 3 n disks number n vary typical values might range 1 8 disk 1 smaller disk 2 turn smaller disk 3 forth disk n largest initially disks peg 1 starting disk n bottom disk n 1 top forth disk 1 top e goal move disks peg 2 may move one disk time top disk three pegs onto top either two pegs moreover constraint must place larger disk top smaller disk e c program used help write assembly language program move n smallest disks start finish using extra void hanoiint n int start int finish int extra ifn 0 hanoin1 start extra finish print_stringmove disk print_intn print_stringfrom peg print_intstart print_stringto peg print_intfinish print_stringn hanoin1 extra finish start main int n print_stringenter number disks n read_int hanoin 1 2 3 return 0 a12 exercises a83 always loved word boolean claude shannonieee spectrum april 1992 shannons masters thesis showed algebra invented george boole 1800s could represent workings electrical switches basics logic designb1 introduction b3b2 gates truth tables logic equations b4b3 combinational logic b9b4 using hardware description language b20b5 constructing basic arithmetic logic unit b26b6 faster addition carry lookahead b38b7 clocks b48bappendixcomputer organization design doi 2013 elsevier inc rights reservedhttpdxdoiorg101016b97801240772630000112013 b8 memory elements flipflops latches registers b50b9 memory elements srams drams b58b10 finitestate machines b67b11 timing methodologies b72b12 field programmable devices b78b13 concluding remarks b79b14 exercises b80 b1 introduction appendix provides brief discussion basics logic design replace course logic design w ill enable cant working logic systems little exposure logic design however appendix prov cient background understand material book addition looking understand motivation behind computers implemented material serve useful introduction curiosity aroused sated appendix references end provide several additional sources information section b2 introduces basic building blocks logic namely gates section b3 uses building blocks construct simple combinational logic systems contain memory exposure logic digital systems probably familiar material thes rst two sections section b5 shows use concepts sections b2 b3 design alu mips processor section b6 shows make fast adder b4 appendix b basics logic design may safely skipped interested topic section b7 short introduction topic clocking necessary discuss memory elements work section b8 introduces memory elements section b9 extends focus random access memories describes characteristics important understanding used discussed chapter 4 background motivates many aspects memory hierarchy design discussed chapter 5 section b10 describes design use nitestate machines sequential logic blocks intend read appendix thoroughly understand material sections b2 b10 intend read material control chapter 4 skim appendices however familiarity material except section b11 section b11 intended want deeper understanding clocking methodologies timing explains basics edgetriggered clocking works introduces another clocking scheme br describes problem synchronizing asynchronous inputs roughout appendix appropriate also include segments demonstrate logic represented verilog introduce section b4 extensive complete verilog tutorial appears elsewhere cd b2 gates truth tables logic equations e electronics inside modern computer digital digital electronics operate two voltage levels interest high voltage low voltage voltage values temporary occur transitioning values discuss later section possible pitfall digital design sampling signal clearly either high low e fact computers digital also key reason use binary numbers since binary system matches underlying abstraction inherent electronics various logic families values relationships two voltage val er us rather refer voltage levels talk signals logically true 1 asserted signals logically false 0 deasserted e values 0 1 called complements inverses one another logic blocks categorized one two types depending whether contain memory blocks without memory called combinational output combinational block depends current input blocks memory outputs depend inputs value stored memory called state logic block section next focus asserted signal signal logically true 1 deasserted signal signal logically false 0 b2 gates truth tables logical equations b5only combinational logic er introducin erent memory elements section b8 describe sequential logic logic including state designedtruth tables combinational logic block contains memory completely sp ed b ning values outputs possible set input values description normally given truth table logic block n inputs 2 n entries truth table since many possible combinations input values entry sp es value outputs particular input combination truth tables consider logic function three inputs b c three outputs e f e functio ned follows true least one input true e true exactly two inputs true f true three inputs true show truth table function e truth table contain 2 3 8 entries inpuinputsoutputsabcdef 000000 001100 010100 011110 100100 101110 110110 111101 truth tables completely describe combinational logic function however grow size quickly may easy understand sometimes want construct logic function 0 many input combinations use shorthand specifying truth table entries nonzero outputs approach used chapter 4 appendix combinational logic logic system whose blocks contain memory hence compute output given input sequential logic group logic elements contain memory hence whose value depends inputs well current contents memory exampleanswer b6 appendix b basics logic design boolean algebraanother approach express logic function logic equation done use boolean algebra named er boole 19thcentury mathematician boolean algebra variables values 0 1 typical formulations three operators e operator written b e result operator 1 either variab e operation also called logical sum since result 1 either operand 1 e operator written b e result operator 1 inputs ar e operator also called logical product since result 1 operands 1 e unary operator written e result operator 1 input 0 applying operator logical value results inversion negation value ie input 0 output 1 vice versa ere several laws boolean algebra helpful manipulating logic equations identity law 0 1 zero one laws 1 1 0 0 inverse laws aa1 aa0 commutative laws b b b b associative laws b c b c b c b c distributive laws b c b c b c b cin addition two useful theorems called demorgans laws discussed depth exercises set logic functions written series equations output th hand side equation formula consisting variables three operators righthand side b2 gates truth tables logical equations b7logic equationsshow logic equations logic functions e f described previous example heres equation ddabc f equally simple fabc e little tricky ink two parts must true e true two three inputs must true true three tr us write e aseabacbcabc also derive e realizing e true exactly two inputs true en write e three possible terms two true inputs one false input eabcacbbca proving two expressions equivalent explored exercises verilog describe combinational logic whenever possible using assign statement described beginning page b23 writ nition e using verilog exclusiveor operator assign e b c b c b c yet another way describe function f even simpler representations like corresponding c code b c f b cexampleanswer b8 appendix b basics logic design gateslogic blocks built gates implement basic logic functions example gate implements function gate implements function since commutative associative gate multiple inputs output equal inpu e logical function implemented inverter always single inpu e standard representation three logic building blocks shown figure b21 rather draw inverters explicitly common practice add bubbles inputs outputs gate cause logic value input line output line inverted example figure b22 shows logic diagram function ab using explicit inverters th bubbled inputs outputs right logical function constructed using gates gates inversion several exercises give opportunity try implementing common logic functions gates next section well see implementation logic function constructed using knowledge fact logic functions constructed single gate type gate invertin e two common inverting gates called nand correspond inverted gates respectively nand gates called universal since logic function built using one gate type e exercises explore concept following two logical expressions equivalent nd setting variables show abcacbbca bacca gate device implements basic logic functions gate inverted gate nand gate inverted gate check figure b21 standard drawing gate gate inverter shown left right e signals th symbol inputs output appears righ e gates two inputs inverters single input ababfigure b22 logic gate implementation ab using explicit inverts left bubbled inputs outputs right logic function simp ed abor verilog b b3 combinational logic b9 b3 combinational logic section look couple larger logic building blocks use heavily discuss design structured logic automatically implemented logic equation truth table translation program last discuss notion array logic blocks decoders one logic block use building larger components decoder e common type decoder nbit input 2 n outputs one output asserted input combinatio decoder translates nbit input signal corresponds binary value nbit inpu e outputs thus usually numbered say out0 out1 out2 n 1 value input true outputs false figure b31 shows 3bit decoder truth table decoder called 3to8 decoder since 3 inputs 8 2 3 outpu ere also logic element called encoder performs inverse function decoder taking 2 n inputs producing nbit output decoder logic block nbit input 2 n outputs one output asserted input combination stuptuo stupni 121110out7out6out5out4out3out2out1out0 0000000000100100000010 01000000100 01100001000 10000010000 10100100000 11001000000 11110000000b truth table 3bit decoder decoder3out0out1out2out3out4out5out6out7a 3bit decoderfigure b31 3bit decoder 3 inputs called 12 11 10 2 3 8 outputs called out0 out7 output corresponding binary value input true shown truth table e label 3 input decoder says input signal 3 bits wide b10 appendix b basics logic design multiplexors one basic logic function use quite en chapter 4 multiplexor multiplexor might properly called selector since output one inputs selected control consider twoinput multiplexor e side figure b32 shows multiplexor three inputs two data values selector control value e selector value determines inputs becomes output represent logic function computed twoinput multiplexor shown gate form right side figure b32 casbs multiplexors created arbitrary number data inputs two inputs selector single signal selects one inputs true 1 false 0 n data inputs need log 2n selector inputs case multiplexor basically consists three parts 1 decoder generates n signals indicatin erent input value 2 array n gates combining one inputs signal decoder 3 single large gate incorporates outputs gates associate inputs selector values en label data inputs numerically ie 0 1 2 3 n 1 interpret data selector inputs binary number sometimes make use multiplex undecoded selector signals multiplexors easily represented combinationally verilog using expressions larger multiplexors case statements convenient care must taken synthesize combinational logic selector value also called control value e control signal used select one input values multiplexor output multiplexor mux10csbaabscfigure b32 twoinput multiplexor left implementation gates right e multiplexor two data inputs b labeled 0 1 one selector input well output c implementing multiplexors verilog requires little work especially wider two inputs show beginning page b23 b3 combinational logic b11twolevel logic plas pointed previous section logic function implemented functions fact much stronger result true logic function written canonical form every input either true complemented variable two levels gatesone orwith possible inversion th nal output representation called twolevel representation two forms called sum products product sums sumofproducts representation logical sum products terms using operator product sums opposite earlier example two equations output eeabacbcabc andeabcacbbca second equation sumofproducts form two levels logic inversions individual variab e rst equation three levels logic elaboration also write e product sumseabcacbbca derive form need use demorgans theorems discussed exercisesin text use sumofproducts form easy see logic function represented sum products constructing representation truth table function truth table entry function true corresponds product ter e product term consists logical product inputs complements inputs depending whether entry truth table 0 1 corresponding variable e logic function logical sum product terms function true easily seen example sum products form logical representation employs logical sum products terms joined using operator b12 appendix b basics logic design sum productsshow sumofproducts representation following truth table dinputsoutputsabcd 00000011 0101 0110 1001 1010 1100 1111 ere four product terms since function true 1 fo erent input combination ese abcabcabcabc us write function sum terms dabcabcabcabc note truth table entries function true generate terms equation use relationship truth table twolevel representation generate gatelevel implementation set logic functions set logic functions corresponds truth table multiple output columns saw example page b5 output column represen erent logic function may directly constructed truth table e sumofproducts representation corresponds common structuredlogic implementation called programmable logic array pla pla set inputs corresponding input complements implemented set inverters two stages e rst stage array gates form set product terms sometimes called minterms product term consist inputs complemen e second stage array gates forms logical sum number product terms figure b33 shows basic form pla exampleanswerprogrammable logic array pla structuredlogic element composed set inputs corresponding input complements two stages logic th rst generates product terms inputs input complements second generates sum terms product terms hence plas implement logic functions sum products minterms also called product terms set logic inputs joined conjunction operations product terms form rst logic stage programmable logic array pla b3 combinational logic b13a pla directly implement truth table set logic functions multiple inputs outputs since entry output true requires product term corresponding row pla output corresponds potential row gates second stage e number gates corresponds number truth table entries output true e total size pla shown figure b33 equal sum size gate array called plane size gate array called plane looking figure b33 see size gate array equal number inputs times number erent product terms size gate array number outputs times number product terms pla two characteristics help make cient way implement set logic functions first truth table entries produce true value least one output logic gates associated second eac erent product term one entry pla even product term used multiple outputs lets look example plasconsider set logic function ned example page b5 show pla implementation example e fexampleand gatesor gatesproduct terms outputsinputsfigure b33 basic form pla consists array gates followed array gates entry gate array product term consisting number inputs inverted inputs entry gate array sum term consisting number product terms b14 appendix b basics logic design truth table constructed earlier inputsoutputsabcdef 000000 001100 010100 011110 100100 101110 110110 111101 since seven unique product terms least one true value output section seven columns plane e number rows plane three since three inputs also three rows plane since three outputs figure b34 shows resulting pla product terms corresponding truth table entries top bottom rather drawing gates figure b34 designers en show position gates gates dots used intersection product term signal line input line output line corresponding gate gate required figure b35 shows pla figure b34 would look drawn way e contents pla ar xed pla created although also forms plalike structures called pals programmed electronically designer ready use roms another form structured logic used implement set logic functions readonly memory rom rom called memory set locations read however contents locations xed usually time rom manufactured ere also programmable roms proms programmed electronically designer knows conten ere also erasable proms devices require slow erasure process using ultraviolet light thus used readonly memories except design debugging process rom set input address lines set outpu e number addressable entries rom determines number address lines answerreadonly memory rom memory whose contents designated creation time er contents read rom used structured logic implement set logic functions using terms logic functions address inputs outputs bits word memory programmable rom prom form readonly memory pro grammed designer knows contents b3 combinational logic b15rom contains 2 addressable entries called height input e number bits addressable entry equal number output bits sometimes called width ro e total number bits rom equal height times widt e height width sometimes collectively referred shape rom abcefoutputsdinputsfigure b34 pla implementing logic function described examplea rom encode collection logic functions directly truth table example n functions inputs need rom address lines 2 entries entry n bits wide e entries input portion truth table represent addresses entries rom contents output portion truth table constitute contents rom truth table organized sequence entries input portion constitutes sequence binary numbers truth tables shown far output portion gives rom contents order well example starting page b13 three inputs three outpu leads rom 2 3 8 entries 3 bits wide e contents entries increasing order address directly given output portion truth table appears page b14 roms plas closely related rom fully decoded contains full output word every possible input combination pla partially decoded means rom always contain entries earlier truth table page b14 rom contains entries eight possible inputs whereas pla contains seven active product terms number inputs grows b16 appendix b basics logic design number entries rom grows exponentially contrast real logic functions number product terms grows much slowly see examples appendix erence makes plas generally mor cient implementing combinational logic functions roms advantage able implement logic function matching number inputs outpu advantage makes easier change rom contents logic function changes since size rom need change addition roms plas modern logic synthesis systems also translate small blocks combinational logic collection gates placed wired automatically although small collections gates usually cient small logic functions less overhead rigid structure rom pla preferred designing logic outside custom semicustom integrated circuit common cho eld programming device describe devices section b12 abcinputsand planeor planedefoutputsfigure b35 pla drawn using dots indicate components product terms sum terms array rather use inverters gates usually inputs run width plane true complement forms dot plane indicates input inverse occurs product term dot plane indicates corresponding product term appears corresponding output b3 combinational logic b17dont cares en implementing combinational logic situations care value output either another output true subset input combinations determines values outputs situations referred dont cares dont cares important make easier optimize implementation logic function ere two types dont cares output dont cares input dont cares represented truth table output dont cares arise dont care value output input combinatio ey appear xs output portion truth table output dont care input combination designer logic optimization program free make output true false input combination input dont cares arise output depends inputs also shown xs though input portion truth table dont cares consider logic function inputs b c ned follows c true output true whatever value b b true output e true whatever value c output f true exactly one inputs true although dont care value f whenever e true show full truth table function truth table using dont cares many product terms required pla heres full truth table without dont cares inputsoutputsabcdef 000000 001101 010011 011110 100111 101110 110110 111110 exampleanswer b18 appendix b basics logic design requires seven product terms without optimizatio e truth table written output dont cares looks like inputsoutputsabcdef 000000 001101 010011 01111x 10011x 10111x 11011x 11111x also use input dont cares truth table simp ed yield following inputsoutputsabcdef 000000 001101 010011 x1111x 1xx11x simp ed truth table requires pla four minterms implemented discrete gates one twoinput gate three gates two three inputs one two inpu compares original truth table seven minterms would required four gates logic minimization critical achieving cient implementations one tool useful hand minimization random logic karnaugh maps karnaugh maps represent truth table graphically product terms may combined easily seen nevertheless hand optimization cant logic functions using karnaugh maps impractical size maps complexity fortunately process logic minimization highly mechanical performed design tools process minimization tools take advantage dont cares specifying importan e text book references end appendix provide discussion logic minimization karnaugh maps theory behind minimization algorithms arrays logic elements many combinational operations performed data done entire word 32 bits dat us en want build array logic b4 using hardware description language b19elements represent simply showing given operation happen entire collection inputs inside machine much time want select pair buses bus collection data lines treated together single logical signal e term bus also used indicate shared collection lines multiple sources uses example mips instruction set result instruction written register come one two sources multiplexor used choose two buses 32 bits wide written result register e 1bit multiplexor showed earlier need replicated 32 times indicate signal bus rather single 1bit line showing thick gure buses 32 bits wide explicitly labeled width show logic unit whose inputs outputs buses means unit must replicat cient number times accommodate width input figure b36 shows draw multiplexor selects pair 32bit buses expands terms 1bit wide multiplexors sometimes need construct array logic elements inputs elements array outputs earlier elements example multibitwide alu constructed cases must explicitly show create wider arrays since individual elements array longer independent case 32bitwide multiplexor bus logic design collection data lines treated together single logical signal also shared collection lines multiple sources uses muxcselect323232bamuxselectb31a31c31muxb30a30c30muxb0a0c0 32bit wide 2to1 multiplexor b 32bit wide multiplexor actually array 32 1bit multiplexorsfigure b36 multiplexor arrayed 32 times perform selection two 32 bit inputs note still one data selection signal used 32 1bit multiplexors b20 appendix b basics logic design parity function output depends number 1s input even parity function output 1 input even number ones suppose rom used implement even parity function 4bit input b c represents contents rom addressabcd00101 10110 20101 30110 40101 50110 60101 70110 81001 91010 101001 111010 121001 131010 141001 151010 b4 using hardware description language today digital design processors related hardware systems done using hardware description language language serves two purposes first provides abstract description hardware simulate debug design second use logic synthesis hardware compilation tools description compiled hardware implementation section introduce hardware description language verilog show used combinational design rest appendix expand use verilog include desig n sequential logic optional sections chapter 4 appear online use verilog describe processor implementations optional section chapter 5 appears online use system verilog describe cache controller implementations system verilog adds structures useful features verilog verilog one two primary hardware description languages vhdl verilog somewhat heavily used industry based c opposed vhdl based ad e reader generally familiar nd basics verilog use appendix easy follow check hardware description language programming language describing hardware used generating simulations hardware design also input synthesis tools generate actual hardware verilog one two common hardware description languages vhdl one two common hardware description languages b4 using hardware description language b21readers already familiar vhdl sho nd concepts simple provided exposed syntax c verilog specify behavioral struct nition digital system behavioral spe cation describes digital system functionally operates structural spe cation describes detailed organization digital system usually using hierarchical description structural sp cation used describe hardware system terms hierarchy basic elements gates switch us could use verilog describe exact contents truth tables datapath last section arrival hardware synthesis tools designers use verilog vhdl structurally describe datapath relying logic synthesis generate control behavioral description addition cad systems provide extensive libraries standardized parts alus multiplexors regist les memories programmable logic blocks well basic gates obtaining acceptable result using libraries logic synthesis requires sp cation written eye toward eventual synthesis desired outcome simple designs primarily means making clear expect implemented combinational logic expect require sequential logic examples use section remainder appendix written verilog eventual synthesis mind datatypes operators verilog ere two primary datatypes verilog 1 wire sp es combinational signal 2 reg register holds value vary time reg need necessarily correspond actual register implementation although en register wire named x 32 bits wide declared array reg 310 x wire 310 x also sets index 0 designate le cant bit register en want access sub eld register wire refer contiguous set bits register wire notation starting bit ending bit indices must constant values array registers used structure like regist le memory us declaration reg 310 registerfile031sp es variable register le equivalent mips register le register 0 th rst accessing array refer single element c using notation registerfileregnumbehavioral spe cation describes digital system operates functionally structural spe cation describes digital system organized terms hierarchical connection elements hardware synthesis tools computeraided design ware generate gate level design based behavioral descriptions digital system wire verilog sp es combinational signal reg verilog register b22 appendix b basics logic design e possible values register wire verilog 0 1 representing logical false true x representing unknown initial value given registers wire connected something z representing highimpedance state tristate gates discuss appendix constant values sp ed decimal numbers well binary octal hexadecimal en want say exactly large constan eld bi done pr xing value decimal number specifying size bits example 4b0100 sp es 4bit binary constant value 4 4d4 8 h4 sp es 8bit constant value 4 twos complement representation values also concatenated placing within separated commas e notation xbitfield replicates bit field x times example 162b01 creates 32bit value pattern 0101 01 a3116b150 creates value whose upper 16 bits come whose lower 16 bits come bverilog provides full set unary binary operators c including arithmetic operators logical operators comparison operators th operators cs conditional operator used form condition expr1 expr2 returns expr1 condition true expr2 false verilog adds set unary logic reduction operators yield single bit applying logical operator bits operand example returns value obtained anding bits together returns reduction obtained using exclusive bits awhich followin ne exactly value l 8bimoooo2 8hf0 3 8d240 4 41b141b0 5 4b14b0check b4 using hardware description language b23structure verilog program verilog program structured set modules may represent anything collection logic gates complete system modules similar classes c although nearly powerful module sp es input output ports describe incoming outgoing connections module module may also declare additional variab e body module consists initial constructs initialize reg variables continuous assignments whic ne combinational logic always constructs ca ne either sequential combinational logic instances modules used implement module ned representing complex combinational logic verilog continuous assignment indicated keyword assign acts like combinational logic function output continuously assigned value change input values r ected immediately output value wires may assigned values cont inuous assignments using continuous assignments ca ne module implements halfadder figure b41 shows assign statements one sure way write verilog generates combinational logic complex structures however assign statements may awkward tedious use also possible use always block module describe combinational logic element although care must taken using always block allows inclusion verilog control constructs ifthenelse case statements statements repeat statements used ese statements similar c small changes always block sp es optional list signals block sensitive list starting wit e always block reevaluated figure b41 verilog module deﬁ nes halfadder using continuous assignments b24 appendix b basics logic design listed signals changes value list omitted always block constantly evaluated always block specifying combinational logic sensitivity list include input signals multiple verilog statements executed always block surrounded keywords begin end take place c always block thus looks like always list signals cause reevaluation beginverilog statements including assignments control statements endreg variables may assigned inside always block using procedural assignment statement distinguished continuous assignment saw ea ere however tw erent types procedural assignmen e assignment operator executes c righthand side evaluated th hand side assigned value furthermore executes like normal c assignment statement completed next statement executed hence assignment operator name blocking assignment blocking useful generation sequential logic return shortly e form assignment nonblocking indicated nonblocking assignment righthand sides assignments always group evaluated assignments done simultaneously rst example combinational logic implemented using always block figure b42 shows implementation 4to1 multiplexor uses case construct make easy write e case construct looks like c switch statement figure b43 sho nition mips alu also uses case statement since reg variables may assigned inside always blocks want describe combinational logic using always block care must taken ensure reg synthesize register variety pitfalls described elaboration elaboration continuous assignment statements always yield combinational logic verilog structures even always blocks yield unexpected results logic synthesis common problem creating sequential logic implying existence latch register results implementation slower costly perhaps intended ensure logic intend combinational synthesized way make sure following 1 place combinational logic continuous assignment always block2 make sure signals used inputs appear sensitivity list always block3 ensure every path always block assigns value exact set bitsthe last easiest overlook read example figure b515 convince property adhered sensitivity list e list signals sp es always block reevaluated blocking assignment verilog assignment completes execution next statement nonblocking assignment assignment continues er evaluating right hand side assigning hand side value er righthand sides evaluated b5 constructing basic arithmetic logic unit b25figure b43 verilog behavioral deﬁ nition mips alu could synthesized using module library containing basic arithmetic logical operations figure b42 verilog deﬁ nition 4to1 multiplexor 32bit inputs using case statement e case statement acts like c switch statement except verilog code associated selected case executed case state break end fall next statement b26 appendix b basics logic design assuming values initially zero values b er executing verilog code inside always block c1a c b c b5 constructing basic arithmetic logic unit e arithmetic logic unit alu brawn computer device per forms arithmetic operations like addition subtraction logical operations like section constructs alu four hardware building blocks gates inverters multiplexors illustrates combinational logic works next section see addition sped clever designs mips word 32 bits wide need 32bitwide alu lets assume connect 32 1bit alus create desired alu well therefore start constructing 1bit alu 1bit alu e logical operations easiest map directly onto hardware components figure b21 e 1bit logical unit looks like figure b51 e multiplexor right selects b b depending whether value operation 0 e line controls multiplexor shown color distinguish lines containing data notice renamed control output lines multiplexor give names r ect function alu e next function include addition adder must two inputs operands singlebit output th ere must second output pass carry called carryout since carryout neighbor adder must included input need third inpu input called carryin figure b52 shows inputs outputs 1bit adder since know addition supposed specify outputs black box based inputs figure b53 demonstrates express output functions carryout sum logical equations equations turn implemented logic gates lets carryout figure b54 shows values inputs carryout 1 turn truth table logical equation carryoutbcarryinacarryinababcarryin check alu n arthritic logic unit rare arithmetic logic unit randomnumber generator supplied standard computer systems stan kellybootle e devils dp dictionary 1981 b1 introduction b 27operation 10resultabfigure b51 1bit logical unit orcarryin sumcarryout abfigure b52 1bit adder adder called full adder also called 32 adder 3 inputs 2 outputs adder b inputs called 22 adder halfadder stuptuo stupni commentsabcarryincarryoutsum 000000 0 0 00two001010 0 1 01two010010 1 0 01two011100 1 1 10two100011 0 0 01two101101 0 1 10two110101 1 0 10two111111 1 1 11twofigure b53 input output speciﬁ cation 1bit adder b28 appendix b basics logic design b carryin true three terms must also true leave last term corresponding fourth line table thus simplify equation carryoutbcarryinacarryinab figure b55 shows hardware within adder black box carryout consists three gates one gate e three gates correspond exactly three parenthesized terms formula carryout gate sums three terms inputsabcarryin 011101 110 111figure b54 values inputs carryout 1 abcarryin carryout figure b55 adder hardware carryout signal e rest adder hardware logic sum output given equation page e sum bit set exactly one input 1 three inputs ar e sum results complex boolean equation recall means sumabcarryinabcarryinabcarryinabcarryin e drawing logic sum bit adder black bo exercise reader b5 constructing basic arithmetic logic unit b29abcarryin carryout operation 102resultfigure b56 1bit alu performs addition see figure b55 figure b56 shows 1bit alu derived combining adder earlier components sometimes designers also want alu perform simple operations generatin e easiest way add operation expand multiplexor controlled operation line example connect 0 directly new input expanded multiplexor 32bit alunow completed 1bit alu full 32bit alu created connecting adjacent black boxes using xi mean ith bit x figure b57 shows 32bit alu single stone cause ripples radiate shores quiet lake single carry le cant bit result0 ripple way adder causing carry th cant bit result31 hence adder created directly linking carries 1bit adders called ripple carry adder well see faster way connect 1bit adders starting page b38 subtraction adding negative version operand adders perform subtraction recall shortcut negating twos complement number invert bit sometimes called ones complement add 1 invert bit simply add 21 multiplexor chooses b b figure b58 shows suppose connect 32 1bit alus figure b57 e added multiplexor gives option b inverted value depending binvert b30 appendix b basics logic design one step negating twos complement number notice least cant bit still carryin signal even though unnecessary addition happens set carryin 1 instead e adder calculate b 1 selecting inverted version b get exactly want abababab 11 e simplicity hardware design twos complement adder helps explain twos complement representation become universal standard integer computer arithmetic a0operation carryin alu0carryout b0carryin a1carryin alu1carryout b1result0result1a2carryin alu2carryout b2a31carryin alu31b31result2result31 figure b57 32bit alu constructed 32 1bit alus carryout th cant bit connected carryin mor cant bi organization called ripple carry b5 constructing basic arithmetic logic unit b31binvert abcarryin carryout operation 102result10figure b58 1bit alu performs addition b b selecting b binvert 1 setting carryin 1 le cant bit alu get twos comple ment subtraction b instead addition b mips alu also needs function instead adding separate gate reuse much hardware already alu like subtrac e insight comes following truth abab b equivalent b fact called demorgans theorem explored exercises depth since b need add alu figure b59 shows change tailoring 32bit alu mips ese four operationsadd subtract orare found alu almost every computer operations mips instructions performed alu design alu incomplete one instruction still needs support set less instruction slt recall operation produces 1 rs rt 0 otherwise consequently slt set le cant bit 0 le cant bit set according comparison alu perform slt w rst need expand threeinput b32 appendix b basics logic design multiplexor figure b58 add input slt result call new input less use slt e top drawing figure b510 shows new 1bit alu expanded multiplexor description slt must connect 0 less input upper 31 bits alu since bits always set 0 remains consider compare set least signi cant bit set less instructions happens subtract b th erence negative b since ababbb ab00we want le cant bit set less operation 1 b 1 b negative 0 positive desired result corresponds exactly sign bit values 1 means negative 0 means positive following line argument need connect sign bit adder output le cant bit get set less unfortunately result output th cant alu bit top figure b510 slt operation output adder alu output slt operation obviously input value less binvertabcarryincarryoutoperation102result10ainvert10figure b59 1bit alu performs addition b b selecting ainvert 1 b binvert 1 get b instead b binvert abcarryin carryout operation 102result10ainvert 1 03lessbinvert abcarryin operation 102result103lessoverflow detectionsetoverflow ainvert 1 0figure b510 top 1bit alu performs addition b b bottom 1bit alu signiﬁ cant bit e top drawing includes direct input connected perform set less operation see figure b511 bottom direct output adder less comparison called set see exercise b24 end appendix see calculate ow fewer inputs b34 appendix b basics logic design us need new 1bit alu th cant bit extra output bit adder outpu e bottom drawing figure b510 shows design new adder output line called set used slt long need special alu th cant bit added ow detec tion logic since also associated bit a0operation carryin alu0lesscarryout b0carryin a1carryin alu1lesscarryout b1result0result1a2carryin alu2lesscarryout b2a31carryin alu31lessb31result2result31 binvert ainvert 000overflow setcarryin figure b511 32bit alu constructed 31 copies 1bit alu top figure b510 one 1bit alu bottom ﬁ gure e less inputs connected 0 except le cant bit connected set output th cant bit alu performs b select input 3 multiplexor figure b510 result 0 001 b result 0 000 otherwise b1 introduction b 35alas test less little complicated described ow explore exercises figure b511 shows 32bit alu notice every time want alu subtract set carryin binvert 1 adds logical operations want control lines 0 therefore simplify control alu combining carryin binvert single control line called bnegate tailor alu mips instruction set must support conditional branch instruction ese instructions branch either two registers equal unequal e easiest way test equality alu subtract b test see result 0 since abab 0 us add hardware test result 0 test equality e simplest way outputs together send signal inverter zerore sultresultresultresultresult 3130 210 figure b512 shows revised 32bit alu think combination 1bit ainvert line 1bit binvert line 2bit operation lines 4bit control lines alu telling perform add subtract set less figure b513 shows alu control lines corresponding alu operation finally seen inside 32bit alu use universal symbol complete alu shown figure b514 deﬁ ning mips alu verilog figure b515 shows combinational mips alu might sp ed verilog sp cation would probably compiled using standard parts library provided adder could instantiated completeness show alu control mips figure b516 used chapter 4 build verilog version mips datapath e next question quickly alu add two 32bit operands determine b inputs carryin input depends operation adjacent 1bit adder trace way chain dependencies connect th cant bit le cant bit th cant bit sum must wait sequential evaluation 32 1bit adder sequential chain reaction slow used timecritical hardware e next section explores speedup additio topic crucial understanding rest appendix may skipped b36 appendix b basics logic design a0operation carryin alu0lesscarryout b0a1carryin alu1lesscarryout b1result0result1a2carryin alu2lesscarryout b2a31carryin alu31lessb31result2result31 bnegate ainvert 000overflow setcarryin zerofigure b512 ﬁ nal 32bit alu adds zero detector figure b511 alu control linesfunction 0000and0001or0010add0110subtract 0111set less 1100nor figure b513 values three alu control lines bnegate operation corresponding alu operations b5 constructing basic arithmetic logic unit b37aluaalu operation bcarryout zeroresultoverflow figure b514 symbol commonly used represent alu shown figure b512 symbol also used represent adder normally labeled either alu adder figure b515 verilog behavioral deﬁ nition mips alu b38 appendix b basics logic design suppose wanted add operation b called nand could alu change support 1 change calculate nand quickly using current alu since abab already b 2 must expand big multiplexor add another input add new logic calculate nand b6 faster addition carry lookahead e key speeding addition determining carry highorder bits sooner ere variety schemes anticipate carry worst case scenario function log 2 number bits adder ese anticipatory signals faster go fewer gates sequence takes many gates anticipate proper carry key understanding fastcarry schemes remember unlike ware hardware executes parallel whenever inputs change fast carry using inﬁ nite hardware mentioned earlier equation represented two levels logic since external inputs two operands carryin least check figure b516 mips alu control simple piece combinational control logic b6 faster addition carry lookahead b39 cant bit adder theory could calculate carryin values remaining bits adder two levels logic example carryin bit 2 adder exactly carryout bit 1 formula carryinbcarryinacarryinab1 211111 similarly carryi ned carryinbcarryinacarryinab 1000000 using shorter traditional abbreviation c carryin rewrite formulas cbcacab cbcacab 2111111 1000000 substituting th nition c1 th rst equation results formula caabaacabc babbac 2100100100 100100 bbcab 10011 imagine equation expands get higher bits adder grows rapidly number bi complexity r ected cost hardware fast carry making simple scheme prohibitively expensive wide adders fast carry using first level abstraction propagate generatemost fastcarry schemes limit complexity equations simplify hardware still making substantial speed improvements ripple carry one scheme carrylookahead adder chapter 1 said computer systems cope complexity using levels abstraction carrylookahead adder relies levels abstraction implementation lets factor original equation rst step c1bcacab ababc iiiiiii iiiii rewrite equation c2 using formula would see repeated patterns cababababc 2111100000 note repeated appearance bi bi formula ese two important factors traditionally called generate gi propagate pi b40 appendix b basics logic design gab pab iii iii using ne c 1 get c1gpc iiii see signals get names suppose g enc1gpc1pc1 iiiiii adder generates carryout c 1 independent value car ryin c suppose g 0 p encgpc1cc iiiiii 10 adder propagate carryin carryout putting two together carryin 1 1 either g 1 p 1 carryin 1as analogy imagine row dominoes set edge e end domino tipped pushing one far away provided gaps two similarly carry made true generate far away provided propagates true relying th nitions propagate generate rst level abstraction express carryin signals economically lets show 4 bits cgpc cgpgppc cgpgpp 1000 2110100 322121 g gpppc cgpgppgpppg 02100 43323213210 pp3p2p1pc 00 ese equations represent common sense carryin 1 earlier adder generates carry intermediary adders propagate carry figure b61 uses plumbing try explain carry lookahead even simp ed form leads large equations hence considerable logic even 16bit adder lets try moving two levels abstraction fast carry using second level abstraction first consider 4bit adder carrylookahead logic single building block connect ripple carry fashion form 16bit adder add faster original little hardware b6 faster addition carry lookahead b41to go faster well need carry lookahead higher level perform carry look ahead 4bit adders need propagate generate signals higher level four 4bit adder blocks ppppp ppppp ppppp pppp 03210 17654 2111098 3151413 p12 super propagate signal 4bit abstraction p true bits group propagate carry super generate signal g care carry cant bit 4bit group obviously occurs generate true tha cant bit also occurs earlier generate true intermediate propagates including th cant bit also true ggpgppgpppg ggpgpp 03323213210 177676 gpppg ggpgppgpp 57654 2111110111091110 p pgggpgppgpppg 98315151415141315141312 figure b62 updates plumbing analogy show p0 g0 en equations higher level abstraction carry 4bit group 16bit adder c1 c2 c3 c4 figure b63 similar carry equations bit 4bit adder c1 c2 c3 c4 page b40 cgpc cgpgppc cgpgpp 1000 2110100 322121 g gpppc cgpgppgpppg 02100 43323213210 ppppc 32100 figure b63 shows 4bit adders connected carrylookahead unit e exercises explore sp erences carry sc erent notations multibit propagate generate signals design 64bit adder b42 appendix b basics logic design c4p3p2p1p0g3g2g1g0c0c2p1p0g1g0c0c1p0g0c0figure b61 plumbing analogy carry lookahead 1 bit 2 bits 4 bits using water pipes valves e wrenches turned open close valves water shown color e output pipe c 1 full either nearest generate value g turned propagate value p water upstream either earlier generate propagate water behind carryin c0 result carry without help generates help propagates b6 faster addition carry lookahead b43g0p3p2p1g3g2g1g0p0p3p2p1p0figure b62 plumbing analogy nextlevel carrylookahead signals p0 g0 p0 open four propagates p open wat ows g0 least one generate g open propagates downstream generate open b44 appendix b basics logic design levels propagate generate determine g pi pi g values two 16bit numbers 0001 1010 0011 0011twob 1110 0101 1110 1011twoalso carryout15 c4 aligning bits makes easy see values generate g ai bi propagate p ai bia 0001 1010 0011 0011b 1110 0101 1110 1011 gi 0000 0000 0010 0011 pi 1111 1111 1111 1011 bits numbered 15 0 fro right next super propagates p3 p2 p1 p0 simply lowerlevel propagates p11111 p11111 p11111 p111 321000 e super generates complex use following equations ggpgppgpppg 03323213210 0101011 001100000 17767657654 0 ggpgppgpppg 10111111000101 2111110111 ggpgpp0 09111098 010110111000000 gpppg g ggpgppgpppg 315151415141315141312 010 110111000000 finally carryout15 cgpgppgpppg ppppc 43323213210 32100 0 1111111111 11000 00000 hence carry adding two 16bit numbers exampleanswer b6 faster addition carry lookahead b45a4carryin alu1 p1 g1b4a5b5a6b6a7b7a0carryin alu0 p0 g0b0carrylookahead unit a1b1a2b2a3b3carryin result0œ3pi gici 1pi 1gi 1c1result4œ7a8carryin alu2 p2 g2b8a9b9a10b10a11b11ci 2pi 2gi 2c2result8œ11a12carryin alu3 p3 g3b12a13b13a14b14a15b15ci 3pi 3gi 3c3result12œ15ci 4c4carryout figure b63 four 4bit alus using carry lookahead form 16bit adder note carries come carrylookahead unit 4bit alus b46 appendix b basics logic design e reason carry lookahead make carries faster logic begins evaluating moment clock cycle begins result change output gate stops changing taking shortcut going fewer gates send carry signal output gates stop changing sooner hence time adder less appreciate importance carry lookahead need calculate relative performance ripple carry adders speed ripple carry versus carry lookahead one simple way model time logic assume gate takes time signal pass time estimated simply counting number gates along path piece logic compare number gate delays paths two 16bit adders one using ripple carry one using twolevel carry lookahead figure b55 page b28 shows carry signal takes two gate delays per bi en number gate delays carry least cant bit carry th cant 16 2 32for carry lookahead carry th cant bit c4 ned example takes two levels logic specify c4 terms pi g several terms p sp ed one level logic using p g sp ed two levels using p g worst case next level abstraction two levels logic p g one level ned terms b assume one gate delay level logic equations worst case 2 2 1 5 gate delays hence path carry carry 16bit addition carrylookahead adder six times faster using simple estimate hardware speed summary carry lookahead ers faster path waiting carries ripple 32 1bit adder faster path paved two signals generate propagate exampleanswer b6 faster addition carry lookahead b47 e former creates carry regardless carry input latter passes carry along carry lookahead also gives another example abstraction important computer design cope complexity using simple estimate hardware speed gate delays relative performance ripple carry 8bit add versus 64bit add using carry lookahead logic 1 64bit carrylookahead adder three times faster 8bit adds 16 gate delays 64bit adds 7 gate delays ey speed since 64bit adds need levels logic 16bit adder 3 8bit adds faster 64 bits even carry lookahead elaboration accounted one arithmetic logical operations core mips instruction set alu figure b514 omits support shift instructions would possible widen alu multiplexor include left shift 1 bit right shift 1 bit hardware designers created circuit called barrel shifter shift 1 31 bits time takes add two 32bit numbers shifting normally done outside alu elaboration logic equation sum output full adder page b28 expressed simply using powerful gate exclusive gate true two operands disagree xy xy 10in technologies cient two levels gates using symbol represent exclusive new equation sumabcarryin also drawn alu traditional way using gates computers designed today cmos transistors basically switches cmos alu barrel shifters take advantage switches many fewer multiplexors shown designs design principles similar elaboration using lowercase uppercase distinguish hierarchy generate propagate symbols breaks two levels alternate notation scales gij pij generate propagate signals bits j thus g 11 generated bit 1 g 41 bits 4 1 g 161 bits 16 1check b48 appendix b basics logic design b7 clocksbefore discuss memory elements se quential logic useful discuss br topic cloc short section introduces topic similar discussion found section 42 details clocking timing methodologies presented section b11 clocks needed sequential logic decide element contains state updated clock simply freerunning signal wit xed cycle time clock frequency simply inverse cycle time shown figure b71 clock cycle time clock period divided two portions clock high clock low text use edgetriggered clocking means state changes occur clock edge use edge triggered methodology simpler explain depending tech nology may may best choice clocking methodology edgetriggered clocking clocking scheme state changes occur clock edge clocking methodology e approach used determine data valid stable relative clock clock period rising edgefalling edge figure b71 clock signal oscillates high low values e clock period time one full cycle edgetriggered design either rising falling edge clock active causes state changed edgetriggered methodology either rising edge falling edge clock active causes state changes occur see next section state elements edgetriggered design implemented contents state elements change active clock edge e choice edge active uenced implementation technology ect concepts involved designing logic e clock edge acts sampling signal causing value data input state element sampled stored state element using edge trigger means sampling process essentially instantaneous eliminating problems could occur signals sampled slightl erent times e major constraint clocked system also called synchronous system signals written state elements must valid active state element memory element synchronous system memory system employs clocks data signals read clock indicates signal values stable b7 clocks b49clock edge occurs signal valid stable ie changing value change inputs change since combinational circuits feedback inputs combinational logic unit changed outputs eventually become valid figure b72 shows relationship among state elements combinational logic blocks sync hronous sequen e state elements whose outputs change er clock edge provide valid inputs combinational logic block ensure values written state elements active clock edge valid clock must long enough period signals comb inational logic block stabilize clock edge samples values storage state elemen constraint sets lower bound length clock period must long enough state element inputs valid rest appendix well chapter 4 usually omit clock signal since assuming state elements updated clock edge state elements written every clock edge others written certain conditions register updated cases explicit write signal state elemen e write signal must still gated clock update occurs clock edge write signal active see done used next section one advantage edgetriggered methodology possible state element used input output combinational logic block shown figure b73 practice care must taken prevent races situations ensure clock period long enough topic discussed section b11 discussed clocking used update state elements discuss construct state elements stateelement1stateelement2combinational logicclock cycle figure b72 inputs combinational logic block come state element outputs written state element e clock edge determines contents state elements updated b50 appendix b basics logic design elaboration occasionally designer nd useful small number state elements change opposite clock edge majority state elements requires extreme care approach effects inputs outputs state element would designers ever consider case amount combinational logic state element small enough could operate onehalf clock cycle rather usual full clock cycle state element written clock edge corresponding half clock cycle since inputs outputs usable onehalf clock cycle one common place technique used register ﬁ les le often done half normal clock cycle chapter 4 makes use idea reduce pipelining overhead b8 memory elements flipflops latches registers section next discuss basic principles behind memory elements starting wit ops latches moving regist les nishing memories memory elements store state output memory element depends inputs value stored inside memory elemen us logic blocks containing memory element contain state sequential register le state element consists set registers read written supplying register number accessed stateelementcombinational logicfigure b73 edgetriggered methodology allows state element read written clock cycle without creating race could lead undetermined data values course clock cycle must still long enough input values stable active clock edge occurs rsqqfigure b81 pair crosscoupled gates store internal value e value stored output q recycled inverting obtain q inverting q obtain q either r q asserted q deasserted vice versa b8 memory elements flipflops latches registers b51 e simplest type memory elements unclocked clock input although use clocked memory elements text unclocked latch simplest memory element lets look circui rst figure b81 shows sr latch setreset latch built pair gates gates inverted outpu e outputs q q represent value stored state complement neither r asserted crosscoupled gates act inverters store previous values q qfor example output q true bottom inverter produces false output q becomes input top inverter produces true output q asserted output q asserted q deasserted r asserted output q asserted q deasserted r deasserted last values q q continue stored crosscoupled structure asserting r simultaneously lead incorrect operation depending r deasserted latch may oscillate become metastable described detail section b11 crosscoupled structure basis complex memory elements allow us store dat ese elements contain additional gates used store signal values cause state updated conjunction cloc e next section shows elements built flipflops latches ops latches simplest memory elements ops latches output equal value stored state inside element furthermore unlike sr latch described latches ops use point clocked means clock input change state triggered cloc e erence betw ip op latch point clock causes state actually change clocked latch state changed whenever appropriate inputs change clock asserted wherea op state changed clock edge since throughout text use edgetriggered timing methodology state updated clock edges need us ops fli ops en built latches start describing operation simple clocked latch discuss operation op constructed latch computer applications function bot ops latches store signal latch op stores value data input signal internal memory although many types latch op type basic building block need latch two inputs two outpu e inputs data value stored called clock signal called c indicates latch read value input store e outputs simply value internal state q latch memory element output equal value stored state inside element state changed whenever appropriate inputs change clock asserted op memory element output equal value stored state inside element internal state changed clock edge op op one data input stores value input signal internal memory clock edge occurs b52 appendix b basics logic design complement q clock input c asserted latch said open value output q becomes value input clock input c deasserted latch said closed value output q whatever value stored last time latch open figure b82 shows latch implemented two additional gates added crosscoupled gates since latch open value q changes changes structure sometimes called transparent latch figure b83 shows latch works assuming output q initially false chang rst mentioned earlier us ops basic building block rather latches fli ops transparent outputs change clock edge op built triggers either rising positive falling negative clock edge designs use either type figure b84 shows fallingedg op constructed pair latches ip op output stored clock edge occurs figure b85 shows op operates cdqqfigure b82 latch implemented gates gate acts inverter inpu us crosscoupled pair gates acts store state value unless clock input c asserted case value input replaces value q stored e value input must stable clock signal c changes asserted deasserted dcqfigure b83 operation latch assuming output initially deasserted clock c asserted latch open q output immediately assumes value input b8 memory elements flipflops latches registers b53dcdlatchdcqdlatchdcqqqqfigure b84 ﬂ ipﬂ op fallingedge trigger e rst latch called master open follows input clock input c asserted clock input c falls th rst latch closed second latch called slave open gets input output master latch verilog description module risingedg op assuming c clock input data input module dffclockdqqbar input clock output reg q q reg since assigned always block output qbar assign qbar q qbar always inverse q always posedge clock perform actions whenever clock rises q endmodulebecause input sampled clock edge must valid period time immediately immediately er clock edge e minimum time input must valid clock edge called setup time dcqfigure b85 operation ﬂ ipﬂ op fallingedge trigger assuming output initially deasserted clock input c changes asserted deasserted q output stores value input compare behavior clocked latch shown figure b83 clocked latch stored value output q change whenever c high opposed c transitions setup time e minimum time input memory device must valid clock edge b54 appendix b basics logic design minimum time must valid er clock edge called hold time us inputs op anything built usin ops must valid window begins time tsetup clock edge ends thold er clock edge shown figure b86 section b11 talks clocking timing constraints including propagation delay throug op detail use array ops build register hold multibit datum byte word used registers throughout datapaths chapter 4 register files one structure central datapath regist le regist le consists set registers read written supplying register number accessed regist le implemented decoder read write port array registers built fro ops reading register change state need supply register number input output data contained register writing register need three inputs register number data write clock controls writing register chapter 4 used regist le two read ports one write por regist le drawn shown figure b87 e read ports implemented pair multiplexors wide number bits register regist le figure b88 shows implementation two register read ports 32bitwide regist le implementing write port slightly complex since change contents designated register using decoder generate signal used determine register write figure b89 shows implement write port regist le important remember th op changes state clock edge chapter 4 hooked write signals regist le explicitly assumed clock shown figure b89 attached implicitly happens register read written clock cycle write regist le occurs clock edge register dcsetup timehold timefigure b86 setup hold time requirements ﬂ ipﬂ op fallingedge trigger e input must stable period time clock edge well er clock edge e minimum time signal must stable clock edge called setup time minimum time signal must stable er clock edge called hold time failure meet minimum requirements result situation output th op may predictable described section b11 hold times usually either 0 small thus cause worry hold time e minimum time input must valid er clock edge b8 memory elements flipflops latches registers b55read registernumber 1 read data 1read register number 2 read data 2write registerwrite write dataregister filefigure b87 register ﬁ le two read ports one write port ﬁ inputs two outputs e control input write shown color read registernumber 1 register 0register 1 register n œ 2register n œ 1muxread registernumber 2 muxread data 1read data 2figure b88 implementation two read ports register ﬁ le n registers done pair nto1 multiplexors 32 bits wide e register read number signal used multiplexor selector signal figure b89 shows write port implemented b56 appendix b basics logic design valid time read saw earlier figure b72 e value returned value written earlier clock cycle want read return value currently written additional logic regist le outside needed chapter 4 makes extensive use logic specifying sequential logic verilog specify sequential logic verilog must understand generate clock describe value written register specify sequential control let us start specifying clock clock pr ned object verilog instead generate clock using verilog notation n statement causes delay n simulation time steps execu tion statement verilog simulators also possible generate clock external input allowing user specify simulation time number clock cycles run simulation e code figure b810 implements simple clock high low one simulation unit switches state use delay capability blocking assignment implement clock write 01nto2ndecodern œ 2n œ 1register 0cdregister 1cdregister n œ 2cdregister n œ 1cd register number register datafigure b89 write port register ﬁ le implemented decoder used write signal generate c input registers three inputs register number data write signal setup holdtime constraints ensure correct data written regist le b8 memory elements flipflops latches registers b57next must able specify operation edgetriggered register verilog done using sensitivity list always block specifying trigger either positive negative edge binary variable notation posedge negedge respectively hence following verilog code causes register written value b positive edge clock figure b810 speciﬁ cation clock figure b811 mips register ﬁ le written behavioral verilog regist le writes rising clock edge roughout chapter verilog sections chapter 4 assume positive edgetriggered design figure b811 shows verilog sp cation mips regist le assumes two reads one write write clocked b58 appendix b basics logic design verilog regist le figure b811 output ports corresponding registers read assigned using continuous assignment register written assigned always block following reason ere special reason simply convenient b data1 data2 output ports writedata input port c reading combinational event writing sequential event b9 memory elements srams drams registers regist les provide basic building blocks small memories larger amounts memory built using either srams static random access memories drams dynamic random access memories rst discuss srams somewhat simpler turn drams sramssrams simply integrated circuits memory arrays usually single access port provide either read write srams hav xed access time datum though read write access characteristics en er sram chip sp c co guration terms number addressable locations well width addressable location example 4m 8 sram provides 4m entries 8 bits wide us 22 address lines since 4m 222 8bit data output line 8bit single data input line roms number addressable locations en called height number bits per unit called width variety technical reasons newest fastest srams typically available narrow co gurations 1 4 figure b91 shows input output signals 2m 16 sram check static random access memory sram memory data stored statically ops rather dynamically dram srams faster drams less dense expensive per bit sram2m 16dout15œ0address21din15œ016chip selectoutput enable write enable 16figure b91 32k 8 sram showing 21 address lines 32k 215 16 data inputs 3 control lines 16 data outputs b9 memory elements srams drams b59to initiate read write access chip select signal must made active reads must also activate output enable signal controls whether datum selected address actually driven pin e output enable useful connecting multiple memories singleoutput bus using output enable determine memory drives bu e sram read access time usually sp ed delay time output enable true address lines valid time data output lines typical read access times srams 2004 varied 24 ns fastest cmos parts tend somewhat smaller narrower 820 ns typical largest parts 2004 32 million bits dat e demand lowpower srams consumer products digital appliances grown greatly th years srams much lower standby access power usually 510 times slower recently synchronous sramssimilar synchronous drams discuss next sectionhave also developed writes must supply data written address well signals cause write occur write enable chip select true data data input lines written cell sp ed address ere setuptime holdtime requirements address data lines fo ops latches addition write enable signal clock edge pulse minimum width requiremen e time complete write sp ed combination setup times hold times write enable pulse width large srams built way build regist le unlike regist le 32to1 multiplexor might practical 64kto 1 multiplexor would needed 64k 1 sram totally impractical rather use giant multiplexor large memories implemented shared output line called bit line multiple memory cells memory array assert allow multiple sources drive single line threestate er tristate er used threestate b er two inputsa data signal output enableand single output one three states asserted deasserted high impedance e output tristate b er equal data input signal either asserted deasserted output enable asserted otherwise highimpedance state allows another threestate b er whose output enable asserted determine value shared output figure b92 shows set threestate bu ers wired form multiplexor decoded input critical output enable one threestate bu ers asserted otherwise threestate bu ers may try set output line erently using threestate bu ers individual cells sram cell corresponds particular output share output line e use set distributed threestate bu ers cient implementation large centralized multiplexor e threestate bu ers incorporated th ip ops form basic cells sram figure b93 shows small 4 2 sram might built using latches input called enable controls threestate output b60 appendix b basics logic design e design figure b93 eliminates need enormous multiplexor however still requires large decoder correspondingly large number word lines example 4m 8 sram would need 22to4m decoder 4m word lines lines used enable individu ops circumvent problem large memories organized rectangular arrays use twostep decoding process figure b94 shows 4m 8 sram might organized internally using twostep decode see twolevel decoding process quite important understanding drams operate recently seen development synchronous srams ssrams synchronous drams sdr e key capability provided synchronous rams ability transfer burst data series sequential addresses within array row e burs ned starting address supplied usual fashion burst lengt e speed advantage synchronous rams comes ability transfer bits burst without specify additional address bits instead clock used transfer successive bits burs e elimination need specify address transfers within burs cantly improves rate transferring block data capability synchronous srams drams rapidly becoming rams choice building memory systems computers discuss use synchronous drams memory system detail next section chapter 5 select 0data 0enable outinselect 1data 1enable outinselect 2data 2enable outinselect 3data 3enable outinoutputfigure b92 four threestate buffers used form multiplexor one four select inputs asserted threestate b er deasserted output enable highimpedance output allows threestate b er whose output enable asserted drive shared output line b9 memory elements srams drams b61latchdcenable qd02to4decoderwrite enable din1latchdcenable qddin1dout1dout0latchdcenable qd1latchdcenable qdlatchdcenable qd2latchdcenable qdlatchdcenable qd3latchdcenable qdaddressfigure b93 basic structure 4 2 sram consists decoder selects pair cells activate e activated cells use threestate output connected vertical bit lines supply requested dat e address selects cell sent one set horizontal address lines called word lines simplicity output enable chip select signals omitted could easily added gates b62 appendix b basics logic design 12to4096decoderaddress21œ1040964k 1024sram4k 1024sram4k 1024sram4k 1024sram4k 1024sram4k 1024sram4k 1024sram4k 1024srammuxdout7muxdout6muxdout5muxdout4muxdout3muxdout2muxdout1muxdout01024address9œ0figure b94 typical organization 4m 8 sram array 4k 1024 arrays e rst decoder generates addresses eight 4k 1024 arrays set multiplexors used select 1 bit 1024bitwide array much easier design singlelevel decode would need either enormo us decoder gigantic multiplexor practice modern ram size would probably use even larger number blocks somewhat smaller b9 memory elements srams drams b63dramsin static ram sram value stored cell kept pair inverting gates long power applied value kep nitely dynamic ram dram value kept cell stored charge capacitor single transistor used access stored charge either read value overwrite charge stored drams use single transistor per bit storage much denser cheaper per bit comparison srams require four six transistors per bit drams store charge capacitor kept nitely must periodically refreshed memory structure called dynamic opposed static storage sram cell refresh cell merely read contents write bac e charge kept several milliseconds might correspond close million clock cycles today singlechip memory controllers en handle refresh function independently processor every bit read dram written back individually large drams containing multiple megabytes would constantly refreshing dram leaving time accessing fortunately drams also use twolevel decoding structure allows us refresh entire row shares word line read cycle followed immediately write cycle typically refresh operations consume 1 2 active cycles dram leaving remaining 98 99 cycles available reading writing data elaboration dram read write signal stored cell transistor inside cell switch called pass transistor allows value stored capacitor accessed either reading writing figure b95 shows singletransistor cell looks pass transistor acts like switch signal word line asserted switch closed connecting capacitor bit line operation write value written placed bit line value 1 capacitor charged value 0 capacitor discharged reading slightly complex since dram must detect small charge stored capacitor activating word line read bit line charged voltage halfway low high voltage activating word line charge capacitor read onto bit line causes bit line move slightly toward high low direction change er detect small changes voltage b64 appendix b basics logic design word line pass transistor capacitorbit linefigure b95 singletransistor dram cell contains capacitor stores cell contents transistor used access celladdress10œ0row decoder11to20482048 2048array column latchesmuxdoutfigure b96 4m 1 dram built 2048 2048 array e row access uses 11 bits select row latched 2048 1bit latches multiplexor chooses output bit 2048 latch e ras cas signals control whether address lines sent row decoder column multiplexor b9 memory elements srams drams b65drams use twolevel decoder consisting row access followed column access shown figure b96 e row access chooses one number rows activates corresponding word line e contents columns active row stored set latch e column access selects data column latches save pins reduce package cost address lines used row column address pair signals called ras row access strobe cas column access strobe used signal dram either row column address supplied refresh performed simply reading columns column latches writing values bac us entire row refreshed one cycle e twolevel addressing scheme combined internal circuitry makes dram access times much longer factor 510 sram access times 2004 typical dram access times ranged 45 65 ns 256 mbit drams full production rst customer samples 1 gb drams became available th rst quarter e much lower cost per bit makes dram choice main memory faster access time makes sram choice caches might observe 64m 4 dram actually accesses 8k bits every row access throws away 4 column access dram designers used internal structure dram way provide higher bandwidth dr done allowing column address change without changing row address resulting access bits column latches make process faster precise address inputs clocked leading dominant form dram use today synchronous dram sdram since 1999 sdrams memory chip choice cachebased main memory systems sdrams provide fast access series bits within row sequentially transferring bits burst control clock signal 2004 ddrrams double data rate rams called double data rate transfer data rising falling edge externally supplied clock heavily used form sdrams discuss chapter 5 highspeed transfers used boost bandwidth available main memory match needs processor caches error correction potential data corruption large memories computer systems use sort errorchecking code detect possible corruption data one simple code heavily used parity code parity code number 1s word counted word odd parity number 1s odd b66 appendix b basics logic design even otherwise word written memory parity bit also written 1 odd 0 ev en word read parity bit read checked parity memory word stored parity bit match error occurred 1bit parity scheme detect 1 bit error data item 2 bits error 1bit parity scheme detect errors since parity match data two errors actually 1bit parity scheme detect odd number errors however probability three errors much lower probability two practice 1bit parity code limited detecting single bit error course parity code tell bit data item error 1bit parity scheme error detection code also error correction codes ecc detect allow correction error large main memories many systems use code allows detection 2 bits error correction single bit error ese codes work using bits encode data example typical codes used main memories require 7 8 bits every 128 bits data elaboration 1bit parity code distance2 code means look data plus parity bit cient generate another legal combination data plus parity example change bit data parity wrong vice versa course change 2 bits 2 data bits 1 data bit parity bit parity match data error detected hence distance two legal combinations parity data detect one error correct error need distance3 code property legal combination bits error correction code data least 3 bits differing combination suppose code one error data case code plus data one bit away legal combination correct data legal combination two errors recognize error correct errors lets look example data words distance3 error correction code 4bit data item data word code bitsdatacode bits0000000100011100010111001100001010110100100011110101100101001101100001010110111010100110011111010001110001111111error detection code code enables detection error data precise location hence correction error b10 finitestate machines b67to see works lets choose data word say 0110 whose error correction code 011 four 1bit error possibilities data 1110 0010 0100 0111 look data item code 011 entry value 0001 error correction decoder received one four possible data words error would choose correcting 0110 0001 four words error one bit changed correct pattern 0110 two bits different alternate correction 0001 hence error correction mechanism easily choose correct 0110 since single error much higher probability see two errors detected simply notice combinations two bits changed different code one reuse code three bits different correct 2bit error correct wrong value since decoder assume single error occurred want correct 1bit errors detect erroneously correct 2bit errors need distance4 codealthough distinguished code data explanation truth error correction code treats combination code data single word larger code 7 bits example thus deals errors code bits fashion errors data bits example requires n 1 bits n bits data number bits required grows slowly distance3 code 64bit word needs 7 bits 128bit word needs 8 type code called hamming code r hamming described method creating codes b10 finitestate machines saw earlier digital logic systems cl ed combinational sequential sequential systems contain state stored memory elements internal syst eir behavior depends set inputs supplied contents internal memory state syst us sequential system described truth table instead sequential system described nitestate machine en state machine nitestate machine set states two functions called nextstate function output function e set states corresponds possible values internal storage us n bits storage 2 n stat e nextstate function combinational function given inputs current state determines next state syst e output function produces set outputs current state inputs figure b101 shows diagrammatically e state machines discuss chapter 4 synchronous means state changes together clock cycle new state computed every cloc us state elements updated clock edge use methodology section throughout chapter 4 nitestate machine sequential logic function consisting set inputs puts nextstate function maps current state inputs new state output function maps current state possibly inputs set asserted outputs nextstate function combinational function given inputs current state determines next state nitestate machine b68 appendix b basics logic design usually show clock explicitly use state machines throughout chapter 4 control execution processor actions datapath illustrate ho nitestate machine operates designed lets look simple classic example controlling tra c light chapters 4 5 contain detailed examples usin nitestate machines control processor execution nitestate machine used controller output function en restricted depend current state nitestate machine called moore machine type nitestate machine use throughout book output function depend current state current input machine called mealy machine ese two machines equivalent capabilities one turned mechanically e basic advantage moore machine faster mealy machine may smaller since may need fewer states moore machine chapter 5 discuss th erences detail show verilog version nitestate control using mealy machine example concerns control tra c light intersection north south route eastwest route simplicity consider green red lights adding yellow ligh exercise want lights cycle faster 30 seconds direction use 0033 hz clock machine cycles states faster every 30 seconds ere two output signals inputscurrent stateoutputsclock nextstate functionoutputfunctionnext statefigure b101 state machine consists internal storage contains state two combinational functions nextstate function output function en output function restricted take current state input change capability sequential machine ect internals b10 finitestate machines b69 nslite signal asserted light northsouth road green signal deasserted light northsouth road red ewlite signal asserted light eastwest road green signal deasserted light eastwest road red addition two inputs nscar indicates car detector placed roadbed front light northsouth road going north south ewcar indicates car detector placed roadbed front light eastwest road going east west e tra c light change one direction car waiting go direction otherwise light continue show green direction last car crossed intersection implement simple tra c light need two states nsgreen e tra c light green northsouth direction ewgreen e tra c light green eastwest direction also need create nextstate function sp ed table inputsnscarewcarnext state nsgreen00nsgreennsgreen01ewgreennsgreen10nsgreennsgreen11ewgreenewgreen00ewgreenewgreen01ewgreenewgreen10nsgreenewgreen11nsgreennotice didnt specify algorithm happens car approaches directions case nextstate function given changes state ensure steady stream cars one direction lock car direction e nitestate machine completed specifying output function examine implement th nitestate machine lets look graphical representation en used fo nitestate machines representation nodes used indicate states inside node place list outputs active state directed arcs used show nextstate b70 appendix b basics logic design woutputsnsliteewlite nsgreen10ewgreen01 function labels arcs specifying input condition logic functions figure b102 shows graphical representation nitestate machine nsliteewlitenscarnsgreen ewgreen ewcarewcarnscarfigure b102 graphical representation twostate trafﬁ c light controller simp ed logic functions state transitions example transition nsgreen ewgreen nextstate table nscarewcarnscarewcar equivalent ewcar nitestate machine implemented register hold current state block combinational logic computes nextstate function output function figure b103 shows ho nitestate machine 4 bits state thus 16 states might look implement th nitestate machine way mu rst assign state numbers stat process called state assignment example could assign nsgreen state 0 ewgreen stat e state register would contain single bi e nextstate function would given nextstatecurrentstateewca rcurrentstatenscar b11 timing methodologies b71where currentstate contents state register 0 1 nextstate output nextstate function written state register end clock cycle e output function also simple nslitecurrentstate ewlite currentstate e combinational logic block en implemented using structured logic pla pla constructed automatically nextstate output function tables fact computeraided design cad programs combinational logicoutputsstate registerinputsnext state figure b103 ﬁ nitestate machine implemented state register holds current state combinational logic block compute next state output functions e latter two functions en split apart implemented two separate blocks logic may require fewer gates take either graphical textual representation nitestate machine produce optimized implementation automatically chapters 4 nite state machines used control processor execution appendix discusses detailed implementation controllers plas roms show might write control verilog figure b104 shows verilog version designed synthesis note simple control function mealy machine useful style sp cation used chapter 5 implement control function mealy machine fewer states moore machine controller b72 appendix b basics logic design smallest number states moore machine mealy machine could fewer states two since could onestate mealy machine might thing b ree since could simple moore machine went one two erent states always returned original state er simple machine twostate mealy machine possible c need least four states exploit advantages mealy machine moore machine b11 timing methodologies roughout appendix rest text use edgetriggered timing methodology timing methodology advantage simpler explain understand leveltriggered methodology section explain timing methodology little detail also introduce levelsensitive clocking conclude section br discussing check figure b104 verilog version trafﬁ c light controller b11 timing methodologies b73the issue asynchronous signals synchronizers important problem digital designers e purpose section introduce major concepts clocking methodology e section makes important simplifying assumptions interested understanding timing methodology detail consult one references listed end appendix use edgetriggered timing methodology simpler explain fewer rules required correctness particular assume clocks arrive time guaranteed system edgetriggered registers blocks combinational logic operate correctly without races simply make clock long enough race occurs contents state element depend relative speed erent logic elements edge triggered design clock cycle must long enough accommodate path one op combinational logic anot op must satisfy setuptime requirement figure b111 shows requirement system using rising edgetrigger ops system clock period cycle time must least large ttt propcombinationalsetup worstcase values three delays ar ned follows tprop time signal propagate throug op also sometimes called clockto q tcombinational longest delay combinational logic b nition surrounded tw ops tsetup time rising clock edge input op must valid flipflopdcqcombinationallogic block flipflopdcqtproptcombinationaltsetupfigure b111 edgetriggered design clock must long enough allow signals valid required setup time next clock edge e time op input propagate th ip outputs tprop signal takes tcombinational travel combinational logic must valid tsetup next clock edge b74 appendix b basics logic design make one simplifying assumption holdtime requirements sa ed almost never issue modern logic one additional complication must considered edgetriggered designs clock skew clock skew th erence absolute time two state elements see clock edge clock skew arises clock signal en use tw erent paths slightly erent delays reach tw erent state elements clock skew large enough may possible state element change cause input anot op change clock edge seen seco op figure b112 illustrates problem ignoring setup time op propagation delay avoid incorrect operation clock period increased allow maximum clock skew us clock period must longer tttt propcombinationalsetupskew constraint clock period two clocks also arrive opposite order second clock arriving tskew earlier circuit work clock skew e erence absolute time times two state elements see clock edge flipflopdcqcombinationallogic block delay time flipflopdcqclock arrives time tclock arrives figure b112 illustration clock skew cause race leading incorrect operation th erence tw ops see clock signal stored th rst op race forward change input seco ip op clock arrives seco op correctly designers reduce clockskew problems carefully routing clock signal minimize th erence arrival times addition smart designers also provide margin making clock little longer minimum allows variation components well power supply since clock skew also ect holdtime requirements minimizing size clock skew important edgetriggered designs two drawbacks require extra logic may sometimes slower looking th op versus levelsensitive latch used construct th op shows edgetriggered design requires logic alternative use levelsensitive clocking state changes levelsensitive methodology instantaneous levelsensitive scheme slightly complex requires additional care make operate correctly levelsensitive clocking timing methodology state changes occur either high low clock levels instantaneous changes edge triggered designs b11 timing methodologies b75levelsensitive timing levelsensitive timing state changes occur either high low levels instantaneous edgetriggered methodology noninstantaneous change state races easily occur ensure level sensitive design also work correctly clock slow enough designers use twophase clocking twophase clocking scheme makes use two nonoverlapping clock signals since two clocks typically called 1 2 nonoverlapping one clock signals high given time figure b113 shows use two clocks build system contains levelsensitive latches free race conditions edgetriggered designs nonoverlapping periods 12figure b113 twophase clocking scheme showing cycle clock nonoverlapping periods latchdcqcombinationallogic block 1latchdcqcombinationallogic block 2latchdc1figure b114 twophase timing scheme alternating latches showing system operates clock phases e output latch stable opposite phase c inpu us th rst block combinational inputs stable input 2 output latched 2 e second rightmost combinational block operates opposite fashion stable inputs 1 us delays combinational blocks determine minimum time respective clocks must asserted e size nonoverlapping period determined maximum clock skew minimum delay logic block one simple way design system alternate use latches open 1 latches open 2 clocks asserted time race occur input combinational block 1 clock output latched 2 clock open 2 input latch closed hence valid output figure b114 shows system twophase timing alternating latches operates edge triggered design must pay attention clock skew particularly two b76 appendix b basics logic design clock phases increasing amount nonoverlap two phases reduce potential margin error us system guaranteed operate correctly phase long enough large enough nonoverlap phases asynchronous inputs synchronizers using single clock twophase clock eliminate race conditions clockskew problems avoided unfortunately impractical make entire system function single clock still keep clock skew small cpu may use single clock io devices probably clock asynchronous device may communicate cpu series handshaking steps translate asyn chronous input synchronous signal used change state system need use synchronizer whose inputs asynchronous signal clock whose output signal synchronous input clock rst attempt build synchronizer uses edgetrigger op whose input asynchronous signal figure b115 shows communicate handshaking protocol matter whether detect asserted state asynchronous signal one clock next since signal held asserted acknowledged us might think simple structure enough sample signal accurately would case except one small problem flipflopdcqclock asynchronous inputsynchronous outputfigure b115 synchronizer built ﬂ ipﬂ op used sample asynchronous signal produce output synchronous clock synchronizer work properly e problem situation called metastability suppose asynchronous signal transitioning high low clock edge arrives clearly possible know whether signal latched high low problem could live unfortunately situation worse signal sampled stable required setup hold times th op may go metastable state state output legitimate high low value indeterminate region furthermore metastability situation occurs signal sampled stable required setup hold times possibly causing sampled value fall indeterminate region high low value b13 concluding remarks b77th op guaranteed exit state bounded amount time logic blocks look output th op may see output 0 others may see situation called synchronizer failure purely synchronous system synchronizer failure avoided ensuring setup hold times fo op latch always met impossible input asynchronous instead solution possible wait long enough looking output th op ensure output stable exited metastable state ever entered long long enough well probability th op stay metastable state decreases exponentially er short time probability th op metastable state low however probability never reaches 0 designers wait long enough probability synchronizer failure low time failures years even thousands years fo op designs waiting period several times longer setup time makes probability synchronization failure low clock rate longer potential metastability period likely safe synchronizer built tw ops figure b116 shows interested reading problems look references synchronizer failure situation op enters metastable state logic blocks reading output op see 0 others see 1 flipflopdcqclock asynchronous inputflipflopdcqsynchronous outputfigure b116 synchronizer work correctly period metastability wish guard less clock period although output rst op may metastable seen logic element second clock second op samples signal time longer metastable state suppose design large clock skewlonger register propagation time always possible design slow clock enough guarantee logic operates properly yes clock slow enough signals always propagate design work even skew large b since possible two registers see clock edge far enough apart register triggered outputs propagated seen second register clock edge check propagation time e time required input op propagate outputs th ip op b78 appendix b basics logic design b12 field programmable devices within custom semicustom chip designers make use th exibility underlying structure easily implemen combinational sequential logic designer want use custom semicustom ic implement complex piece logic taking advantage high levels integration availab e popular component used sequential combinational logic design outside custom semicustom ic eld programmable device fpd fpd integrated circuit containing combinational logic possibly memory devices co gurable end user fpds generally fall two camps programmable logic devices plds purely combinational eld programmable gate arrays fpgas provide combinational logic ops plds consist two forms simple plds splds usually either pla programmable array logic pal complex plds allow one logic block well co gurable interconnections among blocks speak pla pld mean pla user programmable andplane orplane pal like pla except orpla xed discuss fpgas useful talk fpds co gured con guration essentially question make break connections gate register structures static connections co gured notice co guring connections user determines logic functions implemented consider co gurable pla determining connections andplane orplane user dictates logical functions computed pla connections fpds either permanent reco gurable permanent connections involve creation destruction connection two wires current fplds use antifuse technology allows connection built programming time permanent e way co gure cmos fplds sr e sram downloaded poweron contents control setting switches turn determines metal lines connected e use sram control advantage fpd reco gured changing contents sr e disadvantages srambased control two fold co guration volatile must reloaded poweron use active transistors switches slightly increases resistance connections fpgas include logic memory devices usually structured two dimensional array corridors dividing rows columns used eld programmable devices fpd integrated circuit containing combinational logic possibly memory devices co gurable end user programmable logic device pld integrated circuit containing combinational logic whose function co gured end user eld programmable gate array fpga co gurable integrated circuit containing combinational logic blocks ops simple programmable logic device spld programmable logic device usually containing either single pal pla programmable array logic pal contains programmable andplane followed xed plane antifuse structure integrated circuit programmed makes permanent connection two wires b14 exercises b79global interconnect cells th e array cell combination gates ops programmed perform sp c function basically small programmable rams also called lookup tables luts newer fpgas contain sophisticated building blocks pieces adders ram blocks used build regist les large fpgas even contain 32bit risc cores addition programming cell perform sp c function interconnections cells also programmable allowing modern fpgas hundreds blocks hundreds thousands gates used complex logic functions interconnect major challenge custom chips even true fpgas cells represent natural units decomposition structured design many fpgas 90 area reserved interconnect 10 logic memory blocks design custom semicustom chip without cad tools also need fpds logic synthesis tools developed target fpgas allowing generation system using fpgas structural behavioral verilog b13 concluding remarks appendix introduces basics logic design digested material appendix ready tackle material chapters 4 5 use concepts discussed appendix extensively lookup tables luts eld programmable device name given cells consist small amount logic ram reading ere number good texts logic design might like look ciletti 2002 advanced digital design verilog hdl englewood nj prentice hall thorough book logic design using verilog katz r h 2004 modern logic design 2nd ed reading addisonwesley general text logic design wakerly j f 2000 digital design principles practices 3rd ed englewood nj prentice hall general text logic design b80 appendix b basics logic design b14 exercisesb1 10 b2 addition basic laws discussed section two important theorems called demorgans theorems abab abab prove demorgans theorems truth table form ababa ba ba ba b00111111 01100011 10010011 11000000 b2 15 b2 prove two equations e example starting page b7 equivalent using demorgans theorems axioms shown page b7 b3 10 b2 show 2 n entries truth table function n inputs b4 10 b2 one logic function used variety purposes including within adders compute parity exclusive e output twoinput exclusive function true exactly one inputs true show truth table twoinput exclusive function implement function using gates gates inverters b5 15 b2 prove gate universal showing build functions using twoinput gate b6 15 b2 prove nand gate universal showing build functions using twoinput nand gate b7 10 b2 b3 construct truth table fourinput oddparity function see page b65 description parity b8 10 b2 b3 implement fourinput oddparity function gates using bubbled inputs outputs b9 10 b2 b3 implement fourinput oddparity function pla b14 exercises b81b10 15 b2 b3 prove twoinput multiplexor also universal showing build nand gate using multiplexor b11 5 42 b2 b3 assume x consists 3 bits x2 x1 x0 write four logic functions true x contains one 0 x contains even number 0s x interpreted unsigned binary number less 4 x interpreted signed twos complement number negative b12 5 42 b2 b3 implement four functions described exercise b11 using pla b13 5 42 b2 b3 assume x consists 3 bits x2 x1 x0 consists 3 bits y2 y1 y0 write logic functions true x x thought unsigned binary numbers x x thought signed twos complement numbers x yuse hierarchical approach extended larger numbers bits show extend 6bit comparison b14 5 b2 b3 implement switching network two data inputs b two data outputs c control input equals 1 network passthrough mode c equal equal b equals 0 network crossing mode c equal b equal ab15 15 b2 b3 derive productofsums representation e shown page b11 starting sumofproducts representation need use demorgans theorems b16 30 b2 b3 give algorithm constructing sumof products representation arbitrary logic equation consisting e algorithm recursive construct truth table process b17 5 b2 b3 show truth table multiplexor inputs b output c using dont cares simplify table possible b82 appendix b basics logic design b18 5 b3 function implemented following verilog modules module func1 i0 i1 input i0 i1 input output i1 i0 endmodulemodule func2 outctlclkreset output 70 input ctl clk reset reg 70 always posedge clk reset begin 8b0 end else ctl begin 1 end else begin 1 end endmoduleb19 5 b4 e verilog code page b53 fo op show verilog code latch b20 10 b3 b4 write verilog module implementation 2to4 decoder andor encoder b21 10 b3 b4 given following logic diagram accumulator write verilog module implementation assume positive edge triggered register asynchronous rst b14 exercises b83inoutload16adderregisterclkrstload16b22 20 b3 b4 b5 section 33 presents basic operation possible implementations multipliers basic unit implementation andadd unit show verilog implementation unit show use unit build 32bit multiplier b23 20 b3 b4 b5 repeat exercise b22 unsigned divider rather multiplier b24 15 b5 e alu supported set less slt using sign bit adder lets try set less operation using values 7ten 6 ten make simpler follow example lets limit binary representations 4 bits 1001 two 0110 two 1001two 0110two 1001two 1010two 0011two result would suggest 7 6 clearly wrong hence must factor ow decision modify 1bit alu figure b510 page b33 handle slt correctly make changes photocopy gure save time b25 20 b6 simple check ow addition see carryin th cant bit carryout cant bit prove check figure 32 b26 5 b6 rewrite equations page b44 carrylookahead logic 16bit adder using new notation first use names carryin signals individual bits adder use c4 c8 c12 instead c1 c2 c3 addition let p ij mean propagate signal bits j g ij mean generate signal bits j example equation cgpgppc 2110100 b84 appendix b basics logic design rewritten cgpgppc 807474307430 general notation useful creating wider adders b27 15 b6 write equations carrylookahead logic 64 bit adder using new notation exercise b26 using 16bit adders building blocks include drawing similar figure b63 solution b28 10 b6 calculate relative performance adders assume hardware corresponding equation containing terms equations p g page b40 takes one time unit equations consist several terms equations c1 c2 c3 c4 page b40 would thus take two time units 2t e reason would take produce terms additional produce result calculate numbers performance ratio 4bit adders ripple carry carry lookahead terms equations furt ned equations add appropriate delays intermediate equations continue recursively actual input bits adder used equation include drawing adder labeled calculated delays path worstcase delay highlighted b29 15 b6 exercise similar exercise b28 time calculate relative speeds 16bit adder using ripple carry ripple carry 4bit groups use carry lookahead carrylookahead scheme page b39 b30 15 b6 exercise similar exercises b28 b29 time calculate relative speeds 64bit adder using ripple carry ripple carry 4bit groups use carry lookahead ripple carry 16bit groups use carry lookahead carrylookahead scheme exercise b27 b31 10 b6 instead thinking adder device adds two numbers links carries together think adder hardware device add three inputs together bi ci produce two outputs ci 1 adding two numbers together little observation adding two operands possible reduce cost carry e idea form two independent sums called sum bits c carry bits end process need add c together using normal adder technique delaying carry propagation end sum numbers called carry save addition e block drawing lower right figure b141 see shows organization two levels carry save adders connected single normal adder calculate delays add four 16bit numbers using full carrylookahead adders versus carry save carrylookahead adder forming th e time unit exercise b28 b14 exercises b85b32 20 b6 perhaps likely case adding many numbers computer would trying multiply quickly using many adders add many numbers single clock cycle compared multiply algorithm chapter 3 carry save scheme many adders could multiply 10 times faster exercise estimates cost speed combinational multiplier multiply two positive 16bit numbers assume 16 intermediate terms m15 m14 m0 called partial products contain multiplicand anded multiplier bi e idea use carry save adders reduce n operands 2 n3 parallel groups three repeatedly get two large numbers add together traditional adder figure b141 traditional ripple carry carry save addition four 4bit numbers e details shown th individual signals lowercase corresponding higherlevel blocks right collective signals upper case note sum four nbit numbers take n 2 bits s4s3s2s1s0f0e0b0f1e1b1 f2e2b2 f3e3b3 a0a1a2a3s5c3s3s4c2s2c1s1c0s0 carry save adder efbacarry save adder traditional adder scs s5s0b0a0 e0f0s1b1a1 e1f1s2b2a2 e2f2s3b3a3 e3f3s4efsba traditional adder traditional adder traditional adder b86 appendix b basics logic design first show block organization 16bit carry save adders add 16 terms shown right figure b141 en calculate delays add 16 numbers compare time iterative multiplication scheme chapter 3 assume 16 iterations using 16bit adder full carry lookahead whose speed calculated exercise b29 b33 10 b6 ere times want add collection numbers together suppose wanted add four 4bit numbers b e f using 1bit full adders lets ignore carry lookahead would likely connect 1bit adders organization top figure b141 traditional organization novel organization full adders try adding four numbers using organizations convince get answer b34 5 b6 first show block organization 16bit carry save adders add 16 terms shown figure b141 assume time delay 1bit adder 2t calculate time adding four 4bit numbers organization top versus organization bottom figure b141 b35 5 b8 quite en would expect given timing diagram containing description changes take place data input clock input c figures b83 b86 pages b52 b54 respectively would b erences output waveforms q latch ip op sentence two describe circumstances eg nature inputs would erence two output waveforms b36 5 b8 figure b88 page b55 illustrates implementation regist le mips datapath pretend new regist le built two registers one read port register 2 bits data redraw figure b88 every wire diagram corresponds 1 bit data unlike diagram figure b88 wires 5 bits wires 32 bits redraw registers usin ip ops need show implemen op multiplexor b37 10 b10 friend would like build electronic eye use fake security device e device consists three lights lined row controlled outputs le middle right asserted indicate light one light time light moves right right thus scaring away thieves believe device monitoring activity draw graphical representation nitestate machine used specify electronic eye note rate eyes movement controlled clock speed great essentially inputs b38 10 b10 assign state numbers states th nitestate machine constructed exercise b37 write set logic equations outputs including nextstate bits b14 exercises b87b39 15 b2 b8 b10 construct 3bit counter using thre ip ops selection gat e inputs consist signal resets counter 0 called reset signal increment counter called inc e outputs value counter counter value 7 incremented wrap around become 0 b40 20 b10 gray code sequence binary numbers property 1 bit changes going one element sequence another example 3bit binary gray code 000 001 011 010 110 111 101 100 using thre ops pla construct 3bit gray code counter two inputs reset sets counter 000 inc makes counter go next value sequence note code cyclic value er 100 sequence 000 b41 25 b10 wish add yellow light tra c light example page b68 changing clock run 025 hz 4second clock cycle time duration yellow light prevent green red lights cycling fast add 30second timer e timer single input called timerreset restarts timer single output called timersignal indicates 30second period expired also must ne tr c signals include yellow b ning two put signals light green yellow output nsgreen asserted green light output nsyellow asserted yellow light signals red light assert green yellow signals time since american drivers certainly confused even european drivers understand means draw graphical representation th nitestate machine improved controller choose names states erent names outputs b42 15 b10 write nextstate outputfunction tables tra c light controller described exercise b41 b43 15 b2 b10 assign state numbers states tra c light example exercise b41 use tables exercise b42 write set logic equations outputs including nextstate outputs b44 15 b3 b10 implement logic equations exercise b43 pla b2 page b8 1 c 1 b 0 th rst true second false b3 page b20 c b4 pag ey exactly b4 page b26 0 b 1b5 page b38 2 b6 page b47 1 b8 page b58 c b10 page b72 b b11 page b77 b answers check imagination important knowledge albert einstein science 1930sgraphics computing gpusjohn nickolls director architecture nvidia david kirk chief scientist nvidia cappendix c1 introduction c3c2 gpu system architectures c7c3 programming gpus c12c4 multithreaded multiprocessor architecture c24c5 parallel memory system c36c6 floatingpoint arithmetic c41c7 real stuff nvidia geforce 8800 c45c8 real stuff mapping applications gpus c54c9 fallacies pitfalls c70c10 concluding remarks c74c11 historical perspective reading c75 c1 introduction appendix focuses gputhe ubiquitous graphics processing unit every pc laptop desktop computer workstation basic form gpu generates 2d 3d graphics images video enable window based operating systems graphical user interfaces video games visual imaging applications video e modern gpu describe highly parallel highly multithreaded multiprocessor optimized visual computing provide realtime visual interaction computed objects via graphics images video th ed graphics computing architecture serves programmable graphics processor scalable parallel computing platform pcs game consoles combine gpu cpu form heterogeneous systems brief history gpu evolution een years ago thing gpu graphics pc performed video graphics array vga controller vga controller simply memory controller display generator connected dram 1990s semiconductor technology adva ciently functions could added vga controller 1997 vga controllers beginning incorporate threedimensional 3d acceleration functions including graphics processing unit gpu processor optimized 2d 3d graphics video visual computing display visual computing mix graphics processing computing lets visually interact computed objects via graphics images video heterogeneous system system combinin erent processor types pc heterogeneous cpugpu system c4 appendix c graphics computing gpus hardware triangle setup rasterization dicing triangles individual pixels texture mapping shading applying decals patterns pixels blending colors 2000 single chip graphics processor incorporated almost every detail traditional highend workstation graphics pipeline therefore deserved new name beyond vga controller e term gpu coined denote graphics device become processor time gpus became programmable programmable processors repl xed function dedicated logic maintaining basic 3d graphics pipeline organization addition computations became precise time progressing indexed arithmetic integer xed point single precision oatingpoint recently double precisio oatingpoint gpus become massively parallel programmable processors hundreds cores thousands threads recently processor instructions memory hardware added support general purpose programming languages programming environment created allow gpus programmed using familiar languages including c c innovation makes gpu fully generalpurpose programmable manycore processor albeit still special bene ts limitations gpu graphics trends gpus associated drivers implement opengl directx models graphics processing opengl open standard 3d graphics programming available computers directx series microso multimedia programming interfaces including direct3d 3d graphics since application programming interfaces apis ned behavior possible bu ective hardware acceleration graphics processing function ned api one reasons addition increasing device density new gpus developed every 12 18 months double performance previous generation existing applications frequent doubling gpu performance enables new applications previously possible e intersection graphics processing parallel computing invites new paradigm graphics known visual computing replaces large sections traditional sequential hardware graphics pipeline model programmable elements geometry vertex pixel programs visual computing modern gpu combines graphics processing parallel computing novel ways permit new graphics algorithms implemented opens door entirely new parallel processing applications pervasive highperformance gpus heterogeneous system although gpu arguably parallel powerful processor typical pc certainly processor e cpu multicore application programming interface api set function data structure nitions providing interface library functions c1 introduction c 5soon manycore complementary primarily serial processor companion massively parallel manycore gpu together two types processors comprise heterogeneous multiprocessor system e best performance many applications comes using cpu gpu appendix help understand best split work two increasingly parallel processors gpu evolves scalable parallel processor gpus evolved functionally hardwired limited capability vga controllers programmable parallel processor evolution proceeded changing logical apibased graphics pipeline incorporate programmable elements also making underlying hard ware pipeline stages less specialized programmable eventually made sense merge disparate programmable pipeline elements ed array many programmable processors geforce 8series generation gpus geometry vertex pixel processing run type processor cation allows dramatic scalability programmable processor cores increase total system throughput unifying processors also delivers ver ective load balancing since processing function use whole processor array end spectrum processor array built processors since functions run processors cuda gpu computing uniform scalable array processors invites new model programming gpu e large amount oatingpoint processing power gpu processor array attractive solving nongraphics problems given large degree parallelism range scalability processor array graphics applications programming model general computing must express massive parallelism directly allow scalable execution gpu computing term coined using gpu computing via parallel programming language api without using traditional graphics api graphics pipeline model contrast earlier general purpose computation gpu gpgpu approach involves programming gpu using graphics api graphics pipeline perform nongraphics tasks compute unifed device architecture cuda scalable parallel programming model ware platform gpu parallel processors allows programmer bypass graphics api graphics interfaces gpu simply program c c e cuda programming model spmd singleprogram multiple data ware style programmer writes program one thread instanced executed many threads parallel multiple processors gpu fact cuda also provides facility programming multiple cpu cores well cuda environment writing parallel programs entire heterogeneous computer system gpu computing using gpu computing via parallel programming language api gpgpu using gpu generalpurpose computation via traditional graphics api graphics pipeline cuda scalable parallel programming model language based cc parallel programming platform gpus multicore cpus c6 appendix c graphics computing gpus gpu unifes graphics computingwith addition cuda gpu computing capabilities gpu possible use gpu graphics processor computing processor time combine uses visual computing application e underlying processor architecture gpu exposed two wa rst implementing programmable graphics apis second massively parallel processor array programmable cc cuda although underlying processors gpu ar ed necessary spmd thread programs e gpu run graphics shader programs graphics aspect gpu processing geometry vertices pixels also run thread programs cuda e gpu truly versatile multiprocessor architecture supporting variety processing tasks gpus excellent graphics visual computing sp cally designed applications gpu also excellent many general purpose throughput applications rst cousins graphics perform lot parallel work well lot regular problem structure general good match dataparallel problems see chapter 6 particularly large problems less less regular smaller problems gpu visual computing applications visual computing includes traditional types graphics applications plus many new application e original purview gpu anything pixels includes many problems without pixels regular computation andor data structure gpus ar ective 2d 3d graphics since purpose designed failure deliver application performance would fatal 2d 3d graphics use gpu graphics mode accessing processing power gpu graphics apis opengl directx games built 3d graphics processing capability beyond 2d 3d graphics image processing video important applications gpu ese implemented using graphics apis computational programs using cuda program gpu computing mode using cuda image processing simply another dataparallel array program extent data access regular good locality program cient practice image processing good application gpus video processing especially encode decode compression decompression according standard algorithms quit cient e greatest opportunity visual computing applications gpus break graphics pipeline early gpus implemented sp c graphics apis albeit high performance wonderful api supported operations wanted gpu could accelerate task early gpu functionality immutable advent gpu computing cuda gpus programmed implemen erent virtual pipeline simply writing cuda program describe computation dat ow c2 gpu system architectures c 7is desired applications possible stimulate new visual computing approaches c2 gpu system architectures section survey gpu system architectures common use today discuss system co gurations gpu functions services standard programming interfaces basic gpu internal architecture heterogeneous cpugpu system architecture heterogeneous computer system architecture using gpu cpu described high level two primary characteri rst many functional subsystems andor chips used interconnection technologies topology second memory subsystems available functional subsystems see chapter 6 background pc io systems chip sets historical pc circa 1990figure c21 shows highlevel block diagram legacy pc cir e north bridge see chapter 6 contains highbandwidth interfaces connecting cpu memory pci bu e south bridge contains legacy interfaces devices isa bus audio lan interrupt controller dma controller timecounter system display driven simple frameb er subsystem known cpunorthbridgesouthbridgefront side buspci busframebuffermemoryvgacontrollermemoryuartlanvgadisplayfigure c21 historical pc vga controller drives graphics display frameb er memory c8 appendix c graphics computing gpus vga video graphics array attached pci bus graphics subsystems builtin processing elements gpus exist pc landscape 1990 figure c22 illustrates two confgurations common use today ese characterized separate gpu discrete gpu cpu respective memory subsystems figure c22a intel cpu see gpu attached via 16lane pciexpress 20 link provide peak 16 gbs transfer rate peak 8 gbs direction similarly figure c22b amd cpu gpu pciexpress pcie standard system io interconnect uses pointtopoint links links co gurable number lanes bandwidth front side busgpumemorysouthbridgenorthbridgeintelcpuddr2memoryx16 pciexpress linkx4 pciexpress linkderivative128bit667 mtsdisplaygpu128bit667 mtsinternal bus gpumemoryddr2memoryx16 pciexpress linkchipsetcpucoreamdcpugpunorthbridgehypertransport 103displayabfigure c22 contemporary pcs intel amd cpus see chapter 6 explanation components interconnects gure c2 gpu system architectures c 9is attached chipset also via pciexpress available bandwidth cases gpus cpus may access others memory albeit less available bandwidth access directly attached memories case amd system north bridge memory controller integrated die cpu lowcost variation systems ed memory architecture uma system uses cpu system memory omitting gpu memory syst ese systems relatively low performance gpus since achieved performance limited available system memory bandwidth increased latency memory access whereas dedicated gpu memory provides high bandwidth low latency high performance system variation uses multiple attached gpus typically two four working parallel displays daisychained example nvidia sli scalable link interc onnect multigpu system designed high performance gaming workstations e next system category integrates gpu north bridge intel chipset amd without dedicated graphics memory chapter 5 explains caches maintain coherence shared address space cpus gpus multiple address spaces gpus access physical local memory cpu systems physical memory using virtual addresses translated mmu gpu e operating system kernel manages gpus page tables system ph ysical page accessed using either coherent noncoherent pciexpress transactions determined attribute gpus page table e cpu access gpus local memory address range also called aperture pciexpress address space game consolesconsole systems sony playstation 3 microso xbox 360 resemble pc system architectures previously described console systems designed shipped identical performance functionality lifespan last years time system may reimplemented many times exploit advanced silicon manufacturing processes thereby provide constant capability ever lower costs console systems need subsystems expanded graded way pc systems major internal system buses tend customized rather standardized gpu interfaces drivers pc today gpus attached cpu via pciexpress earlier generations used agp graphics applications call opengl segal akeley 2006 direct3d microso directx specifcation api functions use gpu coprocessor e apis send commands programs data gpu via graphics device driver optimized particular gpu ed memory architecture uma system architecture cpu gpu share common system memory agp extended version original pci io bus provided eight times bandwidth original pci bus single card slot primary purpose connect graphics subsystems pc systems c10 appendix c graphics computing gpus mapping graphics pipeline uniﬁ ed gpu processors figure c24 shows logical pipeline comprising separate independent programmable stages mapped onto physical distributed array processors basic unifed gpu architectureu ed gpu architectures based parallel array many programmable processor ey unify vertex geometry pixel shader processing parallel computing processors unlike earlier gpus separate processors dedicated processing type e programmable processor array tightly integrated wi xed function processors textur ltering rasterization raster operations antialiasing compre ssion decompression display video decoding hig nition video processing although th xedfunction processor cantly outperform general programmable processors terms absolute performance constrained area cost power budget focus programmable processors compared multicore cpus manycore gpus hav erent architectural design point one focused executing many parallel thre ciently many inputassemblervertexshadergeometryshadersetup rasterizerpixelshaderraster operationsoutput mergerfigure c23 graphics logical pipeline programmable graphics shader stages blue xedfunction blocks white unified processorarray inputassemblervertexshadersetup rasterizer raster operationsoutput merger geometryshaderpixelshaderfigure c24 logical pipeline mapped physical processors e programmable shader stages execute array ed processors logical graphics pipeline data ow recirculates processors graphics logical pipeline e graphics logical pipeline described section c3 figure c23 illustrates major processing stages highlights important programmable stages vertex geometry pixel shader stages c2 gpu system architectures c 11processor cores using many simpler cores optimizing dataparallel behavior among groups threads perchip transistor budget devoted computation less onchip caches overhead processor array ed gpu processor array contains many processor cores typically organized multithreaded multiprocessors figure c25 shows gpu array 112 streaming processor sp cores organized 14 multithreaded streaming multiprocessors sms sp core highly multithreaded managing 96 concurrent threads state hardware e processors connect four 64bitwide dram partitions via interconnection network sm eight sp cores two special function units sfus instruction constant caches multithreaded instruction unit shared memory basic tesla architecture implemented nvidia geforce 8800 ed architecture traditional graphics programs vertex geometry pixel shading run th ed sms sp cores computing programs run processors gpuhost cpusystem memorydramropl2dramropl2dramropl2dramropl2tpctexture unittex l1smspspspspspspspspsmspspspspspspspsptpctexture unittex l1smspspspspspspspspsmspspspspspspspsptpctexture unittex l1smspspspspspspspspsmspspspspspspspsptpctexture unittex l1smspspspspspspspspsmspspspspspspspsptpctexture unittex l1smspspspspspspspspsmspspspspspspspsptpctexture unittex l1smspspspspspspspspsmspspspspspspspsptpctexture unittex l1smspspspspspspspspsmspspspspspspspspvertex workdistribution input assemblerhost interfacebridgepixel workdistribution viewportclip setuprasterzcullcompute workdistributionspsharedmemoryspspspspspspsmspicachemt issueccachesfusfuinterconnection networkdisplay interfacedisplayhighdefinitionvideo processorssharedmemorysharedmemorysharedmemorysharedmemorysharedmemorysharedmemorysharedmemorysharedmemorysharedmemorysharedmemorysharedmemorysharedmemorysharedmemorysharedmemoryfigure c25 basic uniﬁ ed gpu architecture example gpu 112 streaming processor sp cores organized 14 streaming multiprocessors sms cores highly multithreaded basic tesla architecture nvidia gefor e processors connect four 64bitwide dram partitions via interconnection network sm eight sp cores two special function units sfus instruction constant caches multithreaded instruction unit shared memory c12 appendix c graphics computing gpus e processor array architecture scalable smaller larger gpu co gurations scaling number multiprocessors number memory partitions figure c25 shows seven clusters two sms sharing texture unit texture l1 cache e texture unit deliver ltered results sm given set coordinates texture map becaus lter regions support en overlap successive texture reques ts small streaming l1 texture cache ective reduce number requests memory syst e processor array connects raster operation processors rops l2 texture caches external dram memories system memory via gpuwide interconnection network e number processors number memories scale design balanced gpu systems fo erent performance market segments c3 programming gpus programming multiprocessor gpus qualitativel erent programming multiprocessors like multicore cpus gpus provide two three orders magnitude thread data parallelism cpus scaling hundreds processor cores tens thousands concurrent threads gpus continue increase parallelism doubling every 12 18 months enabled moores law 1965 increasing integrated circuit density improving architect ciency span wide price performance range erent market segmen erent gpu products implement widely varying numbers processors threads yet users expect games graphics imaging computing applications work gpu regardless many parallel threads executes many parallel processor cores expect expensive gpus threads cores run applications faster result gpu programming models applic ation programs designed scale transparently wide range parallelism e driving force behind large number parallel threads cores gpu realtime graphics performancethe need render complex 3d scenes high resolution interactive frame rates least 60 frames per second correspondingly scalable programming models graphics shading languages cg c graphics hlsl highlevel shading language designed exploit large degrees parallelism via many independent parallel threads scale number processor cor e cuda scalable parallel programming model similarly enables general parallel computing applications leverage large numbers parallel threads scale number parallel processor cores transparently application scalable programming models programmer writes code single thread gpu runs myriad thread instances parallel programs thus scale transparently wide range hardware pa simple paradigm arose graphics apis shading languages describe shade one c3 programming gpus c 13vertex one pixel remained ective paradigm gpus rapidly increased parallelism performance since late 1990s section br describes programming gpus realtime graphics applications using graphics apis programming languages describes programming gpus visual computing general parallel computing applications using c language cuda programming model programming realtime graphics apis played important role rapid successful development gpus processor ere two primary standard graphics apis opengl direct3d one microso directx multimedia programming interfaces opengl open standard originally proposed ned silicon graphics incorporated e ongoing development extension opengl standard segal akeley 2006 kessenich 2006 managed khronos industry consortium direct3d blythe 2006 de facto standard ned evolved forward microso partners opengl direct3d similarly structured continue evolve rapidly gpu hardware advances ey ne logical graphics processing pipeline mapped onto gpu hardware processors along programming models languages programmable pipeline stages logical graphics pipelinefigure c31 illustrates direct3d 10 logical graphics pipeline opengl similar graphics pipeline structure e api logical pipeline provide streaming data ow infrastructure plumbing programmable shader stages shown blue e 3d application sends gpu sequence vertices grouped geometric primitivespoints lines triangles polygon e input assembler collects vertices primitiv e vertex shader program executes pervertex processing opengl open standard graphics api direct3d graphics ned microso partners inputassemblervertexshadergeometryshadersetup rasterizerpixelshaderraster operationsoutput mergervertexbuffertexturetexturetexturerendertargetsamplersamplersamplerconstantdepthzbufferconstantconstantstreambufferstreamoutindex buffermemorystencilgpufigure c31 direct3d 10 graphics pipeline logical pipeline stage maps gpu hardware gpu processor programmable shader stages blue xedfunction blocks white memory objects gray stage processes vertex geometric primitive pixel streaming data ow fashion c14 appendix c graphics computing gpus including transforming vertex 3d position screen position lighting vertex determine color e geometry shader program executes perprimitive processing add drop primitiv e setup rasterizer unit generates pixel fragments fragments potential contributions pixels covered geometric primitive e pixel shader program performs perfragment processing including interpolating perfragment parameters texturing coloring pixel shaders make extensive use sampled ltered lookups large 1d 2d 3d arrays called textures using interpolat oatingpoint coordinates shaders use texture accesses maps functions decals images dat e raster operations processing output merger stage performs zb er depth testing stencil testing may discard hidden pixel fragment replace pixels depth fragments depth performs color blending operation combines fragment color pixel color writes pixel blended color e graphics api graphics pipeline provide input output memory objects infrastructure shader programs process vertex primitive pixel fragment graphics shader programsrealtime graphics applications use man erent shader programs model light interacts wit erent materials render complex lighting shadows shading languages based data ow streaming programming model corresponds logical graphics pipeline vertex shader programs map position triangle vertices onto screen altering position color orientation typically vertex shader thread inpu oatingpoint x z w vertex position comput oatingpoint x z screen position geometry shader programs operate geometric primitives lines triangles ned multiple vertices changing generating additional primitives pixel fragment shaders shade one pixel computin oatingpoint red green blue alpha rgba color contribution rendered image pixel sample x image position shaders gpus us oatingpoint arithmetic pixel color calculations eliminate visible artifacts computing extreme range pixel contribution values encountered rendering scenes complex lighting shadows high dynamic range three types graphics shaders many program instances run parallel independent parallel threads works indepen dent data produces independent results ects independent vertices primitives pixels enable graphics program run erently sized gpus pro erent numbers vertices primitives pixels parallel graphics programs thus scale transparently gpus erent amounts parallelism performance users program three logical graphics threads common targeted high level language hlsl highlevel shading language cg c graphics commonly used ey clike syntax rich set library functions matrix operations trigonometry interpolation texture access ltering far general computing languages currently lack general memory texture 1d 2d 3d array supports sampled ltered lookups interpolated coordinates shader program operates graphics data vertex pixel fragment shading language graphics rendering language usually data ow streaming programming model c3 programming gpus c 15access pointer le io recursion hlsl cg assume programs live within logical graphics pipeline thus io implicit example pixel fragment shader may expect geometric normal multiple texture coordinates interpolated vertex values upstrea xedfunction stages simply assign value color output parameter pass downstream blended pixel implied x position e gpu hardware creates new independent thread execute vertex geometry pixel shader program every vertex every primitive every pixel fragment video games bulk threads execute pixel shader programs typically 10 20 times pixel fragments vertices complex lighting shadows require even larger ratios pixel vertex shader thre e graphics shader programming model drove gpu architecture ciently execute thousands independen negrained threads many parallel processor cores pixel shader exampleconsider following cg pixel shader program implements environment mapping rendering technique pixel thread shader pass parameters includin oatingpoint texture image coordinates needed sample surface color oatingpoint vector giving refection view direction surface e three uniform parameters vary one pixel instance thread th e shader looks color two texture images 2d texture access surface color 3d texture access cube map six images corresponding faces cube obtain external world color corresponding refection directio en th nal fourcomponent red green blue alph oatingpoint color computed using weighted average called lerp linear interpolation function void refection float2 texcoord texcoord0 float3 refection_dir texcoord1 float4 color color uniform float shiny uniform sampler2d surfacemap uniform samplercube envmap fetch surface color texture float4 surfacecolor tex2dsurfacemap texcoord fetch reflected color sampling cube map float4 reflectedcolor texcubeenvironmentmap refection_dir output weighted average two colors color lerpsurfacecolor refectedcolor shiny c16 appendix c graphics computing gpus although shader program three lines long activates lot gpu hardware texture fetch gpu texture subsystem makes multiple memory accesses sample image colors vicinity sampling coordinates interpolates th nal result oatingpoint ltering arit e multithreaded gpu executes thousands lightweight cg pixel shader threads parallel deeply interleaving hide texture fetch memory latency cg focuses programmers view single vertex primitive pixel gpu implements single thread shader program transparently scales exploit thread parallelism available processors application sp c cg provides rich set useful data types library functions language constructs express diverse rendering techniques figure c32 shows skin rendered fragment pixel shader real skin appears quit erent fro eshcolor paint light bounces around lot reemerging complex shader three separate skin layers unique subsurface scattering behavior modeled give skin visual depth translucency scattering modeled blurring convolution fattened texture space red blurred green blue blurre e figure c32 gpurendered image give skin visual depth translucency pixel shader program models three separate skin layers unique subsurface scattering behavior executes 1400 instructions render red green blue alpha color components skin pixel fragment c3 programming gpus c 17compiled cg shader executes 1400 instructions compute color one skin pixel gpus evolved superior oatingpoint performance high streaming memory bandwidth realtime graphics attracted highly parallel applications beyond traditional graphics rst access power available couching application graphicsrendering algorithm gpgpu approach en awkward limiting recently cuda programming model provided far easier way exploit scalable highperforman oatingpoint memory bandwidth gpus c programming language programming parallel computing applications cuda brook cal programming interfaces gpus focused data parallel computation rather graphics cal compute abstraction layer lowlevel assembler language interface amd gpus brook streaming language adapted gpus buck et al 2004 cuda developed nvidia 2007 extension c c languages scalable parallel programming manycore gpus multicore cpu e cuda programming model described adapted article nickolls et al 2008with new model gpu excels data parallel throughput computing executing high performance computing applications well graphics applications data parallel problem decomposition map large computing problem ectively highly parallel processing architecture programmer compiler decomposes problem many small problems solved parallel example programmer partitions large result data array blocks partitions block elements result blocks computed independently parallel elements within block computed parallel figure c33 shows decomposition result data array 3 2 grid blocks block decomposed 5 3 array elemen e twolevel parallel decomposition maps naturally gpu architecture parallel multiprocessors compute result blocks parallel threads compute result elements e programmer writes program computes sequence result data grids partitioning result grid coarsegrained result blocks computed independently parallel e program computes result block array negrained parallel threads partitioning work among threads computes one result elements scalable parallel programming cuda e cuda scalable parallel programming model extends c c languages exploit large degrees parallelism general applications highly parallel multiprocessors particularly gpus early experience cuda shows c18 appendix c graphics computing gpus many sophisticated programs readily expressed easily understood abstractions since nvidia released cuda 2007 developers rapidly developed scalable parallel programs wide range applications including seismic data processing computational chemistry linear algebra sparse matrix solvers sorting searching physics models visual computin ese applications scale transparently hundreds processor cores thousands concurrent threads nvidia gpus ed graphics computing architecture described sections c4 c7 run cuda c programs widely available laptops pcs workstations server e cuda model also applicable shared memory parallel processing architectures including multicore cpus cuda provides three key abstractionsa hierarchy thread groups shared memories barrier synchronization provide clear parallel structure conventional c code one thread hierarchy multiple levels threads memory synchronization prov negrained data parallelism thread parallelism nested within coarsegrained data parallelism task pa e abstractions guide programmer partition problem coarse subproblems solved independently parallel int ner pieces solved parallel e programming model scales transparently large numbers processor cores compiled cuda program executes number processors runtime system needs know physical processor count step 1sequenceblo0 blo0 step 2result data grid 1 ck0 block1 0 block1 1 block2 0 block2 1 block 1 1elem0 0elem1 0elem2 0elem3 0elem4 0elem0 1elem1 1elem2 1elem3 1elem4 1elem0 2elem1 2elem2 2elem3 2elem4 2ck1 result data grid 2 figure c33 decomposing result data grid blocks elements computed parallel c3 programming gpus c 19the cuda paradigm cuda minimal extension c c programming languag e programmer writes serial program calls parallel kernels may simple functions full programs kernel executes parallel across set parallel thre e programmer organizes threads hierarchy thread blocks grids thread blocks thread block set concurrent threads cooperate among barrier synchronization shared access memory space private block grid set thread blocks may executed independently thus may execute parallel invoking kernel programmer sp es number threads per block number blocks comprising grid thread given unique thread id number threadidx within thread block numbered 0 1 2 blockdim1 thread block given unique block id number blockidx within grid cuda supports thread blocks containing 512 threads convenience thread blocks grids may 1 2 3 dimensions accessed via x z eldsas simple example parallel programming suppose given two vectors x n oatingpoint numbers wish compute result ax scalar value socalled saxpy kernel ned blas linear algebra library figure c34 shows c code performing computation serial processor parallel using cuda e __global__ declaration sp er indicates procedure kernel entry point cuda programs launch parallel kernels extended function call syntax kerneldimgrid dimblock parameter list dimgrid dimblock threeelement vectors type dim3 specify dimensions grid blocks dimensions blocks threads respectively unsp ed dimensions default one figure c34 launch grid n threads assigns one thread element vectors puts 256 threads block individual thread computes element index thread block ids performs desired calculation corresponding vector elements comparing serial parallel versions code see strikingly similar represents fairly common patter e serial code consists loop iteration independent others loops mechanically transformed parallel kernels loop iteration becomes independent thread assigning single thread output element avoid need synchronization among threads writing results memory e text cuda kernel simply c function one sequential thread us generally straightforward write typically simpler writing parallel code vector operations parallelism determined clearly explicitly specifying dimensions grid thread blocks launching kernel kernel program function one thread designed executed many threads thread block set concurrent threads execute thread program may cooperate compute result grid set thread blocks execute kernel program c20 appendix c graphics computing gpus parallel execution thread management automatic thread creation scheduling termination handle programmer underlying system indeed tesla architecture gpu performs thread management directly hardware e threads block execute concurrently may synchronize synchronization barrier calling __syncthreads intrin guarantees thread block proceed threads block reached barrier er passing barrier threads also guaranteed see writes memory performed threads block barrier us threads block may communicate writing reading perblock shared memory synchronization barrier since threads block may share memory synchronize via barriers reside together physical processor multiprocessor e number thread blocks however greatly exceed number processor e cuda thread programming model virtualizes processors gives programmer exibility parallelize whatever granularity convenient virtualization synchronization barrier reads wait synchronization barrier threads thread block arrive barrier figure c34 sequential code top c versus parallel code bottom cuda saxpy see chapter 6 cuda parallel threads replace c serial loopeach thread computes result one loop iteratio e parallel code computes n results n threads organized blocks 256 threads computing ax serial loopvoid saxpy_serialint n float alpha float x float forint 0 yi alphaxi yi invoke serial saxpy kernel saxpy_serialn 20 x ycomputing ax parallel using cuda __global__void saxpy_parallelint n float alpha float x float int blockidxxblockdimx threadidxx yi alphaxi yi invoke parallel saxpy kernel 256 threads per blockint nblocks n 255 256 saxpy_parallelnblocks 256n 20 x c3 programming gpus c 21into threads thread blocks allows intuitive problem decompositions number blocks dictated size data processed rather number processors system also allows cuda program scale widely varying numbers processor cores manage processing element virtualization provide scalability cuda requires thread blocks able execute independently must possible execute blocks order parallel ser erent blocks means direct communication although may coordinate activities using atomic memory operations global memory visible threadsby atomically incrementing queue pointers example independence requirement allows thread blocks scheduled order across number cores making cuda model scalable across arbitrary number cores well across variety parallel architectures also helps avoid possibility deadlock application may execute multiple grids either independently dependently independent grids may execute concurrently giv cient hardware resources dependent grids execute sequentially implicit interkernel barrier thus guaranteeing blocks th rst grid complete block second dependent grid begins reads may access data multiple memory spaces execution thread private local memory cuda uses local memory thread private variables threads registers well stack frames register spilling thread block shared memory visible threads block lifetime block finally threads access global memory programs declare variables shared global memory __shared__ __device__ type qualifers tesla architecture gpu memory spaces correspond physically separate memories perblock shared memory lowlatency onchip ram global memory resides fast dram graphics board shared memory expected lowlatency memory near processor much like l1 cache therefore provide highperformance communication data sharing among threads thread block since lifetime corresponding thread block kernel code typically initialize data shared variables compute using shared variables copy shared memory results global memory read blocks sequentially dependent grids communicate via global memory using read input write results figure c35 shows diagrams nested levels threads thread blocks grids thread blocks shows corresponding levels memory sharing local shared global memories perthread perthreadblock perapplication data sharing program manages global memory space visible kernels calls cuda runtime cudamalloc cudafree kernels may execute physically separate device case running kernels gpu consequently application must use cudamemcpy copy data allocated space host system memory atomic memory operation memory read modify write operation sequence completes without intervening access local memory per thread local memory private thread shared memory per block memory shared threads block global memory per application memory shared threads c22 appendix c graphics computing gpus e cuda programming model simi lar style familiar single program multiple data spmd modelit expresses parallelism explicitly kernel executes xed number threads however cuda exible realizations spmd kernel call dynamically creates new grid right number thread blocks threads application step e programmer use convenient degree parallelism kernel rather design phases computation use number threads figure c36 shows example spmdlike cuda code sequence rst instantiates kernelf 2d grid 3 2 blocks 2d thread block consists 5 3 threads instantiates kernelg 1d grid four 1d thread blocks six threads kernelg depends results kernelf separated interkernel synchronization barrier e concurrent threads thread block expre negrained data parallelism thread pa e independent thread blocks grid express coarse singleprogram multiple data spmd style parallel programming model threads execute program spmd threads typically coordinate barrier synchronization threadperthread local memorythread blockperblockshared memorygrid 0 grid 1 global memorysequenceintergrid synchronizationfigure c35 nested granularity levelsthread thread block gridhave corresponding memory sharing levelslocal shared global perthread local memory private thread perblock shared memory shared threads block perapplication global memory shared threads c3 programming gpus c 23grained data parallelism independent grids express coarsegrained task parallelism kernel simply c code one thread hierarchy restrictionsfo ciency simplify implementation cuda programming model restriction reads thread blocks may created invoking parallel kernel within parallel kernel together required independence thread blocks makes possible execute cuda programs figure c36 sequence kernel f instantiated 2d grid 2d thread blocks interkernel synchronization barrier followed kernel g 1d grid 1d thread blocks kernelg 1d grid 4 thread blocks block 6 threadssequenceinterkernel synchronization barrier block 2thread 5thread 0 thread 1 thread 2thread 3thread 4kernelf3 2 5 3paramskernelf 2d grid 3 2 thread blocks block 5 3 threadsblock 1 1thread 0 0thread 1 0thread 2 0thread 3 0thread 4 0thread 0 1thread 1 1thread 2 1thread 3 1thread 4 1thread 0 2thread 1 2thread 2 2thread 3 2thread 4 2block 0 1block 2 1block 1 1block 0 0block 2 0block 1 0kernelg4 6paramsblock 0block 2block 1block 3 c24 appendix c graphics computing gpus simple scheduler introduces minimal runtime overhead fact tesla gpu architecture implements hardware management scheduling threads thread blocks task parallelism expressed thread block level bu cult express within thread block thread synchronization barriers operate threads block enable cuda programs run number processors dependencies among thread blocks within kernel grid allowedblocks must execute independently since cuda requires thread blocks independent allows blocks executed order combining results generated multiple blocks must general done launching second kernel new grid thread blocks although thread blocks may coordinate activities using atomic memory operations global memory visible threadsby atomically incrementing queue pointers example recursive function calls currently allowed cuda kernels recursion unattractive massively parallel kernel providing stack space tens thousands threads may active would require substantial amounts memory serial algorithms normally expressed using recursion quicksort typically best implemented using nested data parallelism rather explicit recursion support heterogeneous system architecture combining cpu gpu memory system cuda programs must copy data results host memory device memory e overhead cpugpu interaction data transfers minimized using dma block transfer engines fast interconnects computeintensive problems large enough need gpu performance boost amortize overhead better small problems implications architecture e parallel programming models graphics computing driven gpu architecture erent cpu architecture e key aspects gpu programs driving gpu processor architecture extensive use negrained data parallelism shader programs describe process single pixel vertex cuda programs describe compute individual result highly threaded programming model shader thread program processes single pixel vertex cuda thread program may generate single result gpu must create execute millions thread programs per frame 60 frames per second scalability program must automatically increase performance provided additional processors without recompiling intensiv oatingpoint integer computation support high throughput computations c4 multithreaded multiprocessor architecture c 25 c4 multithreaded multiprocessor architectureto addr erent market segments gpus implement scalable numbers multi processorsin fact gpus multiprocessors composed multiprocessors furthermore multiprocessor highly multithreaded execute man negrained vertex pixel shader thre ciently quality basic gpu two four multiprocessors gaming enthusiasts gpu computing platform dozens th section looks architecture one multithreaded multiprocessor simp ed version nvidia tesla streaming multiprocessor sm described section c7 use multiprocessor rather several independent processor e parallelism within multiprocessor provides localized high performance supports extensive multithreading th negrained parallel programming models described sectio e individual threads thread block execute together within multiprocessor share dat e multithreaded multiprocessor design describe eight scalar processor cores tightly coupled architecture executes 512 threads sm described section c7 executes 768 threads area pow ciency multiprocessor shares large complex units among eight processor cores including instruction cache multithreaded instruction unit shared memory ram massive multithreadinggpu processors highly multithreaded achieve several goals cover latency memory loads texture fetches dram support negrained parallel graphics shader programming models support negrained parallel computing programming models virtualize physical processors threads thread blocks provide transparent scalability simplify parallel programming model writing serial program one thread memory texture fetch latency require hundreds processor clocks gpus typically small streaming caches rather large workingset caches like cpus fetch request generally requires full dram access latency plus interconnect b ering latency multithreading helps cover latency useful computingwhile one thread waiting load texture fetch complete processor execute another thread e negrained parallel programming models provide literally thousands independent threads keep many processors busy despite long memory latency seen individual threads c26 appendix c graphics computing gpus graphics vertex pixel shader program program single thread processes vertex pixel similarly cuda program c program single thread computes result graphics computing programs instantiate many parallel threads render complex images compute large result arrays dynamically balan ing vertex pixel shader thread workloads multiprocessor concurrently executes multip erent thread programs erent types shader programs support independent vertex primitive pixel programming model graphics shading languages singlethread programming model cuda cc gpu thread private registers private perthread memory program counter thread execution state execute independent code path ciently execute hundreds concurrent lightweight threads gpu multiprocessor hardware multithreadedit manages executes hundreds concurrent threads hardware without scheduling overhead concurrent threads within thread blocks synchronize barrier single instruction lightweight thread creation zerooverhead thread scheduling fast barrier synchronizatio ciently support negrained parallelism multiprocessor architecture ed graphics computing multiprocessor executes vertex geometry pixel fragment shader programs parallel computing programs figure c41 shows example multiprocessor consists eight scalar processor sp cores large multithreaded regist le rf two special function units sfus multithreaded instruction unit instruction cache readonly constant cache shared memory e 16 kb shared memory holds graphics data b ers shared computing data cuda variables declared __shared__ reside shared memory map logical graphics pipeline workload multiprocessor multiple times shown section c2 vertex geometry pixel threads independent input output b ers workloads arrive depart independently thread execution sp core contains scalar integer oatingpoint arithmetic units execute instruction e sp hardware multithreaded supporting 64 threads pipelined sp core executes one scalar instruction per thread per clock ranges 12 ghz 16 gh erent gpu products sp core large rf 1024 generalpurpose 32bit registers partitioned among assigned threads programs declare gister demand typically 16 64 scalar 32bit registers per thread e sp concurrently run many threads use registers fewer threads use register e compiler optimizes register allocation balance cost spilling registers versus cost fewer threads pixel shader programs en use 16 fewer registers enabling sp run 64 pixel shader threads cover longlatency texture fetches compiled cuda programs en need 32 registers per thread limiting sp 32 threads limits kernel program 256 threads per thread block example multiprocessor rather maximum 512 threads c4 multithreaded multiprocessor architecture c 27 e pipelined sfus execute thread instructions compute special functions interpolate pixel attributes primitive vertex attribut ese instructions execute concurrently instructions sp e sfu described later e multiprocessor executes texture fetch instructions texture unit via texture interface uses memory interface external memory load store atomic access instruction ese instructions execute concurrently instructions sps shared memory access uses lowlatency interconnection network sp processors shared memory banks singleinstruction multiplethread simt manage execute hundreds threads running sev erent programs ciently multiprocessor employs singleinstruction multiplethread simt architecture creates manages schedules executes concurrent threads groups parallel threads called warps e term warp originates weaving rst parallel thread technology e photograph figure c42 shows warp parallel threads emerging loo example multiprocessor uses simt warp size 32 threads executing four threads eight sp cores four singleinstruction multiplethread simt processor architecture applies one instruction multiple independent threads parallel warp e set parallel threads execute instruction together simt architecture instruction cachemultithreaded instruction unitmultithreaded multiprocessorconstant cachesfusfusprfsprfsprfsprfsprfsprfsprfsprfshared memorytextureinterfacememoryinterfacemultiprocessorcontrolleroutputinterfaceinterconnection networkinputinterfacework interfacefigure c41 multithreaded multiprocessor eight scalar processor sp cores e eight sp cores large multithreaded regist le rf share instruction cache multithreaded instruction issue unit constant cache two special function units sfus interconnection network multibank shared memory c28 appendix c graphics computing gpus cloc e tesla sm multiprocessor described section c7 also uses warp size 32 parallel threads executing four threads per sp core fo ciency plentiful pixel threads computing thre read blocks consist one warps example simt multiprocessor manages pool 16 warps total 512 threads individual parallel threads composing warp type start together program address otherwise free branch execute independently instruction issue time simt multithreaded instruction unit selects warp ready execute next instruction issues instruction active threads warp simt instruction broadcast synchronously active parallel threads warp individual threads may inactive due independent branching predication multiprocessor sp scalar processor core executes instruction four individual threads warp using four clocks r ecting 41 ratio warp threads cores simt processor architecture akin singleinstruction multiple data simd design applies one instruction multiple data lanes bu ers simt applies one instruction multiple independent threads parallel warp 8 instruction 11warp 1 instruction 42warp 3 instruction 95warp 8 instruction 12timesimt multithreadedinstruction schedulerwarp 1 instruction 43warp 3 instruction 96photo judy schoonmakerfigure c42 simt multithreaded warp scheduling e scheduler selects ready warp issues instruction synchronously parallel threads composing warp warps independent scheduler may selec erent warp time c4 multithreaded multiprocessor architecture c 29to multiple data lanes instruction simd processor controls vector multiple data lanes together whereas instruction simt processor controls individual thread simt instruction unit issues instruction warp independent parallel threads fo ciency e simt processo nds datalevel parallelism among threads runtime analogous way superscalar processor nds instructionlevel parallelism among instructions runtime simt processor realizes f ciency performance threads warp take execution path threads warp diverge via data dependent conditional branch execution serializes branch path taken paths complete threads converge execution path equal length paths divergent ifelse code bloc cient e multiprocessor uses branch synchronization stack manage independent threads diverge converge erent warps execute independently full speed regardless whether executing common disjoint code paths result simt gpus dramatically mor cient exible branching code earlier gpus warps much narrower simd width prior gpus contrast simd vector architectures simt enables programmers write threadlevel parallel code individual independent threads well dataparallel code many coordinated threads program correctness programmer essentially ignore simt execution attributes warps however substantial performance improvements realized taking care code seldom requires threads warp diverge practice analogous role cache lines traditional codes cache line size safely ignored designing correctness must considered code structure designing peak performance simt warp execution divergence e simt approach scheduling independent warps mor exible scheduling previous gpu architectures warp comprises parallel threads type vertex geometry pixel compute e basic unit pixel fragment shader processing 2by2 pixel quad implemented four pixel shader threads e multiprocessor controller packs pixel quads warp similarly groups vertices primitives warps packs computing threads warp thread block comprises one war e simt design shares instruction fetch issue uni ciently across parallel threads warp requires full warp active threads get full performa ciency ed multiprocessor schedules executes multiple warp types concurrently allowing concurrently execute vertex pixel warps warp scheduler operates less processor clock rate four thread lanes per processor core scheduling cycle selects warp execute simt warp instruction shown figure c42 issued warpinstruction executes four sets eight threads four processor cycles throughpu e processor pipeline uses several clocks latency complete instruction number active warps times clocks per warp exceeds pipeline latency c30 appendix c graphics computing gpus programmer ignore pipeline latency multiprocessor roundrobin schedule eight warps period 32 cycles successive instructions warp program keep 256 threads active per multiprocessor instruction latencies 32 cycles hidden individual sequential thread however active warps processor pipeline depth becomes visible may cause processors stall challenging design problem implementing zerooverhead warp scheduling dynamic mix erent warp programs program typ e instruction scheduler must select warp every four clocks issue one instruction per clock per thread equivalent ipc 10 per processor core warps independent dependences among sequential instructions warp e scheduler uses register dependency scoreboard qualify warps whose active threads ready execute instruction prioritizes ready warps selects highest priority one issue prioritization must consider warp type instruction type desire fair active warps managing threads thread blocks e multiprocessor controller instruction unit manage threads thread bloc e controller accepts work requests input data arbitrates access shared resources including texture unit memory access path io paths graphics workloads creates manages three types graphics threads concurrently vertex geometry pixel graphics work types independent input output paths accumulates packs input work types simt warps parallel threads executing thread program allocates free warp allocates registers warp threads starts warp execution multiprocessor every program declares per thread register demand controller starts warp allocate requested register count warp threads threads warp exit controller unpacks results frees warp registers resources e controller creates cooperative thread arrays ctas implement cuda thread blocks one warps parallel threads creates cta create cta warps allocate cta resources addition threads registers cta requires allocating shared memory barriers e program declares required capacit ies controller waits allocate amounts launching ct en creates cta warps warp scheduling rate cta program starts executing immediately full multiprocessor performance e controller monitors threads cta exited frees cta shared resources warp resources thread instructions e sp thread processors execute scalar instructions individual threads unlike earlier gpu vector instruction architectures executed fourcomponent vector instructions vertex pixel shader program vertex programs cooperative thread array cta set concurrent threads executes thread program may cooperate compute result gpu cta implements cuda thread block c4 multithreaded multiprocessor architecture c 31generally compute x z w position vectors pixel shader programs compute red green blue alpha color vectors however shader programs becoming longer scalar increasingl cult fully occupy even two components legacy gpu fourcomponent vector architecture ect simt architecture paralle lizes across 32 independent pixel threads rather parallelizing four vector components within pixel cuda cc programs predominantly scalar code per thread previous gpus employed vector packing eg combining subvectors work ga ciency complicated scheduling hardware well compiler scalar instructions simpler compiler friendly texture instructions remain vector based taking source coordinate vector returnin ltered color vector support multiple gpus wit erent binary microinstruction formats high level graphics computing language compilers generate intermediate assembler level instructions eg direct3d vector instructions ptx scalar instructions optimized translated binary gpu microinstructions e nvidia ptx parallel thread execution instruction nition 2007 provides stable target isa compilers provides compatibility several generations gpus evolving binary microinstructionset architectur e optimizer readily expands direct3d vector instructions multiple scalar binary microinstructions ptx scalar instructions translate nearly one one scalar binary microinstructions although ptx instructions expand multiple binary microinstructions multiple ptx instructions may fold one binary microinstruction intermediate assemblerlevel instructions use virtual registers optimizer analyzes data dependencies allocates real register e optimizer eliminates dead code folds instructions together feasible optimizes simt branch diverge converge points instruction set architecture isa e thread isa described simp ed version tesla architecture ptx isa registerbased scalar instruction set comprisin oatingpoint integer logical conversion special function ow control memory access texture operations figure c43 lists basic ptx gpu thread instructions see nvidia ptx sp cation 2007 detai e instruction format opcodetype b cwhere destination operand b c source operands type one typetype specifer untyped bits 8 16 32 64 bitsb8 b16 b32 b64 unsigned integer 8 16 32 64 bitsu8 u16 u32 u64 signed integer 8 16 32 64 bitss8 s16 s32 s64 floatingpoint 16 32 64 bitsf16 f32 f64 c32 appendix c graphics computing gpus figure c43 basic ptx gpu thread instructions basic ptx gpu thread instructions groupinstructionexamplemeaningcomments arithmeticarithmetic type s32 u32 f32 s64 u64 f64addtypeaddf32 bd b subtypesubf32 bd b multypemulf32 bd b madtypemadf32 b cd b c multiplyadddiv typedivf32 bd b multiple microinstructions remtyperemu32 bd b integer remainderabstypeabsf32 ad negtypenegf32 ad 0 mintypeminf32 bd b ab ßoating selects nonnanmaxtypemaxf32 bd b ab ßoating selects nonnansetpcmptypesetpltf32 p bp b compare set predicatenumeric cmp eq ne lt le gt ge unordered cmp equ neu ltu leu gtu geu num nanmov typemovb32 ad move selptypeselpf32 b pd p b select predicatecvtdtypeatypecvtf32s32 ad converta convert atype dtype special functionspecial type f32 f64rcptypercpf32 ad 1a reciprocalsqrt typesqrtf32 ad sqrta square rootrsqrt typersqrtf32 ad 1sqrta reciprocal square rootsintypesinf32 ad sina sinecostypecosf32 ad cosa cosinelg2typelg2f32 ad logalog2 binary logarithm ex2typeex2f32 ad 2 binary exponential logicallogic type pred b32 b64andtypeandb32 bd b typeorb32 bd b xor typexorb32 bd b nottypenotb32 bd oneõs complement cnottypecnotb32 bd a0 10 c logical notshltypeshlb32 bd b shift leftshr typeshrs32 bd b shift rightmemory accessmemory space global shared local const type b8 u8 s8 b16 b32 b64ldspacetypeldglobalb32 aoffd aoff load memory spacestspacetypestsharedb32 doff adoff store memory spacetexnddtypbtypetex2dv4f32f32 bd tex2da b texture lookupatomspcoptypeatomglobaladdu32 da b atomglobalcasb32 da b catomic opa b atomic readmodifywrite operationatom op xor add min max exch casspc global type b32control flowbranchp bra targetif p goto targetconditional branchcallcall ret func paramsret funcparams call functionretretreturn return function call barsync barsync dwait threads barrier synchronization exitexitexit terminate thread execution c4 multithreaded multiprocessor architecture c 33source operands scalar 32bit 64bit values registers immediate value constant predicate operands 1bit boolean values destinations registers except store memory instructions predicated pr xing p p p predicate register memory texture instructions transfer scalars vectors two four components 128 bits total ptx instructions specify behavior one thread e ptx arithmetic instructions operate 32bit 64bi oatingpoint signed integer unsigned integer types recent gpus support 64bit double precisio oatingpoint see section c6 current gpus ptx 64bit integer logical instructions translated two binary microinstructions perform 32bit operation e gpu special function instructions limited 32bi oatingpoint e thread contro ow instructions conditional branch function call return thread exit barsync barrier synchronizatio e conditional branch instruction p bra target uses predicate register p p previously set compare set predicate setp instruction determine whether thread takes branch instructions also predicated predicate register true false memory access instructions e tex instruction fetches lters texture samples 1d 2d 3d texture arrays memory via texture subsystem texture fetches generally use interpolat oatingpoint coordinates address texture graphics pixel shader thread computes pixel fragment color raster operations processor blends pixel color assigned x pixel position writes th nal color memory support computing cc language needs tesla ptx isa implements memory loadstore instructions uses integer byte addressing register plus set address arithmetic facilitate conventional compiler code optimizations memory loadstore instructions common processors cant new capability tesla architecture gpus prior gpus provided texture pixel accesses required graphics apis computing loadstore instructions access three readwrite memory spaces implement corresponding cuda memory spaces section c3 local memory perthread private addressable temporary data implemented external dram shared memory lowlatency access data shared cooperating threads ctathread block implemented onchip sram global memory large data sets shared threads computing application implemented external dram e memory loadstore instructions ldglobal stglobal ldshared stshared ldlocal stlocal access global shared local memory spaces computing programs use fast barrier synchronization instruction barsync synchronize threads within ctathread block communicate via shared global memory c34 appendix c graphics computing gpus improve memory bandwidth reduce overhead local global load store instructions coalesce individual parallel thread requests simt warp together single memory block request addresses fall block meet alignment criteri coalescing memory requests provides cant performance boost separate requests individual thre e multiprocessors large thread count together support many outstanding load requests helps cover loadtouse latency local global memory implemented external dram e latest tesla architecture gpus also prov cient atomic memory operations memory atomopu32 instructions including integer operations add min max xor exchange cas compareandswap operations facilitating parallel reductions parallel data structure management barrier synchronization thread communication fast barrier synchronization permits cuda programs communicate frequently via shared memory global memory simply calling __syncthreads part interthread communication step e synchronization intrinsic function generates single barsync instruction however implementing fast barrier synchronization among 512 threads per cuda thread block challenge grouping threads simt warps 32 threads reduces synchronization culty factor reads wait barrier simt thread scheduler consume processor cycles waiting thread executes barsync instruction increments barriers thread arrival counter scheduler marks thread waiting barrier cta threads arrive barrier counter matches expected terminal count scheduler releases threads waiting barrier resumes executing threads streaming processor sp e multithreaded streaming processor sp core primary thread instruction processor multiprocessor regist le rf provides 1024 scalar 32 bit registers 64 threads executes fundamenta oatingpoint operations including addf32 mulf32 madf32 oating multiplyadd minf32 maxf32 setpf32 oating compare set predicat e oating point add multiply operations compatible ieee 754 standard single precision fp numbers including notanumber nan nity val e sp core also implements 32bit 64bit integer arithmetic comparison conversion logical ptx instructions shown figure c43 e oatingpoint add mul operations employ ieee roundtonearesteven default rounding mode e madf32 oatingpoint multiplyadd operation performs multiplication truncation followed addition round tonearestev e ushes input denormal operands signpreservedzero results ow target output exponent range ar ushed sign preservedzero er rounding c4 multithreaded multiprocessor architecture c 35special function unit sfucertain thread instructions execute sfus concurrently thread instructions executing sp e sfu implements special function instructions figure c43 compute 32bi oatingpoint approximations reciprocal reciprocal square root key transcendental functions also implements 32bi oatingpoint planar attribute interpolation pixel shaders providing accurate interpolation attributes color depth texture coordinates pipelined sfu generates one 32bi oatingpoint special function result per cycle two sfus per multiprocessor execute special function instructions quarter simple instruction rate eight sp e sfus also execute mulf32 multiply instruction concurrently eight sps increasing peak computation rate 50 threads suitable instruction mixture functional evaluation tesla architecture sfu employs quadratic interpolation based enhanced minimax approximations approximating reciprocal reciprocal squareroot log 2x 2x sincos function e accuracy function estimates ranges 22 24 mantissa bits see section c6 details sfu arithmetic comparing multiprocessors compared simd vector architectures x86 sse simt multiprocessor execute individual threads independently rather always executing together synchronous groups simt hardwar nds data parallelism among independent threads whereas simd hardware requires ware express data parallelism explicitly vector instruction simt machine executes warp 32 threads synchronously threads take execution path yet execute thread independently diverge e advantage cant simt programs instructions simply describe behavior single independent thread rather simd data vector four data lanes yet simt multiprocessor simdlik ciency spreading area cost one instruction unit across 32 threads warp across eight streaming processor cores simt provides performance simd together productivity multithreading avoiding need explicitly code simd vectors edge conditions partial divergence e simt multiprocessor imposes little overhead hardware multithreaded hardware barrier synchronizatio allows graphics shaders cuda threads express ver negrained parallelism graphics cuda programs use threads expr negrained data parallelism per thread program rather forcing programmer express simd vector instructions simpler productive develop scalar singlethread code vector code simt multiprocessor executes code simdlike ciency c36 appendix c graphics computing gpus coupling eight streaming processor cores together closely multiprocessor implementing scalable number multiprocessors makes two level multiprocessor composed multiprocessor e cuda programming model exploits twolevel hierarchy providing individual threads fo negrained parallel computations providing grids thread blocks coarsegrained parallel operation e thread program provide bot negrained coarsegrained operations contrast cpus simd vector instructions must use tw erent programming models prov negrained coarsegrained operations coarsegrained parallel threads erent cores simd vector instructions fo negrained data parallelism multithreaded multiprocessor conclusion e example gpu multiprocessor based tesla architecture highly multithreaded executing total 512 lightweight threads concurrently suppor negrained pixel shaders cuda threads uses variation simd architecture multithreading called simt singleinstruction multiplethread e ciently broadcast one instruction warp 32 parallel threads permitting thread branch execute independently thread executes instruction stream one eight streaming processor sp cores multithreaded 64 threads e ptx isa registerbased loadstore scalar isa describes execution single thread ptx instructions optimized translated binary microinstructions sp c gpu hardware instructions evolve rapidly without disrupting compilers ware tools generate ptx instructions c5 parallel memory system outside gpu memory subsystem important determiner performance graphics system graphics workloads demand high transfer rates memory pixel write blend readmodify write operations depth bu er reads writes texture map reads well command object vertex attribute data reads comprise majority memory tr c modern gpus highly parallel shown figure c25 example geforce 8800 process 32 pixels per clock 600 mhz pixel typically requires color read write depth read write 4byte pixel usually average two three texels four bytes read generate pixels color typical case demand 28 bytes times 32 pixels 896 bytes per clock clearly bandwidth demand memory system enormous c5 parallel memory system c 37to supply requirements gpu memory systems following characteristics ey wide meaning large number pins convey data gpu memory devices memory array comprises many dram chips provide full total data bus width ey fast meaning aggressive signaling techniques used maximize data rate bitssecond per pin gpus seek use every available cycle transfer data memory array achieve gpus sp cally aim minimize latency memory system high throughput utilizatio ciency short latency fundamentally co ict compression techniques used lossy programmer must aware lossless invisi ble application opportunistic caches work coalescing structures used reduce amount chip tr c needed ensure cycles spent moving data used fully possible dram considerationsgpus must take account unique characteristics dram dram chips internally arranged multiple typically four eight banks bank includes powerof2 number rows typically around 16384 row contains powerof2 number bits typically 8192 drams impose variety timing requirements controlling processor example dozens cycles required activate one row activated bits within row randomly accessible new column address every four clocks doubledata rate ddr synchronous drams transfer data rising falling edges interface clock see chapter 5 1 ghz clocked ddr dram transfers data 2 gigabits per second per data pin graphics ddr drams usually 32 bidirectional data pins eight bytes read written dram per clock gpus internally large number generators memory tra c erent stages logical graphics pipeline request streams command vertex attribute fetch shader texture fetch loadstore pixel depth color readwrite logical stage en multiple independent units deliver parallel throughpu ese independent memory requestors viewed memory system enormous number uncorrelated req ight natural mismatch reference pattern preferred drams solution gpus memory controller maintain separate heaps tra c bound fo erent dram banks wait c38 appendix c graphics computing gpus enough tra c particular dram row pending activating row transferring tra c note accumulating pending requests good dram row locality th cient use data bus leads longer average latency seen requestors whose requests spend time waiting e design must take care particular request waits long otherwise processing units starve waiting data ultimately cause neighboring processors become idle gpu memory subsystems arranged multiple memory partitions comprises fully independent memory controller one two dram devices fully exclusively owned partition achieve best load balance therefore approach theoretical performance n partitions addresses ar nely interleaved evenly across memory partition e partition interleaving stride typically block hundred byt e number memory partitions designed balance number processors memory requesters cachesgpu workloads typically large working setson order hundreds megabytes generate single graphics frame unlike cpus practical construct caches chips large enough hold anything close full working set graphics application whereas cpus assume high cache hit rates 999 gpus experience hit rates closer 90 must therefore cope many miss ight cpu reasonably designed halt waiting rare cache miss gpu needs proceed misses hits intermingled call streaming cache architecture gpu caches must deliver highbandwidth clients consider case texture cache typical texture unit may evaluate two bilinear interpolations four pixels per clock cycle gpu may many texture units operating independently bilinear interpolation requires four separate texels texel might 64bit value four 16bit components typical us total bandwidth 2 4 4 64 2048 bits per clock separate 64bit texel independently addressed cach e needs handle 32 unique addresses per cloc naturally favors multibank andor multiport arrangement sram arrays mmumodern gpus capable translating virtual addresses physical addresses geforce 8800 processing units generate memory addresses 40bit virtual address space computing load store thread instructions use 32bit byte addresses extended 40bit virtual address adding 40bit set memory management unit performs virtual physical address c5 parallel memory system c 39translation hardware reads page tables local memory respond misses behalf hierarchy translation lookaside b ers spread among processors rendering engines addition physical page bits gpu page table entries specify compression algorithm page page sizes range 4 128 kilobytes memory spaces introduced section c3 cuda expos erent memory spaces allow programmer store data values performanceoptimal way following discussion nvidia tesla architecture gpus assumed global memory global memory stored external dram local one physical streaming multiprocessor sm meant communication among erent ctas thread bloc erent grids fact many ctas reference location global memory may executing gpu time design cuda programmer know relative order ctas executed address space evenly distributed among memory partitions must readwrite path streaming multiprocessor dram partition access global memory erent threads erent processors guaranteed sequential consistency read programs see relaxed memory ordering model within thread order memory reads writes address preserved order accesses erent addresses may preserved memory reads writes requested erent threads unordered within cta barrier synchronization instruction barsync used obtain strict memory ordering among threads ct e membar thread instruction provides memory barrierfence operation commits prior memory accesses makes visible threads proceeding reads also use atomic memory operations described section c4 coordinate work memory share shared memory percta shared memory visible threads belong cta shared memory occupies storage time cta created time terminates shared memory therefore reside onchip approach many ts first shared memory tra c need compete limited chip bandwidth needed global memory references second practical build highbandwidth memory structures onchip support readwrite demands streaming multiprocessor fact shared memory closely coupled streaming multiprocessor c40 appendix c graphics computing gpus streaming multiprocessor contains eight physical thread processors one shared memory clock cycle thread processor process two threads worth instructions 16 threads worth shared memory requests must handled clock thread generate addresses addresses typically unique shared memory built using 16 independently addressable sram banks common access patterns 16 banks ar cient maintain throughput pathological cases possible example 16 threads might happen erent address one sram bank must possible route request thread lane bank sram 16by 16 interconnection network required local memory perthread local memory private memory visible single thread local memory architecturally larger threads regist le program compute addresses local memory support large allocations local memory recall total allocation perthread allocation times number active threads local memory allocated external dram although global perthread local memory reside chip well suited cached onchip constant memory constant memory readonly program running sm written via commands gpu stored external dram cached sm commonly threads simt warp read address constant memory single address lookup per cloc cient e constant cache designed broadcast scalar values threads warp texture memory texture memory holds large readonly arrays data textures computing attributes capabilities textures used 3d graphics although textures commonly twodimensional images 2d arrays pixel values 1d linear 3d volume textures also available compute program references texture using tex instruction operands include iden er name texture 1 2 3 coordinates based texture dimensionality e oatingpoint coordinates include fractional portion sp es sample location en texel locations noninteger coordinates invoke bilinear weighted interpolation four closest values 2d texture result returned program texture fetches cached streaming cache hierarchy designed optimize throughput texture fetches thousands concurrent threads programs use texture fetches way cache global memory c6 floatingpoint arithmetic c 41surfacessurface generic term onedimensional twodimensional three dimensional array pixel values associated format variety formats ar ned example pixel may b ned four 8bit rgba integer components four 16bi oatingpoint components program kernel need know surface type tex instruction recasts result values oatingpoint depending surface format loadstore accessloadstore instructions integer byte addressing enable writing compiling programs conventional languages like c c cuda programs use loadstore instructions access memory improve memory bandwidth reduce overhead local global load store instructions coalesce individual parallel thread requests warp together single memory block request addresses fall block meet alignment criteria coales cing individual small memory requests large block requests prov cant performance boost separate req e large thread count together support many outstanding load requests helps cover loadtouse latency local global memory implemented external dram rop shown figure c25 nvidia tesla architecture gpus comprise scalable streaming processor array spa performs gpus programmable calculations scalable memory system comprises external dram control xed function raster operation processors rops perform color depth frameb er operations directly memory rop unit paired sp c memory partition rop partitions fed sms via interconnection network rop responsible depth stencil tests updates well color blendin e rop memory controllers cooperate implement lossless color depth co mpression 81 reduce external bandwidth demand rop units also perform atomic operations memory c6 floatingpoint arithmetic gpus today perform arithmetic operations programmable processor cores using ieee 754compatible single precision 32bi oatingpoint operations see chapt e xedpoint arithmetic early gpus succeeded 16 bit 24bit 32bi oatingpoint ieee 754compatible 32bi oating c42 appendix c graphics computing gpus point xedfunction logic within gpu textur ltering hardware continues use proprietary numeric formats recent gpus also provide ieee 754 compatible double precision 64bi oatingpoint instructions supported formats e ieee 754 standard fo oatingpoint arithmetic sp es basic storage formats gpus use two basic formats computation 32bit 64bit binary oatingpoint commonly called single precision double precisio e standard also spe es 16bit binary storag oatingpoint format half precision gpus cg shading language employ narrow 16bit half data format cient data storage movement maintaining high dynamic range gpus perform many textur ltering pixel blending computations half precision within textur ltering unit raster operations uni e openexr high dynamicrange imag le format developed industrial light magic 2003 uses identical half format color component values computer imaging motion picture applications basic arithmeticcommon single precisio oatingpoint operations gpu programmable cores include addition multiplication multiplyadd minimum maximum compare set predicate conversions integer oatingpoint numbers floatingpoint instructions en provide source operand mo ers negation absolute value e oatingpoint addition multiplication operations gpus today compatible ieee 754 standard single precision fp numbers including anumber nan nity val e fp addition multiplication operations use ieee roundtonearesteven default rounding mode increas oating point instruction throughput gpus en use compound multiplyadd instruction mad e multiplyadd operation performs fp multiplication truncation followed fp addition roundtonearesteven provides tw oatingpoint operations one issuing cycle without requiring instruction scheduler dispatch two separate instructions computation fused truncates product additio makes erent fused multiplyadd instruction discussed chapter 3 later section gpus typicall ush denormalized source operands signpreserved zero ush results ow target output exponent range signpreserved zero er rounding specialized arithmeticgpus provide hardware accelerate special function computation attribute interpolation textur ltering special function instructions include cosine half precision 16bit binary oatingpoint format 1 sign bit 5bit exponent 10bit fraction implied integer bit multiplyadd mad sing oatingpoint instruction performs compound operation multiplication followed addition c6 floatingpoint arithmetic c 43sine binary exponential binary logarithm reciprocal reciprocal square root attribute interpolation instructions prov cient generation pixel attributes derived plane equation evaluatio e special function unit sfu introduced section c4 computes special functions interpolates planar attributes oberman siu 2005 several methods exist evaluating special functions hardware shown quadratic interpolation based enhanced minimax approximations ver cient method approximating functions hardware including reciprocal reciprocal squareroot log 2x 2x sin cos summarize method sfu quadratic interpolation binary input operand x nbit cand th cand divided two parts xu upper part containing bits x l lower part containing nm bits e upper bits x u used consult set three lookup tables return three niteword co cients c 0 c1 c 2 function approximated requires unique set tab ese co cients used approximate given function fx range x u x xu 2m evaluating expression fxccxcx 01121 2 e accuracy function estimates ranges 22 cand bits example function statistics shown figure c61 e ieee 754 standard sp es exactrounding requirements division square root however many gpu applications exact compliance required rather applications higher computational throughput important lastbit accuracy sfu special functions cuda math library provides full accuracy function fast function sfu instruction accuracy another specialized arithmetic operation gpu attribute interpolation key attributes usually sp ed vertices primitives make scene rendered example attributes color depth texture coordinat ese attributes must interpolated xy screen space needed determine special function unit sfu hardware unit computes special functions interpolates planar attributes functioninput intervalaccuracygood bitsulperror exactly roundedmonotonic 1x1 2240209887yes 1sqrtx1 4234015278yes 2x0 1225114174yes log2x1 22257na nayes sincos0 22247nanano ulp unit last place na applicablefigure c61 special function approximation statistics nvidia geforce 8800 special function unit sfu c44 appendix c graphics computing gpus values attributes pixel locatio e value given attribute u x plane expressed using plane equations form uxyaxbyc uuu b c interpolation parameters associated attribute u e interpolation parameters b c represented single precision oatingpoint numbers given need function evaluator attribute interpolator pixel shader processor single sfu performs functions fo ciency designed functions use sum products operation interpolate results number terms summed functions similar texture operations texture mapping ltering another key set sp oatingpoint arithmetic operations gpu e operations used texture mapping include 1 receive texture address current screen pixel x single precisio oatingpoint numbers 2 compute level detail identify correct texture mipmap level 3 compute trilinear interpolation fraction 4 scale texture address selected mipmap level 5 access memory retrieve desired texels texture elements 6 perform ltering operation texels texture mapping requir cant amount oatingpoint computation fullspeed operation much done 16bit half precision example geforce 8800 ultra delivers 500 gflops proprietary format oatingpoint computation texture mapping instructions addition conventional ieee single precisio oatingpoint instructions details texture mapping ltering see foley van dam 1995 performance e oatingpoint addition multiplication arithmetic hardware fully pipelined latency optimized bal ance delay area pipelined throughput special functions less th oatingpoint addition multiplication operations quarterspeed throughput special functions typical performance modern gpus one sfu shared four sp cores contrast cpus typically hav cantly lower throughput similar functions division square root albeit accurate resul e attribute interpolation hardware typic ally fully pipelined enable fullspeed pixel shaders mipmap latin phrase multum parvo much small space mipmap contains precalculated images erent resolutions used increase rendering speed reduce artifacts c6 floatingpoint arithmetic c 45double precisionnewer gpus tesla t10p also support ieee 754 64bit double precision operations hardware standar oatingpoint arithmetic operations double precision include addition multiplication conversions betw erent oatingpoint integer forma oatingpoint standard includes sp cation fusedmultiplyadd fma operation discussed chapt e fma operation perform oatingpoint multiplication followed addition single roundin e fused multiplication addition operations retain full accuracy intermediate calculation behavior enables accurate oatingpoint computations involving accumulation products including dot products matrix multiplication polynomial evaluatio e fma instruction also enab cient ware implementations exactly rounded division square root removing need hardware division square root unit double precision hardware fma unit implements 64bit addition multiplication conversions fma operation itse e architecture multiplier array53 x 53expdiff bcacarry propagate adder64alignmentshifter inversion32 csa 161 bitscomplementernormalizerrounder53sumcarry shiftedc16164645353sumcarryfigure c62 double precision fusedmultiplyadd fma unit hardware implemen oating point b c double precision c46 appendix c graphics computing gpus double precision fma unit enables fullspeed denormalized number support inputs outputs figure c62 shows block diagram fma unit cands b multiplied form 106 carrysave form parallel 53bit addend c e sum carry results 106bit product summed aligned addend 161bit wide carrysave adder e carrysave output summed together carrypropagate adder produce unrounded result nonredundant twos e result conditionally recomplemented return e complemented result normalized within target format c7 real stuff nvidia geforce 8800 e nvidia geforce 8800 gpu introduced novemb ed vertex pixel processor design also supports parallel computing applications written c using cuda parallel programming model th rst implementation ed graphics computing architecture described section c4 lindholm et al 2008 family tesla architecture gpus addresses erent needs laptops desktops workstations servers streaming processor array spa e geforce 8800 gpu shown figure c71 contains 128 streaming processor sp cores organized 16 streaming multiprocessors sms two sms share texture unit textureprocessor cluster tpc array eight tpcs makes streaming processor array spa executes graphics shader programs computing programs e host interface unit communicates host cpu via pciexpress bus checks command consistency performs context switchin e input assembler collects geometric primitives points lines triang e work distribution blocks dispatch vertices pixels compute thread arrays tpcs sp e tpcs execute vertex geometry shader programs computing programs output geometric data sent viewportclipsetup rasterzcull block rasterized pixel fragments redistributed back spa execute pixel shader programs shaded pixels sent across interconnection network processing rop uni e network also routes texture memory read requests spa dram reads data dram level2 cache back spa c7 real stuff nvidia geforce 8800 c 47textureprocessor cluster tpc tpc contains geometry controller smc two sms texture unit shown figure c72 e geometry controller maps logical graphics vertex pipeline recir culation physical sms directing primitive vertex attribute topolog ow tpc e smc controls multiple sms arbitrating shared texture unit loadstore path io pat e smc serves three graphics workloads simultaneously vertex geometry pixel e texture unit processes texture instruction one vertex geometry pixel quad four compute threads per cycle texture instruction sources texture coordinates outputs weighted samples typically fourcomponent rgb oatingpoint color e texture unit deeply pipelined although contains streaming cache captur ltering locality streams hits mixed misses without stalling gpuhost cpusystem memory dramdramdramdramdramdram ropl2ropl2ropl2ropl2ropl2ropl2 tpcspa tpctpctpctpctpctpctpc texture unit tex l1 texture unit tex l1 texture unit tex l1 texture unit tex l1 texture unit tex l1 texture unit tex l1 texture unit tex l1 texture unit tex l1 smsmsmsmsmsmsmsmsmsmsmsmsmsmsmsm spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp spspspsp vertex work distribution input assembler host interface bridge pixel work distribution viewportclip setupraster zcullcompute work distribution interconnection network interface display highdefinitionvideo processorssharedmemory sharedmemory sharedmemory sharedmemory sharedmemory sharedmemory sharedmemory sharedmemory sharedmemory sharedmemory sharedmemory sharedmemory sharedmemory sharedmemory sharedmemory sharedmemory figure c71 nvidia tesla uniﬁ ed graphics computing gpu architecture geforce 8800 128 streaming processor sp cores 16 streaming multiprocessors sms arranged eight textureprocessor cluster e processors connect six 64bit wide dram partitions via interconnection network gpus implementing tesla architecture vary number sp cores sms dram partitions units c48 appendix c graphics computing gpus streaming multiprocessor sm e ed graphics computing multiprocessor executes vertex geometry pixelfragment shader programs parallel computing programs e sm consists eight sp thread processor cores two sfus multithreaded instruction fetch issue unit mt issue instruction cache read constant cache 16 kb readwrite shared memory executes scalar instructions individual threads e geforce 8800 ultra clocks sp cores sfus 15 ghz peak 36 gflops per sm optimize power ciency sm nondatapath units operate half sp clock rate smcgeometry controllertpctexture unittex l1spsharedmemoryspspspspspspspicachemt issueccachesfusfuspsharedmemoryspspspspspspspicachemt issueccachesfusfusharedmemoryicachemt issueccachesfusfusmsmsm spspspspsp spspspfigure c72 textureprocessor cluster tpc streaming multiprocessor sm sm eight streaming processor sp cores two sfus shared memory c7 real stuff nvidia geforce 8800 c 49to e ciently execute hundreds parallel threads running sev erent programs sm hardware multithreaded manages executes 768 concurrent threads hardware zero scheduling overhead thread thread execution state execute independent code path warp consists 32 threads typevertex geometry pixel compute e simt design previously described section c4 shares sm instruction fetch issue uni ciently across 32 threads requires full warp active threads full performa ciency e sm schedules executes multiple warp types concurrently issue cycle scheduler selects one 24 warps execute simt warp instruction issued warp instruction executes four sets 8 threads four processor cyc e sp sfu units execute instructions independently issuing instructions alternate cycles scheduler keep fully occupied scoreboard qu es warp issue cycle e instruction scheduler prioritizes ready warps selects one highest priority issue prioritization considers warp type instruction type fairness warps executing sm e sm executes cooperative thread arrays ctas multiple concurrent warps access shared memory region allocated dynamically cta instruction set reads execute scalar instructions un like previous gpu vector instruction architectures scalar instructions simpler compiler friendly texture instructions remain vector based taking source coordinate vector returning ltered color vector e registerbased instruction set includes th oatingpoint integer arithmetic transcendental logical ow control memory loadstore texture instructions listed ptx instruction table figure c43 memory loadstore instructions use integer byte addressing registerpluso set address arithmetic computing loadstore instructions access three readwrite memory spaces local memory perthread private temporary data shared memory low latency percta data shared threads cta global memory data shared threads computing programs use fast barrier synchronization barsync instruction synchronize threads within cta communicate via shared global memory e latest tesla architecture gpus implement ptx atomic memory operations facilitate parallel reductions parallel data structure management streaming processor sp e multithreaded sp core primary thread processor introduced section c4 regist le provides 1024 scalar 32bit registers 96 threads threads example sp section c4 oatingpoint add c50 appendix c graphics computing gpus multiply operations compatible ieee 754 standard single precision fp numbers including notanumber nan nity e add multiply operations use ieee roundtonearesteven default rounding mode e sp core also implements 32bit 64bit integer arithmetic comparison conversion logical ptx instructions figur e processor fully pipelined latency optimized balance delay area special function unit sfu e sfu supports computation transcendental functions planar attribute interpolation described section c6 uses quadratic interpolation based enhanced minimax approximations approximate reciprocal reciprocal square root log 2x 2x sincos functions one result per cycle e sfu also supports pixel attribute interpolation color depth texture coordinates four samples per cycle rasterizationgeometry primitives sms go original roundrobin input order viewportclipsetuprasterzcull bloc e viewport clip units clip primitives view frustum enabled user clip planes transform vertices screen pixel space surviving primitives go setup unit generates edge equations rasterizer coarserasterization stage generates pixel tiles least partially inside primitive e zcull unit maintains hierarchical z surface rejecting pixel tiles conservatively known occluded previously drawn pixe e rejection rate 256 pixels per clock pixels survive zcull go nerasterization stage generates detailed coverage information depth values e depth test update performed ahead fragment shader er depending current state e smc assembles surviving pixels warps processed sm running current pixel shader e smc sends surviving pixel associated data rop raster operations processor rop memory system rop paired sp c memory partition pixel fragment emitted pixel shader program rops perform depth stencil testing updates parallel color blending updates lossless color compression 81 depth compression 81 used reduce dram bandwidth rop peak rate four pixels per clock supports 16bi oating point 32bi oatingpoint hdr formats rops support doubleratedepth processing color writes disabled c7 real stuff nvidia geforce 8800 c 51antialiasing support includes 16 multisampling supersamplin e coveragesampling antialiasing csaa algorithm computes stores boolean coverage 16 samples compresses redundant color depth stencil information memory footprint bandwidth four eight samples improved performance e dram memory data bus width 384 pins arranged six independent partitions 64 pins partition supports doubledatarate ddr2 graphicsoriented gddr3 protocols 10 ghz yielding bandwidth 16 gbs per partition 96 gbs e memory controllers support wide range dram clock rates protocols device densities data bus widths texture loadstore requests occur tpc memory partition interconnection network routes requests responses scalability e ed architecture designed scalability varying number sms tpcs rops caches memory partitions provides right balance erent performance cost targets gpu market segments scalable link interconnect sli connects multiple gpus providing scalability performance e geforce 8800 ultra clocks sp thread processor cores sfus 15 ghz theoretical operation peak 576 gflo e geforce 8800 gtx 135 ghz processor clock corresponding peak 518 gflops e following three sections compare performance geforce 8800 gpu multicore cpu thre erent applicationsdense linear algebra fast fourier transforms sortin e gpu programs libraries compiled cuda c code e cpu code uses single precision multithreaded intel mkl 100 library leverage sse instructions multiple cores dense linear algebra performance dense linear algebra computations fundamental many applications volkov demmel 2008 present gpu cpu performance results single precision dense matrixmatrix multiplication sgemm routine lu qr cholesky matrix factorizations figure c73 compares gflops rates sgemm dense matrixmatrix multiplication geforce 8800 gtx gpu quad core cpu figure c74 compares gflops rates matrix factorization gpu quadcore cpu sgemm matrixmatrix multiply similar blas3 routines bulk work matrix factorization performance sets upper bound factorization rate matrix order increases beyond 200 400 factorization c52 appendix c graphics computing gpus figure c74 dense matrix factorization performance rates e graph shows gflops rates achieved matrix factorizations using gpu using cpu alone adapted figure 7 volkov e black lines 135 ghz nvidia geforce 8800 gtx cuda 11 windows xp attached 267 ghz intel core2 duo e6700 windows xp including cpugpu data transfer times e blue lines quadcore 24 ghz intel core2 quad q6600 64bit linux intel mkl 100 figure c73 sgemm dense matrixmatrix multiplication performance rates e graph shows single precision gflops rates achieved multiplying square n n matrices solid lines thin n64 64 n matrices dashed lines adapted figure 6 volkov e black lines 135 ghz geforce 8800 gtx using volkovs sgemm code nvidia cublas 20 matrices gpu memory e blue lines quadcore 24 ghz intel core2 quad q6600 64bit linux intel mkl 100 matrices cpu memory 2101801501209060300gflopsn641282565121024204840968192 ann bnnan64 b64ngeforce 8800 gtxcore2 quadlucholeskyqrcore2 quad210180150 1209060300order matrix gflopsgeforce 8800 gtx core2 duo 64128256512102420484096819216384 c7 real stuff nvidia geforce 8800 c 53problem becomes large enough sgemm leverage gpu parallelism overcome cpugpu system copy overhead volkovs sgemm matrix matrix multiply achieves 206 gflops 60 geforce 8800 gtx peak multiplyadd rate qr factorization reached 192 gflops 43 times quadcore cpu fft performance fast fourier transforms used many applications large transforms multidimensional transforms partitioned batches smaller 1d transforms figure c75 compares inplace 1d complex single precision fft performance 135 ghz geforce 8800 gtx dating late 2006 28 ghz quadcore intel xeon e5462 series code named harpertown dating late 2007 cpu performance measured using intel math kernel library mkl 100 fft four threads gpu performance measured using nvidia cufft 21 library batched 1d radix16 decimationinfrequency ffts cpu gpu throughput performance measured using batched ffts batch size 2 24n n transform size us workload every transform size 128 mb determine gflops rate number operations per transform taken 5 n log2 nfigure c75 fast fourier transform throughput performance e graph compares performance batched onedimensional inplace complex ffts 135 ghz geforce 8800 gtx quadcore 28 ghz intel xeon e5462 series code named harpertown 6mb l2 cache 4gb memory 1600 fsb red hat linux intel mkl 100 80geforce 8800gtx xeon 546270gflops605040302010number elements one transform 01282565121024204840968192163843276865536131072262144524288104857620971524194304 c54 appendix c graphics computing gpus sorting performance contrast applications discussed sort requires far substantial coordination among parallel threads parallel scaling correspondingly harder obtain nevertheless variety wellknown sorting algorithms e ciently parallelized run well gpu satish et al 2008 detail design sorting algorithms cuda results report radix sort summarized figure c76 compares parallel sorting performance geforce 8800 ultra 8core intel clovertown system date earl e cpu cores distributed two physical sockets socket contains multichip module twin core2 chips chip 4mb l2 cache sorting routines designed sort keyvalue pairs keys values 32bit integer e primary algorithm studied radix sort although quicksortbased parallel_sort procedure provided intel reading building blocks also included comparison two cpubased radix sort codes one implemented using scalar instruction set utilizes carefully handtuned assembly langua ge routines take advantage sse2 simd vector instructions e graph shows achieved sorting rat ned number elements sorted divided time sortfor range sequence sizes figure c76 parallel sorting performance graph compares sorting rates parallel radix sort implementations 15 ghz geforce 8800 ultra 8core 233 ghz intel core2 xeon e5345 system 010203040506070 80100010000100000100000010000000100000000 millionssequence sizesorting rate pairsseccpu quick sortcpu radix sort scalargpu radix sortcpu radix sort simd c8 real stuff mapping applications gpus c 55apparent graph gpu radix sort achieved highest sorting rate sequences 8kelements larger range average 26 times faster quicksortbased routine roughly 2 times faster radix sort routines using eight available cpu cor e cpu radix sort performance varies widely likely due poor cache locality global permutations c8 real stuff mapping applications gpus e advent multicore cpus manycore gpus means mainstream processor chips parallel systems furthermore parallelism continues scale moores law e challenge develop mainstream visual computing highperformance computing applications transparently scale parallelism leverage increasing number processor cores much 3d graphics applications transparently scale parallelism gpus widely varying numbers cores section presents examples mapping scalable parallel computing applications gpu using cuda sparse matrices wide variety parallel algorithms written cuda fairly straightforward manner even data structures involved simple regular grids sparse matrixvector multiplication spmv good example important numerical building block parallelized quite directly using abstractions provided cud e kernels discuss combined provided cublas vector routines make writing iterative solvers conjugate gradient method straightforward sparse n n matrix one number nonzero entries small fraction total sparse matrix representations seek store nonzero elements matrix since fairly typical sparse n n matrix contain nonzero elements represents substantial saving storage space processing time one common representations general unstructured sparse matrices compressed sparse row csr representatio e nonzero elements matrix stored rowmajor order array av second array aj records corresponding column index entry av finally array ap n 1 elements records extent row previous arrays entries row aj av extend index api including index api 1 implies ap0 always 0 apn always number nonzero elements matrix figure c81 shows example csr representation simple matrix c56 appendix c graphics computing gpus given matrix csr form vector x compute single row product ax using multiply_row procedure shown figure c82 computing full product simply matter looping rows computing result row using multiply_row serial c code shown figure c83 algorithm translated parallel cuda kernel quite easily simply spread loop csrmul_serial many parallel threads thread compute exactly one row output vector e code kernel shown figure c84 note looks extremely similar serial loop used csrmul_serial procedure ere really two points erence first row index thread computed block thread indices assigned thread eliminating forloop second conditional evaluates row product row index within bounds matrix necessary since number rows n need multiple block size used launching kernel float multiply_rowunsigned int rowsize unsigned int aj column indices row float av nonzero entries row float x rhs vector float sum 0 forunsigned int column0 columnrowsize column sum avcolumn xajcolumn return sumfigure c82 serial c code single row sparse matrixvector multiply 3001aa sample matrix a00 2004110010row 0 b csr representation matrix row 2row 3 av7aj7ap50 30212303 124111 2257 figure c81 compressed sparse row csr matrix c8 real stuff mapping applications gpus c 57figure c83 serial code sparse matrixvector multiply void csrmul_serialunsigned int ap unsigned int aj float av unsigned int num_rows float x float forunsigned int row0 rownum_rows row unsigned int row_begin aprow unsigned int row_end aprow1 yrow multiply_rowrow_endrow_begin ajrow_begin avrow_begin x figure c84 cuda version sparse matrixvector multiply __global__void csrmul_kernelunsigned int ap unsigned int aj float av unsigned int num_rows float x float unsigned int row blockidxxblockdimx threadidxx rownum_rows unsigned int row_begin aprow unsigned int row_end aprow1 yrow multiply_rowrow_endrow_begin ajrow_begin avrow_begin x assuming matrix data structures already copied gpu device memory launching kernel look like unsigned int blocksize 128 size 512 unsigned int nblocks num_rows blocksize 1 blocksizecsrmul_kernelnblocksblocksizeap aj av num_rows x c58 appendix c graphics computing gpus e pattern see common one e original serial algorithm loop whose iterations independent loops parallelized quite easily simply assigning one iterations loop parallel thread e programming model provided cuda makes expressing type parallelism particularly straightforward general strategy decomposing computations blocks independent work sp cally breaking independent loop iterations unique cud common approach used one form another various parallel programming systems including openmp intel reading building blocks caching shared memory e spmv algorithms outlined fairly simp ere number optimizations made cpu gpu codes improve performance including loop unrolling matrix reordering register blocking e parallel kernels also reimplemented terms data parallel scan operations presented sengupta et al 2007 one important architectural features exposed cuda presence perblock shared memory small onchip memory low latency taking advantage memory deliver substantial performance improvements one common way use shared memory waremanaged cache hold frequently reused data modifcations using shared memory shown figure c85 context sparse matrix multiplication observe several rows may use particular array element xi many common cases particularly matrix reordered rows using xi rows near row therefore implement simple caching scheme expect achieve performance bene e block threads processing rows j load xi xj shared memory unroll multiply_row loop fetch elements x cache whenever possible e resulting code shown figure c85 shared memory also used make optimizations fetching aprow1 adjacent thread rather refetching memory tesla architecture provides explicitly managed onchip shared memory rather implicitly active hardware cache fairly common add sort optimization although impose additional development burden programmer relatively minor potential performance bene ts substantial example shown even fairly simple use shared memory returns roughly 20 performance improvement representative matrices derived 3d sur e availability explicitly managed memory lieu implicit cache also advantage caching prefetching policies sp cally tailored application needs c8 real stuff mapping applications gpus c 59__global__ void csrmul_cachedunsigned int ap unsigned int aj float av unsigned int num_rows const float x float cache rows x corresponding block __shared__ float cacheblocksize unsigned int block_begin blockidxx blockdimx unsigned int block_end block_begin blockdimx unsigned int row block_begin threadidxx fetch cache window x rownum_rows cachethreadidxx xrow __syncthreads rownum_rows unsigned int row_begin aprow unsigned int row_end aprow1 float sum 0 x_j forunsigned int colrow_begin colrow_end col unsigned int j ajcol fetch x_j cache possible jblock_begin jblock_end x_j cachejblock_begin else x_j xj sum avcol x_j yrow sum figure c85 shared memory version sparse matrixvector multiply c60 appendix c graphics computing gpus ese fairly simple kernels whose purpose illustrate basic techniques writing cuda programs rather achieve maximal performance numerous possible avenues optimization available several explored williams et al 2007 handful erent multicore architectures nevertheless still instructive examine comparative performance even simplistic kernels 2 ghz intel core2 xeon e5335 processor csrmul_serial kernel runs roughly 202 million nonzeros processed per second collection laplacian matrices derived 3d triangulated surface meshes parallelizing kernel parallel_for construct provided intels reading building blocks produces parallel speedups 20 21 23 running two four eight cores machine respectively geforce 8800 ultra csrmul_kernel csrmul_cached kernels achieve processing rates roughly 772 920 million nonzeros per second corresponding parallel speedups 38 46 times serial performance single cpu core scan reductionparallel scan also known parallel pre x sum one important building blocks dataparallel algorithms blelloch 1990 given sequence n elements aaa n011 binary associative operator scan function computes sequence scan aaaaaaa n 001011 example take usual addition operator applying scan input array a31704163 produce sequence partial sums scan 34111115162225 scan operator inclusive scan sense element output sequence incorporates element ai input incorporating previous elements would yield exclusive scan operator also known pre xsum operation e serial implementation operation extremely simple simply loop iterates entire sequence shown figure c86 rst glance might appear operation inherently serial however actually implemented pa ciently e key observation c8 real stuff mapping applications gpus c 61figure c86 template serial plusscan figure c87 cuda template parallel plusscan templateclass t__host__ plus_scant x unsigned int n forunsigned int i1 xi xi1 xi templateclass t__device__ plus_scant x unsigned int threadidxx unsigned int n blockdimx forunsigned int offset1 offsetn offset 2 ifioffset xioffset __syncthreads ifioffset xi xi __syncthreads return xibecause addition associative free change order elements added together instance imagine adding pairs consecutive elements parallel adding partial sums one simple scheme hillis steele 1989 implementation algorithm cuda shown figure c87 assumes input array x contains exactly one element per thread thread block performs log 2 n iterations loop collecting partial sums together understand action loop consider figure c88 illustrates simple case n 8 threads elements level diagram represents one step loop e lines indicate location data fetched element output ie th nal row diagram building summation tree input elemen e edges highlighted blue show form summation tree th nal elemen e leaves tree initial elements tracing back output element shows incorporates input values including c62 appendix c graphics computing gpus simple algorithm cient would like examining serial implementation see performs addition e parallel implementation contrast performs log n additions reason wo cient since work serial implementation compute result fortunately techniques implementing scan work e cient details mor cient implementation techniques extension perblock procedure multiblock arrays provided sengupta et al 2007 instances may interested computing sum elements array rather sequence pr x sums returned scan parallel reduction problem could simply use scan algorithm perform computation reduction generally implemented ciently scan figure c89 shows code computing reduction using addition example thread simply loads one element input sequence ie initially sums subsequence length 1 end reduction want thread 0 hold sum elements initially loaded threads bloc e loop kernel implicitly builds summation tree input elements much like scan algorithm end loop thread 0 holds sum values loaded block want th nal value location pointed total contain total elements array must combine partial sums blocks grid one strategy would block write partial sum second array launch reduction kernel repeating process reduced sequence single value attractive alternative supported tesla gpu architecture use atomicadd primitive cient atomic figure c88 treebased parallel scan data references x0x0x0x0x1x1x1x1x2x2x2 x2x3x3x3x3x4x4x4x4x5x5x5x6x6x6x5x6x7 x7xi xiœ1 xi xiœ2 xi xiœ4 x7x7 c8 real stuff mapping applications gpus c 63readmodifywrite primitive supported memory subsyst eliminates need additional temporary arrays repeated kernel launches parallel reduction essential primitive parallel programming highlights importance perblock shared memory lowcost barriers making cooperation among thre cien degree data sh ing among threads would prohibitively expensive done chip global memory radix sort one important application scan primitives implementation sorting rout e code figure c810 implements radix sort integers across single thread block accepts input array values containing one 32bit integer thread block fo ciency array stored perblock shared memory required sort behave correctly fairly simple implementation radix sort assumes availability procedure partition_by_bit partition given array __global__void plus_reduceint input unsigned int n int total unsigned int tid threadidxx unsigned int blockidxxblockdimx threadidxx block loads elements shared memory padding 0 n multiple blocksize __shared__ int xblocksize xtid inputi 0 __syncthreads every thread holds 1 input value x build summation tree elements forint sblockdimx2 s0 ss2 iftid xtid xtid __syncthreads thread 0 holds sum input values block add sum running total tid 0 atomicaddtotal xtidfigure c89 cuda implementation plusreduction c64 appendix c graphics computing gpus values 0 designated bit come values 1 bit produce correct output partitioning must stable implementing partitioning procedure simple application sca read holds value xi must calculate correct output index write value needs calculate 1 number threads j designated bit 1 2 total number bits designated bit e cuda code partition_by_bit shown figure c811 __device__ void radix_sortunsigned int values forint bit0 bit32 bit partition_by_bitvalues bit __syncthreads figure c810 cuda code radix sort __device__ void partition_by_bitunsigned int values unsigned int bit unsigned int threadidxx unsigned int size blockdimx unsigned int x_i valuesi unsigned int p_i x_i bit 1 valuesi p_i __syncthreads compute number bits including p_i record total number f bits well unsigned int t_before plus_scanvalues unsigned int t_total valuessize1 unsigned int f_total size t_total __syncthreads write every x_i proper place p_i valuest_before1 f_total x_i else valuesi t_before x_ifigure c811 cuda code partition data bitbybit basis part radix sort c8 real stuff mapping applications gpus c 65a similar strategy applied implementing radix sort kernel sorts array large length rather oneblock array e fundamental step remains scan procedure although computation partitioned across multiple kernels must doubleb er array values rather partitioning place details performing radix sorts large arra ciently provided satish et al 2008 nbody applications gpu1nyland et al 2007 describe simple yet useful computational kernel excellent gpu performancethe allpairs nbody algorithm timeconsuming component many scien c applications nbody simulations calculate evolution system bodies body continuously interacts every body one example astrophysical simulation body represents individual star bodies gravitationally attract examples protein folding nbody simulation used calculate electrostatic van der waals forces turbulen ow simulation global illumination computer graphics e allpairs nbody algorithm calculates total force body system computing pairwise force system summing body many scientists consider method accurate loss precision coming th oatingpoint hardware operation e drawback on2 computational complexity far large systems 10 bodies overcome high cost several simp cations proposed yield n log n n algorithms examples barneshut algorithm fast multipole method particlemeshewald summation fast methods still rely allpairs method kernel accurate computation shortrange forces thus continues important nbody mathematicsfor gravitational simulation calculate bodybody force using elementary physics two bodies indexed j 3d force vector frrijijijijijgmm 2r e force magnitude calculated th term direction computed right unit vector pointing one body given list interacting bodies entire system subset calculation simple pairs interactions compute force sum body total forces calculated used update bodys position velocity based previous position velocity e calculation forces complexity n2 update n1 adapted nyland et al 2007 fast nbody simulation cuda chapter 31 gpu gems 3 c66 appendix c graphics computing gpus e serial forcecalculation code uses two nested forloops iterating pairs bo e outer loop selects body total force calculated inner loop iterates bo e inner loop calls function computes pairwise force adds force running sum compute forces parallel assign one thread body since calculation force body independent calculation bodies forces computed positions velocities bodies updated e code serial parallel versions shown figure c812 figure e serial version two nested forloo e conversion cuda like many examples converts serial outer loop perthread kernel thread computes total force single body e cuda kernel computes global thread id thread replacing iterator variable serial outer loop ker nish storing total acceleration global array used compute new position velocity values subsequent step __global__ void accel_on_one_body int threadidxx blockdimx blockidxx int j float3 acc00f 00f 00f j 0 j n j acc body_body_interactionacc bodyi bodyj acceli acc figure c813 cuda thread code compute total force single body figure c812 serial code compute pairwise forces n bodiesvoid accel_on_all_bodies int j float3 acc00f 00f 00f 0 n j 0 j n j acc body_body_interactionacc bodyi bodyj acceli acc c8 real stuff mapping applications gpus c 67 e outer loop replaced cuda kernel grid launches n threads one body optimization gpu execution e cuda code shown functionally correct cient ignores key architectural features better performance achieved three main optimizations first shared memory used avoid identical memory reads threads second using multiple threads per body improves performance small values n ird loop unrolling reduces loop overhead using shared memory shared memory hold subset body positions much like cache eliminating redundant global memory requests threads optimize code shown p threads threadblock load one position shared memory total p positions threads loaded value shared memory ensured __syncthreads thread perform p interactions using data shared memor repeated np times complete force calculation body reduces number requests memory factor p typically range 32128 e function called accel_on_one_body requires changes support optimizatio e mo ed code shown figure c814 __shared__ float4 shposition256__global__ void accel_on_one_body int threadidxx blockdimx blockidxx int j k int p blockdimx float3 acc00f 00f 00f float4 mybody bodyi j 0 j n j p outer loops jumps p time shpositionthreadidxx bodyjthreadidxx __syncthreads k 0 k p k inner loop accesses p positions acc body_body_interactionacc mybody shpositionk __syncthreads acceli acc figure c814 cuda code compute total force body using shared memory improve performance c68 appendix c graphics computing gpus e loop formerly iterated bodies jumps block dimension p iteration outer loop loads p successive positions shared memory one position per thre e threads synchronize p force calculations computed thread second synchronization required ensure new values loaded shared memo ry prior threads completing force calculations current data using shared memory reduces memory bandwidth required less 10 total bandwidth gpu sustain using less 5 gbs optimization keeps application busy performing computation rather waiting memory accesses would done without use shared memory e performance varying values n shown figure c815 using multiple threads per bodyfigure c815 shows performance degradation problems small values n n 4096 geforce 8800 gtx many researc orts rely nbody calculations focus small n long simulation times making target optimizatio orts presumption explain lower performance simply enough work keep gpu busy n small e solution allocate threads per body change threadblock dimensions p 1 1 p q 1 q threads divide work single body equal parts allocating additional threads within thread block partial results stored shared memory force calculations figure c815 performance measurements nbody application geforce 8800 gtx geforce 9600 e 8800 128 stream processors 135 ghz 9600 64 080 ghz 30 th e peak performance 242 gflops gpu processors problem needs bigger achieve full performance 9600 peak around 2048 bodies 8800 doesnt reach peak 16384 bodies small n one thread per body ca cantly improve performance eventually incurs performance penalty n grows 250nbody performance gpus 20015010050gflopsnumber bodies0512768102415362048307240966144819212288 1638424576327681 thread 88002 threads 8800 4 threads 8800 1 thread 96002 threads 9600 4 threads 9600 c8 real stuff mapping applications gpus c 69done q partial results collected summed compute th nal result using two four threads per body leads large improvements small nas example performance 8800 gtx jumps 110 n 1024 one thread achieves 90 gflops four achieve 190 gflops performance degrades slightly large n use optimization n smaller e performance increases shown figure c815 gpu 128 processors smaller gpu 64 processors clocked two thirds speed performance comparison e performance nbody code shown figure c815 figure c816 figure c815 performance high mediumperformance gpus shown along performance improvements achieved using multiple threads per body e performance faster gpu ranges 90 250 gflops figure c816 shows nearly identical code c versus cuda running intel core2 cpu e cpu performance 1 gpu range 02 2 gflops remaining nearly constant wide range problem sizes figure c816 performance measurements nbody code cpu e graph shows single precision nbody performance using intel core2 cpus denoted cpu model number note dramatic reduction gflops performance shown gflops yaxis demonstrating much faster gpu compared cpu e performance cpu generally independent problem size except anomalously low performance n 16384 x9775 cpu e graph also shows results running cuda version code using cudaforcpu compiler single cpu core outperforms c code 24 programming language cuda exposes parallelism locality compiler exploi e intel cpus 32 ghz extreme x9775 code named penryn 266 ghz e8200 code named wolfdale desktop prepenryn cpu 183 ghz t2400 code named yonah 2007 laptop cpu e penryn version core 2 architecture particularly interesting nbody calculations 4bit divider allowing division square root operations execute four times faster previous intel cpus number bodiesnbody performance intel cpus 218161412108 0604020512gflops768102415362048307240966144 8192122881638424576 32768t2400e8200x9775x9775cuda c70 appendix c graphics computing gpus e graph also shows results compiling cuda version code cpu performance improves 24 cuda programming language exposes parallelism allowing compiler make better use sse vector unit single core e cuda version nbody code naturally maps multicore cpus well grids blocks achieves nearly perfect scaling eightcore system n 4096 ratios 20 397 794 two four eight cores respectively resultswith mo ort developed computational kernel improves gpu performance multicore cpus factor 157 execution time nbody code running recent cpu intel penryn x9775 32 ghz single core took 3 seconds per frame run code runs 44 hz frame rate geforce 8800 gpu prepenryn cpus code requires 616 seconds older core2 processors pentium iv processor time 25 seconds must divide apparent increase performance half cpu requires half many calculations compute result using optimization forces pair bodies equal strength opposite direction gpu speed code large amoun e answer requires inspecting architectural detai e pairwise force calculation requires oatingpoint operations comprised mostly addition multiplication instructions combined using multiplyadd instruction also division square root instructions vector normalization intel cpus take many cycles single precision division square root instructions 2 although improved latest penryn cpu family faster 4bit divider 3 additionally limitations register capacity lead many mov instructions x86 code presumably tofrom l1 cache contrast geforce 8800 executes reciprocal squareroot thread instruction four clocks see section c6 special function accuracy larger regist le per thread shared memory accessed instruction operand finally cuda compiler emits 15 instructions one iteration loop compared 40 instructions variety x86 cpu compilers greater parallelism faster execution complex instructions register space cient compiler combine explain dramatic performance improvement nbody code cpu gpu 2 e x86 sse instructions reciprocalsquareroot rsqrt reciprocal rcp considered accuracy low comparable 3 intel corporation intel 64 ia32 architectures optimization reference manual november 2007 order number 248966016 also available www3intelcomdesign processormanuals248966pdf c8 real stuff mapping applications gpus c 71on geforce 8800 allpairs nbody algorithm delivers 240 gflops performance compared less 2 gflops recent sequential processors compiling executing cuda version code cpu demonstrates problem scales well multicore cpus cantly slower single gpu coupled gpu nbody simulation graphical display motion interactively display 16k bodies interacting 44 frames per second allows astrophysical biophysical events displayed navigated interactive rates additionally parameterize many settings noise reduction damping integration techniques immediately displaying ects dynamics syst provides scientists stunning visual imagery boosting insights otherwise invisible systems large small fast slow allowing create better models physical phenomena figure c817 shows timeseries display astrophysical simulation 16k bodies body acting galaxy e initial co guration figure c817 12 images captured evolution nbody system 16384 bodies c72 appendix c graphics computing gpus spherical shell bodies rotating zaxis one phenomenon interest astrophysicists clustering occurs along merging galaxies time interested reader cuda code application available cuda sdk wwwnvidiacomcuda c9 fallacies pitfalls gpus evolved changed rapidly many fallacies pitfalls arisen cover fallacy gpus simd vector multiprocessors easy draw false conclusion gpus simply simd vector multiprocessors gpus spmdstyle programming model programmer write single program executed multiple thread instances multiple dat e execution threads purely simd vector however single instruction multiplethread simt described section c4 gpu thread scalar registers thread private memory thread execution state thread id independent execution branch path ective program counter address memory independently although group threads eg warp 32 threads executes mor ciently pcs threads necessary multiprocessors purely simd e thread execution model mimd barrier synchronization simt optimizations execution cient individual thread loadstore memory accesses coalesced block accesses well however strictly necessary purely simd vector architecture memoryregister accesses fo erent threads must aligned regular vector pattern gpu restriction register memory accesses however execution cient warps threads access local blocks data departure pure simd model simt gpu execute one warp threads concurrently graphics applications may multiple groups vertex programs pixel programs geometry programs running multiprocessor array concurrently computing programs may also execut erent programs concurrentl erent warps fallacy gpu performance grow faster moores law moores law simply rate speed light limit rate moores law describes expectation time semiconductor technology advances transistors become smaller manufacturing cost per transistor decline c9 fallacies pitfalls c 73exponentially put another way given constant manufacturing cost number transistors increase exponentially gordon moore 1965 predicted progression would provide roughly two times number transistors manufacturing cost every year later revised doubling every two years although moore made initial prediction 1965 50 components per integrated circuit proved remarkably consisten e reduction transistor size historically b ts lower power per transistor faster clock speeds constant power increasing bounty transistors used chip architects build processors memory components time cpu designers used extra transistors increase processor performance rate similar moores law much many people think processor performance growth two times every 1824 months moores law fact microprocessor designers spend new transistors processor cores improving architecture design pipelining clock speed e rest new transistors used providing cache make memory access faster contrast gpu designers use almost none new transistors provide cache transistors used improving processor cores adding processor cores gpus get faster four mechanisms first gpu designers reap moores law bounty directly applying exponentially transistors building parallel thus faster processors second gpu designers improve architecture time increasing th ciency processin ird moores law assumes constant cost moores law rate clearly exceeded spending larger chips transistors fourth gpu memory systems increased ective bandwidth pace nearly comparable processing rate using faster memories wider memories data compression better cach e combination four approaches historically allowed gpu performance double regularly roughly every 12 18 month rate exceeding rate moores law demonstrated graphics applications approximately ten years shows sign cant slowdo e challenging rate limiter appears memory system competitive innovation advancing rapidly fallacy gpus render 3d graphics cant general computation gpus built render 3d graphics well 2d graphics video meet demands graphics ware developers expressed interfaces performance feature requirements graphics apis gpus become massively parallel programmab oatingpoint processors graphics domain processors programmed graphics apis arcane graphics programming languages glsl cg hlsl opengl direct3d however c74 appendix c graphics computing gpus nothing preventing gpu architects exposing parallel processor cores programmers without graphics api arcane graphics languages fact tesla architecture family gpus exposes processors ware environment known cuda allows programmers develop general application programs using c language soon c gpus turingcomplete processors run program cpu run although perhaps less well perhaps faster fallacy gpus run double precisio oatingpoint programs fast past gpus could run double precisio oatingpoint programs except ware emulation thats fast gpus made progression indexed arithmetic representation lookup tables colors 8bit integers per color component xedpoint arithmetic single precision oatingpoint recently added double precision modern gpus perform virtually calculations single precisio oatingpoint arithmetic beginning use double precision addition small additional cost gpu support double precisio oatingpoint well single precisio oatingpoint today double precision runs slowly single precision speed abou ten times slower incremental additional cost double precision performance increased relative single precision stages applications demand fallacy gpus dont oatingpoint correctly gpus least tesla architecture family processors perform single precisio oatingpoint processing level prescribed th oatingpoint standard terms accuracy gpus equal ieee 754compliant processors today gpus implement sp c features described standard handling denormalized numbers providing precis oating point exceptions however recently introduced tesla t10p gpu provides full ieee rounding fusedmultiplyadd denormalized number support double precision pitfall use threads cover longer memory latencies cpu cores typically designed run single thread full speed run full speed every instruction data need available time instruction run next instruction ready data required instruction available instruction run processor stalls external memory distant processor takes many cycles wasted execution fetch data memory consequently cpus require large local caches keep running c9 fallacies pitfalls c 75without stalling memory latency long avoided striving run cache point program working set demands may larger cache cpus used multithreading tolerate latency number threads per core generally limited small number e gpu strateg erent gpu cores designed run many threads concurrently one instruction thread time another way say gpu runs thread slowly aggregate runs threads ciently thread tolerate amount memory latency threads run e downside multiplemany multiple threadsare required cover memory latency addition memory accesses scattered correlated among threads memory system get progressively slower responding individual request eventually even multiple threads able cover latency pitfall use threads strategy work covering latency enough threads threads wellbehaved terms locality memory access fallacy n algorithms ar cult speed matter fast gpu processing data steps transferring data device may limit performance algorithms n complexity small amount work per dat e highest transfer rate pcie bus approximately 48 gb second dma transfers used slightly less nondma transfer e cpu contrast typical access speeds 812 gbsecond system memory example problems vector addition limited transfer inputs gpu returning output computation ere three ways overcome cost transferring data first try leave data gpu long possible instead moving data back forth fo erent steps complicated algorithm cuda deliberately leaves data alone gpu launches support second gpu supports concurrent operations copyin copyout computation data streamed device computing model useful data stream processed arrives examples video processing network routing data compressiondecompression even simpler computations large vector mathematics e third suggestion use cpu gpu together improving performance assigning subset work treating system heterogeneous computing platfor e cuda programming model supports allocation work one gpus along continued use cpu without use threads via asynchronous gpu functions relatively simple keep gpus cpu working concurrently solve problems even faster c76 appendix c graphics computing gpus c10 concluding remarks gpus massively parallel processors become widely used 3d graphics also many application wide application made possible evolution graphics devices programmable processors e graphics application programming model gpus usually api directx opengl generalpurpose computing cuda programming model uses spmd singleprogram multiple data style executing program many parallel threads gpu parallelism continue scale moores law mainly increasing number processors parallel programming models readily scale hundreds processor cores thousands threads successful supporting manycore gpus cpus also applications many largely independent parallel tasks w ill accelerated massively parallel manycore architectures parallel programming models gpus becoming mor exible graphics parallel computing example cuda evolving rapidly direction full cc functionality graphics apis programming models likely adapt parallel computing capabilities models cuda spmdstyle threading model scalable convenient succinct easily learned model expressing large amounts parallelism driven changes programming models gpu architecture turn becoming exible programmable xedfunction units becoming accessible general programs along lines cuda programs already use texture intrinsic functions perform texture lookups using gpu texture instruction texture unit gpu architecture continue adapt usage patterns graphics application programmers gpus continue expand include processing power additional processor cores well increasing thread memory bandwidth available programs addition programming models must evolve include programming heterogeneous manycore systems including gpus cpus acknowledgments appendix work several authors nvidia gratefully acknowledge th cant contributions michael garland john montrym doug voorhies lars nyland erik lindholm paulius mici kevicius massimiliano fatica stuart oberman vasily volkov c11 historical perspective reading c 77 c11 historical perspective readinggraphics pipeline evolution3d graphics pipeline hardware evolved large expensive systems early 1980s small workstations pc accelerators mid late 1990s period three major transitions occurred performanceleading graphics subsystems declined price 50000 200 performance increased 50 million pixels per second 1 billion pixels per second 100000 vertices per second 10 million vertices per second native hardware capabilities evolved wireframe polygon outlines shaded constant colo lled polygons smooth shaded interpolated colo lled polygons fullscene antialiasing texture mapping rudimentary multitexturing fixedfunction graphics pipelines roughout period graphics hardware co gurable programmable application developer generation incremental improvements ered developers growing sophisticated asking new features could reasonably ered buil xed function e nvidia geforce 3 described lindholm et al 2001 took th rst step toward true general shader programmability exposed application developer private internal instruction set th oatingpoint vertex engine coincided release microso directx 8 opengls vertex shader extensions later gpus time directx 9 extended general programmability oating point capability pixel fragment stage made texture available vertex stage e ati radeon 9700 introduced 2002 featured programmable 24bi oatingpoint pixel fragment processor programmed directx 9 op e geforce fx added 32bi oatingpoint pixel processor part general trend toward unifying functionality th erent stages least far application programmer concerned nvidias geforce 6800 7800 series built separate processor designs separate hardware dedicated vertex fragment processin e xbox 360 introduced earl ed processor gpu 2005 allowing vertex pixel shaders execute processor c78 appendix c graphics computing gpus evolution programmable realtime graphics last 30 years graphics architecture evolved simple pipeline drawing wireframe diagrams highly parallel design consisting several deep parallel pipelines capable rendering complex interactive imagery appears threedimensional concurrently many calculations involved became far sophisticated user programmable graphics pipelines certain stages great deal oatingpoint arithmetic completely independent data transforming position triangle vertexes generating pixel color data independence key erence gpus cpus single frame rendered 160th second might 1 million triangles 6 million pixe e opportunity use hardware parallelism exploit th data independence tremendous e sp c functions executed graphics pipeline stages vary rendering algorithms evolved programmable vertex programs map position triangle vertices screen altering position color orientation typically vertex shader thread inpu oatingpoint x z w vertex position comput oatingpoint x z screen position geometry programs operate primitiv ned multiple vertices changing generating additional primitives pixel fragment shaders shade one pixel computin oatingpoint red green blue alpha rgba color contribution rendered image pixel sample x image position three types graphics shaders program instances run parallel works independent data produces independent results ects programmable graphics pipeline stages dozens xedfunction stages perform ned tasks far ciently programmable processor could would b far less programmability example geometry processing stage pixel processing stage rasterizer complex state machine determines exactly pixels portions thereof lie within geometric primitives boundaries together mix programmable xedfunction stages engineered balance extreme performance user control rendering algorithms common rendering algorithms perform single pass input primitives access memory resources highly coherent manner algorithms provide excellent bandwidth utilization largely insensitive memory latency combined pixel shader workload usually computelimited characteristics guided gpus alon erent evolutionary path cpus whereas cpu die area dominated cache memory gpus dominated oatingpoint datapath xedfunction logic gpu memory interfaces emphasize bandwidth latency since latency readily hidden high thread count indeed bandwidth typically many times higher cpu exceeding 100 gbsecond cas e farhigher number negrained lightweight thre ectively exploits rich parallelism available c11 historical perspective reading c 79beginning nvidias geforce 8800 gpu 2006 three programmable graphics stages mapped array ed processors logical graphics pipeline physically recirculating path visits processors three times much xedfunction graphics logic visits erent rendering algorithms present wildly erent loads among three programmable stages cation provides processor load balancing uniﬁ ed graphics computing processors directx 10 generation functionality vertex pixel fragment shaders made identical programmer fact new logical stage introduced geometry shader process vertices primitive rather vertices isolatio e geforce 8800 designed directx 10 mind developers coming sophisticated shading algorithms motivated sharp increase available shader operation rate particularly oatingpoint operations nvidia chose pursue processor design higher operating frequency standardcell methodologies allowed deliver desired operation throughput ciently possible high clockspeed design requires substantially engineerin ort favored designing one processor rather two three given new geometry stage became worthwhile take engineering challenges ed processor load balancing recirculation logical pipeline onto threads processor array get b ts one processor design gpgpu intermediate step directx 9capable gpus became available researchers took notice raw performance growth path gpus began explore use gpus solve complex parallel problems directx 9 gpus designed match features required graphics api access computational resources programmer cast problem native graphics operations example run many simultaneous instances pixel shader triangle issued gpu clipping rectangle shape thats desired shaders means perform arbitrary scatter operations memory e way write result memory emit pixel color value co gure frameb er operation stage write blend desired result two dimensional frameb er furthermore way get result one pass computation next write parallel results pixel frameb er use frameb er texture map input pixel fragment shader next stage computation mapping general computations gpu era quite awkward nevertheless intrepid researchers demonstrated handful useful applications painstakin eld called gpgpu general purpose computing gpus c80 appendix c graphics computing gpus gpu computingwhile developing tesla architecture geforce 8800 nvidia realized potential usefulness would much grea ter programmers could think gpu processor nvidia selected programming approach programmers would explicitly declare dataparallel aspects workload directx 10 generation nvidia already begun work high ciency oatingpoint integer processor could run variety simultaneous workloads support logical graphics pipeline processor designed take advantage common case groups threads executing code path nvidia added memory load store instructions integer byte addressing support requirements compiled c programs introduced thread block cooperative thread array grid thread blocks barrier synchronization dispatch manage highly parallel computing work atomic memory operations added nvidia developed cuda cc compiler libraries runtime ware enable programmers readily access new dataparallel computation model develop applications scalable gpusscalability attractive feature graphics systems beginning workstation graphics systems gave customers choice pixel horsepower varying number pixel processor circuit boards installed prior mid 1990s pc graphics scaling almost nonexisten ere one optionthe vga controller 3dcapable accelerators appeared market room range erings 3dfx introduced multiboard scaling original sli scan line interleave voodoo2 held performance crown time 1998 also 1998 nvidia introduced distinct products variants single architecture riva tnt ultra highperformance vanta lo rst speed binning packaging separate chip designs geforce 2 gts geforce 2 mx present given architecture generation four separate gpu chip designs needed cover range desktop pc performance price points addition separate segments notebook workstation system er acquiring 3dfx nvidia continued multigpu sli concept 2004 starting geforce 6800providing multigpu scalability transparently programmer user functional behavior identical across scaling range one application run unchanged implementation architectural family cpus scaling higher transistor counts increasing number constantperformance cores die rather increasing performance single core writing industry transitioning dualcore quad core eightcore far behind programmers forced nd fourfold eightfold task parallelism fully utilize processors applications using task parallelism must rewritten frequently target successive doubling c11 historical perspective reading c 81core count contrast highly multithreaded gpu encourages use many fold data parallelism thread parallelism readily scales thousands parallel threads many processor e gpu scalable parallel programming model graphics parallel computing designed transparent portable scalability graphics program cuda program written runs gpu number processors shown section c1 cuda programmer explicitly states bot negrained coars egrained parallelism thread program decomposing problem grids thread blocksthe program r ciently gpus cpus size current future generations well recent developments academic industrial work applications using cuda produced hundreds examples successful cuda programs many programs run application tens hundreds times faster multicore cpus capable running examples include nbody simulation molecular modeling computatio nance oil gas exploration data processing although many use single precisio oatingpoint arithmetic problems require double precisio e recent arrival double precisio oating point gpus enables even broader range applications b gpu acceleration comprehensive list examples current developments applications accelerated gpus visit cudazone wwwnvidiacomcuda future trends naturally number processor cores continue increase proportion increases available transistors silicon processes improve addition gpus continue enjoy vigorous architectural evolution despite demonstrated high performance dataparallel applications gpu core processors still relatively simple design aggressive techniques introduced successive architecture increase actual utilization calculating units scalable parallel computing gpus ne eld novel applications rapidly created studying gpu designers discover implement new machine optimizations reading akeley k jermoluk 1988 highperformance polygon rendering proc siggraph 1988 august 23946akeley k 1993 realityengine graphics proc siggraph 1993 august 10916 blelloch g b 1990 pr x sums eir applications john h reif ed synthesis parallel algorithms morgan kaufmann publishers san francisco blythe 2006 e direct3d 10 system acm trans graphics vol 25 3 july 72434 c82 appendix c graphics computing gpus buck foley horn j sugerman k fatahlian houston p hanrahan 2004 brook gpus stream computing graphics hardware proc siggraph 2004 77786 august httpdoiacm org10114511865621015800 elder g 2002 radeon 9700 eurographicssiggraph workshop graphics hardware hot3d session wwwgraphicshardwareorgpreviouswww_2002presentationshot3dradeon9700ppt fernando r j kilgard 2003 e cg tutoria e nitive guide programmable realtime graphics addisonwesley reading fernando r ed 2004 gpu gems programming techniques tips tricks realtime graphics addisonwesley reading httpdevelopernvidiacomobjectgpu_gems_homehtml foley j van dam feiner j hughes 1995 computer graphics principles practice second edition c addisonwesley reading hillis w g l steele 1986 data parallel algorithms commun acm 29 12 dec 117083 http doiacmorg10114579027903 ieee std 7542008 2008 ieee standard floatingpoint arithmetic isbn 9780738157528 std95802 httpieeexploreieeeorgservletopacpunumber 4610933 aug 29 industrial light magic 2003 openexr wwwopenexrcom intel corporation 2007 intel 64 ia32 architectures optimization reference manual november order number 248966016 also www3intelcomdesignprocessormanuals248966pdf kessenich j 2006 e opengl sha ding langua ge language version 120 sept 2006 wwwopenglorg documentationspecs kirk voorhies 1990 e rendering architecture dn10000vs proc siggraph 1990 august 299307 lindholm e j kilgard h moreton 2001 user programmable vertex engine proc siggraph 2001 august 14958 lindholm e j nickolls oberman j montrym 2008 nvidia tesla u ed graphics computing architecture ieee micro vol 28 2 marchapril 3955 microso corporation microso directx sp cation httpmsdnmicroso comdirectx microso corporation 2003 microso directx 9 programmable graphics pipeline microso press redmond wa montrym j baum dignam c migdal 1997 nitereality realtime graphics system proc siggraph 1997 august 293301 montrym j h moreton 2005 e geforce 6800 ieee micro vol 25 2 marchapril 4151 moore g e 1965 cramming components onto integrated circuits electronics vol 38 8 april 19 nguyen h ed 2008 gpu gems 3 addisonwesley reading c11 historical perspective reading c 83nickolls j buck garland k skadron 2008 scalable parallel programming cuda acm queue vol 6 2 marchapril 4053 nvidia 2007 cuda zone wwwnvidiacomcuda nvidia 2007 cuda programming guide 11 httpdeveloperdownloadnvidiacomcomputecuda1_1 nvidia_cuda_programming_guide_11pdf nvidia 2007 ptx parallel read execution isa version 11 wwwnvidiacomobjectio_1195170102263 html nyland l harris j prins 2007 fast nbody simulation cuda gpu gems 3 h nguyen ed addisonwesley reading oberman f siu 2005 highperformance cient multifunction interpolator proc seventeenth ieee symp computer arithmetic 27279patterson j l hennessy 2004 computer organization desig e hardwareso ware inter face third edition morgan kaufmann publishers san francisco pharr ed 2005 gpu gems 2 programming techniques highperformance graphics general purpose computation addisonwesley reading satish n harris garland 2008 designin cient sorting algorithms manycore gpus nvidia technical report nvr2008001 segal k akeley 2006 e opengl graphics system speci cation version 21 dec 1 2006 www openglorgdocumentationspecs sengupta harris zhang j owens 2007 scan primitives gpu computing proc graphics hardware 2007 august 97106 volkov v j demmel 2008 lu qr cholesky factorizations using vector capabilities gpus technical report ucbeecs200849 111 wwweecsberkeleyedupubstechrpts2008eecs2008 49html williams l oliker r vuduc j shalf k yelick j demmel 2007 optimization sparse matrix vector multiplication emerging multicore platforms proc supercomputing 2007 november custom format slave architecture hardware instruction set serves e format must strike proper compromise rom size romoutput decoding circuitry size machine execution rate jim mckevit et al 8086 design report 1997 mapping control hardware dd1 introduction d3d2 implementing combinational control units d4d3 implementing finitestate machine control d8d4 implementing nextstate function sequencer d22appendix d5 translating microprogram hardware d28d6 concluding remarks d32d7 exercises d33 d1 introductioncontrol typically two parts combinational part lacks state sequential control unit handles sequencing main control multicycle design combinational control units en used handle part decode control pro e alu control chapter 4 example singlecycle implementation like chapter 4 also use combinational controller since require multiple states section d2 examines implementation two combinational units truth tables chapter 4 since sequential control units larger en complex wider variety techniques implementing sequential control uni e usefulness techniques depends complexity control characteristics average number next states given state implementation technology e straightforward way implement sequential control function block logic takes inputs current state opco eld instruction register produces outputs datapath control signals value next state e initial representation may eith nitestate diagram microprogram latter case microinstruction represents state d4 appendix mapping control hardware implementation usin nitestate controller nextstate function computed logic section d3 constructs implementation rom pla alternative method implementation computes nextstate function using counter increments current state determine next state next state doesnt follow sequentially logic used determine state section d4 explores type implementation shows used implemen nitestate control section d5 show microprogram representation sequential control translated control logic d2 implementing combinational control unitsin section show alu control unit main control unit single clock design mapped gate level modern computer aided design cad systems process completely mechanical e examples illustrate cad system takes advantage structure control function including presence dontcare terms mapping alu control function gatesfigure d21 shows truth table alu control function developed section 44 logic block implements alu control function four distinct outputs called operation3 operation2 operation1 operation0 corresponding one four bits alu control last column figure e logic function output constructed combining truth table entries set particular output example loworder bit alu control operation0 set last two entries truth table figure us truth table operation0 two entries figure d22 shows truth tables four alu control bits taken advantage common structure truth table incorporate additional dont cares example th lines truth table figure d21 set operation1 reduced two entries figure d22 logic minimization program use dontcare terms reduce number gates number inputs gate logic gate realization truth tables confusing aspect figure d22 logic function opera tio control line used operation needed mips subset figure 412 simp ed truth table figure d22 generate logic shown figure d23 call alu control block process straightforward d2 implementing combinational control units 5aluopfunct ﬁeld operationaluop1aluop0f5f4f3f2f1f0 00xxxxxx0010 x1xxxxxx0110 1xxx0000 0010 1xxx0010 0110 1xxx01000000 1xxx01010001 1xxx1010 0111 figure d21 truth table 4 alu control bits called operation function aluop function code ﬁ eld table shown figure 413 ﬁ edoc noitcnufpoula elds aluop1aluop0f5f4f3f2f1f0 01xxxxxx 1xxxxx1x truth table operation2 1 table corresponds second left bit operation eld figure d21 ﬁ edoc noitcnufpoula elds aluop1aluop0f5f4f3f2f1f0 0xxxxxxx xxxxx0xx b truth table operation1 1 ﬁ edoc noitcnufpoula elds aluop1aluop0f5f4f3f2f1f0 1xxxxxx1 1xxx1xxx c truth table operation0 1 figure d22 truth tables three alu control lines entries output 1 sho e bits eac eld numbered right starting 0 thus f5 cant bit function eld f0 le cant bit similarly names signals corresponding 4bit operation code supplied alu operation3 operation2 operation1 operation0 last le cant bi us truth table shows input combinations alu control 0010 0001 0110 0111 combinations us e aluop bits named aluop1 al e three output values depend 2bit al eld eld equal 10 6bit function code instruction accordingly al eld equal 10 dont care function code value represented x ere truth table operation3 1 always set 0 figure d21 see appendix b background dont cares d6 appendix mapping control hardware done cad program example logic gates derived truth tables given legend figure d23 alu control logic simple three outputs possible input combinations need recognized large number possible alu function codes transformed alu control signals simple method would b cient instead could use decoder memory structured array logic gat ese techniques described appendix b see examples examine implementation multicycle controller section d3 elaboration general logic equation truth table representation logic function equivalent discuss detail appendix b however tr es entries result nonzero outputs may completely describe logic function full truth table completely indicates dontcare entries example encoding 11 aluop always generates dont care output thus complete truth table would xxx output portion entries 11 eld eld 10 operation2 operation1 operation0 operation aluop1f3f2 f1 f0f 5œ0aluop0aluopalu control block operation3 figure d23 alu control block generates four alu control bits based function code aluop bits logic generated directly truth table figure d22 four six bits function code actually needed inputs since upper two bits always dont cares lets examine logic relates truth table figure d22 consider operation2 output generated two lines truth table operatio e second line two terms f1 1 aluop1 1 top twoinput gate corresponds ter e term causes operation2 asserted simply al ese two terms combined gate whose output operatio e outputs operation0 operation1 derived similar fashion truth table since operation3 always 0 connect signal complement inputs gate generate 0 d2 implementing combinational control units 701 1x x1 respectively incorporating dontcare terms minimizing logic complex errorprone thus better left program mapping main control function gatesimplementing main control function unstructured collection gates alu control reasonable control function neither complex large see truth table shown figure d24 however 64 possible opcodes used many control lines number gates would much larger gate could many inputs since function computed two levels logic another way implement logic function structured twolevel logic array figure d25 shows implementation uses array gates followed array gat structure called programmable logic array pla pla one common ways implement control function return topic using structured logic elements implement control implement th nitestate controller next section controlsignal namerformat lwswbeq inputsop50110 op40000 op30010 op20001 op10110 op00110 outputsregdst10xx alusrc0110 memtoreg01xx regwrite1100 memread0100 memwrite0010 branch0001 aluop11000 aluop00001 figure d24 control function simple oneclock implementation completely speciﬁ ed truth table table shown figure 422 d8 appendix mapping control hardware d3 implementing finitestate machine controlto implement contro nitestate machine mu rst assign number 10 states state could use number use sequential numbering simplicity figure d31 shows th nitestate diagram 10 states need 4 bits encode state number call state bits s3 s2 s1 e currentstate number stored state register shown figure d32 states assigned sequentially state encoded using rformatiwswbeq op0op1op2op3op4op5inputsoutputsregdstalusrcmemtoregregwrite memreadmemwrite branch aluop1aluop0figure d25 structured implementation control function described truth table figure d24 e structure called programmable logic array pla uses array gates followed array gat e inputs gates function inputs inverses bubbles indicate inversion e inputs gates outputs gates degenerate case function inputs invers e output gates function outputs d3 implementing finitestate machine control 9pcwrite pcsource 10alusrca 1alusrcb 00aluop 01pcwritecond pcsource 01alusrca 1alusrcb 00aluop 10regdst 1regwritememtoreg 0memwriteiord 1memreadiord 1alusrca 1alusrcb 10aluop 00regdst 0 regwritememtoreg 1alusrca 0alusrcb 11aluop 00memreadalusrca 0iord 0irwritealusrcb 01aluop 00pcwritepcsource 00instruction fetchinstruction decoderegister fetchjumpcompletionbranchcompletionexecutionmemory addresscomputationmemory accessmemory accessrtype completionwriteback step op lw op swop rtypeop beqop j op swop lw4019862753startfigure d31 ﬁ nitestate diagram multicycle control d10 appendix mapping control hardware state bits binary number example state 6 encoded 0110 two s3 0 s2 1 s1 1 s0 0 also written s3 s2 s1 s0 e control unit outputs specify next state ese written state register clock edge become new state beginning next clock cycle following active clock edge name outputs ns3 ns2 ns1 ns0 determined number inputs states outputs know basic outline control unit look like show figure d32 pcwrite pcwritecond iordmemtoregpcsource aluop alusrcbalusrcaregwrite regdstns3ns2ns1ns0op5op4 op3 op2 op1 op0s3s2 s1 s0state registerirwrite memreadmemwrite instruction register opcode fieldoutputscontrol logic inputsfigure d32 control unit mips consist control logic register hold state e state register written active clock edge stable clock cycle d3 implementing finitestate machine control 11 e block labeled control logic figure d32 combinational logic think big table giving value outputs terms inpu e logic block implements tw erent parts th nitestate machine one part logic determines setting datapath control outputs depend state bi e part control logic implements nextstate function equations determine values nextstate bits based currentstate bits inputs 6bit opcode figure d33 shows logic equations top portion shows outputs bottom portion shows nextstate functio e values table posetats tnerructuptuopcwritestate0 state9 pcwritecondstate8 iordstate3 state5 memreadstate0 state3 memwritestate5 irwritestate0 memtoregstate4 pcsource1state9 pcsource0state8 aluop1state6 aluop0state8 alusrcb1state1 state2 alusrcb0state0 state1 alusrcastate2 state6 state8 regwritestate4 state7 regdststate7 nextstate0state4 state5 state7 state8 state9 nextstate1state0 nextstate2state1 op lw op sw nextstate3state2 op lw nextstate4state3 nextstate5state2 op sw nextstate6state1 op rtype nextstate7state6 nextstate8state1 op beq nextstate9state1 op jmp figure d33 logic equations control unit shown shorthand form remember stands logic equation e state inputs nextstate outputs must expanded using state encoding blank entry dont care d12 appendix mapping control hardware determined state diagram figure d31 whenever control line active state state entered second column table likewise nextstate entries made whenever e state successor another figure d33 use abbreviation state n stand current state n us state n replaced term encodes state number n use nextstate n stand setting nextstate outputs n output implemented using nextstate outputs ns nextstate n active bits ns30 set corresponding binary version value n course since given nextstate bit activated multiple next states equation state bit terms activate signal likewise use term op lw corresponds opcode inputs sp es encoding opcode lw 6 bits simple control unit previous section chapter translating entries figure d33 logic equations outputs straightforward logic equations nextstate outputsgive logic equation loworder nextstate bit ns0 e nextstate bit ns0 active whenever next state ns0 1 state encodin true nextstate1 nextstate3 nextstate5 nextstate7 nextstat e entries states figure d33 supply conditions nextstate values active e equation next states given e rst equation states next state 1 current state 0 current state 0 state input bits 0 rightmost product term indicates nextstate1 state0 s3 s2 s1 s0 nextstate3 state2 op501w s3 s2 s1 s0 op5 op4 op3 op2 op1 op0exampleanswer d3 implementing finitestate machine control 13nextstate5 state2 op50sw s3 s2 s1 s0 op5 op4 op3 op2 op1 op0nextstate7 state6 s3 s2 s1 s0nextstate9 state1 op50jmp s3 s2 s1 s0 op5 op4 op3 op2 op1 op0ns0 logical sum terms seen control function expressed logic equation outpu set logic equations implemented two ways corresponding complete truth table corresponding twolevel logic structure allows sparse encoding truth table look implementations lets look truth table complete control function simplest break control functio ned figure d33 two parts nextstate outputs may depend inputs control signal outputs depend currentstate bits figure d34 shows truth tables datapath control signals signals actually depend state bits opcode entries table figure d34 actually represents 64 26 entries 6 bits named op possible values op bits dontcare bits determining data path control outputs figure d35 shows truth table nextstate bits ns30 depend state input bits instruction bits supply opcode elaboration many opportunities simplify control function observing similarities among two control signals using semantics implementation example signals pcwritecond pcsource0 aluop0 asserted exactly one state state 8 three control signals replaced single signal d14 appendix mapping control hardware s3s2s1s0s3s2s1s0s3s2s1s0 000010000011 10101001dnocetirwcprofelbathturtbetirwcprofelbathturtac truth table iord s3s2s1s0s3s2s1s0s3s2s1s0 000001010000 0011d truth table memreade truth table memwritef truth table irwrite s3s2s1s0s3s2s1s0s3s2s1s0 010010011000 g truth table memtoregh truth table pcsource1i truth table pcsource0 s3s2s1s0s3s2s1s0s3s2s1s0 011010000001 0010 1bcrsularofelbathturtl0poularofelbathturtk1poularofelbathturtjs3s2s1s0s3s2s1s0s3s2s1s0 000000100100 000101100111 1000m truth table alusrcb0n truth table alusrcao truth table regwrite s3s2s1s0 0111p truth table regdstfigure d34 truth tables shown 16 datapath control signals depend currentstate input bits shown table truth table row corresponds 64 entries one possible value six op bits notice outputs active nearly circumstances example case pcwritecond pcsource0 aluop0 signals active state 8 see b ese three signals could replaced one signal ere opportunities reducing logic needed implement control function taking advantage similarities th e truth tables d3 implementing finitestate machine control 15a rom implementation probably simplest way implement control function encode truth tables readonly memory ro e number entries memory truth tables figures d34 d35 equal possible values inputs 6 opcode bits plus 4 state bits 2 inputs 210 e inputs op5op4op3op2op1op0s3s2s1s0 0000100001 0001000001 truth table ns3 output active next state 8 9 signal activated current state 1 op5op4op3op2op1op0s3s2s1s0 0000000001 1010110010 xxxxxx0011 xxxxxx0110 b truth table ns2 output active next state 4 5 6 7 situation occurs current state one 1 2 3 6 op5op4op3op2op1op0s3s2s1s0 0000000001 1000110001 1010110001 1000110010 xxxxxx0110 c truth table ns1 output active next state 2 3 6 7 next state one 2 3 6 7 current state one 1 2 6 op5op4op3op2op1op0s3s2s1s0 xxxxxx0000 1000110010 1010110010 xxxxxx0110 0000100001 truth table ns0 output active next state 1 3 5 7 9 happens current state one 0 1 2 6 figure d35 four truth tables four nextstate output bits ns30 e next state outputs depend value op50 opco eld current state given s3 e entries x dontcare terms entry dontcare term corresponds two entries one input 0 one input us entry n dontcare terms actually corresponds 2n truth table entries d16 appendix mapping control hardware control unit become address lines rom implements control logic block shown figure e width entry word memory 20 bits since 16 datapath control outputs 4 nextstate bi means total size rom 2 10 20 20 kbits e setting bits word rom depends outputs active word look control words need order bits within control input address output words contents respectively number bits using order figure d32 nextstate bits loworder bits control word currentstate input bits loworder bits address means pcwrite output high order bit bit 19 memory word ns0 loworder bi e highorder address bit given op5 highorder bit instruction loworder address bit given s0 construct rom contents building entire truth table form row corresponds one 2 n unique input combinations set columns indicates outputs active input combination dont space show 1024 entries truth table however separating datapath control nextstate outputs since datapath control outputs depend current state e truth table datapath control outputs shown figure d36 include encodings state inputs use values 0 9 corresponding 10 states state machine e truth table figure d36 directly gives contents upper 16 bits word ro e 4bit inpu eld gives loworder 4 address bits word column gives contents word address show full truth table datapath control bits state number opcode bits inputs opcode inputs would dont cares construct rom dont cares since addresses rom must complete us datapath control outputs occur many times rom since part rom whenever state bits identical independent value opcode inputs control rom entries rom addresses bit corresponding pcwrite high bit control word 1 example d3 implementing finitestate machine control 17pcwrite high states 0 9 corresponds addresses 4 loworder bits either 0000 e bit high memory word independent inputs op50 addresses bit high ar 1111110000 e general form xxxxx x0000 xxxxxx1001 xxxxxx combination bi ts corresponds 6bit opcode output depend answer03s seulav tupnistuptuo0000000100100011010001010110011110001001 pcwrite1000000001 pcwritecond0000000010 iord0001010000 memread1001000000 memwrite0000010000 irwrite100000 0000memtoreg0 000100000 pcsource10000000001 pcsource00000000010 aluop10 000001000 aluop00 000000010 alusrcb10110000000 alusrcb01100000000 alusrca0010001010 regwrite0 000100100 regdst0000000100 figure d36 truth table 16 datapath control outputs depend state inputs e values determined figure d34 although 16 possible values 4bit stat eld ten used shown e ten possible values shown top column shows setting datapath control outputs state input value appears top column example state inputs 0011 state 3 active datapath control outputs iord memread d18 appendix mapping control hardware show entire contents rom two parts make easier show figure d37 shows upper 16 bits control word comes directly figure ese datapath control outputs depend state inputs set words would duplicated 64 times full rom discussed e entries corresponding input values 1010 1111 used care contain figure d38 shows lower four bits control word corresponding nextstate outpu e last column table figure d38 corresponds possible values opcode match sp ed opcodes state 0 next state always state 1 since instruction still fetched er state 1 opco eld must valid e table indicates entries marked illegal discuss deal exceptions interrupts opcodes section 49 representation two separate tables compact way show rom contents also cient way implement rom e majority outputs 16 20 bits depends 4 10 inpu e number bits total control implemented two separate roms 24 16 210 4 256 4096 43 kbits h size single rom requires 2 10 20 20 kbi ere overhead associated structuredlogic block case additional overhead extra rom would much smaller savings splitting single rom lower 4 bits addressbits 194 word 00010000001010010000000110000000000010000010100000000000010000000000000011001100010000000100000000100000000000010100101000100010000000000110110000000000000011100010010100000010000100000000100000011001figure d37 contents upper 16 bits rom depend state inputs ese values figure d36 simply rotate set control words would duplicated 64 times every possible value upper six bits address d3 implementing finitestate machine control 19although rom encoding control function simple wasteful even divided two pieces exa mple values instruction register inputs en needed determine next state us next state rom many entries either duplicated dont care consider case machine state 0 2 6 entries rom since opco eld value entries contents namely control word e reason much rom wasted rom implements complete truth table providing opportunity erent output every combination inputs combinations inputs either never happen redundant op 50current state s30000000rformat 000010jmp000100beq100011lw101011swany value0000000100010001000100010001 000101101001100000100010illegal 0010xxxxxxxxxxxx00110101illegal 001101000100010001000100illegal 010000000000000000000000illegal 010100000000000000000000illegal 011001110111011101110111illegal 011100000000000000000000illegal 100000000000000000000000illegal 100100000000000000000000illegal figure d38 table contains lower 4 bits control word ns outputs depend state inputs s30 opcode op50 correspond instruction opcode ese values determined figure e opcode name shown encoding headin e four bits control word whose address given currentstate bits op bits shown entry example state input bits 0000 output always 0001 independent inputs state 2 next state dont care three inputs 3 lw 5 sw together entries figure d37 table sp es contents control unit rom example word address 1000110001 obtained b nding upper 16 bits table figure d37 using state input bits 0001 concatenating lower four bits found using entire address 0001 nd row 100011 nd col e entry figure d37 yields 0000000000011000 appropriate entry table immediately us control word addr e column labeled value applies op bits match one sp ed opcodes d20 appendix mapping control hardware pla implementationwe reduce amount control storage required cost using complex address decoding control inputs encode input combinations needed e logic structure en used programmed logic array pla mentioned earlier illustrated figure d25 pla output logical one minterms minterm also called product term simply logical one inpu e inputs thought address indexing pla minterms select possible address combinations interesting minterm corresponds single entry truth table figure d34 including possible dontcare terms output consists minterms exactly corresponds complete truth table however unlike rom truth table entries produce active output needed one copy minterm required even minterm contains dont cares figure d39 shows pla implements control function see pla figure d39 17 unique minterms10 depend current state 7 others depend combination th eld currentstate bi e total size pla proportional inputs product terms outputs product terms see symbolically th gure means total size pla figure d39 proportional 10 17 20 17 510 comparison size single rom proportional 20 kb even twopart rom total 43 kb size pla cell slightly larger size bit rom pla much mor cient implementation control unit course split rom two could split pla two plas one 4 inputs 10 minterms generates 16 control outputs one 10 inputs 7 minterms generates 4 nextstate outputs e rst pla would size proportional 4 10 10 16 200 second pla would size proportional 10 7 4 7 would yield total size proportional 298 pla cells 55 size single pl ese two plas considerably smaller implementation using two roms details plas implementation well references books logic design see appendix b d3 implementing finitestate machine control 21op5op4op3 op2 op1 op0 s3 s2 s1 s0iordirwrite memreadmemwrite pcwrite pcwritecond memtoregpcsource1aluop1alusrcb0alusrcaregwrite regdstns3 ns2 ns1 ns0alusrcb1aluop0pcsource0figure d39 pla implements control function logic multicycle implementation e inputs control appear th outputs righ e top half th gure plane computes minterm e minterms carried plane vertical lines colored dot corresponds signal makes minterm carried line e sum terms computed minterms gray dot representing presence intersecting minterm sum term output consists single sum term d22 appendix mapping control hardware d4 implementing nextstate function sequencerlets look carefully control unit built last section examine roms implement control figures d37 d38 see much logic used specify nextstate function fact implementation using two separate roms 4096 4368 bits 94 correspond nextstate function furthermore imagine control logic would look like inst ruction set many erent instruction types required many clocks implemen ere would many states th nitestate machine states might branching large number erent states depending instruction type state 1 th nitestate machine figure d31 however many states would proceed sequential fashion states 3 4 figure d31 example incl oating point would see sequence many states row implement multicyc oatingpoint instruction alternatively consider control might look machine multiple memory operands per instruction would require many states fetch multiple memory op e result would control logic dominated encoding nextstate function furthermore much logic devoted sequences states one path look like states 2 4 figure d31 instructions sequences consist many sequentially numbered states simple subset encode complex control function ciently use control unit counter supply sequential next state counter en eliminates need encode nexts tate function explicitly control unit shown figure d41 adder used increment state essentially turning counter e incremented state always state follows numerical order however th nitestate machine sometimes branches example state 1 th nitestate machine see figure d31 four possible next states one sequential next state us need able choose incremented state new state based inputs instruction register current state control word include control lines determine next state chosen easy implement control output signal portion control word since use state numbers portion control word look exactly like rom contents shown figure d37 however method d4 implementing nextstate function sequencer 23for selecting next stat ers nextstate function th nitestate machine explicit counter providing sequential next state control unit logic need specify choose state sequentially following state ere two methods e rst method already seen namely control unit explicitly encodes nextstate function e erence control unit need set nextstate lines designated next state state counter indicates number addrctloutputspla rom stateaddress select logicop5œ0adderinstruction register opcode field1control unit inputpcwrite pcwritecond iordmemtoregpcsourcealuopalusrcbalusrcaregwrite regdstirwrite memreadmemwrite figure d41 control unit using explicit counter compute next state control unit next state computed using counter least states comparison figure d32 encodes next state control logic every st ate control unit signals labeled addrctl control next state determined d24 appendix mapping control hardware states large nextstate function need encode mostly empty may good choice since resulting control unit lots empty redundant space alternative approach use separate external logic specify next state counter specify state many control units especially implement large instruction sets use approach focus specifying control externally although nonsequential next state come external table control unit needs specify occur nd next state ere two kinds branching must implement address select logic first must able jump one number states based opcode portion instruction register operation called dispatch usually implemented using set special roms plas included part address selection logic additional set control outputs call addrctl indicates dispatch done looking th nitestate diagram figure d31 see two states branch based portion opcode us need two small dispatch tables alternatively could also use single dispatch table use control bits select table address bits choose portion dispatch table select address e second type branching must implement consists branching back state 0 initiates execution next mips instruction us four possible ways choose next state three types branches plus incrementing currentstate number encoded 2 bits lets assume encoding follows addrctl valueaction 0set state 0 1dispatch rom 1 2dispatch rom 2 3use incremented state use encoding address select logic control unit implemented shown figure d42 complete control unit need specify contents dispatch roms values addresscontrol lines state already sp ed datapath control portion control word using rom contents figure d37 corresponding portions pla figure e nextstate counter dispatch roms take place portion control unit computing next state shown figure d38 d4 implementing nextstate function sequencer 25only implementing portion instruction set dispatch roms largely empty figure d43 shows entries must assigned subset stateopadder1pla rom mux3210dispatch rom 1 dispatch rom 2 0addrctladdress select logicinstruction register opcode fieldfigure d42 address select logic control unit figure d41 2 mor hctapsid1 mor hctapsidopopcode namevalueopopcode namevalue 000000rformat0110100011 lw0011000010jmp1001101011 sw0101000100beq1000100011lw0010101011sw0010figure d43 dispatch roms 2 6 64 entries 4 bits wide since number bits state encoding gure shows entries rom interest subs e rst column table indicates value op address used access dispatch ro e second column shows symbolic name opcode e third column indicates value address rom determine setting address selection lines addrctl control word e table figure d44 shows address control must d26 appendix mapping control hardware set every state information used specify setting addrct eld control word associated state e contents entire control rom shown figure e total storage required control quite small ere 10 control words 18 bits wide total 180 bits addition two dispatch tables 4 bits wide 64 entries total 512 additional bi total 692 bits beats implementation uses two roms nextstate function encoded roms requires 43 kbits course dispatch tables sparse could mor ciently implemented two small pla e control rom could also replaced pla state numberaddresscontrol actionvalue addrctl 3etats detnemercni esu011 mor hctapsid esu122 mor hctapsid esu23etats detnemercni esu300 yb rebmun etats ecalper400 yb rebmun etats ecalper53etats detnemercni esu600 yb rebmun etats ecalper700 yb rebmun etats ecalper800 yb rebmun etats ecalper9figure d44 values addresscontrol lines set control word corresponds state state numbercontrol word bits 172control word bits 10 1100010000001010010100001100000000000101001010000000000021100000000000011003000100000001000000400000000000001010051100100010000000006001100000000000000700001001010000001080000000000100000019figure d45 contents control memory implementation using explicit counter e rst column shows state second shows datapath control bits last column shows addresscontrol bits control word bits 172 identical figure d37 d4 implementing nextstate function sequencer 27optimizing control implementationwe reduce amount logic control unit tw erent techniq e rst logic minimization uses structure logic equations including dontcare terms reduce amount hardware required e success process depends many entries exist truth table entries related example subset lw sw opcodes active value signal op5 replace two truth table entries test whether input lw sw single test bit similarly eliminate several bits used index dispatch rom single bit used nd lw sw th rst dispatch rom course opcode space less sparse opportunities optimization would mor cult locate however choosing opcodes architect provide additional opportunities choosing related opcodes instructions likely share states control erent sort optimization done assigning state numbers nitestate microcode implementation minimize th optimization called state assignment tries choose state numbers resulting logic equations contain redundancy thus simp ed lets consider case nitestate machine encoded nextstate contro rst since allows states assigned arbitrarily example notice th nitestate machine signal regwrite active states 4 7 encoded states 8 9 rather 4 7 could rewrite equation regwrite simply test bit s3 states 8 renumbering allows us combine two truth table entries part figure d34 replace single entry eliminating one term control unit course would renumber existing states 8 9 perhaps 4 7 e optimization applied implementation uses explicit program counter though restricted nextstate number en computed incrementing currentstate number arbitrarily assign states however keep states incremented state used next state order reassign consecutive states block implementation explicit nextstate counter state assignment may allow us simplify contents dispatch roms look control unit figure d41 looks remarkably like computer righ e rom pla thought memory supplying instructions datapat e state thought instruction address hence origin name microcode microprogrammed control e control words thought microinstructions control datapath state register called microprogram counter figure d46 shows view control unit microcode e next section describes map microprogram microcode d28 appendix mapping control hardware d5 translating microprogram hardware translate microprogram actual hardware need specify eld translates control signals implement microprogram either nitestate control microcode implementation explicit sequencer choos nitestate machine need co nstruct nextstate function pcwrite pcwritecond iordmemtoregpcsourcealuopalusrcbalusrcaregwrite addrctloutputsmicrocode memory irwrite memreadmemwrite regdstcontrol unit inputmicroprogram counter address select logicop5œ0adder1instruction register opcode fieldbwrite datapathfigure d46 control unit microcode e use word micro serves distinguish program counter datapath microprogram counter microcode memory instruction memory d5 translating microprogram hardware 29the microprogram function known map set truth table entries nextstate outputs section show translate microprogram assuming next state sp ed sequencer truth tables construct would straightforward build nextstate function fo nitestate machine tnemmocevitca slangiseulaveman dleifalu controladdaluop 00cause alu add subtaluop 01cause alu subtract implements compare branches func codealuop 10use instructions function code determine alu control src1pcalusrca 0 rst alu input aalusrca 1 rst alu input src2balusrcb 00register b second alu input 4alusrcb 01use 4 second alu input extendalusrcb 10use output sign extension unit second alu input extshftalusrcb 11use output shiftbytwo unit second alu input register control srebmun retsiger eht sa ri eht fo sdle tr dna sr eht gnisu sretsiger owt daerdaerand putting data registers b write aluregwrite regdst 1 memtoreg 0 eld ir register number contents aluout data write mdrregwrite regdst 0 memtoreg 1write register using r eld ir register number contents mdr datamemory read pcmemread iord 0 irwrite read memory using pc address write result ir mdr read alumemread iord 1read memory using aluout address write result mdr write alumemwrite iord 1write memory using aluout address contents b data pc write controlalupcsource 00 pcwritewrite output alu pcaluoutcondpcsource 01 pcwritecond zero output alu active write pc contents register aluoutjump addresspcsource 10 pcwritewrite pc jump address instruction sequencingseqaddrctl 11choose next microinstruction sequentially fetchaddrctl 00 rst microinstruction begin new instruction dispatch 1addrctl 01dispatch using rom 1 dispatch 2addrctl 10dispatch using rom 2 figure d51 microcode ﬁ eld translates set control signals set es erent values th elds specify required combinations 18 control lines control lines set correspond actions 0 de fault multiplexor control lines set 0 output matters multiplexor control line explicitly set output dont ca used d30 appendix mapping control hardware assuming explicit sequencer need two additional tasks translate microprogram assign addresses microinstructions contents dispatch ro process essentially process translating assembly language program machine instructions th elds assembly language microprogram instruction translated labels instructions must resolved addresses figure d51 shows various values microinstructio eld controls datapath thes elds encoded control signals eld corresponding signal ects unit state ie memory memory register alu destination pcwritecontrol blank control signal active eld corresponding multiplexor control signal alu operation control ie aluop src1 src2 blank output unused associated signals may set dont care e sequencin eld four values fetch meaning go fetch state dispatch 1 dispatch 2 seq ese four values encoded set 2bit address control figure d44 fetch 0 dispatch 1 1 dispatch 2 2 seq 3 finally need specify contents dispatch tables relate dispatch entries seq eld symbolic labels microprogram use dispatch tables earlier figure d43 microcode assembler would use encoding sequencin eld contents symbolic dispatch tables figure d52 sp cation figure d51 actual microprogram generate microinstructions since microprogram abstract representation control great deal exibility microprogram translated example address assigned many microinstructions chosen arbitrarily restrictions imposed fact certain microinstructions must 2 elbat hctapsid edocorcim1 elbat hctapsidopcode ﬁ eldopcode namevalueopcode ﬁ eldopcode namevalue 000000rformatrformat1100011 lwlw2 000010jmpjump1101011 swsw2000100beqbeq1100011lwmem1101011swmem1figure d52 two microcode dispatch roms showing contents symbolic form using labels microprogram d5 translating microprogram hardware 31occur sequential order incrementing state register generates address next instructio us microcode assembler may reduce complexity control assigning microinstructions cleverly organizing control reduce logicfor machine complex control may great deal logic control uni e control rom pla may costly although simple implementation 18bit microinstruction assuming explicit sequencer machines microinstructions hundreds bits wide clearly designer would like reduce number microinstructions width e ideal approach reducing control store rst write complete microprogram symbolic notation measure control lines set microinstruction taking measurements able recognize control bits encoded eld example one eight lines set simultaneously microinstruction subset control lines encoded 3bi eld log2 8 change saves bits every microinstruction hurt cpi though mean extra hardware cost 3to8 decoder needed generate eight control lines required datapath may also small clock cycle impact since decoder signal path however shavin bits control store width usually overcome cost decoder cycle time impact probably small nonexistent example technique applied bits 136 microinstructions machine since one seven bits control word ever active see figure d45 technique reducin eld width called encoding save space control lines may encoded together occasionally set microinstruction two microinstructions instead one required must set long doesnt happen critical routines narrower microinstruction may justify extra words control store microinstructions made narrower still broken erent formats given opcode format eld distinguish th e forma eld gives unsp ed control lines default values change anything else machine similar opcode instruction powerful instruction set example could us erent format microinstructions memory accesses registerregister alu operations taking advantage fact memory access control lines needed microinstructions controlling alu operations reducing hardware costs using forma elds usually additional performance cost beyond requirement decoders microprogram using single microinstruction format specify combination operations datapath take fewer clock cycles microprogram made restricted microinstructions perform combination operations d32 appendix mapping control hardware single microinstruction however full capability wider microprogram word heavily used much control store wasted machine could made smaller faster restricting microinstruction capability e narrow usually longer approach en called vertical microcode wide short approach called horizontal microcode noted terms vertical microcode horizontal microcode universal nitionthe designers 8086 considered 21bit microinstruction horizontal singlechip computers time e related terms maximally encoded minimally encoded probably better vertical horizontal d6 concluding remarks began appendix looking translat nitestate diagram implementation usin nitestate machine looked explicit sequencers us erent technique realizing nextstate function although large microprograms en targeted implementations using explicit nextstate approach also implement microprogram nitestate machine saw rom pla implementations logic functions possible e advantages explicit versus encoded next state rom versus pla implementation summarized independent whether control represente nitestate diagram microprogram translation hardware control implementation similar state microinstruction asserts set control outputs sp es choose next state e nextstate function may implemented either encoding nitestate machine using explicit sequencer e explicit sequencer cient number states large many sequences consecutive states without branching e control logic may implemented either roms plas even mix plas cient unless control function dense roms may appropriate control stored separate memory opposed within chip datapath bigpicture d5 exercises 33 d7 exercisesd1 10 d2 instead using four state bits implement th nitestate machine figure d31 use nine state bits 1 th nite state machine particular state eg s1 1 state 1 s2 1 state 2 etc redraw pla figure d39 d2 5 d3 wish add instruction jal jump link make necessary changes datapath control signals needed photocopy gures make faster show additions many product terms required pla implements control singlecycle datapath jald3 5 d3 wish add instruction addi add immediate add necessary changes datapath control signals many product terms required pla implements control single cycle datapath addiud4 10 d3 determine number product terms pla implements th nitestate machine addi e easiest way construct additions truth tables addid5 20 d4 implement th nitestate machine using explicit counter determine next state fill new entries additions figure d45 also add entries needed dispatch roms figure d52 d6 15 d3d6 determine size plas needed implement multicycle machine assuming n extstate function implemented counter implement dispatch tables figure d52 using two plas contents main control unit figure d45 using another pla total size solution compare single pla solution next state encoded main plas approaches split two separate plas factoring nextstate address select signals computer organization design doi 2013 elsevier inc rights reserved httpdxdoiorg101016b9780124077263000011 2013risc computer announced er 1985 survey risc architectures desktop server embedded computers eappendixsteven przybylskic designer stanford mips e1 introduction e3e2 addressing modes instruction formats e5e3 instructions mips core subset e9e4 instructions multimedia extensions desktopserver riscs e16e5 instructions digital signalprocessing extensions embedded riscs e19e6 instructions common extensions mips core e20e7 instructions unique mips64 e25e8 instructions unique alpha e27e9 instructions unique sparc v9 e29e10 instructions unique powerpc e32e11 instructions unique parisc 20 e34e12 instructions unique arm e36e13 instructions unique thumb e38e14 instructions unique superh e39e15 instructions unique m32r e40e16 instructions unique mips16 e40e17 concluding remarks e43 e1 introductionwe cover two groups reduced instruction set computer risc architectures appe e rst group desktop server riscs digital alpha hewlettpackard parisc ibm motorola powerpc mips inc mips64 sun microsystems sparc e4 appendix e survey risc architectures e second group embedded riscs advanced risc machines arm advanced risc mac umb hitachi superh mitsubishi m32r mips inc mips16 alpha mips parisc 11 powerpc sparcv8 date announced 1992 1986 1986 1993 1987 instruction size bits 32 32 32 32 32 address space size model64 bits ß 32 bits ß 48 bits segmented32 bits ß 32 bits ß dengila dengilanu dengila dengila dengila tnemngila atad data addressing modes 1 1 5 4 2 egap egap egap egap egap noitcetorp minimum page size 8 kb 4 kb 4 kb 4 kb 8 kb deppam yromem deppam yromem deppam yromem deppam yromem deppam yromem oi integer registers number model size 31 gpr 64 bits 31 gpr 32 bits31 gpr 32 bits32 gpr 32 bits 31 gpr 32 bitsseparate ß oatingpoint registers 31 32 31 64 bits 16 32 16 64 bits 56 32 28 64 bits 32 32 32 64 bits 32 32 32 64 bits floatingpoint format ieee 754 single doubleieee 754 single doubleieee 754 single doubleieee 754 single doubleieee 754 single doublefigure e11 summary ﬁ rst version ﬁ architectures desktops servers except number data address modes instruction set details integer instruction sets architectures similar contrast figure e171 later versions architectures suppor 64bit address space arm thumb superh m32r mips16 6991 7991 5991 2991 5891 decnuonna etadinstruction size bits 32 16 16 1632 1632 address space size model32 bits ß 32 bits ß 32 bits ß 32 bits ß 3264 bits ß dengila dengila dengila dengila dengila tnemngila ataddata addressing modes 6 64 3 2 integer registers number model size 15 gpr x 32 bits 8 gpr sp lr x 32 bits16 gpr x 32 bits 16 gpr x 32 bits 8 gpr sp ra x 3264 bits deppam yromem deppam yromem deppam yromem deppam yromem deppam yromem oifigure e12 summary ﬁ architectures embedded applications except number data address modes instruction set details integer instruction sets architectures similar con trast figure e171 e2 addressing modes instruction formats e 5 ere never another class computers similar similarity allows presentation 10 architectures 50 pages characteristics desktop server riscs found figure e11 embedded riscs figure e12 notice embedded riscs tend 8 16 generalpurpose registers desktopserver riscs 32 length instructions 16 32 bits embedded riscs always 32 bits desktopserver riscs although shown separate embedded instruction set architectur umb mips16 really optional modes arm mips invoked call instructions mode execute subset native architecture using 16bitlong instruction ese 16bit instruction sets intended full architectures enough encode procedures machines expect procedures homogeneous instructions either 16bit mode 32bit mode programs consist procedures 16bit mode density 32bit mode performance one complication description older riscs extended years decided describe latest versions architectures mips64 alpha version 3 parisc 20 sparc version 9 desktopserver arm versio umb version 1 hitachi superh sh3 m32r version 1 mips16 version 1 embedded ones e remaining sections proceed follows er discussing addressing modes instruction formats risc architectures present survey instruction steps instructions found mips core whic ned chapters 2 3 main text multimedia extensions desktopserver riscs digital signalprocessing extensions embedded riscs instructions found mips core found two architectures e unique instructions characteristics ten architectures give evolution instruction sets th nal section conclude speculation future directions riscs e2 addressing modes instruction formats figure e21 shows data addressing modes supported desktop architectures since one register always value 0 used address modes absolute address mode limited range synthesized using zero base displacement addressin register changed e6 appendix e survey risc architectures alu operations powerpc always 0 machines similarly register indirect addressing synthesized using displacement addressing set 0 simp ed addressing modes one distinguishing feature risc architectures figure e22 shows data addressing modes supported embedded architectures unlike desktop riscs embedded machines reserve register contain 0 although two three simple addressing modes arm superh several including fairly complex calculations arm addressing mode ca one register amount add registers form address update one register new address references code normally pcrelative although jump register indirect supported returning procedures case statements pointer function calls one variation pcrelative branch addresses ar ed two bits added pc desktop riscs thereby increasing branch distance works length instructions desktop riscs 32 bits instructions must aligned 32bit words memory embedded architectures 16bitlong instructions usuall pcrelative address 1 similar reasons addressing mode alpha mips64 parisc 20 powerpc sparcv9 register offset displacement based x x x xx x x sdaol x pf x dexedni retsiger retsigerregister scaled register scaled x register offset update register x x register register update register x x figure e21 summary data addressing modes supported desktop architectures pa risc also short address versions set addressing modes mips64 indexed addressing fo oatingpoint loads stor ese addressing modes described figure 218 addressing mode armv4 thumb superh m32r mips16 register offset displacement based x x x x x register register indexed x x x x delacs retsiger delacs retsigerregister offset update register x register register update register x x x tceridni retsigerautoincrement autodecrement x x x x sdaol x x sdaol x x atad evitalercpfigure e22 summary data addressing modes supported embedded architectures superh m32r separate register indirect register set addressing modes rather putting 0 set latter mode increases use 16bit instructions m32r gives wider set address modes erent data transfer instructions superh get greater addressing range arm umb set one two bits data size halfword word ese addressing modes described figure 218 e2 addressing modes instruction formats e 7figure e23 shows format desktop risc instructions include size address instruction set architecture uses four primary instruction formats figure e24 shows six formats embedded risc mac e desire smaller code size via 16bit instructions leads instruction formats registerregisteralphamips powerpc parisc sparc 31292418131240 312520151040 op6opx11opx6opx11opx8opx11op6op6op6rs15rs15rs15rd5rd5rd5rd5const5op2opx6rs25rs150rs25rs25rs25rs25rs15rd5registerimmediatealphamipspowerpc parisc sparc 3129241813120 051025213op6const16const16const16const16const13op6op6op6rd5rs15rs25rd5op2opx6rs15rs151rd5rd5rs15rd5branchalphamips powerpc parisc sparc 312918120 1051025213op6const21const16const14opx2const11occonst19op6op6op6rs15rs15rs25opx6op2opx11opx3opx5rs25rs15rs15jumpcallalphamipspowerpcparisc sparc 31292015120 10025213op6const21const26const24opx2const21o1c1const30op6op6op6rs15op2opcoderegisterconstantfigure e23 instruction formats desktopserver risc architectures ese four formats fo architectur e superscr notation gure means width eld bits although regist elds located similar pieces instruction aware destination two sour elds scrambled op main opcode opx opcode extension rd destination register rs1 source register 1 rs2 source register 2 const constant used immediate address unlike riscs al pha format immediates arithmetic logical operations erent data transfer format shown provides 8bit immediate bits 20 13 rr format bits 12 5 remaining opcode extension e8 appendix e survey risc architectures opcoderegisterconstant registerregisterarmthumb superh m32r mips1615107410 312719151130 opx4opx4opx4opx4opx4opx8op6op4op4rd4rd4rs24op5rs13rs23rs14rd4opx2rd3rs3rs4rd3rs14registerimmediatearmthumbsuperhm32rmips161510740 31271915110 opx4opx4op3const12op5op4op4rd4rd4op5rs3const5rs14rd4rd3const8const8rs4rd3const16data transferarmthumbsuperhm32rmips161510740 31271915110 opx4opx4op3const12op5op4op4rd4rd4rs4op5rs3const5rs14rd4const5rs3rd3const4rs4rd3const16brancharmthumb superh m32rmips16151070 0327213opx4opx4opx4op4const24op4op8op4rd4op5const8const8const8rs4rd3const16jumparmthumbsuperhm32r mips1615100 0327213opx4opx4op4const24op5op4op4op5const11const11const12const8callarm thumbsuperh m32rmips16052510327213opx4op8op4const24op5op4op6const26const11opx5const11const12const24figure e24 instruction formats embedded risc architectures ese six formats fo architectur e notation figure e23 note similarities branch jump call formats diversity registerregister registerimmediate data transfer formats e erences result whether architecture 8 16 registers whether 2 3operand format whether instruction length 16 32 bits e3 instructions mips core subset e 9figures e25 e26 show variations extending constan elds full width registers subtle point riscs similar identical e3 instructions mips core subset e similarities architecture allow simultaneous descriptions starting operations equivalent mips core mips core instructions almost every instruction found mips core found architectures figures e31 e35 show reference nitions mips instructions found mips reference data card beginning book instructions listed four categories data transfer figure e31 arithmeticlogical figure e32 control figure e33 oating point figur h category figure e35 shows conventions register format instruction category alpha mips64 parisc 20 powerpc sparcv9 ngisngisngisngisngisllahcnarbngisngisngisñngisllallacpmujregisterimmediate data transfersign sign sign sign sign registerimmediate arithmeticzero sign sign sign sign ngisorezñorezorezlacigoletaidemmiretsigerfigure e25 summary constant extension desktop riscs e constants jump call instructions mips signextended since replace lower 28 bits pc leaving upper 4 bits unchanged parisc logi cal immediate instructions format instruction category armv4 thumb superh m32r mips16 ngis ngis ngis ngis ngis lla hcnarb ñ ngis ngis orezngis ngis lla llacpmujregisterimmediate data transferzero zero zero sign zero registerimmediate arithmeticzero zero sign sign zerosign ñ orez orez ñ orezlacigol etaidemmiretsigerfigure e26 summary constant extension embedded riscs e 16bitlength instructions much shorter immediates desktop riscs typically eight bits embedded riscs however way get long address procedure calls two sequencial halfword e constants jump call instructions mips signextended since replace lower 28 bits pc leaving upper 4 bits unchanged e 8bit immediates arm rotated right even number bits 2 30 yielding large range immediate values example powers two immediates arm e10 appendix e survey risc architectures data transfer instruction formats ri ri ri rr ri rr ri rr instruction name alpha mips64 parisc 20 powerpc sparcv9 load byte signed ldbu sextb lb ldb extrws 318 lbz extsb ldsb load byte unsigned ldbu lbu ldb ldbx ldbs lbz ldub load halfword signed ldwu sextw lh ldh extrws 3116 lha ldsh load halfword unsigned ldwu lhu ldh ldhx ldhs lhz lduh load word ldls lw ldw ldwx ldws lw ld load sp ß oat ldslwc1 fldwx fldws lfs ldf load dp ß oat ldt ldc1 flddx fldds lfd lddf store byte stb sb stb stbx stbs stb stb store halfword stw sh sth sthx sths sth sth store word stl sw stw stwx stws stw st store sp ß oat sts swc1 fstwx fstws stfs stf store dp ß oat stt sdc1 fstdx fstds stfd stdf read write special registers mf_ mt_ mf mt_ mfctl mtctl mfspr mf_ mtspr mt_ rd wr rdpr wrpr ldxfsr stxfsr move integer fp register itofs mfc1dmfc1 stw fldwx stw ldfs st ldf move fp integer register fttois mtc1dmtc1 fstwx ldw stfs lw stf ld figure e31 desktop risc data transfer instructions equivalent mips core sequence instructions synthesize mips instruction shown separated semicolons several choices instructions equivalent mips core separated commas th gure halfword 16 bits word 32 bits note alpha lds converts single precisio oating point double precision loads entire 64bit register usage pseudoinstructions architecture mips core instruction requires short sequence instructions architectures instructions separated semicolons figures e31 e35 avoid confusion destination register always th operand appendix independent notation normally used architecture figures e36 e39 show equivalent listing embedded riscs note tha oating point generally ned embedded riscs every architecture must scheme compare conditional branch despite similarities architectures fo erent way perform operation compare conditional branchsparc uses traditional four condition code bits stored program status word negative zero carry ow ey set arithmetic logical instruction unlike earlier architectures setting optional instruction explicit option leads fewer problems pipelined implementation although condition codes ect operation explicit compares synthesized subtract using r0 destination sparc conditional branches e3 instructions mips core subset e 11arithmeticlogical instruction formats rr ri rr ri rr ri rr ri rr ri instruction name alpha mips64 parisc 20 powerpc sparcv9 add addl addu adduaddl ld0 addi uaddcmadd addiadd add trap overß ow addlvadd addiaddo addioaddo mcrxr bcaddcc tvssub sublsubusub subisubfsub sub trap overß ow sublvsubsubto subiosubfoesubcc tvsmultiply mullmult multushiadd i123mullw mullimulx multiply trap overß ow mullvñshiaddoññdivide ñdiv divuds dsdivwdivx divide trap overß ñññññ wo andand dnadnaidna andiand bisor roroiro orior xor xorxor roxroxirox xori xorload high part register ldah lui ldil addis sethi b fmtshift left logical sllsllv slldepw z 31i32i rlwinmsll shift right logical srlsrlv srlextrw u 31 32irlwinm 32isrl shift right arithmetic sra srav sra extrw 31 32israwsra compare cmpeq cmplt cmplesltu ccbusrlcipmcbmocuitls r0 figure e32 desktop risc arithmeticlogical instructions equivalent mips core dashes mean operation available architecture synthesized instructions sequence instructions shown separated semicolons several choices instructions equivalent mips core separated commas note arithmeticl ogical category machines sparc use separate instruction mn emonics indicate immediate operand sparc ers immediate versions instructions uses single mnemonic course separate opcodes control instruction formats b jc b jc b jc b jc b jc instruction name alpha mips64 parisc 20 powerpc sparcv9 branch integer compareb_ notbeq bne b_z comb comib bc br_z bpcc branch ß oatingpoint comparefb_ notbc1t bc1ffstwx f0 ldw bb bc fbpfcc jump jump register br jmp j jr bl r0 blr r0 b bclr bcctr ba jmpl r0call call register bsr jal jalr bl ble bl bla bclrl bcctrlcall jmpl trap call_pal gentrap break break tw twi ticc sir return interrupt call_pal reijr eret rfi rfir rfi done retry returnfigure e33 desktop risc control instructions equivalent mips core several choices instructions equivalent mips core separated commas e12 appendix e survey risc architectures floating point instruction formats rr rr rr rr rr instruction name alpha mips64 parisc 20 powerpc sparcv9 add single double adds addt adds adddfadd fadddbl fadds fadd fadds faddd subtract single double subs subt subs subd fsub fsubdbl fsubs fsubfsubs fsubd multiply single double muls mult muls muld fmpy fmpydblfmuls fmulfmuls fmuld divide single double divs divt divs divd fdiv fdivdblfdivs fdiv fdivs fdivd compare cmpt_ unc_s c_d fcmp fcmpdbl fcmp fcmps fcmpd move rr addt fd f31 fsmovs movd fcpy fmv fmovsdq convert single double integer single double integer cvtst cvtts cvttq cvtqs cvtqt cvtsd cvtds cvtsw cvtdw cvtws cvtwdfcnvffsd fcnvffds fcnvxfss fcnvxfdd fcnvfxss fcnvfxdsñ frsp ñ fctiwñ ñ fstod fdtos fstoi fdtoi fitos fitod figure e34 desktop risc ﬂ oatingpoint instructions equivalent mips core dashes mean operation available architecture synthesized instructions several choices instructions equivalent mips core separated commas conventions alpha mips64 parisc 20 powerpc sparcv9 register value 0 r31 source r0 r0 r0 addressing r0 return address register r31 r2 r31 link special r31 noop ldq_u r31 sll r0 r0 r0or r0 r0 r0 ori r0 r0 0 sethi r0 0 move rr integer bis r31 add r0or r0 rx ry ry r0 operand order op rs1 rs2 rdop rd rs1 rs2op rs1 rs2 rdop rd rs1 rs2op rs1 rs2 rd figure e35 conventions desktop risc architectures equivalent mips core test condition codes determine possible unsigned signed relations floating point uses separate condition codes encode ieee 754 conditions requirin oatingpoint compare instruction version 9 expanded sparc branches four ways separate set condition codes 64bit operations branch tests contents register branches value 0 see mips three sets oatingpoint condition codes branch instructions encode static branch prediction powerpc also uses four condition codes less greater equal summary owbut eight copies th redundancy allows powerpc instructions us erent condition codes without co ict essentially giving powerpc eight extra 4bit registers eight condition codes target compare instruction source conditional branc e integer instructions option bit behaves integer op e3 instructions mips core subset e 13instruction name armv4 thumb superh m32r mips16 data transfer instruction formats dt dt dt dt dt load byte signed ldrsb ldrsb movb ldb lb load byte unsigned ldrb ldrb movb extub ldub lbu load halfword signed ldrsh ldrsh movw ldh lh load halfword unsigned ldrh ldrh movw extuw lduh lhu load word ldr ldr movl ld lw store byte strb strb movb stb sb store halfword strh strh movw sth sh store word str str movl st sw read write special registers mrs msr ñ1 ldc stc mvfc mvtc move figure e36 embedded risc data transfer instructions equivalent mips core sequence instructions synthesize mips instruction shown separated semicolons note tha oating point generally ned embe umb mips16 16bit instruction subsets arm mips architectures machines switch modes execute ful l instruction set use 1 show sequences available 32bit mode 16bit mo umb mips16 followed compare zero sets th rst condition register powerpc also lets second register optionally set b oatingpoint instructions powerpc provides logical operations among eight 4bit condition code registers crand cror crxor crnand crnor creqv allowing complex conditions tested single branch mips uses contents registers evaluate conditional branches two registers compared equality beq inequality bne branch taken condition ho e set less instructions slt slti sltu sltiu compare two operands set destination register 1 less 0 otherwise ese instructions enough synthesize full set relations popularity comparisons 0 mips includes special compare branch instructions comparisons greater equal zero bgez greater zero bgtz less equal zero blez less zero bltz course equal equal zero synthesized using r0 beq bne like sparc mips uses condition code fo oating point separate oatingpoint compare branch instructions mips iv expanded eight oatingpoint condition codes th oating point comparisons branch instructions specifying condition set test alpha compares cmpeq cmplt cmple cmpult cmpule test two registers set third 1 condition true 0 otherwise floatingpoint compares cmteq cmtlt cmtle cmtun set result 20 condition holds 0 otherwise e branch instructions compare one register 0 beq bge bgt ble blt bne le cant bit 0 blbc blbs branch condition holds e14 appendix e survey risc architectures parisc many branch options well see sectio e straightforward compare branch instruction comb compares two registers branches depending standard relations tests least cant bit result comparison arm similar sparc provides four traditional condition codes optionally set cmp subtracts one operand th erence sets condition codes compare negative cmn adds one operand sum sets condition codes tst performs logical two operands set condition codes ow teq uses exclusive set th rst three condition codes like sparc conditional version arm branch instruction tests condition codes determine possible unsigned signed relations arithmeticlogical instruction formats rr ri rr ri rr ri rr ri rr ri instruction name armv4 thumb superh m32r mips16 add add add add add addi add3 addu addiu add trap overß ow adds swivs add bvc 4 swiaddv addv addv3 ñ1 subtract sub sub sub sub subu subtract trap overß ow subs swivs sub bvc 1 swi subv subv ñ1 multiply mul mul mul mul mult multu multiply trap overß ow ñdivide ññ div1 divos divou div divu div divu divide trap overß ñññ wo and3 orr orr or3 xor eor eor xor xor xor3 xor load high part register ññ seth ñ1 shift left logical lsl3lsl2shll shlln sll slli sll3 sllv sll shift right logical lsr3lsr2shrl shrln srl srli srl3 srlv srl shift right arithmetic asr3asr2shra shad sra srai sra3 srav sra compare cmpcmn tstteq cmp cmn tstcmpcond tst cmpi cmpui cmpi2 slti sltiu figure e37 embedded risc arithmeticlogical instructions equivalent mips core dashes mean operation available architecture synthesized instructions sequence instructions shown separated semicolons several choices instructions equivalent mips core separated co umb mips16 16bit instruction subsets arm mips architectures machines switch modes execute full instruction set use 1 show sequences available 32bit mode 16bit mo umb e superscript 2 shows new instructions found 16bit mode umb mips16 cmpi 2 arm incl part every data operation instruction th superscript 3 variation move instruction lsr 3 e3 instructions mips core subset e 15as shall see section e12 one unusual feature arm every instruction option executing conditionally depending condition co bears similarities annulling option parisc seen section e11 surprisingly umb follo e erences setting condition codes optional teq instruction dropped conditional execution instructions e hitachi superh uses single tbit condition set compare instructions two branch instructions decide branch either bit 1 bt bi e tw avors branches allow fewer comparison instructions mitsubishi m32r also ers single condition code bit c used signed unsigned comparisons cmp cmpi cmpu cmpui see one register less similar mips set less instructions two branch instructions test see c bit 1 0 bc bn e m32r also includes instructions branch equality inequality registers beq bne relations register 0 bgez bgtz blez bltz beqz bnez unlike bc bnc last instructions 32 bits wide mips16 keeps set less instructions slt slti sltu sltiu instead putting result one eight registers placed special register named mips16 always implemented machines also full 32bit mips instructions registers hence register really register 24 full mips architecture e mips16 branch instructions test see register equal zero beqz bnez ere also instructions branch conventions armv4 thumb superh m32r mips16 return address reg r14 r14 pr special r14 ra special noop mov r0 r0 mov r0 r0 nop nop sll r0 r0 operands order op rd rs1 rs2 op rd rs1 op rs1 rd op rd rs1 op rd rs1 rs2 figure e39 conventions embedded risc instructions equivalent mips core control instruction formats b j c b j c b j c b j c b j c instruction name armv4 thumb superh m32r mips16 branch integer compare bcond bcond bf bt beq bne bc bnc b__z beqz 2 bnez 2 bteqz 2 btnez2jump jump register mov pc ri mov pc ri bra jmp bra jmp b 2 jr call call register bl bl bsr jsr bl jl jal jalr jalx 2 kaerb part apart iws iws part return interrupt movs pc r14 ñ1ñ etr str1figure e38 embedded risc control instructions equivalent mips core umb mips16 16bit instruction subsets arm mips architectures machines switch modes execute full instruction set use 1 show sequences available 32bit mode 16bit mo umb e superscript 2 shows new instructions found 16bit mode umb mips16 bteqz 2 e16 appendix e survey risc architectures register equal zero bteqz btnez test two registers equal mips added compare instructions cmp cmpi compute exclusive two registers place result register compare added since instructions compare branch registers equal beq bnefigures e310 e311 summarize schemes used conditional branches e4 instructions multimedia extensions desktopserver riscs since every desktop microprocessor nition graphical displays transistor budgets increased inevitable support would added graphics operations many graphics systems use eight bits represent three primary colors plus eight bits location pixel alpha mips64 parisc 20 powerpc sparcv9 number condition code bits integer fp0 8 fp 8 fp 8 4 2 4 integer 4 2 fp basic compare instructions integer fp 1 integer 1 fp1 integer 1 fp 4 integer 2 fp 4 integer 2 fp 1 fp basic branch instructions integer fp 1 2 integer 1 fp 7 integer 1 3 integer 1 fp compare register registerconst branch ñ even odd ñ ñ compare register zero branch even odd even odd ñ figure e310 summary ﬁ desktop risc approaches conditional branches floatingpoint branch parisc accomplished copying fp status register integer register using branch bit instruction test th e fp comparison bit integer compare sparc synthesized arithmetic instruction sets condition codes using r0 desti nation armv4 thumb superh m32r mips16 number condition code bits 4 4 1 1 1 basic compare instructions 4 3 2 2 2 basic branch instructions 1 1 2 3 2 compare register registerconst branchñ ñ ñ compare register zero branch ñ ñ figure e311 summary ﬁ embedded risc approaches conditional branches e4 instructions multimedia extensions desktopserver riscs e 17 e addition speakers microphones teleconferencing video games suggested support sound well audio samples need eight bits precision 16 bits ar cient every microprocessor special support bytes halfwords take less space stored memory due infrequency arithmetic operations data sizes typical integer programs little support beyond data transfer e architects intel i860 ju ed graphical accelerator within company recognized many graphics audio applications would perform operation vectors data although vector unit beyond transistor budget i860 1989 partitioning carry chains within 64bit alu could perform simultaneous operations short vectors eight 8bit operands four 16bit operands two 32bit opera e cost partitioned alus small applications lend support include mpeg video games like doom 3d graphics adobe photoshop digital photography teleconferencing audio image processing like virus time multimedia support spread nearly every desktop microprocessor hp th rst successful desktop risc include support shall see virus spread unevenly e powerpc holdout rumors running fever ese extensions called subword parallelism vector simd single instruction multiple data see chapter 6 since intel marketing uses simd describe mmx extension 8086 become popular name figure e41 summarizes support architecture figure e41 see general mips mdmx works eight bytes four halfwords per instruction hp parisc max2 works four half words sparc vis works four halfwords two words alpha doesnt muc e alpha max operations byte versions compare min max absolut erence leaving ware isolat elds perform parallel adds subtracts multiplies bytes halfwords mips also added operations work two 32bi oatingpoint operands per cycle considered part mips v simply multimedia extensions see section e7 one feature generally found generalpurpose microprocessors saturating operations saturation means calculation ows result set largest positive number negative number rather modulo calculation twos complement arithmetic commonly found digital signal processors see next section saturating operations helpful routines fo ltering ese machines largely used existing register sets hold operands integer registers alpha hp parisc oatingpoint registers mips sun hence data transfers accomplished standard load store instructions mips also added 192bit 364 wide register act accumulator operations three times native data width partitioned accumulate either eight bytes 24 bits p eld four halfwords 48 bits e18 appendix e survey risc architectures p wide accumulator used add subtract multiply add instructions mips claims performance advantages two four times accumulator perhaps surprising conclusion table lack consistency e operations found four logical operations xor need partitioned alu leave frugal alpha common operations parallel adds subtracts four halfwords manufacturer states instructions intended used handoptimized subroutine libraries intention likely followed compiler works well multimedia extensions desktop riscs would challenging instruction category alpha max mips mdmx parisc max2 powerpc sparc vis w2 h4 h4 h4 b8 tcartbusdda h4 h4 b8 busdda gnitarutas hb4 h4 b8ylpitlum ton w2 h4 h4 b8 b8 erapmoc h4 h4 b8 tfelthgir tfihs h4 h4 citemhtira thgir tfihs h4 b8 dda dna ylpitlumshift add saturating 4h w2 h4 b8 w2 h4 b8 w2 h4 b8 w2 h4 b8 roxrodnaabsolute difference 8b 8b maxmin 8b 4w 8b 4h pack 2 n bits n b2w2 h2w2b8h42 b8h42 h4w22 b4h4 b2w2 stib 4h4b b8b42 h4b4h4h22 b8b42 h4b4 w2b2 egremkcapnu h4 h4 b8e ßfuhsetumrep tp lf regetni cca b291 tp lf regetni stes retsigerfigure e41 summary multimedia support desktop riscs b stands byte 8 bits h half word 16 bits w word 32 bi us 8b means operation eight bytes single instruction pack unpack use notation 22w mean two operands two words note mdmx vectorscalar operations scalar sp ed element one vector register table simp cation full multimedia architectures leaving many details example mips mdmx includes instructions multiplex two operands hp max2 includes instruction calculate averages sparc vis includes nstructions set registers constants also table include memory alignment operation mdmx max vis e5 instructions digital signalprocessing extensions embedded riscs e 19 e5 instructions digital signalprocessing extensions embedded riscsone feature found every digital signal processor dsp architecture support integer multiplyaccumulate e multiplies tend shorter words regular integers 16 bits accumulator tends longer words 64 bi e reason multiplyaccumulate ciently implement digit lters common dsp applications umb mips16 subset architectures provide support instead programmers use dsp multimedia extensions found 32bit mode instructions arm mips64 figure e51 shows size multiply size accumulator operations instruction names embedded riscs machines accumulator sizes greater 32 less 64 bits force upper bits remain sign bits thereby saturating add set maximum minim xedpoint values operations ow armv4thumb superh m32r mips16 size multiply 32b 32b ñ 32b 32b 16b 16b 32b 16b 16b 16b ñ ñ b65 b46b84 b24b23 ñ b46b23 rotalumucca fo ezis ñ cca lcam hcam ñ srpg fo sriap ro rpg yna eman rotalumuccaoperations 32b64b product 64b accumulate signedunsignedñ 32b product 42b32b accumulate operands memory 64b product 64b48b accumulate operands memory clear mac 32b48b product 64b accumulate round move ñ corresponding instruction names mla smlal umlalñ mac macs macl macls clrmac machimaclo macwhimacwlo rac rach mvfachi mvfaclo mvtachi mvtaclo ñ figure e51 summary ﬁ embedded risc approaches multiplyaccumulate e20 appendix e survey risc architectures e6 instructions common extensions mips corefigures e61 e67 list instructions found figures e35 e311 four categories instructions put lists appear one standard architectur e instructions ar ned using hardware description languag ned figure e68 although categories selfexplanatory bear comment e atomic swap row means primitive exchange register memory without interruptio useful operating system semaphores uniprocessor well multiprocessor synchronization see section 211 chapter 2 e 64bit data transfer operation rows show mips powerpc spar ne 64bit addressing integer operations sparc simply nes register addressing operations 64 bits adding name deþ nitionalphamips64parisc 20powerpcsparcv9 atomic swap rm locks semaphores temprd rdðmemx memxtemp ldlq_l stlq_c scñ see d8 lwarx stwcx casa casxload 64bit integerrdð 64 memx ldq ld lddld ldx store 64bit integermemx 64 rd stq sd std std stx load 32bit integer unsigned rd3263ð32 memx rd031ð32 0 ldl extll lwu ldwlwz lduw load 32bit integer signed rd3263ð32 memx 32 rd031ð32 memx0 ldllw ldw extrds 63 8 lwa ldswprefetch cachexðhint fetch fetch_mpref prefxldd r0 ldw r0 dcbt dcbtst prefetch load coprocessor coprocessorð memx ñ lwci cldwx cldws ñ ñ store coprocessor memxð coprocessor ñ swci cstwx cstws ñ ñ endianbiglittle endian eithereithereithereither either cache ß ushflush cache block addressecbcp0opfdc ficdcbfflush shared memory synchronizationall prior data transfers complete next data transfer may start wmbsyncsyncsyncmembar figure e61 data transfer instructions found mips core found two ﬁ desktop architectures e load linkedstore conditional pair instructions gives alpha mips atomic operations semaphores allowing data read memory mo ed stored without fear interrupts machines accessing data multiprocessor see chapter 2 prefetching alpha external caches accomplished fetch fetch_m onchip cache prefetches use ld_q r31 ld_y f31 used alpha 21164 see bhandarkar 1995 p 190 e6 instructions common extensions mips core e 21name deþ nitionalphamips64parisc 20powerpcsparcv9 64bit integer arithmetic opsrdð64rs1 op64 rs2add sub muldadd dsub dmult ddivadd sub shladd dsadd subf mulld divdadd sub mulx sudivx 64bit integer logical opsrdð64rs1 op64 rs2 xorand xorand xorand xorand xor64bit shifts rdð 64rs1 op64 rs2sll sra srldsllv dsrav dsrlvdepdz extrds extrdusld srad srldsllx srax srlx conditional move cond rdðrs cmov_ movnz subc n add ñ movcc movr support multiword integer addcarryout rd ð rs1 rs2 oldcarryout ñ adu sltu addu dadu sltu dadduaddc addc adde addcc support multiword integer sub carryout rd ð rs1 rs2 oldcarryout ñ subu sltu subu dsubu sltu dsubu subb subfc subfe subcc rd ð rs1 rs2 bicñandcm andc andn notrd ð rs1 rs2 ornotññorcorn add high immediate rd 015ðrs1015 const16ññaddil ri addis ri ñ coprocessor operationsdeþ ned coprocessorñ copi copriñimpdepi figure e62 arithmeticlogical instructions found mips core found two ﬁ desktop architecturesname deþ nitionalphamips64parisc 20powerpcsparcv9 optimized delayed branchesbranch always delayed ñ beql bnel b_zl combt n combf nñ bpcc fpbcc conditional trap cond r31pc pc ð00i ñ t_t_i subc n breaktw td twi tdi tcc control registers misc regs virtual memory interrupts 6equiv 12323329 figure e63 control instructions found mips core found two ﬁ desktop architectures special instructions 64bi data transfers branches mips includes extensions plus adds separate 64bit signed arithmetic instructions powerpc adds 64bit righ load store divide compare separate mode determining whether instructions interpreted 32 64bit operations 64bit operations work machine e22 appendix e survey risc architectures name deþ nitionalphamips64parisc 20powerpcsparcv9 multiply add fd ð fs1 fs2 fs3 ñ maddsd fmpyfadd sgldblfmadds multiply sub fd ð fs1 fs2 ð fs3 ñ msubsd fmsubs neg mult add fd ð fs1 fs2 fs3 ñ nmaddsd fmpyfneg sgldblfnmadds neg mult sub fd ð fs1 fs2 ð fs3 ñ sbusmnfdsbusmn square root fd ð sqrtfs sqrt_ sqrtsd fsqrt sgldbl fsqrtsfsqrtsd conditional move cond fdðfs fcmov_ movft movftsd ftestfcpy ñ fmovcc negate fd ð fs x80000000 cpysn negsd fneg sgldbl fneg fnegsdq absolute value fd ð fs x7fffffff ñ abssd fabsdbl fabs fabssdq figure e64 floatingpoint instructions found mips core found two ﬁ desktop architecturesname deþ nition armv4 thumb superh m32r mips16 atomic swap rm semaphorestempðrd rdðmemx memxðtemp swp swpb ñ1see tas lock unlockñ1 memory management unitpaged address translation via coprocessor instructions ñ1ldtlb ñ1endian biglittle endian either either either big either figure e65 data transfer instructions found mips core found two ﬁ embedded architectures use 1 show sequences available 32bit mode 16bit mo umb mips16 supports 32bit mode parisc expanded 64bit addressing operations version 20 e prefetch instruction supplies address hint implementation data hints include whether data likely read written soon likely read written likely read written many times prefetch cause exceptions mips version adds two registers get address fo oatingpoint programs unlike oatingpoint mips programs endian row biglittle means bit program status register allows processor act either big endian little endian see app accomplished simply complementing le cant bits address data transfer instructions e6 instructions common extensions mips core e 23name deþ nition armv4 thumb superh m32r mips16 load immediate rdimm mov mov mov mova ldi ld24 li support multiword integer addcarryout rd rd rs1 oldcarryout adcs adc addc addx ñ1 support multiword integer subcarryout rd rd ð rs1 oldcarryout sbcs sbc subc subx ñ1 1sr ð 0 dr etagenneg2neg neg neg 1sr drtonmvn mvn 1sr dr evommov mov mov mv move rotate right rd rs rd0 ið1 rs31ði 31ror ror rotc 2sr 1sr dr ton dnabic bic figure e66 arithmeticlogical instructions found mips core found two ﬁ embedded architectures use 1 show sequences available 32bit mode 16bit mo umb e superscript 2 shows new instructions found 16bit mode umb mips16 neg 2name deþ nition armv4 thumb superh m32r mips16 control registers misc registers 2129 9536 figure e67 control information ﬁ embedded architectures e shared memory synchronization helps cachecoherent multi processors loads stores executed instruction must complete loads stores er start see chapter 2 e coprocessor operations row lists several categories allow processor extended specialpurpose hardware erence needs longer explanation optimized branches figure e69 shows option e alpha powerpc er branches tak ect immediately like branches earlier architectures accelerate branches machines use branch prediction see chapter 4 rest desktop riscs er delayed branches see app e embedded riscs generally support delayed branch exception superh option e three desktop riscs provide version delayed branch makes easier delay slo e sparc annulling branch executes instruction delay slot branch taken otherwise instruction annulled means instruction target branch safely copied delay slot since executed branch tak e restrictions target another branch target known compile time sparc also ers nondelayed jump unconditional branch annul bit set execute following instruction later versions mips e24 appendix e survey risc architectures plain branch delayed branch annulling delayed branch found architecturesalpha powerpc arm thumb superh m32r mips16 mips64 parisc sparc superh mips64 sparcparisc execute following instructiononly branch taken always branch taken forward branch taken backward branch taken figure e69 instruction following branch executed three types branches gninaem elpmaxe gninaem noitatondata transfer length transfer given destinationõs length length speciþ ed clear regsr1regsr2 transfer contents r2 r1 registers þ xed length transfers shorter register size must indicate bits used array memory accessed bytes starting address transfer indicated index memory array regsr1mx place contents memory location x r1 transfer starts mi requires 4 bytes transferred bytes mi mi1 mi2 mi3 n transfer nbit þ eld used whenever length transfer clear my16mx transfer 16 bits starting memory location x memory location length two sides match xn subscript selects bit regsr100 change sign bit r1 0 bits numbered msb starting 0 xmn subscript selects þ eld regsr32431mx moves contents memory location x loworder byte r3 xn superscript replicates bit þ eld regsr3023024 sets highorder three bytes r3 0 concatenates two þ elds regsr3240 mx f2f364mx moves contents location x low byte r3 clears upper three bytes moves 64 bits memory starting location x 1st 32 bits go f2 2nd 32 f3 dereference pointer get address variablepx assign object pointed p address variable x c logical shifts left right regsr1 5 shift r1 left 5 bits c relational operators equal equal greater less greater equal less equal regsr1 regsr2 regsr3regsr4true contents r1 equal contents r2 contents r3 equal contents r4 c bitwise logical operations exclusive complement regsr1 regsr2 regsr3 bitwise r1 bitwise r2 r3 figure e68 hardware description notation standard c operators e7 instructions unique mips64 e 25architecture added branch likely instruction also annuls following instruction branch taken parisc allows almost instruction annul next instruction including branches nullifying branch option execute next instruction depending direction branch whether taken ie forward branch taken backward branch taken presumably choice made optimize loops allowing instructions following exit branch looping branch exe cute common case covered similarities focus unique features architecture rst cover desktopserver riscs ordering length description unique features shortest longest embedded riscs e7 instructions unique mips64 mips gone throug generations instruction sets evolution generally added features found architectures salient unique features mips th rst several found original instruction set nonaligned data transfers mips special instructions handle mi saligned words memory rare event programs included supporting 16bit minicomputer applications memcpy strcpy faster although riscs trap try load word store word misalig ned address architectures misaligned words accessed without traps using four load byte instructions assembling result usin logical e mips load store word right instructions lwl lwr swl swr allow done two instructions lwl loads th portion register lwr loads right portion register swl swr corresponding stores figure e71 shows wo ere also 64bit versions instructions remaining instructions list remaining unique details mips64 architecture logical instruction calculates rs1 rs2 constant sh amount nonvariab use 5bit constan eld shown registerregister format figure e23 syscall special trap instruction used invoke operating system e26 appendix e survey risc architectures move tofrom control registers ctci cfci move integer registers control registers jumpcall pcrelative e 26bit address jumps calls added pc ed two bits replaces lower 28 bits pc would mak erence program located near 256 mb boundary tlb instructions translationlookaside b er tlb misses handled ware mips instruction set also instructions manipulating registers tlb see chapter 5 tlbs ese registers considered part system coprocessor since mips case 1 beforem100100101102103 dav m104r2r2afterafter104105106107 eeojhn nlwl r2 101dav r2lwr r2 104dav case 2 beforem200200201202203 dm204r4r4afterafter204205206207 evaeojhn nlwl r4 203doh r4lwr r4 206dav figure e71 mips instructions unaligned word reads gure assumes operation bigendian mode case rst loads three bytes 101 102 103 th r2 leaving least cant byte undisturbed e following lwr simply loads byte 104 le cant byte r2 leaving bytes register unchanged using lwl cas rst loads byte 203 cant byte r4 following lwr loads three bytes r4 memory bytes 204 205 206 lwl reads word th rst byte memory th discard unneeded bytes changes bytes rd e bytes transferred th rst byte lowestorder byte word e following lwr addresses last byte righ discard unneeded bytes nally changes bytes rd e bytes transferred last byte highestorder byte word store wor swl simply inverse lwl store word right swr inverse lwr changing littleendian mo ips bytes selected discarded biglittle right loadstore seem confusing dont worry work e8 instructions unique alpha e 27the instruction er among versions architecture part implementations part instruction set architecture reciprocal reciprocal square root ese instructions follow ieee 754 guidelines proper rounding included apparently applications value speed divide square root value accuracy conditional procedure call instructions bgezal saves return address branches content rs1 greater equal zero bltzal less zero e purpose instructions get pcrelative call ere likely versions instructions well parallel single precisio oatingpoint operations well extending architecture parallel integer operations mdmx mips64 also supports two parallel 32bit oatingpoint operations 64bit registers single instruction paired single operations include add addps subtract subps compare c__ps convert cvtpss cvtspl cvtspu negate negps absolute value absps move movps movfps movtps multiply mulps multiplyadd maddps multiplysubtract msubps ere sp c provision mips architecture fo oatingpoint execution proceed parallel integer execution mips implementations oating point allow happen checking see arithmetic interrupts possible early cycle normally exception detection would force serialization execution integer oatingpoint operations e8 instructions unique alpha e alpha intended architecture made easy build high performance implementations toward goal architects originally made two controversial decisions imprecis oatingpoint exceptions byte halfword data transfers simplify pipelined execution alpha require exception act instructions past certain point executed point executed supplies trapb instruction stalls prior arithmetic instructions guaranteed complete without incurring arithmetic exceptions conservative mode placing one trapb per exceptioncausing instruction slows execution roughl times provides precise exceptions see darcy gay 1996 e28 appendix e survey risc architectures code include trapb obey th oatingpoint standard e reason parts standard nan nities denormals implemented ware alpha many microprocessors implement operations ware however programs mu nd ending instruction operand values done imprecise interrupts architecture developed believed architects byte loads stores would slow data transfers byte loads require er data transfer path byte stores require memory system perform readmodifywrite memory systems error correction codes since new ecc value must recalculated omission meant byte stores required sequence load word replaced desired byte stored word inconsistently oatingpoint loads go considerable byte swapping convert obtuse v oatingpoint formats canonical form reduce number instructions get desired data alpha includes elaborate set byte manipulation instructions extrac eld zero rest register extxx inser eld insxx mask rest register mskxx zer elds register zap compare multiple bytes cmpgeapparently implementors bothered load store byte original architects beginning shrink second version alpha chip 21164a architecture include loads stores bytes halfwords remaining instructions list remaining unique instructions alpha architecture pal code provide operations vax performed microcode alpha provides mode runs privileges enabled interrupts disabled virtual memory mapping turned instructions pal privileged architecture library code used tlb management atomic memory operations operating system primitives pal code called via call_pal instruction divide integer divide supported hardware unaligned loadstore ldq_u stq_u load store 64bit data using addresses ignore le cant three bits extract instructions select desired unaligned word using lower address bi ese instructions similar lwlr swlr mips floatingpoint single precision represented double precision single precision data kept conventional 32bit formats memory converted 64 bit double precision format registers floatingpoint regist xed zero simplify comparisons zero e9 instructions unique sparc v9 e 29 va oatingpoint formats maintain compatibility vax architecture addition ieee 754 single double precision formats called alpha supports vax single double precision formats called f g vax format narrow exponen eld useful double precision replaced g vax code bit count instructions version 3 architecture added instructions count number leading zeros ctlz count number trailing zeros cttz count number ones word ctpop originally found cray computers instructions help decryption e9 instructions unique sparc v9 several features unique sparc register windows e primary unique feature sparc register windows optimization reducing register tra c procedure calls several banks registers used new one allocated procedure call although could limit depth procedure calls limitation avoided operating banks circular bu er providing unlimited dept e knee costperformance curve seems six eight banks sparc 2 32 windows typically using 8 registers globals locals incoming parameters outgoing parameters given window 16 unique registers implementation sparc 40 physical registers many 520 although 128 136 far rather tie window changes call return instructions sparc separate instructions save restore save used save callers window pointing next window registers addition performing add instructio e trick source registers callers window addition operation destination register callees window sparc compilers typically use instruction changing stack pointer allocate local variables new stack frame restore inverse save bringing back callers window acting add instruction source registers callees window destination register callers window automatically deallocates stack frame compilers also make use generating callees nal return value e danger register windows larger number registers could slow clock rate case early implementation e sparc architecture register windows mips r2000 architecture without e30 appendix e survey risc architectures built several technologies since 1987 several generations sparc clock rate slower mips clock rate implementations similar technologies probably cache access times dominate register access times implementation e currentgeneration machines took erent implementation strategiesin order versus orderand unlikely number registers determined clock rate either machine recently architectures included register windows tensilica ia64 another data transfer feature alternate space option loads stores simply allows memory system identify memory accesses input output devices control registers devices cache memory management unit fast traps version 9 sparc includes support make traps fast expands single level traps least four levels allowing window ow ow trap handlers interrupted e extra levels mean handler need check page faults misaligned stack pointers explicitly code thereby making handler faster two new instruct ions added return multilevel handler retry retries interrupted instruction done support userlevel traps instruction return return trap nonprivileged mode support lisp smalltalk e primary remaining arithmetic feature tagged addition subtraction e designers sparc spent time thinking languages like lisp smalltalk th uenced features sparc already discussed register windows conditional trap instructions calls 32bit instruction addresses multiword arithmetic see taylor et al 1986 ungar et al 1984 small amount support ered tagged data types operations addition subtraction hence compariso e two le cant bits indicate whether operand integer coded 00 taddcc tsubcc set ow bit either operand tagged integer result large subsequent conditional branch trap instruction decide operands integers ware recovers operands checks types operands invokes correct operation based types turns misaligned memory access trap also put use tagged data since loading pointer wrong tag invalid access figure e91 shows types tag support e9 instructions unique sparc v9 e 31overlapped integer floatingpoint operations sparc allo oatingpoint instructions overlap execution integer instructions recover interrupt situation sparc queue pendin oatingpoint instructions addresses rdpr allows processor empty queue e seco oatingpoint feature inclusion oatingpoint square root instructions fsqrts fsqrtd fsqrtqremaining instructions e remaining unique features sparc follows jmpl uses rd specify return address register specifying r31 makes similar jalr mips specifying r0 makes like jr ldstub loads value byte rd stores ff16 addressed byte version 8 instruction used implement synchronization see chapter 2 casa casxa atomically compares value processor register 32bit 64bit value memory equal swaps value memory value second processor register version 9 add sub orcompare integers coded 00taddcc r7 r5 r6000000r5r7r6b loading viavalid pointer coded 11ld rd r4 œ3œ11003r4wordaddressfigure e91 sparc uses two least signiﬁ cant bits encode different data types tagged arithmetic instructions integer arithmetic takes single cycle long operands result integers b e misaligned trap used catch invalid memory accesses trying use integer pointer languages paired data like lisp set 3 used access even word pair car 1 used odd word pair cdr e32 appendix e survey risc architectures instruction used construct waitfree synchronization algorithms require use locks xnor calculates exclusive complement second operand bpcc bpr fbpcc include branch prediction bit compiler give hints machine whether branch likely taken illtrap causes illegal instruction trap muchnick 1988 explains used proper execution aggregate returning procedures c popc counts number bits set one operand also found third version alpha architecture nonfaulting loads allow compilers move load instructions ahead conditional control structures control use hence nonfaulting loads executed speculatively quadruple precision oatingpoint arithmetic data transfer allow oatingpoint registers act eight 128bit registers fo oatingpoint operations data transfers multiple precision oatingpoint results multiply mean two single precision operands result double precision product two double precision operands result quadruple precision produc ese instructions useful complex arithmetic models oating point calculations e10 instructions unique powerpc powerpc result several generations ibm commercial risc machines ibm rtpc ibm power1 ibm power2plus motorola 8800 branch registers link counter rather dedicate one 32 generalpurpose registers save return address procedure call powerpc puts address special register called link register since many procedures return without calling another procedure link doesnt always saved making return address special register makes return jump faster since hardware need go register read pipeline stage return jumps similar vein powerpc count register used loops program iterat xed number times using special register branch e10 instructions unique powerpc e 33hardware determine quickly whether branch based count register likely branch since value register known early execution cycle tests value count register branch instruction automatically decrement count register given count register link register already located hardware controls branches one problems branch prediction getting target address early pipeline see appendix powerpc architects decided make second use registers either register hold target address conditional branc us powerpc supplements basic conditional branch two instructions get target address registers bclr bcctrremaining instructions unlike risc machines register 0 hardwired value 0 used base registerthat generates 0 casebut base index addressing used th e unique features powerpc follows load multiple store multiple save restore 32 registers single instruction lsw stsw permit fetching storing xed variablelength strings arbitrary alignment rotate mask instructions support bit eld extraction insertion one version rotates data per forms logical mask ones thereby extractin e version rotates data places bits destination register corresponding 1 bit mask thereby insertin eldalgebraic right shi sets carry bit ca operand negative 1 bits ar ed ou us signed divide constant power two rounds toward 0 accomplished srawi followed addze adds ca register cbtlz count leading zeros subfic computes immediate ra used develop ones twos complement logical shi ed immediate instruction 16bit immediate th 16 bits performing xor e34 appendix e survey risc architectures e11 instructions unique parisc 20 parisc expanded slightly 1990 version 11 change cantly 20 64bit extensions 1996 parisc perhaps unusual features desktop risc machine example addressing modes instruction formats shall see several instructions really combination two simpler instructions nulliﬁ cationas shown figure e69 several risc machines choose execute instruction following delayed branch improve utilization branch slot called nulli cation parisc generalized apply arithmeticlogical instruction well branch us add instruction add two operands store sum cause following instruction skipped sum zero like co nditional move instructions n cation allows parisc avoid branches cases one instruction part statement cornucopia conditional branches given n cation parisc need separate conditional branch instruction e inventors could recommended nullifying instructions precede unconditional branches thereby simplifying instruction set instead parisc largest number conditional branches risc machine figure e111 shows conditional branches parisc see several really combinations two instructions synthesized multiply divideparisc provides several primitives multiply divide synthesized ware instructions tha one operand 1 2 3 bits add trapping ow useful multiplies alpha also includes instructions multiply second operand adds subtracts 4 8 s4add s8add s4sub s8sub e divide step performs critical step nonrestoring divide adding subtracting depending sign prior result magen heimer et al 1988 measured size operands multiplies divides show well multiply step would work using data c programs muchnick 1988 found making special cases average multiply constant takes 6 clock cycles multiply variables takes 24 clock cycles pa risc ten instructions operations e11 instructions unique parisc 20 e 35 e original sparc architecture used similar optimizations increasing numbers transistors instruction set expanded include full multiply divide operations parisc gives support along lines putting full 32bit integer multiply th oatingpoint unit however integer data must rst moved oatingpoint registers decimal operationscobol programs compute decimal values stored four bits per digit rather converting back forth binary decimal parisc instructions convert sum normal 32bit add proper decimal digits also provides logical arithmetic operations set condition codes test carries digits bytes halfword ese operations also test whether bytes halfwords zero ese operations would useful arithmetic 8bit ascii characters five parisc instructions provide decimal support remaining instructions remaining parisc instructions branch vectored index regist three bits adds base register branches calculated address used case statements extract deposit instructions allow arbitrary bit elds selected inserted registers variations include whether extracte eld signextended whether bi eld sp ed directly instruction indirectly another register whether rest register set zero unchanged parisc 12 instructions noitatonnoitcurtsniemancomb compare branch 21tesffocpcp2sr1srdnocficomib compare immediate branch 21tesffocpcp2sr5mmidnocfimovb move branch rs2 rs1 condrs10 pc pc offset12 movib move immediate branch rs2 imm5 condimm50 pc pc offset12 addb add branch rs2 rs1 rs2 condrs1 rs20 pc pc offset12 addib add immediate branch rs2 imm5 rs2 condimm5 rs20 pc pc offset12 bb branch bit 21tesffocpcp0psrdnocfibvb branch variable bit 21tesffocpcp0rassrdnocfifigure e111 parisc conditional branch instructions e 12bit set called offset12 table 5bit immediate called imm5 e 16 conditions odd signed ow unsigned ow zero ow unsigned never respective complemen e bb instruction selects one 32 bits register branches depending whether value 0 e bvb selects bit branch using th amount register specialpurpose register e subscript notation sp es bit eld e36 appendix e survey risc architectures simplify use 32bit address constants parisc includes addil adjusted 21bit constant register places result regist e following data transfer instruction uses set addressing add lower 11 bits address regist pair instructions allows parisc add 32bit constant base register cost changing register 1 parisc nine debug instructions set breakpoints instruction data addresses return trapped addresses load clear instructions provide semaphore lock reads value memory writes zero store bytes short optimizes unaligned data moves moving either th rightmost bytes word th ective address depending instruction options condition code bits loads stores work well caches options give hints whether load data cache already cache example load destination regist ned ware controlled cache prefetch parisc 20 extended cache hints stores indicate block copies recommending processor load data cache already cache also suggest loads stores spatial locality prepare cache subsequent sequential accesses parisc 20 also provides optional branch target stack predict indirect jumps used subroutine returns ware suggest addresses get placed removed branch target stack hardware controls whether valid multiplyadd multiplysubtract ar oatingpoint operations launch two independen oatingpoint operations single instruction addition fused multiplyadd fused multiplynegateadd introduced version 20 parisc e12 instructions unique arm hard pick unusual feature arm perhaps conditional execution instructions every instruction starts 4bi eld determines whether act nop real instruction depending condition codes hence conditional branches properly considered conditionally executing unconditional branch instruction conditional execution allows e12 instructions unique arm e 37avoiding branch jump single instruction takes less code space time simply conditionally execute one instruction e 12bit immediate eld novel interpretatio e eight le cant bits zeroextended 32bit value rotated right number bits sp ed th rst four bits th eld multiplied two whether split actually catches immediates simple 12bi eld would interesting study one advantage scheme represent powers two 32bit word opera ing limited immediat e second register arithmetic logical processing operations option bein ed operated e options ar logical right logical right arithmetic rotate right would interesting see en operations like rotateandadd rightandtest occur arm programs remaining instructions list remaining unique instructions arm architecture block loads stores control 16bit mask within instructions 16 registers loaded stored memory single instructio ese instructions save restore registers procedure entry retur ese instructions also used block memory copyo ering four times bandwidth single register loadstoreand today block copies important use reverse subtract rsb allows th rst register subtracted immediate ed register rsc thing includes carry calculating th erence long multiplies similarly mips hi lo registers get 64bit signed product smull 64bit unsigned prod uct umull divide like alpha integer divide supported hardware conditional trap common extension mips core found desktop riscs figures e61 e64 comes free conditional execution arm instructions including swi coprocessor interface like many deskto nes full set coprocessor instructions data transfer moves general purpose coprocessor registers coprocessor operations floatingpoint architecture using coprocessor interface oatingpoint architecture ned arm implemented fpa10 coprocessor branch exchange instruction sets e bx instruction transition arm umb using lower 31 bits register set pc th cant bit determine mode arm 1 umb 0 e38 appendix e survey risc architectures e13 instructions unique thumb arm version 4 model frequently executed procedures use arm instructions get maximum performance less frequently executed ones usin umb reduce overall code size program since typically procedures dominate execution time hope hybrid gets best worlds althou umb instructions translated hardware conventional arm instructions execution several restrictions first conditional execution dropped almost instructions second th rst eight registers easily available instructions stack pointer link register program counter used implicitly instruction ird umb uses two operand format save space fourth uniq ed immediates ed second operands disappeared replaced separat instructions h addressing modes simp ed finally putting instructions 16 bits forces many instruction formats many ways simp ed umb architecture conventional arm additional changes made arm going umb drop immediate logical instructions logical immediates gone condition codes implicit rather condition codes set optionally ar ned opcode alu instructions none data transfers set condition codes hilo register access e 16 arm registers halved lo registers hi registers eight hi registers including stack pointer sp link register e lo registers available alu operations variations add bx cmp mov also work combinations lo hi registers sp pc registers also available variations data transfers add immediates operations hi registers require one mov put value lo register perform operation transfer data back hi register branchcall distance since instructions 16 bits wide 8bit conditional branch addr ed 1 instead 2 branch link sp ed two instructions concatenating 11 bits instruction ing th form 23bit address load pc distance data transfer sets e set bits general purpose registers eight bits sp pc e14 instructions unique superh e 39 e14 instructions unique superh register 0 plays special role superh address modes added another register form address indirect indexed addressing pcrelative addressing r0 used load constants give larger addressing range easily 16bit instructions superh r0 also register operand immediate versions cmp xor list remaining unique details superh architecture decrement test dt decrements register sets bit 1 result 0 optional delayed branch although embedded risc machines generally use delayed branches see appendix b superh ers optional delayed branch execution bt bf many multiplies depending whether operation signed unsigned operands 16 bits 32 bits product 32 bits 64 bits proper multiply instruction muls mulu dmuls dmulu mul e product found macl mach registers zero sign extension byte halfwords either zeroextended extu signextended exts within 32bit register onebit shi amounts perhaps attempt make th within 16bit instruction instructions onl single bit time dynamic shi amount ese variab test sign amount register determine whether positive right negative logical shld arithmetic shad instructions supported ese instructions help set 1bit constan amounts standard rotate superh ers rotations 1 bi rotl right rotr set bit value rotated also variations include bit rotations rotcl rotcr swap instruction swaps either high low bytes 32bit word two bytes rightmost 16 bits extract word xtrct e middle 32 bits pair 32bit registers placed another register negate carry like subc figure e66 except th rst operand 0 cache prefetch like many desktop riscs figures e61 e64 superh instruction pref prefetch data cache e40 appendix e survey risc architectures testandset superh uses older testandset tas instruction perform atomic locks semaphores see chapter 2 tas rst loads byte memory sets bit 1 byte 0 0 byte 0 finally sets th cant bit byte 1 writes result back memory e15 instructions unique m32r e unusual feature m32r slight vliw approach pairs 16bit instructions bit reserved th rst instruction pair say whether instruction executed parallel next instruction two instructions independentor two must executed sequentially earlier machine ered similar option inte feature included future implementations architecture one surprise branch displacements ar ed 2 bits added pc lower 2 bits pc set 0 since instructions 16 bits long means branch go instruction program branch instructions word boundaries similar restriction placed return address branchandlink jumpand link instructions return word boundary us slightly larger branch distance ware must ensure branch addresses return addresses aligned word boundary e m32r code space probably slightly larger probably executes nop instructions would branch address ed 1 bit however vliw feature means nop execute parallel another 16bit instruction padding doesnt take clock cyc e code size expansion depends ability compiler schedule code pair successive 16bit instructions mitsubishi claims code size overall 7 larger motorola 6800 architecture e last remaining novel feature result divide operation remainder instead quotient e16 instructions unique mips16 mips16 really separate instruction set 16bit extension full 32bit mips architecture compatible 32bit address mips architectures mips mips ii 64bit architectures mips iii iv e isa mode bit determines width instructions 0 means 32bitwide instructions e16 instructions unique mips16 e 41and 1 means 16bitwide instruction e new jalx instruction toggles isa mode bit switch isa jr jalr ned set isa mode bit th cant bit register containing branch address bit considered part address jumpandlink instructions save current mode bit th cant bit return address hence mips supports whole procedures containing either 16bit 32bit instructions support mixing two lengths together single procedure e one exception jal jalx two instructions need 32 bits even 16bit mode presumably get large enough address branch far procedures picking subset mips decided include opcodes threeoperand instructions keep 16 opcodes 64bit operation e combination many opcodes operands 16 bits led architects provide eight easy touse registersjust like umbwhereas embedded riscs er 16 registers since hardware must include full 32 registers 32bit isa mode mips16 includes move instructions copy values eight mips16 registers remaining 24 registers full mips architecture reduce pressure eight visible registers stack pointer considered separate register mips16 includes variety separate opcodes data transfers using sp base register increment sp lwsp ldsp swsp sdsp adjsp dadjsp addiuspd daddiuspto within 16bit limit immediate elds generally shortened eight bits mips16 provides way extend shorter immediates full width immediates 32bit mode borrowing trick intel 8086 extend instruction really 16bit pr x prepended mips 16 instruction address immediat eld e pr x supplies enough bits turn 5bi eld data transfers 5 8bi elds arithmetic immediates 16bit constants alas two exceptions addiu daddiu start 4bit immediate elds since extend supply 11 bits wider immediate limited 15 bits extend also extends 3bi elds 5bit elds fo case wondering extend pre x need start 32bit boundary address supply constants mips16 added new addressing mode pcrelative addressing load word lwpc load double ldpc 8bit immediate eld two three bits respectively adding pc lower two three bits cleared e constant word doubleword loaded register us 32bit 64bit constants included mips16 code despite loss liu set upper register bits given new addressing mode also instruction addiupc calculate pcrelative address place register ers embedded riscs subset 64bit address architecture result 16bit instructionlength versions 64bit e42 appendix e survey risc architectures data operations data transfer ld sd lwu arithmetic operations dadduiu dsubu dmultu ddivu dsllv dsrav dsrlvsince mips plays prominent role book show additional changes made mips core instructions going mips16 drop signed arithmetic instructions arithmetic instructions trap dropped save opcode space add addi sub dadd daddi dsub drop immediate logical instructions logical immediates gone andi ori xori branch instructions pared comparing two registers branching comparisons register zero hence instructions didnt make either beq bne bgez bgtz blez bltz mentioned section e3 help compensate mips16 includes compare instructions test two registers equal since compare set less set new register branches added test register branch distance since instructions 16 bits wide branch address ed one instead two delayed branches disappear e branches tak ect next instruction jumps still oneslot delay extension distance data transfer sets e 5bit 8bi elds zeroextended instead signextended 32bit mode get greater range immediate elds ar ed one two three bits depending whether data halfword word doubleword extend pre x prepended instructions use conventional signed 16bit immediate 32bit mode extension arithmetic immediates e 5bit 8bi elds zero extended set less compare instructions forming pc relative address adding sp placing result register addiusp daddiusp extend pre x prepended instructions use conventional signed 16bit immediate 32bit mode ey still signextended general adds adding sp placing result back sp adjsp dadjsp alas code density orthogonality strange bedfellows mips16 ning amount 0 nes value 0 3bi eld mean 8 bits new instructions added due loss register 0 zero load immediate negate added since operations could longer synthesized instructions using r0 source e17 concluding remarks e 43 e17 concluding remarks appendix covers addressing modes instruction formats instructions found ten risc architectures although later sections appendix concentrate th erences would possible cover ten architectures pages many similarities fact would guess 90 instructions executed architectures would found figures e35 e311 contrast homogeneity figure e171 gives summary four architectures 1970s format similar shown figure e11 imagine trying write single chapter style architectures history computing never widespread agreement computer architecture ibm 360370 intel 8086 motorola 68000 dec vax date announced 19641970 1978 1980 1977 instruction sizes bits 16 32 48 8 16 24 32 40 48 16 32 48 64 80 8 16 24 32 432 addressing size model 24 bits ß at31 bits ß 4 16 bits segmented24 bits ß 32 bits ß data aligned yes 360no 370 16bit aligned 419532sedomgnisserddaatadegaplanoitpoenonegapnoitcetorpbk50bk23ot520ñbk4bk2ezisegapdeppamyromemdeppamyromemedocpoedocpooiinteger registers size model number 16 gpr 32 bits 8 dedicated data 16 bits 8 data 8 address 32 bits 15 gpr 32 bits separate ß oatingpoint registers 4 64 bits optional 8 80 bits optional 8 80 bits 0 floatingpoint format ibm ß oating hexadecimal ieee 754 single double extended ieee 754 single double extended dec figure e171 summary four 1970s architectures unlike architectures figure e11 little agreement architectures category style architecture remain static however like people instruction sets tend get bigger get older figure e172 shows genealogy instruction sets figure e173 shows features added deleted generations desktop riscs time see desktop risc machines evolved 64bit address architectures done fairly painlessly e44 appendix e survey risc architectures 1960cdc 66001963cray11976m32r1997thumb1995armv41995arm31990arm21987arm11985sparcv8 1987sparcv9 1994mips161996mips i1986mips ii1989mips iii1992alpha1992parisc 1986parisc 11 1990parisc 20 1996rtpc1986power11990powerpc1993power21993alphav31996mips iv1994mips v1996mips642002mips322002berkeley risc11981stanford mips1982digital prism1988ibm asc 1968ibm 8011975america1985superh199219651970 1975 198019851990199520002002figure e172 lineage risc instruction sets commercial machines shown plain text research machines bold e cdc 6600 cray1 loadstore machines regist xed 0 separate integer oatingpoint registers instructions could cross word boundaries early ibm research machine led 801 america research projects 801 leading unsuccessful rtpc america leading successful power architecture people worked 801 l ater joined hewlettpackard work pa e two university projects basis mips sparc machines according furber 1996 berkeley risc project inspiration arm architecture arm1 arm2 arm3 names architectures chips arm version 4 name architecture used arm7 arm8 strongarm chi ere armv4 arm5 chips arm6 early arm7 chips use arm3 architecture dec built risc microprocessor 1988 intro duce instead dec shipped workstations using mips microprocessors three years brought risc instruction set alpha 21064 similar mips iii pris e alpha architecture small extensions formalized version numbers used version 3 version reference manual e alpha 21164a chip added byte halfword loads stores alpha 21264 includes max multimedia bit count instructions internally digital names chips er fabrication technology ev4 21064 ev45 21064a ev5 21164 ev56 21164a ev6 21264 ev stands extended vax reading e 45we would like thank following people comments dra appendix professor steven b furber university manchester dr dileep bhandarkar intel corporation dr earl killian silicon graphicsmips dr hiokazu takata mitsubishi electric corporation reading bhandarkar p 1995 alpha architecture implementations newton digital press darcy j gay 1996 fleckmarks measurin oating point performance using full ieee compliant arithmetic benchmark cs 252 class project uc berkeley see httpcsberkeleyedu darcy projectscs252 digital semiconductor 1996 alpha architecture handbook version 3 maynard digital press order number ecqd2kbte october rewopspimcrapscsirapfeature 10 11 20 v8 v9 ii iii iv v 1 2 pc interlocked loads x ó ó x ó ó ó x ó ó loadstore fp double x ó ó x ó ó ó x ó ó semaphore x ó ó x ó ó ó x ó ó square root x ó ó x ó ó ó ó óóóxóxóóxspopfnoisicerpelgnis memory synchronize x ó ó x ó ó ó x ó ó coprocessor x ó ó x ñ x ó ó ó óóxóxóóxgnisserddaxedniesabóóxóóósretsigerpftib4623viuqeannulling delayed branch x ó ó x ó ó ó branch register contents x ó ó x ó ó ó óóóxónaidneelttilgibóóxóótibnoitciderphcnarbñóxevomlanoitidnocóóxehcacotniatadhcteferpóspotnignisserddatib4632bit multiply divide ó x ó ó ó x ó ó ñdauqpferotsdaolóóxddalumpfdesufñóxóóxsnoitcurtsnignirtsxxóxtroppusaidemitlumfigure e173 features added desktop risc machines x means original machine means added later means continued prior machine means removed architec ture alpha included added byte word loads stores bit count multimedia extensions version 3 mips v added mdmx instructions paired sing oatingpoint operations e46 appendix e survey risc architectures furber b 1996 arm system architecture harlow england addisonwesley see wwwcsmanacuk amuletpublicationsbooksarmsysarch hewlettpackard 1994 parisc 20 architecture reference manual 3rd ed hitachi 1997 superh risc engine sh7700 series programming manual see wwwhalsphitachicomtech_ prod search title ibm 1994 e powerpc architecture san francisco morgan kaufmann kane g 1996 parisc 20 architecture upper saddle river nj prentice hall ptr kane g j heinrich 1992 mips risc architecture englewood nj prentice hall kissell k 1997 mips16 highdensity embedded market see wwwsgicommipsarchmips16 mips16whitepaperpdf magenheimer j l peters k w pettis zuras 1988 integer multiplication division hp precision architecture ieee trans computers 378 98090mips 1997 mips16 application speci c extension product description see wwwsgicommipsarch mips16mips16pdf mitsubishi 1996 mitsubishi 32bit single chip microcomputer m32r family ware manual september muchnick 1988 optimizing compilers sparc sun technology 13 summer 6477 seal arm architecture reference manual 2nd ed morgan kaufmann 2000 silicon graphics 1996 mips v instruction set see wwwsgicommipsarch isa5mipsv_indx sites r l r witek eds 1995 alpha architecture reference manual 2nd ed newton digital press sloss n symes c wright arm system developers guide san francisco elsevier morgan kaufmann 2004 sun microsystems 1989 e sparc architectural manual version 8 part 800139909 august 25 sweetman see mips run 2nd ed morgan kaufmann 2006 taylor g p hi nger j larus patterson b zorn 1986 evaluation spur lisp architecture proc 13th symposium computer architecture june tokyo ungar r blau p foley samples patterson 1984 architecture soar smalltalk risc proc 11th symposium computer architecture june ann arbor mi 18897 weaver l germond 1994 e sparc architectural manual version 9 englewoo nj prentice hall weiss j e smith 1994 power powerpc san francisco morgan kaufmann chapter 1 book presents many examples computer systems presents enough detail meaningful engineering study analysis possible examples presented using original descriptions technical literature others redescribed us especially original descriptions existed technical manuals cases considerable discussion analysis computer struc tures problems intended solve solutions adopted solutions fared yet em phasis remained detailed descriptions precise enough systems available independent study one want produce book collections reprintings technical literature common many science engineering fields eg ﬁprogramming systems languagesﬂ rosen 19671 departed tradi tional exercise two ways seem important us first presented substantial amounts detail effect block diagrams computer structures equivalents programming manuals constitute neither good reading way communicating ﬁessential ideasﬂ field second introduced system notation used parts written also provide addi tional sometimes redundant descriptions computer systems reprinted articles book like reasons several require background discussion opment science technology computers one us also likes build computers understand particular book seems us right way push development particular time requires characterizing current state computersystems technology computer system complex several ways figure 1 shows important least four levels system descrip tion possibly five used computer alternative descriptions sense anything said one way said another contrary level arises ab straction levels job lower levels could perform became unnecessary detail would forced carry around system level characterized set components certain properties posited set ways com bining components produce systems formalized appro priately behavior systems determined behavior components specific modes combination used l 1 fly computer systems ii r computer systems one example mans complex arti ficial systemsl existed successful engineering prod ucts long enough undergo radical evolution give rise number basic unique technologies sufficiently complex given rise science con tinuing institutionalized endeavor understand sort beast brought forth2 fundamental interest devel iwe need argue complex system view myopic setting aside quasinatural systems cities economies still case modern aircraft carrier complex modern computer reasonable measure 2here uniqueness claimed perhaps since artifactual systems excluding quasinatural ones provide new phenomena require sustained scientific investigation understand structures network computerc b components processorsp memoriesm switchess controlsk transducers data operators links l circuits arithmetic unit components registers transfers controls data operators etc 1 circuits counters controls sequential transducer function generator register arrays components flip flops resetset us jks delay toggle 7 iotch deloy one shot circuits encoders decoders transfer arrays dot0 ops selectors distribu ors iterative networks compoynts 8nd nand tf state system level lh componen states outputs circuits amplifiers delays ottenuators multivibrators clocks gates differentiator transistors passive components resistor u capacitor c inducterl diode deloy lines 1 active components relays vacuum tubes 1 b certainly science aircraft carriers computer science fig 1 hierarchy levels computer structure 4 part 1 1 structure computers elementary circuit theory almost prototypic example components rs ls cs voltage sources mode combination run wires terminals components corresponds identification current voltage terminals algebraic differential equations circuit theory provide means whereby behavior circuit computed properties components way circuit constructed recursive feature system descriptions system composed components structured given way may considered component construction yet sys tems course primitive components whose properties explicable resultant system type example resistor explained subcircuit taken primitive sometimes absolute primitives matter convention basis taken example one build logical design systems many different primitive sets logical operations nand etc system level used term fig 1 charac terized distinct language representing system components modes combination laws behavior distinct languages reflect special properties types components way combine otherwise would point adopting special representation nevertheless levels exist system analysts way describing structure behavior 30volts ﬂ c 3 e w 270 uuf 0 ic 0 ic ie 1 1 f 0 e 0 15 rc 6 di eceooat ai ot e 3volt step input e h 30 volts u 5 0 1a et 151eﬂrcs 9 fig 2 electroniccircuit level inverter circuit physically existing system fact languages highly distinct makes possible confident existence different system levels fuzzy existence additional intermediate level new representa tions yet congealed distinct formal languages noted within level exists whole hierarchy systems subsystems however long described language eg subroutine hierarchy given machineassembly language constitute separate sys tem levels general view let us work levels com puter systems starting bottom level fig 1 actually two languages representations associated alge braic one graphical one isomorphic entities properties relations given lowest level fig 1 circuit level com ponents rs ls cs voltage sources nonlinear devices behavior system measured terms voltage current magnetic flux continuously varying quantities asso ciated various components continuous havior time components discrete number terminals whereby connected components figure 2 shows algebraic graphical description inverter circuit well algebraic graphical descrip tion behavior note structure specified first circuit directed graph symbols arcs nodes particular circuit still abstraction transistor q1 resistor r stray capacitors c given token values structure described symbolically first writing relationship describing components ie ohms law faradays law etc equation describes interconnection components ie kirchhoffs laws observe behavior circuit probably using oscilloscope applying input eit observing output et alterna tively solve equations specify structure obtain expressions describe behavior explicitly circuit level fact lowest level might used describing computer system devices require different language either electromagnetic theory quantum mechanics solidstate devices usually exercise course maxwells equations show circuit theory derived specialization appropriately restricted boundary conditions actually even level ab straction circuit theory quite adequate describe computer technology since number mechanical devices must represented magnetic tapes drums likely chapter 1 5 come mind first card readers card punches teletype terminals examples devices obey laws motion analyzed units mass length time next level logic level unique digital technol ogy whereas circuit level digital technol ogy shares rest electrical engineering behavior system described discrete variables take two values called 0 1 true false high low components perform logical functions nand etc systems constructed way circuit level connecting terminals components thereby identify behavioral values laws bool ean algebra used compute behavior system behavior properties components previous paragraph described combinatorial circuits whose outputs directly related inputs instant time circuit ability hold values time store infor mation get sequential circuits problem com binatoriallevel analysis solves production set outputs time function number inputs time described textbooks analysis abstracts trans port delays input output however engineering practice analysis delays usually considered still part combinatorial level fig 3 show combinatorial network formed combinatorial elements realize three boolean output expressions function input boolean variables b note symbolic representa tion structure write expression reflects structure combinatorial network reduction boolean equations longer reflect actual structure combinatorial circuit become model predict behavior representation sequential switching circuit basically combinatorial switching circuit although one needs add memory components delay element produces output time input time thus equations specify structure must difference equations involving time distinction even representa tion synchronous circuits asynchronous circuits namely whether behavior represented sequence values integral time points 1 2 3 must deal continuous time minor variation figure 4 gives sequential logic circuit algebraic graphical form shows also representation behavior system clear logic circuits simply subspecies general circuits indeed design logic components one con structs circuitlevel descriptions instance fig 5 c shows circuit nand gate plus table behavior evident behavior corresponds nand gate certain restrictions hold namely one look voltage identified behavior variable logic circuit certain periods transient ﬁsettling downﬂ use common phrase thus logic level instance circuit level sense circuit level instance maxwells equationsas limiting case certain features deliberately ignored one buys great deal specialization logic circuits since one compute behavior circuits logic level extremely complex circuit level techniques use entirely different mathematical apparatus general cross another level representation previous level provides information longer relevant lower level concerned explaining behavior certain structure whereas next highest level takes lower level given primitive higher level concerned internal behavior primitives combined glance fig 1 shows described lower part logic level another part called register transfer level rt level still uncertain level matter time alternatively fig 3 combinatorialswitchingcircuit sublevel logic level realiza tion three logic expressions 6 part 1 structure computers structure behavior ﬂ r mi sum n 0 0 0 ill ii 0 time f sinput xr rinput 7 xi 7 x 7xrvx pmj 0 lo 0o lo 0o 01 sum output table fig 4 sequentialswitchingcircuit sublevel logic level computa tion x 1 serial input string x discuss finished describing com ponents rt system registers functional transfers registers register device holds set bits behavior system given time course values registers ie bit sets system undergoes discrete operations whereby values various registers combined according rule stored another register thus ﬁtransferred law combination may almost anything simple unmodified transfer b logical combination b c arithmetic b c thus specification behavior equivalent boolean equations sequential circuits differential equations circuit level set expressions often called productions give conditions transfers made fig 6 give picture rt system compute sum integers figure includes specification assumes elementary state variable system holds bit ie one two values 0 1 need sometimes elementary variable holds decimal digit one 10 values character one say 48 values present purposes talk terms bits without losing anything thereby behavior table shows resulting behavior time graphical structure system includes registers n transfers c l data operators 1 n etc flowchart shows behavior control time registertransfer level still uncertain substantial agreement neither exact language used level techniques analysis synthesis go note circuit level logiccircuit level exist welldefined representations guaranteed speak standard textbooks college courses teach levels standard texts digital computers make informal vse rt vel indeed systems level emergence one restricts transfer operations boolean operations thinks register simply set 1bit memories one write set logic equations registertransfer system furthermore one considers role logic design digital computers encompassed sequential circuits registertransfer e e table 4 nand table inputs behavior inputs behavior 111 000 logic element 1 1 0 0 nand logic element 0 structure 0 structure 1 0 01 1 1 100 1 101 1 110 1 111 0 000 circuit level 15volts output 15 volts inputs 10jolts node multiple input inverter circuit structure table circuit behavior 03 0 0 3 3 3 3 3 0 3 3 3 0 3 3 3 0 behavior fig 5 change representation circuit level combinatorial switching sublevel boundary chapter 1 7 lj present state n c level practicing logic designer institutionalized position par circuit designer sequential combinatorial circuits basic analytic tools attempts design systems registertransfer level eg central proc essors tools registertransfer level emerged informal attempts create notation closer job done recently number efforts construct formalized registertransfers systems built around construction programming system language permits computer simulation systems rt level although agreement basic components types opera tions much less agreement representation laws system corresponding tke production system fig xrj wts 00 01 n nic n cic u 0 start runso i0 start0 runi runi5nii 1 ss 1 inrun 0 1 abbreviation start 2 r 1s abbreviation run 3 combinational network 4 clock event time 5a4 x n fig 6 registertransfer sublevel logic level computation sum integers structure behavior 3 output table sum1 conventions condition output fig 7 statesystem representation logic level computation x 1 serial input string x 6 way represent dynamic behavior correspond ipg behavior table figure another representation used logic level statesystem representation put one side fig 1 state system general representation discrete system avai1ablel system represented capable one n abstract states instant time digital systems n finite enumerable behavior specified transition function takes arguments current state current input determines next state concomitant output digital computer principle representable state system number states far large make useful instead state system becomes useful representation dealing various subparts total machine sequential circuit controls magnetic tape number states small enough tractable thus placed state systems one side auxiliary logic level fig 7 give common representations state system co lthere energetic attempts apply statesystem approach control systems general nature zadeh desoer 19831 although concern us 8 part 1 1 structure computers incidently use representations fig 7 sequential switching circuit fig 4 fig 7 may viewed abstraction physical system fig 4 logic designer state system useful abstraction logic design design usually passes following problem representations 1 2 problem exists natural language problem converted state diagram output function state input state diagram represented state table output table states assigned physical memory elements used excitation table output tables formed excitation output logic equations written constrained actual logic elements sequential circuit drawn 3 4 5 6 7 let us go next higher level program leoel unique level description digital technology logic level uniquely associated computers namely digital devices central component interprets programming language many uses digital technology especially instrumentation digital con trols require interpretation device hence logic level program level components program level set memories set operations memories hold data structures represent things inside outside memory eg num bers payrolls molecules data structures etc operations take various data structures inputs produce new data struc tures reside memories thus behavior system time pattern data structures held memories unique feature program level representation provides combining components specifying operations executed data structures program consists sequence instructions struction specifies given operation operations exe cuted specified data structures superimposed control structure specifies instruction interpreted next normally done order instructions given jumps sequence specified branch instructions fig 8 shows simple program data structures behavior two things separate logic level program level first computer systems logic level parallel devices components active simultaneously program level com puters represented essentially serial devices second program level logic level essentially linguistic nature program level things named abbreviations used decisions made instructions interpreted concepts strikingly absent physical systems course ﬁreallyﬂ absent since one give full description operation program logic level one carrying mind set physical behaviors discovered computers make show appropriate linguistic behavior program level thus one ﬁgo alpha accumulator negative one logic circuit transfers contents address field instruction register program counter anding transfer sign accumulator take place accumulator negative translation reveals distinct system boundary registertransfer level pro gram level size gap also revealed ability people become expert programmers without knowing anything representations programming level program level constitutes entire technology right one carries within emergent charac teristics computer systems make worthy science among programming languages alone levels lan guage distinct constitute system levels fully important ones exhibited fig 1 never theless viewpoint someone basically concerned hardware systems accounted single level least present one aspect programming systems concern operating systems still fragmented state even begin distinct system level one peculiarity program level exists universal representation circuit logiccircuit level hoped soon register transfer level machine machine language assemblers command languages built chine languages languages forms complete sys tem program level applicable machine question universal machine language although much common conceptual level existing machine languages existed longstanding attempt within programming field develop uncol uni versal computer oriented language steel 19611 would play role never successful reasons far seek role machine language inter chapter 1 9 e 0 0 preted machine order produce behavior free arbitrarily desirable properties human viewpoint since details affect efficient operation computer much much space devoted program much time saved special order oriented matrix multiply etc uncol also attempting fill role machine languages one compile machine code arbitrary machine another reason universal programming representation particular machine language language universal description would seem description class languages means impossible wide use notations backus normal form bnf sh0wl nevertheless contrib uted lack universal notation move fourth last level fig 1 called iil pxway she4 for4kert name recognized since level exists informally nevertheless existence hardly doubt view one takes computer system one considers aggregate behavior consists central proc essors core memories tapes disks inputoutput processors com munication lines printers tape controllers busses teletypes scopes etc system viewed processing medium infor mation measured bits digits characters words etc thus components capacities flow rates operating characteristics details program sup pressed although many gross distinctions encoding infor propose notation later see also work f haney generalized instruction system gis haney 19681 structure start pop8 symbolic machine language program loc oper start clo dca dca loop tad tad dca n tad n cia 72 tad 0 0 smo cla stop hlt n is2 5 imp loop nn action comments s0 10 clear ac deposlt ac mclear ac twos complement add negate aclin twos complement hait iitl indexbyiskip if0 lump rsi skipitacclear ac sum ooti 01 n integers 01 n volue nwhere ocs2 algol program start 0 stop friopl n ssi behavior time f time11 5 ps 0 1 3 5 7 9 11 13 14 16 17 19 zg 15xn1 15xnltz 15xnt13 program ac counter stort 0 0 0 startl 0 q q start t2 0 0 0 loop g 0 0 loopl 0 0 0 loop 2 0 0 0 loop3 0 0 0 loop4 n 0 0 loop6 n 0 0 loop8 0 0 0 loop9 0 1 0 loop 0 1 0 bp5 n 0 0 loop 6 ntn n 12 n stop 0 n 12 n stop 1 0 n 12 n halted fig 8 programming level computation sum integers 10 part 1 structure computers mation type remain depending analysis thus one may distinguish program data file space resident monitor one may remain concerned fact input data alphameric must converted binary bitserial must converted bitparallel might characterize level ﬁchemical engineering view digital computerﬂ likens continuous process petroleumdistilling plant place complex fortran programs applied matrices data indeed system level nearly abstraction logic level program level since returns simultaneously operating flow system one might question whether distinct systems level early days computers almost computer systems could represented diagram mits whirlwind computer programming manual fig 9 classic boxes memory storage control arithmetic inputoutput actually view computer 1953 considerably advanced texts logic design computers 1960s detailed model model secondary memory magnetic tape drums whirlwinds case interesting aspect model text writers omit kind switch ing bus fig 9 bus provides communication path link components certainly pushbuttons actually console novel model compare diagram modern computer system fig 10 shows twoprocessor univac 1108 level abstraction fig 9 arithmetic element fig 9 disap difference la u u fig 9 automatic digital computation whirlwind computer manual mit permission publishers peared replaced processor combined control arithmetic element fig 10 central control fig 9 distributed throughout remaining components control fig 10 combined unit transforming serial character information stream words also manages transmission word vector primary memory terminal secondary memory resource allocation diagram troduced fig 10 describe allocation use hence havior pms components function time chapter 2 describes figures fully another indication emergence pms level lies models used operationsresearch types studies computer systems early 1960s practi cally nonexistent advent multiprogramming multiprocessing time sharing imminent arrival computer networks substantial numbers studies level abstraction always one considers flows stocks information measured bits equivalent perhaps divided several subtypes concerns bottle necks capacities total flow rates queuing problems buffer sizes like indicates system level logic level program level uniform language representation level even noted standard name used term pms analogy use rt registertransfer level processors memories switches main kinds com ponents systems level built one names number components pms level previously one finds switches list ﬁbussesﬂ list would one although many would think first data transfer charac teristics book amply shows makes pms level interesting complex existence switches govern pattern information flow system one reason seem buried association com ponents addressing systems components besides processors memories switches namely links transducers controls first three p seem appropriate characterize level known whether yet systems levels say one pms level networks come existence simplicity top level argues may show narrow vision important realize levels sacrosanct depend strongly physical technology thus move toward integrated circuitry may emerge representations registertransfer diagrams lat ter may never develop clear systems level one could even chapter 1 11 imagine something happening circuit level continuous distributions became important although use equiva lent circuits well embedded engineering culture concerned predicting particular changes wish emphasize systemlevels diagram fig 1 reflection current technology ways analyzing given physical systems levels certain im permanency problem systems levels described correspond tech nologies available analysis synthesis com puter systems levels exists fact precisely extent technology become well developed thus circuit level lower half logic level combinato rial sequential circuits highly polished technologies one learns today one wants become computer en gineer textbooks exist courses taught flourish ing cumulative technical literature progress systems levels matters become progressively worse registertransfer level yet well established although considerable current activity area next years may see universal establishment although programming certainly well defined machine king court common technology program level relevant design computer systems latter phrase must added since taking specialized viewpoint consider world programming research entirely divorced computersystems designl finally top practi cally consensus nature systems level nothing surprising state affairs reflects accurately fundamental fact past years computer systems become complex enough higher levels emerge distinct systems levels computers could described diagram fig 9and diagram reprinted innumerable times first decade need haire technology pms level registers expensive one could count registers processor fingers one hand thumbs allowed one need registertransfer language order describe entirely true level must provide coupling adjacent levels major issue computerdesign tradeoff hardware software 2 0 graphic pic tconsole pctconsole kio 16 kiol 16 kiol 16 sk cards 0 0 r sksttelephone mprprimary memory mssecondary memory pccentral processor tterminal llink uswitch kcontrol kiocontrol io equipment imp07 core 32760 word resource allocation diagram time fig 10 pms level univac 1108 12 part 1 1 structure computers flows cases informal block diagram conveyed information adequately question programming level somewhat different since level existed formal language start key aspect seems us since welldefined languages existed little pressure find better one fact languages completely idiosyncratic machine since emerged product design simply worry anyone overly much language provided design framework one could work seemed suffice led true game ﬁwe another bit left mode field instructiongot another mode youd likeﬂ made computer designers feel creating order code something art thus feel increased complexity computer systems making higher system levels increasing importance since second decade serious development computer systems upper levels good shape instance textbooks devote little attention area textbooks especially good ones tend techniqueoriented giving attention known students always used wonder mathematics texts told problems solvable closed form thus present need material higher levels constitutes major motivation book second feature current scene enters motivation book around 1000 different computer systems built represents substantial amount pragmatic experimentation especially true program ming level pms level also extent register transfer level many things tried many found worth many found wanting good deal reinvention goes thus concerned history experimentation lost true underlying technology changes enough experience may become largely irrelevant appear us imminent development admit also third concern stem role computer engineers concerned design role computer scientists fascinated phenom ena computers variety 1000 computers represents beginning proliferation species biologi cal control rather economic intellectual control nevertheless every sense word evolutionary population find feeling little like naturalists must felt confronted proliferation organic world one time tempted call book ﬁcomputer botanyﬂ another ﬁcomputer taxonomyﬂ feel attempt gather document classify existing computers worthy endeavor right one might think material easily available record fades rapidly especially much exists manufacturers manuals papers assorted proceedings main reasons producing book particular character evident need material upper levels computer systems teaching new students computer science engineering making past record available professional designers since technologies well developed upper levels possible write textbook making use wellaccepted techniques njtations results instead one settles making available collection examples systems studied analyzed directly notations remains say word two notations introduced motivations character already implicit foregoing ac count started simply produce set readings computer systems motivated lack detailed examples could use course one us gb giving computer design noted felt need expose students real examples complex computer structures gathered material became im pressed depressed actually better term diversity ways describing higher levels even amount clumsy descriptiondownright verbosityeven purely technical manuals acted depressant thought putting congeries descriptions hard covers one person peruse study almost much contem plate gradually began rewrite condense many descriptions set common notations developed becoming aware happening devoted substantial amount attention effort creating notational systems consistency hope chance job required pms descriptive system pms level sic isp instructionset processor descriptive sys tem program level requires comment nature role think play pms descriptivesystem meant provide notation top level computer systems figure 10 given notation surface largely selfexplanatory given chapter 1 13 mnemonics p processor memory switch transducer hence also terminal k control since c computer also l link computer struc tures unnecessary distinguish separate link component except show connectivity become appropriate com munication delays exist issue whether small set components appropriate set primitives issue major proportions real issues development notation come stress two opposite forces one hand one wants extremely compact notations expressing computer sys tems systems large event much extra notational freight way fixed formats forced writing already known assumed etc notation neither useful used hand tremen dous variety quantity information potentially must capable written description word size capacity flow operation rate datatypes variations operation rate different classes instructions parity checking technology thus one needs notation responds demandsand without hopelessly complex difficult learn attempt solution involves basically simple lan guage comprehensive think natural ways sys tematic abbreviation abstraction isp descriptive system meant provide uniform way describing instruction sets giving information contained programming manual must provide instruc tion format registers referenced instructions rules interpretation instruction semantics instruction processors repertoire must able existing computer plus expected extensions future homeliest virtue make possible read descriptions fortyodd computer systems described book without fight new notation system still know detail instructions really attempt solution turns generalized sort instruction rather similar flavor register transfer scheme differences lie able suppress timing information detail essential standing instructions isp variety uncol one program rather language one describe particular instruction set thus avoid many pitfalls uncollike efforts price paid introducing new notations must learned feel two systems introduced natural enough require almost learning superficial use eg looking fig 10 modest amounts full exploitation seem us vastly preferable array ad hoc notations faced initially almost faced reader still aware price word said antecedents pms descriptive system close way computer scientists talk informally top level computer systems one effort environment stands predecessor notations cpu central processing units become widespread clearly assimilated modifications pc instead cpu dictated entirely attempt build consistent notation whole range computer systems respect isp heavily influenced work register transfer languages one used kernel grow isp work darringer parnas dar ringer 19691 particular decision work within framework algol suited sensibilities even though final version isp departs sequential algorithmic language number respects finally word said innocence aspirations putting pms isp forward two notations also imply particular view digital processing thus entirely innocent would appropriate explore fully view justify particular decompositions definitions used say views pecu liarly implicit informal use similar descrip tive systems however attempt formalize notation makes accessible accept obligation perform exploration volume place would turn something treatise textbook book appropriate take notations face value companion volume preparation attempts job aspiration aspirations well notations computer world turn working tools many tasks communicative one book notation useful others easy imagine writing specifications new machines sure computer salesmen selling standardization programming manuals learning new machine easier etc tasks influenced direct way work iverson falkoff iverson sussenguth 19641 sense patterning notation nevertheless creation full description ibm system30 apl stands important milestone moving toward formal descriptions machines 14 part 1 structure computers notations must become formal programming languages analysis synthesis procedures carried automatically terms noted development isp pms germinated purely notational issues let aspirations turn simulation languages delay use purely descriptive purposes thus accept obli gation also develop operational tools also aspiration dealt anywhere within book plan book enough background explain structure book two chapters complete introductory part chapter 2 provides exposition pms isp descriptive systems noted attempt explore seriously view digital processing implicit notations although provide small amount motivation summary language conventions parameter values given end book appendix chapter 3 provides description space computer systems one view computer systems occupying space whose dimensions various important systems features many features actual systems relatively locked together example word size number instructions reper toire covary 12bit machine 200 instructions several 32 bits thus number significant dimensions variation much less total number features computer systems space provides basic frame choose representative computer systems inclusion book hope chap 3 also justify feeling diversity proliferation computer systems worthy serious study remainder book divided five parts 2 6 introduction constituting part l part sections chapter gives description computer system instance part section usually chapter describes one computer computer system although exceptions part 6 computer families word needs said ﬁvirtualﬂ table contents many example computers relevant one part section physically located one place permited multiple entries contents instance chap 33 ibm 1800 appears sec 1 part 2 example oneaddress isp sec 1 part 4 terminal control finally sec 2 part 5 example pms one central processor multiple inputoutput processors 1 pc multipio physically located latter section using different type faces hope reader become confused virtual actual little point outlining content various parts sections better done end chap 3 computer space laid references brackets used enclose authors year publication eg dar ringer 19691 falkoff iverson sussenguth 19641 list references chapter given code end chapter code refers bibliography end book 7 rchar acter code follows characters 14 character 5 characters 67 character 8 first four characters last name author first author first initial author first author year publication 1900 optional h c used denote multiple refer enced publications author year references darrj69 faika64 hanef68 roses67 steet61 zadel63 pms isp descriptive systems task chapter provide introduction pms descriptive system top computersystem level isp descriptive system program level take view informal notations exist use pms isp attempt tidy notationsto make consistent powerful thus depend reader already stand implicitly much notation used consequence attempt chapter provide formal treatment whole system appendix 1 end book contains complete summary notation rules including component attributes values abbreviations ie main technical vocabulary pro vide brief discussion conceptual view underlying two systems since appropriate way make notation understandable informal heuristic two descriptive systems independent common set notational conventions abbreviating giving parameter values appendix separates likewise exists effect isp description every pms component conversely isp statements imply particular pms component structures natural way present pms first also serve introduce main notational devices give isp finally add comments rela tionship pms isp pms level description digital systems characterized generally systems time exist one discrete set states undergo discrete changes state time highly ab stract view nothing said physical state corresponds system state nothing said laws physics trans form system one state another states given abstract labels transitions provided statetransition table many entries form system state si input ij system transformed state evokes output 0 alternatively state diagram information virtue statesystem view truly seems capture mean dis crete digital system disadvantage lies com prehensiveness makes impossible deal large systems immense number states order 10o states big computer existing digital computers viewed discrete state systems specialized three ways three speciali zations make possible much compact useful description systems one call pms description first state realized medium called information stored memories thus core store n words 32 bits digital device exist one 232n states sim ilarly states processor made explicit set registers accumulator address register instruction register status register etc holds specified number bits permanent information kept digital devices except encoded bits memory two qualifications blanket statement first basic unit information need bit could base one ternary machines decimal machines etc second sequential logic circuits carry operations system intermediate states strictly temporary affair operation occurring example intermediate inaccessible partial results multiply operation endwhen smoke cleared speakall information carried next operation encoded bits memories somewhere pms level care end result operations second specialization general statesystem view current digital computer systems consist small number discrete subsystems linked together flows information distinct component called memory another called central processor another called card reader etc analogous lumpedparameter specialization circuit level thus natural representation digital computer system graph component systems nodes information flows branches fact discrete character digital encoding bits prevents truly continu ous digital devices analogy continuously distributed parameter circuits one distributed networks small components iterated arrays topic much noted fig 1 chap 1 actually describe parts control mechanisms computers statesystem diagrams however exceedingly small pieces example may seen fig 7 page 7 15 16 part 1 structure computers current investigation possibility manufacturing integratedcircuit techniques emerged distributed net works look different computer systems today although still digital systems thus representation flow network functionally specialized nodes real specialization third specialization general statesystem viewpoint associated component digital system small number discrete operations changing state state neighboring components transitions must occur application operations evoked function current state component total behavior system built repeated execution operations conditions execution become realized results prior operations general statesystem view general statetransition table system may exhibit arbitrary pattern immediate state transitions without regard transition would physically realized summarize within specialized view one wants way describing system interconnected set components individual devices associated set operations work medium infomation measured bits base major complication picture amount detail involved describing actual computers takes whole manual instance describe operations major computer ibm 7090 thus descriptive system must permit compressed descriptions must also permit description aspects components interest ignoring rest interest pms level besides description gross structure computer system primarily analysis amounts information held various components flows information components distribution control accomplishes flows thus pmslevel description analogous chemical engineers diagram refinery interested various kinds liquid gas flow account matter energy loss system various stages involving trans duction materials one form another specific chemical plants external performance measured terms production flow rate given cost computers external performance concerned economical accomplishment discrete tasks pms level translates operation rates cost operations pms level ignore fine structure informa tion processing consider system consisting components work homogeneous medium called information infor mation comes packets called iunits information units measured bits equivalent units characters iunits sort hierarchical structure indicated phrase record consists 300 words word consists 4 bytes byte consists 8 bits record contains 300 x 4 x 8 9600 bits numbers300 4 8is called length since one often thinks iunit spatial sequence next lower iunits composed example one speaks ﬁword lengthﬂ record ﬁ300 words longﬂ decomposable hierarchy factors iunits structure pms level referent meaning thus possible say iunit refers employers payroll pressure boiler prime number satisfying certain conditions course iunits encode information necessary make reference pms level concerned referred fact certain components transform iunits modify meaning fact meaningpreserving operations basic information processing operations provide basic classi fication computer components pms primitives pms seven basic component types distinguished kinds operations performs memory component holds stores information ie iunits time operations reading iunits memory writing iunits memory memory holds single iunit associated addressing system means particular iunits designated selected memory also consid ered switch number submemories iunits changed way stored memory link l component transfers information ie iunits one place another computer system fixed ports operation transmitting iunit sequence component one port component except change spatial position change sort iunits control k component evokes operations components system components taken consist set discrete operations evoked accomplishes discrete transformation state chapter 2 pms isp descriptive systems 17 exception processor p components essentially passive require active agent k set small episodes activity switch component constructs link components switch associated set possible links operations consist setting links breaking others transducer component changes iunit used encode given meaning ie given referent change may involve medium used encode basic bits eg voltage levels magnetic flux voltage levels holes paper card may involve structure iunit eg bitserial bitparallel note ts meaningpreserving necessarily informationpreserving number bits since encoding invariant meaning need equally opti mal dataoperation component produces iunits new meanings component accomplishes dataoperations eg arithmetic logic shifting etc processor p component capable interpreting program order execute sequence operations consists set operations types already mentionedm l k dplus control necessary obtain instruc tions memory interpret operations carried throughout pms isp operation taken mean transformation bits one specific memory another instance operation transmit word information memory memory different operation transmit word memory mﬂ similarly operation add contents memory different operation add contents mﬂ reason emphasizing point one often talks addition operation ignoring specific locus operands discussion computer systems operation must include specification locus operands reason physical devices realize operations always local ized space instance wish physical device corresponds addition operands anywhere mem ory must couple physical device adds devices either transmit information memory adder exotic modify adder differ ent cells memory terminals thus symbol taken incomplete specification operation computer model pms components seven types connected make stored program digital computers abbreviated c instance classical configuration computer c mppctx pc indicates central processor mp primary memory namely one directly accessible p holds program transducer connected external environ ment represented x colonequals indicates c name follows right thus computer central processor connected primary memory one hand transducer input output device actually classic diagram four components since decomposed pc control k arithmetic unit dataoperation bp ktmsx mdtmsx solid informationcarrying lines instructions data dotted lines signify control often logic operations lumped control instead data operations longer seems appro priate way decompose system functionally associate local control component ap propriate component get l j solid lines carry information inter ested dotted lines carry information evoke operations respective components solid information iﬂ expresses mutually exclusive alternatives ms exists periphery 18 part 1 structure computers carrying lines k mp instructions suppress ing ks lumping processor state memory data operators control dataoperations processor state memory form central processor get mppctx computer systems described pms varying levels detail instance diagrams write links ls separate components would inter est delays transmission significant dis cussion hand iunits transmitted l different available terminals since usually case current computers one indicates simply two com ponents eg mp pc connected together similarly often encoding information iunits unimportant reason show ts statement holds ks sometimes one wants show locus control say one control many components tape controller often interest reason show ks pms diagram somewhat different case ds never occur pms diagrams computers since present design technology ds occur subcomponents ps make pmstype diagrams analog computers ds would show extensively multipliers summers integrators etc would mem ories variable switches rather large patchboard would represented elaborate manually fixed switch components often decomposable arrangements components thus memories composed switchthe addressing switchand number submemories thus memory recursively defined decomposition stops unit memory one stores single iunit hence requires addressing likewise switch often composed cascade oneway nway switches example switch addresses word multipleheaded disk might look like randoms randoms nears cyclicm word first srandom selects specific msdiskdriveunit sec ond random switch random addressing selects head hence platter side s1inear switch linear accessing selects track scyc1ic switch cyclic addressing finally selects mword along circular track note switches realized differing technologies first two srandoms generally electronic andor gates selection times 10 100 microseconds perhaps electro mechanical relay s1inear electromechanical action stepping motor pneumaticdriven servomechanism controlled arm holds readwrite heads selection time new track 50 500 milliseconds finally scyclic determined rotation time disk requires 16 60 milliseconds depending speed 3600 1000 write decompositions component sub components either actually know structure component even know behavior example could write memory random access mrandom even fact cyclic long behavior far larger system concerned took account cyclic character accepting average access time randomaccess time people speak control element computer often refer mainly processorsnot control disk magnetic tape however often complex suppress detail control often disappears pms diagram similarly agglomerate primitive components combining mp kmp mp physically distinct subparts computer system sepa rate control k often occurs functionally physically separate controll evolved past decade controls often big pc computers stored control pro grams decompose compound control find data operations calculating addresses error detection error correction data transducers changing logic signal levels information flow widths memory used k buffering finally large control k coordinates activities primitives clear discussion components named according function perform composed many different types components thus control k may memory subcomponent memory may transducer well switch subcomponents sibcomponents exist accomplish total function component make component also type instance transduction voltages input wires magnetism cores second transduction magnetism voltages output wires thereby become transducer far total variety names ks used controller adapter channel buffer interface etc rpm chapter 2 pms isp descriptive systems 19 system functioning concerned rest system remember iunits accepting delivering form voltages appendix end book define type simple component compound component reflecting part fact complex subsystems put together perform single function viewpoint total system example typewriter may 46 simple information transduction channels pms notation discussions used various notations designate additional specifications component example mp functional classification scyclic type access function many additional specifications one wants give many makes sense enumerate advance fixed position notation standard function notation fxyz first second third argument places fixed interpretation suitable instead agree single general way providing additional specifications x com ponent write xavav indicate x specified attribute value vl attribute a2 value v2 etc parameter call pair av well defined independently whatever parameters given hence significance order written number written according notation written mfunction primary saccessfunctionrandom rather mp sran dom shows immediately price paid general convention requires excessive amount writing would even apparent large number parameters given extra information seems redundant cases compensate disadvantages several conventions abbreviating abstracting parameters conventions listed appendix let us illustrate showing alternative ways writing mp mfuncti0nprimary complete specification mprimary mprimary drop attribute ﬁfunctionﬂ since inferred value use value outside parentheses concatenated dot use explicitly given abbreviation namely primaryp ambiguous drop concatenation marker dot needed recover two parts components given single capital letterhere rules corresponds natural tendency abbreviate redundant information given condition recovery must possible full description appendix component defined given large number parameters le attributes domain values throughout use slash introduce abbreviations aliases go thus p introduced abbreviation ﬁprimaryﬂ writing primaryp ﬁprimaryﬂ given one values attribute ﬁfunctionﬂ memory respect processors see page 607 list parameters appendix exhaust aspects component one might want talk instance many distinct dimensions component addition information dimension packaging physical size physical lo cation energy use cost weight style color reliability main tainability etc furthermore dimensions includes entire set parameters information dimension breaks set parameters given appen dix thus descriptive system open one new param eters definable occasion large number parameters provides one major challenges creating viable scheme describe computer sys tems responded part providing automatic ways one compress descriptions appropriate abbreviation still avoiding highly cryptic encoding separate aspect abstraction another major area conventions help handle large numbers parameters often happens one imperfect information attribute one wishes give value approximately partially instance one attribute processor time taken operations attribute defined com plex value pcoperationtimes add4 ps store4 p load4 ps multiply16 ps value list times separate operation however one might wish give range numbers difficulty distinguishing use use slash division sign latter takes priority since specific use slash 20 part 1 1 structure computers done without introducing new attribute ie operation timerange simply indicating value range pcoperationtime 4 16 ps similarly one could given typical times average times assumed frequency mix instructions pcoperationtime 4 ps pcoperationtime average 81 ps primary advantage notational convention per mits descriptions values used place actual values whenever desired keeps number attributes defined much smaller otherwise pms example using dec pdp8 let us describe pms structure actual though small generalpurpose computer dec linc8 pdp8 linc processor figure 1 gives detailed pms diagram explaining concentrate making notation clear rather discussing substantive features system described chap 5 simplified pms diagram system shows essential structure pdisp1ayt pc l nc ms l shows basic mppctx structure c addition secondary memory ms two processors one pclinc ms two switches used 10 bus permits access devices data break mp via pc highdatarate devices many switches actual system one see fig 1 example mp really one eight separate modules connected switch pc also many ts connected inputoutput switch sio collapsed single similarly data break consider mp module specifications assert made core technology word size 13 bits 12 data bits plus one different function size 4096 words operation time 15 ps could written information mfuncti0nprimary techno1ogycore operationtime 15 ps size 4096 w word 12 1 b fig 1 wrote values suppressing attributes since moderate familiarity memories permits immediate infer ence attributes involved example com mon knowledge computer memories store information words therefore 4096 w must number words memory another example specify function additional bit word wrote 12 1 b informed reader assume parity bit since common reason extra bit word extra bit unusual function would needed define absence additional information common interpretation assumed fact could even cryptic still com municated readers mcore1s psw 4 kw 12 b corresponds phrase ﬁa 12bit 15ps 4k core storeﬂ intelligible computer engineer 4 kw stands 4 x 1024 4096 known computer engineers however someone less informed took 4 x 1000 4000 real harm would done consider magnetic tapes pc since eight possible tapes make use controller k switch label 0 7 actually abbreviation index attribute like whose values integers since attribute unique character write 3 although could additional parameters give information physical attributes encoding alternative values tape one use vertical bar indicate bnf notation grammars thus 75 1 112 ins says one tape speed 75 inches per second one 112 inches per second tape switched dynamically run either speed many components information given thus knowing mmagnetictape connected control pc tells generally k ﬁtape controllerﬂ evokes actions tape read write rewind therefore actions done pc fact one k many mss implies one tape accessed time infor chapter 2 pms isp descriptive systems 21 multiplexor radial 7 pk consol e mp 07 s2sdcs4 k5 tcteletype io chars 8 bchar 64 char paper tape reader 300 charsi punch 100 chars 8 bchar 3 1 k 164 charcol 3 30 uspoint 01 1005 inpoint 3 kt incremental point plot 300 points 01 4 c npoi nt ktcard reader 2001800 cardmin ktcard punch 100 cardmin line printer 300 linemin 120 colline crt display area io x io in215 x 5 in2 k tliqht pen8 k tdataphone 12 48 kbs kl iolanalog output 0 10 volts ksl063 analog input 0 10 volts k k063 teletype 110 180 bs f12l parity bw 2 pdisp1ay 338 t03 crt display area io x io t03 light pen t03 push buttons console tconsole t015 knobs analog input tcrt display 5 x 5 in2 tdigita1 input output tdata terminal panel digital input output mpcore 15 pw 4096 w 12 ib smemory bus 3pcl 2 winstruction data w ibv 12 bw mprocssor statei2 31 w technolooy transistors 4stl0 bus pc 64 k ki 4 instructions mbufferl char2 w antecedents pdp5 descpndants pdp85 pdp81 pdfl fig 1 dec linc8pdp8 pms diagram 22 part 1 structure computers mation could given although provided usual specifying controller overall description sys tem next level detail goes structure actual operations instructions belongs isp level pms level used several different ways saying thing fig 1 order show range descriptive notations thus 64 teletypes shown describing single connection switch putting number links switch connecting line consider finally pc fig 1 given param eters datatypes processor state descendants etc parameters hardly define processor several important parameters easily inferred mp basic operation time processor small multiple read time mp thus predictable pc stores reads informa tion 2 x 15 ps one instruction fetch one data fetch case cdc 6600 neces sary say similarly word size pc word size mp 12 data bits generally pc must instructions take care evoking components pms structure instructions see switches controls distinct entities rather speak directly oper ation ms ts connected via switches controls summary parameters could given pc none would come close specifying behavior uniquely although knowledgeable computers still inferred parameters given instance knowing datatypes available pc number instruc tions one come close predicting exactly instructions nevertheless way describe pc full detail add larger larger numbers summary param eters direct revealing develop description level instructions isp description let us end introduction pms descriptive system returning critical item design philosophy descriptive scheme systems complex detailed digital computers must ability range extremely complete highly simplified descriptions must permit highly compressed descrip tions well extensive ones must permit selective suppression amplification whatever aspects computer system interest user pms attempts fulfill criteria providing simple conventions detailed description additional conventions permit abbreviation abstrac tions almost without limit result notation may seem somewhat fluid especially first contact brief intro duction assimilated pms seems allow flexibility natural language within enough notational controls enhance communication considerably isp level description behavior processor completely determined nature sequence operations sequence completely determined set bits mp called program set interpretation rules specify particular bit configura tions evoke operations thus specify nature operations rules interpretation actual behavior processor depends solely particular program mp also initial state data level programmer wants processor describedand pro gramming manual providessince wishes determine program thus isp instructionset processor description must provide scheme specifying set operations rules interpretation actually isp descriptive scheme need general enough cover broad range possibilities adequate past current generations machines along likely descendants saw earlier discussing pms level certain restrictions placed nature computer system specializing general concept discrete state system processes medium called informa tion system discrete components linked together information transfers component characterized small set operations assumptions built pms descriptive scheme integral way similarly isp level add two restrictions turn provide shape descriptive scheme first specialization program conceived distinct set instructions operationally means set bits read program mp memory within p called instruction register minstrnctionmi set bits determines immediately following sequence oper ations single operation may determined setting bit internal state p substantial number operations may determined ﬁrepeatﬂ instruction evokes search mp typical one twoaddress machine number operations per instruction ranges two five event sequence operations occurred next instruction fetched mp determined obtained entire cycle repeats chapter 2 pms isp descriptive systems 23 cycle activity described called inter pretation cycle part p performs called interpreter effect instruction expressed entirely terms information held memories end cycle plus changes made outside world execution operations may internal states sequential circuits represented bits memories end interpretation cycle whatever effect carried later time staticized bits mem0ryl second additional specialization dataoperations processors total set operations divided two parts one part contains necessary operate components given pms diagram links switches memories transducers etc operations associated components extent indirectly controlled p highly restrained basic nature components con trols second part contains operators associated processors component far said nothing except exclude completely pms com ponents except p operations produce bit pat terns new meaningthat ﬁrealﬂ processing changing informatiom2 dataoperations system would merely transmit information noted original definitions page 17 1 including com ponent capable directly changing information p create modify destroy information single operation noted earlier ds like primitive components analog com puter later express instruction sets simple arithmetic expressions ds primitive operators example description holds true p single active control inter preter ps ep cdc oo several active controls get involved ﬁoverlappingﬂ several instructions reordering opera tions according data devices available complex statement required express general restriction stating simple ps program decomposed sequence bit sets instructions local control behavior p limited period time interinstruc tion effects staticized bits ms 21n principle view 11 components ﬁrealﬂ processing false shown universal turing machine built l k components key operation write operation suffices construct arbitrary bit patterns suitably con trolled switches hence arbitrary data operations built stated view correct practice dataoperations provided p highly efficient bit transformations foolish add integers modern computer table lookup x x 2ﬂ v concatenation etc evoked instructionsetinterpreter part processor specialization dataoperations char acterized working various datutypes example datatype called signed integer dataopera tions add two signed integers subtract multiply take absolute value test two greater etc datatype compound two things referent bit pattern eg set bits refers integer certain range representation bit pattern eg bit 31 sign bits 30 0 coefficients successive powers 2 binary representation integer thus processor may several datatypes representing numbers unsigned integers signed integers single precision floating point double precision floating point etc distinct datatype requires distinct operations process occasion operations several datatypes may encoded single instruction datatype subfield selects whether data fixed floating point operations still sepa rate matter packaged datatypes remain distinct two additional specializationsinstructions datatypeswe define isp description processor processor completely described isp level giving instruction set interpreter terms operations data types memories let us concentrate first instruction set leaving interpreter later effect instruction described instructionexpression form condition actionsequence condition describes instruction evoked actionsequence describes transformations data take place memories right arrow control action k evoking operation recall operations computer system result modi fications hits memories thus action sequence ultimately form memoryexpression dataexpression left arrow transmit operation link corre sponds algol assign operation left side must describe memory location affected right side must describe information pattern placed memory loca tion details data expressions memory expressions patterned standard mathematical notation communi 24 part 1 structure computers cated easily examples true condition standard expression involving boolean values rela tions among memory contents get examples let us note two features action sequence first action sequence may conditional le form ﬁcondition actionse quenceﬂ second actions sequentially de pendent result one used input occasions set actions inde pendent occur parallel normal situation parallel one thus action sequence tx x x tx transfers information may considered simultaneous particular xs values defined situation transfer example b two registers atb bta exchanges contents b sequence required term ﬁnextﬂ used thus b next b transfers contents b transfers back b leaving b holding original contents b contrived example essentially b zsp example using dec pdp8 memories operations instructions datatypes need declared processor easily ex plained example although full definitions given appendix end book consequently let us examine isp description pc pdp8 given fig 2 pdp8 explained fully chap 5 throughout book isp descriptions computers follow highly structured format isp notation requires order help reader see similarities among computers processor state first need specify memories pc detail providing names various bits thus ac0ll accumulator memory called ac 12 bits labeled 0 11 left comments given italicsin case ac features notation use italics easily carried current computer character sets thus isp fig 2 publication language called accumulator designers pdp8 ac corre sponds actual register pc however isp imply particular implementation names may assigned various sets bits purely descriptive convenience colon used denote range list values alternatively could listed bit separating bit names commas ac01234567891011 defined second memory l single bit one could define combined register lac terms l ac lacl011 loac colonequal used definition middle square box 0 denotes concatenation note bit named l register lac merely happens correspond 1bit l register primary memory state dealing addressed memory either mp various forms working memory within processor need indicate multidimensional arrays thus mp07777 0 11 gives primary memory consisting 10000 le base 8 words 12 bits addressed indicated address necessarily reflect switching structure address occurs though often needless say reflects addressing space much actual available pms structure general memory within processor occur operands processors operators one ex ception primary memory mp defined memory external p directly accessible writing memories natural use base 10 numbers consider basic iunit memory bit always assumed unless otherwise indicated since used base 8 numbers specifying addressing range indicated change number base subscript standard fashion unit information bit used would subscript angle brackets thus mp077770 164 reflects memory choice carries course presumption organization terms base 64 characters would show specification operators true fact pdp8 also multi dimensional memories le arrays though examples occur chapter 2 pms isp descriptive systems 25 op ii fig 2 add extra dimensions extra pair brack ets example p pagedddress 111ll1 mabcd ghxy pdp8 memory might better described mp070310 127 0 11 representing 8 memory fields 32 pages per field 128 words per page 12 bits per word instruction fomat possible several names set bits eg defined instruction0ll define format instruction follows op02 instruction02 indirectbitib instruction3 pageobitp instruction4 pageaddress06 instruction5ll colonequal used allow us assign names various parts instruction effect making definition equivalent conventional diagram instruction notice pageaddress names bits shifted eg pageaddress4 instruction9 appendix gives permissible alphabet symbols isp general ﬁnameﬂ combination uppercase lowercase letters numerals including names would considered numbers integers mixed numbers fractions etc compound name sequences names separated spaces order make certain compound names reada ble space symbol may optionally used signify nonprinting character periods hyphens also used instruction set registers defined give instructions shown second page fig 2 unexplained parts left bottom first page return second page actually single expression named instructionexecution consists list instructions listed vertically page ease reading instruction consists condition action sequence separated condition arrow case condition expression form op octal digit recall op instruction02 expresses condition operation code machine particular value condition given name passing eg ﬁandﬂ name op 0 provides correspondence opera tion code mnemonic name operation code correspondence established elsewhere care numerical operation code ﬁandﬂ instruction could written ac ac mz would known condition name ﬁandﬂ stood could surmised little difficulty simply equality test operation code number isp descriptions later book gener ally form instruction written twos complement addtad op 1 loac tloac mz simultaneously define action tad instruction name abbreviation name conditions tads execution parentheses effect remark allow inline definition example single isp statement equivalent twos complement addtad loac loac mz followed tad op 1 instructions list constitute total instruction repertoire pc since conditions disjoint one one condition satisfied given instruction interpreted hence one one action sequence occur actually operation codes might present would illegal op codes would evoke action se quence act selection usually called operation decoding isp implies particular mechanism car ried normally logic circuit works directly op part instruction register way op codes assigned significant complexity decoding circuit thus times one exhibits instructions twodimensional decoding diagram makes evident bit patterns see fig 2 chap 5 rather linear list might wondered general introduce 26 part 1 structure computers pc state ac4 l pc4 1 run nte rrupt ta te ioulsel i04ulsej i0pulsea mp state tended memory included mo777784l pageoo177 i4l mo177 autoindexo74ll pageglo i7 4ll 88 8 8 accumulator link bitac extension overf low carry program counter 1 pc interpreting instructions running 1 pc interrupted programmed control io pulses io devices special array directly addressed memory registers special array addressed indirectlyis incremented 1 1c console state keys start stop continue examine load memory deposit store memory included oata switchesall instruction format instructionidlll opco 2 pagejq tp indirectbitib pageaddress4 6 thispage04 pco 0se 1 ec 5 opl b op2b iod4bit sza snl i42 i3 i4 i511 pco4 pcoii 1 i38 ili iio id i5 i6 id data entered via console op code 0 direct 1 indirect memory refereme 0 sezects page 0 1 selects page selects ms device 3 bits control selective generation 3 volts 04 ks pulses 10 devices p bit skip minus ac operate 2 gyoup u bit skip zero ac bit skip non zero link effective address calculation process r011 b 2 ib io z 17 f mz mz 1 next ib 3 mz 8 8 zo11 7 ib z ib mz zo pageobi 4 thispageopageaddress pageob oopageaddress li microcoded instruction instruction bitls within instruction effective auto indexing direct address fig 2 dec pdp8 isp description chapter 2 1 pms isp descriptive systems 27 instruction interpretation process run interruptrequest h interruptstate f instruction cmpci pc cpc next instructionexecution run interruptrequest interruptstate mo pc interruptstate 0 pc 1 instruction set instruction execution process instructionexecution op 0 f ac tac mzl tad op loac c loac mzl isz op 2 mzl mzl 1 next mzl 01 c epc 111 dca op 3 f me21 ac ac 0 jms op 4 f mzl cpc next pc cz 1 jmp op 5 pc z iot op 6 ioplbit f iopulse1 c next iop2bit i0pulse2 c next iophbit iopulselt c opr op 7 operateexecution interrupt interpreter fetch execute interrupt interpreter logical twos complement add index skip zero deposit clear ac jwnp subroutine jwi0 p transfer microurogrammed generate 3 pulses io device addressed i0select operate instruction defined end instruction execution operate instruction set microprogramed operate instructions operate group 1 operate group 2 extended arithmetic defined separate instruction set operateexecution cla i4 1 ac c 0 oprl io 0 operate group 3 c11 i5 1 l 0 next p clear link cma id 1 ac c ac u complement ac cml ir l 7 l next il complement l iac ili 1 f lmc clc 1 next u increment ac ral idio 2 lwc lmc x 2 rotate p rotate left rt i810 3 loac loac x 2 rotate3 rar i810 4 loac cloac 2 rotate rtr i810 5 loac cloac z2 rotatel clear ac connnon ooerate instructions u rotate twice left u rotate right p rotate twice right opr3 i31i 10 operate group 2 skip condition 62 id 1 f pc pc next skip condition ac 0 v sza ac 0 v snl l u acl skip test nsr i9 1 ac ac v data switches hlt i103 1 run w switches halt stop optional fa1 description eae i411 11 teafinstructionxecution 28 part 1 structure computers additional conventions language eg list instructions table mnemonic names special column rather write whole affair expression fact ex amine first page fig 2 note entire descrip tion pdp8 pc single expression reason although many processors fit format well eg microprogrammed machines making isp descrip tion general expression evoking actionsequences obtain generality need cover variations two examples pdp8 microprogrammed feature fact interpretive cycle simply becomes part total expression behavior processor let us consider actionsequence use standard mathematical infix notation thus write ac ac mz indicates word mp address z anded accumulator result left accumulator sumed operation designated hy well understood c course transmit operation processor basic set operations work datatypes machine datatype simply 12hit word viewed array hits operators need involve memories actually within pc processor state thus expresses change word mp directly must mechanized pdp8 means register pc irrelevant isp description also use functional notation example ac absac replaces contents ac absolute value action unspecified function operation generally write afab atub atbbc function unary operation binary operation respectively efectiveaddress calculation process examples given used z address mp effective address defined conditional expression manner algol lisp z0ll ib zﬂ ib 10 q zﬂ 17 mzﬂ mzﬂ 1 next ib mzﬂ right arrow analogous conditional sign used main instruction equivalent ﬁif ﬂ algol parentheses used indicate grouping usual fashion however arrange expressions page make reading easier expression z shows permit conditionals within conditionals also nesting definitions z defined terms zﬂ emphasize structure definitions may reflect underlying hardware organization hut need describing existing processors book isp description often reflects hardware one designing processor isp expressions would stated design objectives rt structure latter might differ considerably special note taken opr instruction op 7 fig 2 since provides microprogramming feature two separate options depending instruction3 0 1 common operation clearing ac associated instruction4 within one option instruction3 0 series independently executable actions following clearing l within instruc tion3 l three independently settable control ac tions nested conditionals use ﬁnextﬂ force se quential behavior make easy see exactly going fact good deal easier describing natural language instruction interpreter instructions defined pdp8 including effectiveaddress computation z remains define interpreter hardware point view interpreter consists mechanisms fetching new instruction decoding instruction executing operations designated determining next instruction substantial amount total job already taken care part isp explained instruc tion carries condition amounts one fragment decoding operation likewise decoding instruction might done common interpreter chapter 2 pms isp descriptive systems 29 rather individual operation circuits implied expressions instruction expression effective address thing left fetch next instruction execute standard machine basic principle defines operationally meant ﬁnext instructionﬂ normally current instruction address incremented 1 principles used eg processor cyclic mp addition several specific operations exist repertoire affect program control basic principle acts like default condition nothing specific happens determine program control normal ﬁnextﬂ instruction taken thus pdp8 get interpretation process essentially classic fetchexecute cycle ignoring interrupts run instruction mpc pc c pc 1 next fetch instructionexecution execute sequence evoked long run true ie bit value 1 processor simply cycle sequence fetch ing executing instruction pdp8 exists halt operation sets run 0 console keys course stop computer noted isp descriptions book generally include console behavior state diagram fig 3 useful represent behavior instructioninterpretation process instruction inter preted system moves state state states null case simple transition made successor null state kinstruction interpreter con fetch read determines instruction q operotion calculation decoding iﬁ request operond mp rand multiple operands l pcz pc2 operotion specified calculotion 0vr operand store write ii restore results operond address calculation ov w return string instruction complete vector data fetch next instructioh mp controlled state pc controlled state note state may null state name soqoq saqoq oao savrovr savrav r soo sovwovw savwov w time stote toq taq ta0 tov r tav r tav w tav w meaning operation determine instruction q access mp instruction q operation decode operotion q operation determine variable address v access mp read variable v operation specified q operation determine variable address v access mp write voriable v fig 3 isp interpretation state diagram 30 part 1 structure computers trols movements according information instruc tion states null multiple alternative transitions occur depend instruction interpreted within state various operations carried control subordinate ks note upper states fig 3 controlled mp whereas lower ones controlled pc tried use simple mnemonic scheme label states operation q instruction access r read w write similarly prefix state indicate time duration state may prefix state figure 3 somewhat detailed usual use chap 3 describe number different processors however figure simplifies familiar fetchexecute cycle fetch oq aq tfetch toq taq execute 00 ovr avr 0 ovw avw texecute t0vr tavr t0vr tavr t0vw tavw consider way example tad instruction pdp8 using general state diagram fig 3 isp net effect run instruction mpc pc pc 1 next tad op 1 lu ac lo ac mz z0 11 specijies effectiveaddress calculation process state diagram detail explain computers behavior respect timing temporary registers note complete state diagram physical pdp8 given fig 11 chap 5 actual state table appears page 31 notice isp description determine way processor organized achieve sequencing take advantage fact many instructions lead similar sequences specify unambiguously oper ations must carried program mp 1sp descrip tion specify actual format instruction enters total operation although sometimes indirectly example case instruction op 0 definition ac shows ac depend instruction definition z shows z depends fields instruction indirectbit pageobit pageaddress likewise form isp expression shows ac pc enter instruction implicitly isp description de pendence memory exp1icitl datatypes dataoperations completes description isp pdp8 complex machines number datatypes operations much extensive datatypes may declared independently instruction set manner declared memory fact one major piece organization structure processors isp level appeared example involves datatypes datatype set operations proper add subtract multiply divide proper numerical datatype well absolute value negation need exist computer datatype since several alternative bases well levels completeness instance notice pdp8 first multiply divide unless one special option thus relatively minimal level arithmetic operations second subtract operation using twos complement add permits negation ac accomplished complementation tac followed add 1 still options rather provided one de cided include given datatype repertoire ap pendix end book given datatypes classes thereof sets operations proper datatype pdp8 example several data representa tions externally considered entity oper ator floating add one integer add however denote symbol case indicating difference parenthetically expression alternatively specification data type attached data thus ibm 7094 instructions correct actually physically realizing isp description additional memories may utilized may even necessary said isp description memories implicit however consistent complete description isp made without use additional memories whereas say singleaddress machine seem possible describe instruction without refer ence implicit memoriesas see effectiveaddress calcula tion procedures definitions look much like registers chapter 2 pms isp descriptive systems 31 stutes time soq toq isp effect operational description pc calculate address instruction q calculate address next instruction q 1 address stored address register used control access pc c pc 1 sfetch 1 1 taq 1 tmma saq s0vr sexecute savr fetch data memory location mma ie essentially mpc place result buffer temporary register t0vr tfmbir calculate address data tavr mb mma fetch data mp l 0 actl 0 ac operation specified instruction so0 7 ir tmbo2 1 calculate decode instruction add ac ac add carry logical wordacl ac ac unsignedinteger floating addfad ac c ac sf unnormalized floating addufa ac c ac suf doubleprecision floating adddfad acmq acmq meome 11 df doubleprecision unnormalized floating adddufa acmq acmq 0 11 duf first one without special indicator datatype taken integer addition next unsigned integer next single precision floating point next unnormalized single precision floating point next double precision floating point last unnormalized double precision floating point although often clues could used infer form addition defined eg double precision takes two words label integer operation use braces differentiate operation performed examples thus datatype enclosed braces refers memory elements oper ands expression alternatively use braces modifier memory signify information meaning example fixed point floating point dataconversion operation would given acfloating acfixed also use braces modifier operationtype exam ple shifting left right multiplication division base always arithmetic operation pdp8 instance l 0 ac l 0 ac x 2 rotate end bits l acl1 connected shift occurs operator also referred circular shift general nature operations used processors sufficiently familiar computer professional definitions required taken primitive necessary agreed upon conventions different data repre sentations used appendix provides basic abbreviations essence datatype made recursively concatenation subparts datatypes concatenation may iteration datatype form array fig 4 shows structure various datatypes built primitive datatypes required operation defined terms presumably primitive operations necessary first define data format explicitly including perhaps addi tional memory variables operands permitted natural way example binary singleprecision floatingpoint multiplication 36bit machine could defined terms data fields follows 32 part 1 structure computers stacks linked vector n elementslineor list matrixn xm elements zdimen xdex xdn elements simple multiple type structures unnormal flaotinguf double flooting complex double complex ore normally considered non decomposable primitives fig 4 common datatypes recognized processor hardware sf mantissamantissa 027 sf exponentexponent 2835 sf exponentsign 28 sf signsign 0 xl x2 x x3sf xl mantissa x2 mantissa x x3 mantissa xl exponent x2 exponent x3 exponent next xl normalize xl sf normalize xl normalizex2 sf xl mantissa 0 xl exponent 0 xi mantissa 0 x20 x2 1 xl mantissa xi mantissa x 2 xl exponent x2 exponent 1 next xl normalizex2 sf three additional aspects need noted respect data types two substantive one notational first everything one item data makes use properties datatype example numbers moved place place operation numerical operation depend item number fact purpose data transmission item word assuming fits single word treated second one often embed one kind operation another coalesce data types saw small extent example pdps arithmetic operations pervasive example encod ing mp addresses integer datatype used regular arithmetic need separate datatype addresses upshot aspects seen present outline structure datatypes shows one datatype embedded another various purposes datatypes embedded datatypes common operations word integer fraction mixed unsigned integer address integer boolean single bit integer sign divide multiply two operations field single precision unnormalized floating boolean vector single precision floating double word double precision integer fraction mixed double precision unnormalized floating point double precision floating point character string digit string however logical course may seem always done way example ibm 7090 members family 15bit address datatype 36bit integer datatype separate operations chapter 2 1 pms isp descriptive systems 33 notational aspect use isp mnemonic abbre viation scheme datatypes already used sf single precision floating point generally table 1 shows abbreviation made letter giving precision letter giving name letter giving length full treatment found appendix simple naming convention take account known datatype information carrier data partially included length characteristic thus carrier also include data base sign conven tion representing negative numbers common sign con ventions sign magnitude true complement ie twos comple ment base 2 radix1 complement ie ones complement base 2 datatypes processor must implied operators fact able represent particular entity useful particular transformations carried entity primitive operation data movement ie trans mission data movement thought complex operation consisting accessing locating reading writing datatypes represent numbers require ability perform arith metic operations x abs sqrt max min etc address integer special case arithmetic quantity often additive arithmetic operations available boolean scalars vectors require subset 16 logical operations sufficient subsets l l v character strings represented concatenation deletion transmission operations required alternatively look string processing languages like snobol comit see operations require strings also represent numeric quan tities arithmetic operations necessary almost arithmetic symbolic data require relational operations tween two quantities yielding boolean result true false relational operators arithmetic quanti ties includes complex structured data types eg vectors arrays also range certain primi tive operations scalar accessing transmission typical operations vectors search elementbyelement compare operations relationship pms zsp introduction chapter discussed briefly rela tionship pms isp two described precise really two questions first two descriptive systems fit respect general hierarchical view computer structures discussed table 1 abbreviations used name datatypes precision datatypename lengthtype fractionalf booleanb sca r quarterq halfh ﬁsingles doubled triplet sign vectorv decimal digitdigitd matrix octal digitoctalo array charactercharchc stringst byteby quad r u pleq syllable wordw multiplem integer eq 10 signed integeri unsigned integerui fractionfr fixed ixed mx floatingrealf unnormalizedfloatinguf complex realcomplexcx examples w word bv boolean vector integer sfr single precision fraction mx mixed di double integer 10d 10 decimal digit scalar 3ch 3 character scalar chst character string sf single precision floating suf single precision unnormalized floating df double precision floating duf double precision unnormalized floating may optionally omitted name chap 1 second relationship pms diagram processor isp processor questions related best answered separately respect first question pms system describes topmost system level recall fig 1 chap l programming logic circuit levels lacks characteristic levels share namely providing complete description computers performance programming manual timing tells everything significant performance computer runs errorfree true full description registertransfer level logic circuit level electrical circuit level pms level approximate description certain aspects systems performance calculated 34 part 1 structure computers isp constitute distinct system level rather describes interface two levels registertransfer level programming level used define compo nents programming levelinstructions operations seqnences instructionsin terms next lower level principle usually fact language lower level used describe components modes connections one level many ways isp registertransfer language symbolic rather graphical formbut noted chap 1 appear always two isomorphic notations system level however isp extended allowing instructionexpression general linguistic expression computation isp fortran algol permits us talk isp necessarily determining exact set physical registers transfer paths instruc tionexpressions describe functions performed without entirely committing rt structure isp interface language rt pro gramming levels relationship pms one level every pms component associated set operations control structure getting operations executed connection arrival various external signals noted earlier chapter isp description operation context control isp interface language describing pms components terms registertransfer level p happens one pms components processor carries entire new systems levelthe programming level compo nents analog programming level interface directly registertransfer level even simple cases logiccircuit level precisely simplicity bothered develop isp descriptions components components processors second question namely relation isp pms descriptions processor arises ability represent pms components recursively pms structures made elementary pms components thus mp32 kw 16 b considered compounded 32k memories ml w 16 b addressing switch random indeed one carries limit ms single bit memories flipflops ss one bit gates couple specific ks defined etc possible draw pms diagram isomorphic logic circuit thus processor p rep resented pms involving ms ks ds ss etc varying levels detail since also description p isp appropriate consider correspondence first every memory isp description corresponds memory pms description data operations isp imply corresponding ds pms every occurrence transmit c implies corresponding link ms ds right hand side left written instructions isp evoked certain condi tions implies control koperationdecode exist pms structure similarly simple twostate storedprogram model instructionfetch instructionexecute interpreter implies interpreter control kinterpreter actionsequence instruction contains semicolons nexts requires addi tional k possibly additional structure involves em bedded operations b x c thus every isp component implied component pms struc ture processor pms diagram model computer shown initially page 17 ﬁnatural unitsﬂ implied isp description exception instruction format part suggested page 24 dataoperations therefore implied time operation written process implies control lump single k figure model also shows arrival instructions flow data proc essor p memory mp several memories within pc explicitly shown page 17 include temporary memory within k carrying complex arithmetic operations interpreter control temporary memory course finally kinds memories omitted simplify model multiprogrammed computers mapping control memory would used pipeline highly parallel processors would temporary memory various buffering eg instruc tions data appendix lists various memories processor kp control processor controls data move ment among mp mprocessorstate evokes data operations functionally kp broken several parts responsible part overall instruc tion interpretation execution process corresponds part isp description decomposition allowed pms component would contain independent control domain eg kd kmp k1nstructionset interpreter elaborate processor structures imply controls functions like multiprogram mapping k1nstructionset interpreter supervisory component causes processor ks utilized complex processor isp description c interpreter usually chapter 2 pms isp descriptive systems 35 selects next instruction decoding exam ining proceeds instruction executed kinstruction execution resource allocution pms level concept resources uses allocation becomes major focus analysis obvious multiprogramming multiprocessing sys tems many programs share mp hence must allocated space holds equally well levels detail giving resource allocation diagram along state diagram fig 5 show relationship resources func tion time instructioninterpretation process fig 5 add instruction simple 1 accumulator computer con sisting 1pc2mp given interpretation fig 5 isp follows calculates address instruction q state soq toq pc pc 1 next aduunce program counter instruction fetched accessed mp state saq taq minstruction mppc next operation performed address part v data minstruction added obtained state so0 s0vr t0vr maddress minstruction v next data mpv fetched state savr tavr mtemporary mpmaddress next operation part instruction carried actual addition performed data previously accessed state mtemporary next state diagram state represents time spent given activity two states top state diagram fig 5 waiting primary memory accesses three lower states represent processor activity waits specialize state diagram conventional 1 address instruction computer would need one additional state repre senting operand storage savw would occur state note ignored operation decoding state s00 course conditional state transformation paths added describe instructions eg complementtheaccumulator instruction states soq saq similarly could instruction data operand fetch fetch mptl 1 mp 0 instruction data instruction address address execution calculation calculation operation 1 j time spent state processor state tcycle data fetch instruction interpreted mp 1 tad aatmzl tl f2 instruction execution 30 instruction data address address colculotion colculotion fig 5 state resource allocation diagram 1pc2mp add instruc tioninterpretation process make general state diagram handle different proc essors eg multiple addressesinstruction stack general reg isters shown fig 4 pms level derivative state diagram resource allocation diagram useful cause relates physical structure resource allocation diagram expresses instruction activity terms time unit occupied particular activity diagram slightly complex computer struc ture two primary memories assumed case add instruction long memorycycle time suggests two memories used operand fetched instruction memory restoration occurs diagrams show time various resources utilized thus performance utilization measured resource allocation diagrams express time scales interest operatingsystem software analysis often ac tivities longer time scale resources utilization 36 part 1 structure computers function various programs subprograms may show mp memory occupancy multiprogrammed environment time scales particular interest instructions short instruction sequences subprograms program times first two time scales influenced predominantly hardware latter time scale influenced software ex ternal environment resource allocation diagrams also describe utiliza tion cs resources time eg throughout instruc tioninterpretation process provide basis detailed analysis design design problem pmsisp interface mainly one resources scheduling 1 fixed set operations performed jobs job instruction instruction may create small definitive subjobs fixed set operators handle various parts operations jobs instructions enter p sequentially 2 3 4 may ask 1 2 many operators type scheduling policy assigning instructions operators many instructions p one time order must processing performed jobs interlocked 3 attempt answer questions intend show relationship various parts define problem isp implies certain structure conversely pms behavior specified terms isp language particular isp structure program denote certain path state space specified state diagram finally physical sources pms constrained operate according state diagram expressed using resources allocation diagram resource allocation diagram used evaluate structures performance pms higher level eg number instructionssecond executes state diaaram behayj isp description progrom rt description behavior rt level summary isp descriptions computers usually given appendix chapter organize description following units state p console state memory declaration instruction format datatype formats special data effectiveaddress calculation process operation definitions process interpreter instruction interpretation process formats operators instruction instructionset instruction execution set execution description format conveys rather narrowminded view isp structure computer systems however almost present computers fit easily format presume say whether suffice future isps introduction given definitions example appendix end book possible understand pms diagrams isp descriptions used throughout book chapter 3 computer space introduction preceding two chapters provided view computer system organized hierarchy many levels physical devices electronic circuits logic circuits registertransfer systems pro grams pms systems must remember levels description remains physical system higher level describes total system loss detail engineered system great care taken level represent adequately behavior necessary determine performance system natural systems often many levels description eg biological systems molecule organelle cell tissue organ organism however natural systems usually depend statistics eliminate details lower levels permit aggregation always imperfectly computer systems hand aggregation intended perfect fails course error detection error correction exist fundamental activities computer systems imperfec tions ascribed system description opposite treat natural systems pms level description natural sense intended result design perform ance defined ultimately programming level aggrega tions simplifications go pms description eg measuring power bits per second approximations natural system eg measuring productivity economy gross national product provided descriptive systems top levels hierarchy pms level isp level latter defining basic components programming level terms rt level two descriptions concern overall design computer system define lower levels go beyond focus book neither define program level partly exists uniform description common programming language partly computer designer works mostly interface defining instruction set latter isp pr0videsl increasingly popular view program rt levels isp one thus erasing difference hardware pms isp permit description indefinite number computer systemsindeed come within scope current design art might even taken definition current art lo4 lo5 individual computer systems fact come existence described pms isp radically individual lo3 types computer systems represented define two systems pc type exercising various options single computer type could take lo5 different forms thousandodd types present book 402 sort total population miniscule sample look like compared whole fundamentally significant aspects computer systems used comparison classification questions try deal chapter neither comprehensive elegant simply yet done necessary study base adequate taxonomy computer systems hut present rough picture based common lore field filled predilections system either entire computer c component p convenient distinguish function performance structure system designed operate task environment accomplish tasks function well tasks performance evaluation performance normally restricted tasks although always noteworthy system perform adequately outside specified domain eg business computer also good control computer rarely worth noting system perform tasks built perform thus function denotes scope performance denotes evaluation within scope structure denotes aspects system allow perform includes descriptions subcomponents organized performance subcomponents often may considered structure far whole system concerned especially performance taken given example early digital transmissionoriented telephone lines came two capacities 200 bitssec 2000 bitssec view point telephone system performance measures software boundary appears us quite invisible take important task drawing boundary right place specific design 2counting families part 6 one computer ibm sys tem360 actually series 37 38 part 1 structure computers viewpoint computer system remote terminals structural parameters typically design proceeds context function tobedeveloped system taken given certain struc tures available problem construct structure achieves adequate performance terms apply designed system example con sider automotive vehicles function classification use cars carry people trucks carry goods racers win competitions antiques satisfy nostalgia collectors pride performance aspects behavior relevant function maximum speed powertoweight ratio cargo capacity run versus run antique structure things number wheels shape vehicle stroke volume gear ratios structure determines performance although standpoint design course causality runs way function perform ance structure three main ways classify describe computer system according function performance structure consists turn number dimensions useful think dimensions making large space computer system located point space thousand computer types built date constitute sparse scatter clustering hoped various regions make sense functionally economically 40 computer types book sample larger scatter way give picture entire space part already explored many dimensions computer space definitely many one wants locate computer ultimate precision fact one wants go way one might well give pms isp descriptions rt logic circuit device levels virtue thinking space abstract small number dimensions select relevant functions one wants influence design performance one wants make largest difference structure affect performance represent possible design choices computer engineer addition one wants dimen sions along significant variation aspects computer systems common use binary devices though supreme interest part computer space dimensions computer space marked earlier sufficiently comprehensive theory computer systems tell us considerable lore grown lip experience date designing machines point one must simply propose set dimensions let justify fact table 1 gives set function structure table 3 page 52 gives set performance table 1 gives single dimension computer system func tion 19 computer structure table 3 gives 8 per formance however dimensions independent many structure dimensions highly though perfectly correlated thus table 1 put structure dimen sions seven horizontal groups one lefthand side relevant first structure group also added two temporal dimensions since strong correla tion time exists performance dimensions form tree structure higher dimensions essentially aggre gate summaries lower ones finally general correlation overall performance various structure dimensions table 1 increasing performance one moves dimensions left two important dimensions values reliability mean time failures per operation physical size density eg bitsft3 increase generation dimension indicated range possible values pcspeed example numerical quan tity however range discrete set design choices may may simple ordering clearly discrete values selections meaningful subspace design choices mostly know construct subspace values given arisen practice serve classify computers book obtaining rational subspace task future research body chapter taken discussion dimensions discuss definition basis selection reasons behind arrangements tables 1 3 give entire set dimensions beginning later reference emphasize view single computer space com puter systems located refer tables 1 3 simply computer space narrowly computer structure space computer performance space etc history like systems subject variation selection computers evolved time striking rapid evolution concept ﬁgenerationﬂ become firmly embedded computer engineering culture say nothing marketing culture view lay public best ambiguous term none sharpness root term biological evolution possible draw strict genealogical tree chapter 3 computer space 39 nevertheless term useful stressing history computer systems story particular men discovering building particular things somewhat impersonal widespread series advances changed computer systems radically generations best defined solely terms logic tech nology first generation vacuum tubes 1945 1958 second generation transistors 1958 1966 third generation integrated circuits 1966 fact current usage describes hybrid logic technology machines ibm system360 third generation extension must included called fourth generation yet emerge likely medium large scale integrated circuits possibly integrated circuit primary memory measure american industrys generally ahistorical view things title ﬁfirstﬂ generation allowed attached collection machines genera tions removed beginnings reasonable accounting mechanical electromechanical computers existed prior electronic ones furthermore functional equivalents electronic computers realized also separated wide gap performance structure vacuum tube machines thus rea sonable reckoning currently fifth generation com puters third usage well established change actually always viewed thus figure 1 reproduces genealogical tree early computers prepared na present generation first generation predecessors 5 roots fig 1 ﬁfamily treeﬂ computer design remarkable growth electronic computing systems western world began primarily government support research development universities need dataprocessing facilities increased capacity inspired support development educational institutions private industry current generation computers predominantly result development private industry tree lists many machines developed ways roots contributions many existing technologies rapid growth electromechanical electronic systems milestones eniac electronic numerical integrator computer first electronic computer edvac electronic discrete variable automatic computer first internally stored program computer first acoustic delayline storage madm manchester automatic digital machine first index registers 6 lines first cathoderaytube electrostatic storage mtc memory test computer first corestorage computer courtesy national science foundation 40 part 1 structure computers table 1 computerspace dimensions computer function scientific business control communications file control switchinglstore forward terminal time sharing logic historical costoperation technologq generation date pcspeed sec hit 1s mechanical electromechanical 1930 101 1000 fluidics 1970 102 vacuum tube first 1945 103 10 transistor second 1958 105 1 hybrid 1964 106 integratedlc third 1966 107 01 medium large fourth 197 108 001 scale integrated msi lsi word size base datatypes 8b binary word decimal integer1 address integer bitlbit vector instruction floating point 12 b 24 b 32 b 48 b character 64b character string 16 b 31 character 6b word vector character 8b vector matrix array lists stacks addressesinstruction mprocessor state excluding program counter 0 address stack stack 1 address 1 accumulator 1 x index address 1 g general register address 2 address 3 address explicit state n 1 address language determined compound microprogrammed accumulator index registers general registers array chapter 3 1 computer space 41 pms structure switching processor function 1 pc 1pcnpio nm timemultiple x pc io 1 pcnpiopdisplay pi0 2c duplex 2n dualduplex pdisplay npc mu1 ti processing npcparray1 special algorithm parray npcparalle1 processing pvector move c network palgorithm network n2n2 nonhierarchy planguage accessing algorithm mpsize mssize mpspeed bs msspeed bs ln duplex pmicroprogram lpcinterrupt pc nm crosspoint linear stack linear queue bilinear cyclicrandom cyclic random content associative tape large disk medium magnetic card largel drum large drum small photostore large 106 core medium core smaller 107 film small 108 integrated circuit 109 r 105 mp concurrency lnterprocess communication 1 program subroutines traps 1 program interrupts interrupts 1 program multiple concurrent subprograms example 1pcnpio monitor fixed programm 1 program n swapped programs n programs multiprogramming interprocessor interrupts extracodes programmed operators monitor calls relocation 1 segment 2 segments pure impure 2 segments pages fixed length paged segments multiplelength paged segments n segments shared programs intersegment communication variablelength segments named segments processor concurrency serial bit parallel word multiple instruction streams 1pc multiple data streams arrays 1 instruction buffer n instruction buffer lookaside memories pipeline processing 42 part 1 structure computers tional science foundation 1959 notice harvard mark machines constructed relays hence electro mechanical accorded place honor first generation babbage nowhere seen appropriate provide adequate history computer technology early story often told starting babbage early mechanical calculators hollerith punched cards relay calculators bell laboratories harvard birth electronic machines enjac finally storedprogram concept von neumann machine institute advanced studies ias edsac cambridge university edvac university pennsyl vania contemporary developments zuse germany often left scattered attempts tell story last three generations date really satisfactory historical account given due part recency part difficulties evaluating sorting significant developments complex technology undergoing rapid growth appropriate view evolution computer systems measured dimensions computer space localize examples book relation calendar time computers concept generation led others attempt thing constructing family tree fig 1 one example relationships computers nearly simple tree implies prefer plot straightforward time chart shown fig 2 group machines manufacturer within group ac knowledged family relationship example 701704709etc clearly relatively closer kinship within company whereas checked time chart numerous times accuracy make claim nuniber errors still relied following source data 1 original papers mostly shown chart ﬁpﬂ normally reader infer work pre sented paper occurs prior actual publication notable exceptions eg core memory atlas papers first pub lished lay claims certain ideas 2 historical reviews primary torical papers include rosen 1969 serrell 1962 secondary torical review papers include bowden 1953 campbell 1952 chase 1952 nisenoff l966 samuel 1957 3 encyclopedia 4 computer surveys two sources used adams associates computer characteristics quarterly published since 1960 adams 1960 adams assoc 1966 1967 1968 martin h weiks four surtieys domestic electronic digital computer systems weik 1955 weik 1961 third weik 1964 fourth adams charts give date first delivery weik survey gives date computer first operating 5 manufacturer organization person supplied dates cases asked directly sdecific oeerational delivery companies one advantage time chart depiction life history single system showing long takes computer systems go paper prototype production computer types shown chart 250 estimated 1000 types lack space perseverance accounts omissions major united states manufacturers well minor ones chines substantial historical interest represented machines discussed book gathered together sep arate line though also occur elsewhere appropriate foreign machines omitted unless described book addition machines many early minor manufac turers missing alwac elecom etc second part time chart arranges many computers word size give reader classification unfortunately samples given owing space limitations thus density graph indicate true density existing machines many small computers dedicated particular task beginning built comparatively small number large computers built bottom fine line place machines book third part time chart deals technology listing events along various dimensions significant evolution computers besides dimensions computer space also added dimensions describing software systems although able deal programming level book except isp interface development clearly important hardware exists strong mutual interaction two fourth final part time chart gives selected technological events leading development com puter includes early work babbage desk calculators bell labs harvard calculators many stories read chart example note early bell telephone laboratories relay calculator used remotely dartmouth 1940 20 years prior remote use timeshared computers note also successful manufacturers tend small number computer families add members technology dictates omit exodus computer companies hope reader gets much en joyment browsing chart even put together computer space table 1 time chart fig 2 provide overall framework ready consider dimensions individually starting system func information tion performance finally structure l92 1343 l9t4 19145 l9i6 ic7 19148 19149 iq50 1251 i952 1253 1954 l955 1956 i957 l958 i959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 sosscientific data systems decolqifal eguipmevt corporation cdclcontrol data corporation gegeneral electric honeydel burroughs rcaradio corporation america pop10 ir 9100 k 36 bw pop6 iflme shared hit llnc based pop8 lin8 qpriz_pdp pdpbl 12 bwl k pop5 k pdp4 pdp7 pop9 pp15 18 bw pdpid 6400 6500 7600 ku large scale scientific 60 bw k 6600 17016 bwr k 3200 lioo33no 3500 k 3600 3400 3800 160a 160g 80908092 24 bw 12 bwl ku 160 148 bwl ku 1604 1604a i36 bwl k 63564562543pp 412 24 bwl 215 235 205 24 bw 4040 405046ol4o20 bw ge 210 16 dw 4050 1 ge loo erma 7 dw e 22001200120 42008200 200 series 6 bchar ibm 1401 based 2oo 224124 24 bw 316 l4ooldo ku 800400 datamatic 1000 12 48 bw note family wrpw computer controls division 48 bw stack muitiproce5sor 05000 0825 6000 85000 05500 88501 b6500 88501 bu5ine55 8 bchar b2500 b2501b3500 6bchar k 8250 8300 0260 8263 8160 8270 e213 8170 ir 12 dwpluqboaid program eiol e102 e103 8280 8283 0180 220 i10 dw k 204205 oatatron division lcpc 607 604 609 608610 6400 360195 stretch 170301 164 bw larqe scale accounting machinescaculators scienci f c business hachines eraengineering research assol scipntl univac univac 12 bw univac ill27 bw b bchar i050 30 bwbcd 0111255 bmeckertmauchly business fc ivac ice university rice muse atlas atlas manchester university mark index registerslbtvber atlaslatlas2 feiranti corporation nplnational physics laboratory 5 ace based machines dyseac nbsnafionalbureau standards seac tudvcircyi nit lincoln laboratory tcmemry e computer txo ceg24 ace wlis electric deuce ndix g15 one level extra codes serc _fxi linclaboratory lnstrumnt computer phw cons ruct tapedrum core memory 50mht10gicin operation wolf r z whirlwind edsac bared jqhnniac tubes selecfron mmor lmagnetlc core transistors arithmetic element1 universlty chicago maniac i1 ias compatible 111 e p university illinois ordvac brl illiac also silliac cyclone illiac i1 illiac 111 illiac iv lasburkr goldstine vonneumann welzac mistic design 1 based solonan based edsac neumann dt ias based cambridge university eosac willies university ennsyvania moore school electrical engineering edvac eckert hauchly yon neurnann announcement sale 51 scheduled delivered first w wi thdrawn p 0 operational k reasonably compatible series bell teledhone laboratorits nonstored program calculator haryaard universyty hark markli hark 171 mark iv 5 project started enlac patent eectdc circuits p paper ku upward compatible lit ivbaliistici v vi leprechan transistor 1542 1443 194 1945 1946 1947 if48 15149 1950 1951 is152 lm3 19 i555 lh6 1g57 l8 1559 1 1961 1g62 63 184 15 i66 19x7 1968 is9 1970 fig 2a time chart computers originator 2448 1624 1216 i10 character string business decimal word business shall early scientific e _ _ 940 941 942 1943 944 1945 1946 1947 194r 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 l961 1962 1963 1964 1965 1966 1967 1968 969 1970 2b time chart computers word size software lines operating systems discrete simulation languages ist processingstring manipulatii algebraic manipulation languages algorithmic languages assemblers loadersiders hardware lines mapping pc concurrency pc function pms structure secondary memory hemory technology primary memory 5 zewi h speed logic technology 46 part 1 structure computers analytical charles babbage difference 17921871 card controlled hullers difference engine 50 digitswordl 100 wordr 0 first generft onsfcondth rd bell telephone labs ill iv v vi vacuum tubes 21 zi rlegraph j mfchanical memory j electro electromagnet telephone u fig 2d time chart precomputer technology 35 40 l5 50 55 60 6 70 9 operational p paper function striking fact function existence single dimension values perhaps taken simplistic view functions computers perform think computer space represents reality wit tkere remarkably little shaping computer structure fit func tion performed root lies generalpurpose nature computers functional specialization occurs time programming time design however might seem specialized environments would require gen erality functional adaptation would still possible appears two reasons first level opera tions pc defined isp basic reflect kind specialization offered environment think infor mationtransfer conditionaltransfer operations second environments ultimately require variety tasks addition main specialized task include least language com pilation assembly readable formatted output debugging aids utility routines time added substantial requirement generality generated however whole story second part differ ence computer type specific configuration assembled task latter often carefully specialized function performed mostly amount mp amount types ms number types ts within limit items attached type computer ie pc handled environment independent way thus little specialization computer types great specialization particular configurations case indicates something nature functional specializationthat expressed adequately gross pms terms bits storage data rate still story functional specialization exists indicated dimension depends primarily two kinds things beyond reach configurational adapta tion described first consists demands reliability ruggedness small size etc strong effects design isp pms levels second consists demands large amounts processing power one response affects design lower levels logic devices circuitry little impact design isp pms level response also possible terms datatypes built isp large machines datatypes appropriate tasks operations match affect chapter 3 computer space 47 design fact effect substance functional spe cialization shown computerspace dimension finally one last part story interesting various groups computer engineers felt strongly time time functional specialization exist set create machines efforts often produced machines different exist ing main line computers ie appropriately specialized net effect almost attempts new idea seen good general computers taken back main line computers thus started functional separation turned simply way produce rapid development universally applicable computer classic example expansion inputoutput facilities creating functionally specialized business machine simply led better 10 facilities computers say examples discuss values along dimension computersystem function scientific first machines clearly designed scientific calculations fact aberdeen proving grounds funded early work eniac computation ballistic firing tables image used frequently early computer designers computer statistical clerk arithmetic unit desk calculator memory work sheet program instructions mathematician gave clerk design standpoint scientific computation posed two striking requirements first great accuracy num bers led word lengths 36 60 bits 11 18 decimal digits significance arises propagation roundoff error repeated arithmetic operations second emphasis fast arithmetic operations ie arithmetic power early machines standard rule estimating computation times count number multiplications program else could neglected arithmetic unit developed floating point multiply hardly expensive floating point add requirement fast arith metic however really directed logical design level isp pms level thus main effect isp adoption long word lengths floating point datatypes addition integers extensive repertoire arithmetic operations isp main pms effect emphasis classic ﬁstatistical clerkﬂ pms design press increased arithmetic processing led recent times development various forms pc concurrency lookahead stretch chap 34 ninstruction buffer cdc 6600 chap 39 might considered unique functional specialization scientific computation early tell impression although needs sci entific computation initiated exploration concurrency parallelism eventually see computers certain power whatever task domain physical limits component speed signal propagation make tech niques universally attractive better case permanent specialization made special algorithm computers compute fast fourier transform vector operations finally systems whose whole design responsive narrow class problems may extend special kinds pc parallelism exhib ited illiac iv chap 27 although substantial generality systems business early days electronic computing felt many major functional separation busi ness computing scientific c0mputingl scientific problems ﬁlarge computingsmall inputoutputﬂ business problems ﬁsmall computinglarge inputoutputﬂ certainly existing computers designed scientific computation poor inputoutput facilities ibm 701 example used pc control everything dynamically actually catching bits running tapes fly executing welltimed small loops design efforts business computers resulted ibm 702 subsequently ibm 705708 7080 machine two major innovations ibm used characters pms structure permitted flexible voluminous inputoutput latter feature immediately incorporated scientific computers eg 709 large scientific computers separate inpntoutput control either kio pio realized also demands input output scientific calculation thus bifurcation tempo rarily halted specialization characters basic type opposed long words already present ibm 702 effect 5 years later development ibm 1401 chap 18 latter machine adapted business characterbased small enough small businesses could afford extremely successful many thou sands produced certainly represents successful func feelings still extant concerned validity feelings led particular period computer development 48 part 1 structure computers tional specialization business however interesting specialization maintained ibm sys tem360 chaps 43 44 single machine although essence two internal isps one centered around characters around floating point datatypes business scientific specialization residing side sidel control third functional value computer used control real time examples processcontrol computers aerospace computers laboratory instrumentcontrol computers role computer act sophisticated control k larger physical process thus plays subordinate role relatively late arrival due high cost unreliability early computers well lack necessary interface equipment functional specialization seen strongly word size reflects appropriate numerical datatype numbers used control processes generated physical de vices rarely better 01 percent accurate since elab orate arithmetic calculations called numbers hence word size around 12 bits control com puters 12 18 bitsword second specialization reflecting appropriate datatypes control computers binary boolean operations arises many external conditions sensed effected binary nature functional specialization control com puters interrupt2 capability allow respond many potentially simultaneous external conditions real time provides apparent parallelism though still using sequential processor another possible example functional speciali zation leading reunification rather divergence widely accepted generalpurpose computers must good interrupt capabilities however actuality interrupts though existing early computers developed obtain good inputoutput facilities control computers chapters 7 29 give examples aerospace computers chap 33 describes ibm 1800 specifically designed process control examples show complex isp lthe story told exclusively terms ibm machines although distort picture strongly terms total movements field since ibm dominated market concurrent developments taking place throughout field univac first computer built manufacturer idiosyncrasies ascribe ibm hand marketing effort nil apparently introduced univac 1103 necessarily required part reflects fact control computers may retain programs whole lifetime programming reprogramming less important absent however strong functional adaptation communication functional specialization communication could taken subfunction control computer function mainly behave switch messageswitching application computer transfers messages terminals links primary sometimes secondary memories transfers terminals links message switching messages first stored forwarded computer telephone exchange functions sophisticated switch control computer reads offthehook signal detects dialed numbers rings dialed parties finally sets switches connect telephones together instances swers information inquiries new telephone numbers routes calls phones functions memory thus communications computer functionally switch control switch main distinction control computers commu nications computers task environment latter since consists digitally encoded messages even case voice telephone exchange handled directly communications computer communications computer work transshipment storage well control pure examples communications computers book however pios serve essentially function within single computer part 4 sec l profitably examined viewpoint file control list separate specialization number computers built exactly task specialization easily described communication com puter messages characters since built business large memory file considered part system examples filecontrol computers book early ibm 305 univac file computers serve function ibm 1800 used control 1012bit photooptical memory example terminal since possible obtain separate computer system whose function run display listed separate functional specialization fact better viewed almost always occurs component larger computer system chapter 3 1 computer space 49 ie special pio dec 338 pdisplay described later chapter detail chap 25 timesharing requirement large number users simultaneous conversational interaction single large machine bred new specialization timesharing computer computers described timeshared even interrupts inherent multiprogram ming however emphasis mode operation particular timing flexibility requirements human users general computing consoles multiple software systems led number innovations design important virtualmemory techniques achieving multiprogramming described part 3 sec 6 also substantially increased complexity pms structure handle integration large files swapping memories huge software systems seem endemic timesharing systems still early tell whether design responses produce permanent spe cialization simply first instigation design features become universally used summary see functional specialization translates mostly total size machine datatypes available many design aspects created response functional specialization instead become common property machines performance device complex job meaningless ask single precise index performance like asking average speed given model car lifetime without specifying drive sort terrain encounter along way notice diffi culty much complexity task environment complexity internal workings machine specify everything environment performance often given single figure may hard determine least well defined know terrain road conditions perfectly car driven structure car possible figure instantaneous velocity construct average speed put terms computers given particular configura tion computer system given particular program given particular set input data possible determine aspects performance long took much space used whether correct interested specifics want know well computer system performs given vague notion kind taskprograms datathat used although know adequate measures believe something said performancethat tells us cdc 6600 many times powerful actual performance pdp8 interesting way look problem specifying perform ance play simple game give number say 4 give best description computer systems involv ing many parameters equivalently dimensions attri butes best description computer stated four numbers game easier play speak dimensions rather information content description bits say lie still defined ﬁbestﬂ course taken mean best prediction relative ordering computer system better index means better task2 start beginning single number would give characterize computers power question makes people uncomfortable since strong feelings exist least two kinds numbers dealing speed memory respectively forced would probably settle something related proc essing speed cycle time primary memory possibility simple machines determines limits operation rate structural parameter reason avoid performance index average number instructions per second operations per second better indicator since latter take account size word proc essed perhaps average bits processed per second best single number measure number processor may include instruction data streams take average must adopt weightings sim plest scheme simply add instruction operation times divide number equivalent weighting equally rare ones common ones want better need data several sets relative frequencies instruction types called ﬁmixesﬂ used literature table 2 gives four examples gibson mix fair course invent tricks encode many conceptually independent dimensions single one beat limit hand composite dimensions average operation time perfectly acceptable 2definitional precision appropriate since attempting deal seriously technical questions indices illustrate issues 50 part 1 structure computers table 2 instructionmix weights evaluating computer power arbuckle 1966 gibson knight scientijic knight commercial fixed x floating floating x floating loadstore 95 56 20 285 6 3 1 25 move indexing 225 conditional branch 132 20 compare 24 branch character 10 edit 4 10 initiate 7 187 published reference unknown extra weight either indirect addressing index registers probably best known best source data comes instruction counts running programs knight takes view fig 3 single number used indicate power formula evaluated 300 computers knight 19661 formula product three factors processing time memory size words word length formula derived roughly measure power technological change could modeled applying formula like measuring automotivevehicle power product speed weight number wheels indicator roughly proportional cars momentum thus although reason able singlenumber indication power computer buyer could use directly taking averages case mixes suggests sophis ticated approach collection programs called ﬁbench markﬂ developed variety different tasks one number time takes collection bench mark generates frequencies occurrence primitive instructions brings number additional dimensions affect performance instruction code size mp pro gramming skill inputoutput devices etc also carries implicit frequency different kinds task demands much set involves compiling much number crunching much io etc severe practical problems carrying meas urements many computers since problems must coded run systems somewhat easier task set 1025 6 2 10 25452 1 72 74 restricted programs coded procedureoriented language fortran computers accept fortran nevertheless although often done compare two systems occasionally done even modest number feel generalpurpose computer com pilerderived bench mark reasonable singleperformance number much actual use compiler good compilers produce code rival hand coding special fea tures machine utilized cox 1968 compares several using hand coding compilers several tasks difficulty benchmark scheme inher ent strongest advantage total problem thus integrating features computer number obtained depends type computer example ibm 704 exact configuration example 16 kwords mp versus 32 kwords even operating system soft ware version fortran thus although number perhaps comes closest adequate singleperformance figure becomes much less parameter characterizing structure computer one characterizing contingent total system let us underscore distinction computer type particular configuration possibly including basic software assembled particular installation computer systems designed certain forms variability speci cdc 1604 specify many things isp pc cycle time mp ks used control secondary memories ms interfaces external world leaves open many chapter 3 computer space 51 iiriiihlisnttrihutes computing system p l computing power nfh computing system word lengths bits total number words memory time central processing unit perform 1 million operations time central processing unit stands idle waiting 10 take time central processing unit perform 1 fixed point addition time central processing unit perform 1 floating point addition time central processing unit perform 1 multiply time central processing unit perform 1 divide l time central processing unit perform 1 logic operation b number characters 10 word ki1 input transfer rate characters per second primary 10 system kol output transfer rate characters per second primary io system kip input transfer rate characters per second secondary 10 system ko2 output transfer rate characters per second secondary 10 si start time primary 10 system overlapped compute hi stop time primary 10 system overlapped compute sz start time secondary 10 system overlapped compute ha stop time secondary 10 system overlapped compute r1 1 fraction useful primary 10 time required non place system overlap rewind time cp c3 c4 cs p wil wol semiconstant factors values scientific commercial symbol description computation computation wf word factor fixed word length memory 1 1 memory 2 2 b variable word length c1 weighting factor representing percentage fixed add operations computers without index registers indirect addressing 10 25 b computers index registers indirect addressing 25 45 fig 3 knights functional model algorithm calculate p com puter system courtesy datamation vol 12 9 september 1966 page 42 weighting factor indicates percentage floating additions percentage multiply operations percentage divide operations percentage logic operations percentage 10 uses primary 10 system systems primary 10 system b systems primary secondary 10 system weighting factor indicates weighting factor indicates weighting factor indicates number input words per million internal operations using primary 10 system magnetic tape 10 system b 10 systems number output words per million internal operations using primary 10 system per million internal operations using secondary 10 system number times separate data read computer per million operations overlap factor 1the fraction primary 10 systems time overlapped compute overlapno buffer b read write com putesingle buffer c read write com putesingle buffer multiple read write computeseveral buffers e multiple read write compute program interrupt several buffers overlap factor 2the fraction secondary 10 systems time lapped compute number inputoutput words exponential memory weighting factor 10 0 6 1 2 0 72 74 1 10 variable variable 20000 100000 2000 10000 values given wi1 values given wi1 4 20 1 1 85 a5 7 7 60 60 25 55 values given ol1 e 5 333 52 part 1 structure computers things e types sizes ms size mp computers even leave open part isp eg multiplydivide options many small machines speed pc mp eg ibm system360 ask questions computer systems clear whether talking computer ﬁtypeﬂ cdc 1604 whether talking particular installa tion variability specified possible describe either pms isp provided recognize diagrams types represent maximal possibilities assembling par ticular systems almost pms isp diagrams book prepared point view ﬁnumber gameﬂ talking computer types might prefer numbers depend particular configuration two numbers available describing performance would clearly several directions go one could fractionate bench mark one bench mark arithmeticrich tasks bench mark others composite compiling data processing one could decom pose processing rate say operations per second word size bits per second recaptured approximately alternatively one could retain single number processing rate add measure memory available eg size mp bits three would choose latter especially talking particular installation rather com puter types mp size remains variable continue game several numbers table 3 shows choices various parameters drop change decomposed parameters recovered thus initially mp must measured bits word size given mp reasonably measured words one reasons exposing list emphasize judgmental approximate character yet way validate proposals brief descriptions table 3 performance parameters specification function allowable number parameters bench marks approximations measuring performance might look well param eters table 3 predict bench marks remain difficulties take account additional aspects total system eg compiler efficiency implied bench mark alternatively one might want construct mixed description benchmark numbers measurements kind table 3 relationship bench marks measurements would become indirect measure efficiency rest system discussed performance crude cavalier way accurately reflects state art precise measures performance precise structure per formance measures individual components eg memory size speed word length processor instruction times designers users faced obtaining certain total performance given cost method bench mark task significant variable performance increased unless task sufficiently trivial difficult predict effect changing even direct structural variables eg memory speed structure turn function performance provide design constraints objectives dimensions structure provide space design actually cast structural dimension one designer attain values along dimension relatively direct means thus machine completely specified listing values along structural dimensions systems function performance within function determined dimensions selected structure view point distinctly different performance one number parameters allowed 1 2 3 4 5 parameters pciratebs pcoperationrateops mpsizeb pciwidthb msiwords bt mssizeb mpi words chapter 3 computer space 53 averages combines many features summarize effective put tends obscure structure structure one wants maximally independent aspects easily obtained se lected design choice example computer designer single dimension describe computer would undoubtedly select logic technology used pc ks tells good deal many aspects computers structure fact technology average bits processed per second pc correlated used predict though imperfectly one interested performance effective bits per second preferred one interested design technology preferred computer space table 1 presents choice major structure dimensions even less means validate choice dimensions performance never theless hallmarks perhaps important redundancy opposite side coin independence mentioned several dimensions structure may covary giving one tantamount giving others covariation need come physical dependence may arise nature appropriate design good engineer ing practice cluster covarying dimensions likely indicate important dimension one among correlates used secondary matter table 1 organized terms clusters one selected main representa tive placed left second hallmark derives hierarchical nature computer systems generally description system consists union description parts plus description interconnections basic style pms example features affect total system le affect many components usually rather important technology prime example yet third clue dimensions discriminate actual population computers machines singleaddress structions instance would sense using number addresses per instruction dimension computer engineer studied machines would know true computers thus one looks dimensions spread machines evenly substantial number categories dimensions space known computer sup posed defined single point existing computers actually case however computer system complicated enough say consisting several processors built different technologies different number ad dresses per instruction representation would possible instance rice university computer uses vacuum tubes transistors integratedcircuit logic complexi ties rare time good engineering practice work necessary consider cases additional dimensions eg secondary tertiary logic could added several points space given computer could used computerstructure space thus choice seven important dimensions response speak playing number game given seven descriptors arranged order importance although clearly simple way exists validate order three attributes describe structure computer system would pick logic technology word size pms structure ie processors exist functions point ready proceed space de scribing various dimensions discussing computer systems book illustrate various points along take major dimension separately correlated dimensions accorded separate sections discussed along main dimension technology computers constrained physical technology constructed new technologies provide greater speed size reliability less cost although course technologies dictate kinds structures considered thus come shape whole view computer instance emergence pms system level due advances technology prior transistor technol ogy make sense think elaborate pms structures costs various parts high reliabilities low occasionally machine fact designed invariably proved far ahead time succeed example book might rw40 described 1960 chap 38 classic example analytic engine babbage designed 1844 never able com p1etel technology time entirely mechanical crude state accounts large share failure thus technology odds important single attribute know computer system many technologies go making computer type component typically uses different one current socalled thus first real digital computer established precedent failing large margin meet expected dates completion full operation 54 part 1 structure computers thirdgeneration machines pc may use hybrid inte gratedcircuit technology logic thinfilm technology pc generalized registers core technology mp electro mechanical technology tapes disks integrated circuits logic mechanical technology card punches type writers even manual technology mounting tapes disk packs existence technologies poses major issues systems balance issues imperfectly resolved example remains true current generation input output balance internal structures due crude state terminal technology appears cost much provide appropriate solution heterogeneity technologies consequence costbenefit analysis rather represents forefront tech nology type device shown course cost performance exchange component usually within technology thus sense leading technology used represent technol ogy used logic level one listed computer space known transistor logic used pc computer safe prediction ms electromechanical mp core tio electromechanical printers punches etc reflects fact technology develops hence comes locked calendar time thus prediction logic technology date things known current date correlation date technology given com puter space along generation also seen time chart correspondences must taken rough technologies listed increasing power decreasing cost dates run exactly order one exception fluidics introduced recently special technology ruggedness reliability direct external coupling certain control systems small fluidic computers early prototype stage alongside technology dimension list dimensions pc speed operations per second cost dollars per million op erations vary directly inversely logic tech nology general costs extremely difficult determine espe although beside point current discussion one reason imbalances appear ﬁpermanentﬂ time constant change technology order time constant human beings ie systems analysts programmers users understand imbal ance system imbalance diagnosed solved terms problem change inducing new imbalances cially technological costs interest rather market costs reflect numerous factors nevertheless effect technology costs striking simulta neously pushing performance along dimensions seemed necessary give measure cost table 1 matter crude indicated dimensions corre lated technology fact dimensions table 1 independent technology word length pc addressesinstruction rest show dependence technol ogy memory speed size direct correlation others pms structure pc concurrency development complex versionsthe leading edge speakdepends technology free use versions existence given time still dimensions importance shown table 1 also changed technology eg electricpower consumption one way see varies independent technology compare selected machines instance whirl wind chap 6 firstgeneration system ibm 1800 chap 33 thirdgeneration system reasonably similar isp descrip tions one ignores index registers invented time whirlwinds design however different pms structures whirlwind early system transferred infor mation tios ms program control pc existing pc registers transfer gates used expensive separate ones 1800 uses hybrid circuits economical additional subsystems devoted special functions hence many pios operating independently main pc cost alone limited complexity firstgeneration vacuumtube systems large physical size tubes introduced substantial transmission delays large power consumption added dependency cooling system limited life deteriorating nature constrained number tubes could used system requiring high reliability ibm 700 scientific series 701 704 709 7090 7040 7044 7094 11 offers another comparison evolv ing structure time hence across technologies reasons compatibility isps remained almost constant except 701 see radical increases inperform ance pc speed increases factor 5 701 704 another 10 7094 11 pms complexity various features though affecting compatibility locked isp remained fairly constant example mp size went 32 kw kilowords early series 704 chapter 3 computer space 55 took jerryrigged modification get 64 kw 7094 toward end lifetime series see chap 41 page 517 throughout section referred technology dominant factor computer mean computer development waits upon new fundamental windfalls lucky getting transistor lesser degree integrated circuit external efforts however core memories invented computer resulted need readonly memories also resulted development circuit level pressure requiring mem ories developed electromechanical secondary mem ories le magnetic tape drums disks photostores resulted computers needs thus although technology dominant computer often forces development pc operation rate strongly correlated logic tech nology indicated computer space discussion technology generations also operation rate principal reason higher operation rate faster logic technology technology also secondary effect creasing speed reliable devices allow large computers built smaller devices allow higher device densities thus de creasing stray capacitance inductance shortening trans mission delays smaller components also allow increased inter connection density operation rate also relatively highly correlated total performance hold structure concurrency constant simplest way increase performance increasing clock rate increase performancecost ratio past two decades computer evolution made primary gains higher operation rates two 16bit computers already mentioned whirlwind chap 6 ibm 1800 chap 33 provide nice comparison evolution difference 10 years two generations cost ratio 1ol whereas performance 15 internal clock rates also 15l znformation structure word length information base datatypes computers structure information hierarchy units defined iunit chap 2 example ibm system360 starts bit byte 8 bits word 4 bytes record variable number words playing minor roles decimal however dramatic example could find picking better thirdgeneration example might get cost ratio 1ool performance ratio 1lo digits 4 bits halfword double word number features design related hierarchical organization data consider need characterize organization one characteristic organization word length bits gives information rest hierarchy adding little let us see bottom bit encoded twostate devices although numbers states possible ternary threestate machines proposed occasion ally digital technology developed exclusively handle binary information several reasons first requirement high reliability high signaltonoise ratios basic devices generally basic nstate device one built kstate devices realized breaking continuous physical dimension voltage current magnetic flux n discrete levels regions reliability signaltonoise ratio depend keeping adequate separation easiest two states eg limit become onoff devices becomes progressively difficult n creases second reason simplicity logical design binary representations basic device combining two ternary digits must deal 3 x 3 9 configurations rather 2 x 2 4 configurations binary case also gets worse n increases final reasonthe coup de grace speakis one ever found striking advantages resulting processing structure two states thus com pelling reasons suffer first two disadvantages short might important dimension distinguish computers namely number states basic encoding turns instead one great uniformities digital technology information base physical devices deal ultimately bits imply information processing must organized terms bits possible select arbitrary base one number states construct entire isp terms base unit represented physically course set bits one wanted base 13 machine example one would use least 4 bits 16 states encode operations isp level would refer anything base units data structures built sets base units would way manipulate directly bits represented base thus using base binary obtains whatever advantages might accrue nstate units without disadvantages device level 56 part 1 1 structure computers computers built variety different bases main ones binary decimal character character shifted 6bit character 8bit character byte arguments bases binary repre sents natural base computer hinge alphabets used externally human beings desire avoid conver sions different representation inside computer universal acceptance higher languages fortran algol argument also lost much force fact thirdgeneration machines binary nevertheless fifties much controversy base use machines presented book exhibit three bases little difference binary decimal com puters isp organization however great differ ence two character machines latter designed handling text constructed deal varia blelength strings characters correspondingly deempha size numerical computation decisions affect isp considerably thus computer space indicate base dimension along wordlength dimension two gether make single dimension word length let us examine role word length word first major information unit base defined n bits binary computer n digits decimal computer character machines excluded fixed word length sometimes intermediate units always play minor role disregard stage noted earlier main determinant word length function total system large word lengths arithmetic systems small word lengths control systems character strings business thus within narrow limits word length free design choice however interesting thing word length much determinant way affects aspects total system design starts design decision unit information transfer components word soon becomes case registers various com ponents must hold word since arrives transmitted thus word becomes information unit mp registers pc hold one word instruc tion designed fit one word since number bits obtained ﬁat onceﬂ hence used effect next time increment processing seven bits proposed communication purposes never made basis machine far know basic features set others follow integer number smaller units character fit word since otherwise set words provide homoge neous sequence subunits five 6bit characters fit 32 bits set 32bit words filled 6bit characters number 2bit holes complicate algorithms deal long character strings constraint compati bility strong ms since speeds slow enough permit conversion algorithms either hardware software still system simpler therefore usually work better incommensurabilities information units exist thus pick example number parallel tracks magnetic tapes tends divide evenly word length ibm tapes 700 series 36bit machines six data tracks sys tem360 32bit word tapes eight data tracks interesting correlation word length computer number datatypes makes availa ble saw chap 2 operations computer classified according type data operate upon data type tends certain set operations appropriate example x numbers decision include datatype carries decision include operations thus number operations tends grow number datatypes total amount hardware computer grows word size data paths word parallel2 also number operations thus machines large word size tend large machines many datatypes many operations ﬁlargeﬂ adjective machines invariably means big expensive hencegiven eco nomicscapable large amounts processing two additional somewhat independent features support relationship word size number datatypes size computer first large system already available many pieces necessary add additional oper ations marginal cost new operation goes system grows therefore given large system tendency add operations number operations per datatype easy increase rather one adds new datatypes second small word lengths one define many worth datatypes fit word multipleword data types left programmer define software large word lengths many different worthwhile datatypes fit word instance decompositions word partial words character strings requires issue bitserial versus bitparallel discussed subsequently chapter 3 computer space 57 additional operations since initial datatypes involve entire word large part ie word address integer operations sum word length stands indicator many aspects machine tells something basic organi zation many components indicates big computer number datatypes number operations figure 2 shows time lines wellknown computers word length special time line ones book five groups suggested figure classify c0mputersl classes overlap separate computer one two classes requires knowledge eg number datatypes example 24bit sds 9300 cdc 3200 appear class 36bit ibm 7090 machines floating point hardware fact perform comparably arithmetic tasks one design choice makes word length consequences described making computer bitserial rather bitparallel many machines information transfers con ducted single bit stream especially pcmp transfers coinci dent construction operations bitbybit basis works well arithmetic logical operations time traded hardware cost system becomes independ ent word length processing rates go correspond ingly design decision extremely important one logic expensive unreliable become less current era processors transfer paths relatively number cost reliability components improved however large parallel processors con sidered lo3 ps bitserial processors become serious design alternative see serial computers part 3 sec 2 summary word length important dimension find many characteristics either proportional inversely pro portional sure relations hold current design practice seen bitserial designs mainline computers part 2 ordered according increasing word length datatypes presented number datatypes correlated word length also computer size effect number operations although far perfect rough order specific datatypes included computer listed main types order datatype dimension computer space see chap 2 class number essentially logmp word length 21 definitions located point dimension say floating point means data types dimension ie word address integer boolean occa sionally machines violate arisen decimal chines generally boolean datatypes attempt machines floating point ie without separate integer type eg cdc g202 reason behind cumulation datatypes fixed order certain general tasks must performed computer must transmit data pc mp trans mission nothing meaning content data thus always ﬁunit transmissionﬂ word except character machines next computers manipulate addresses achieve generality eg compile providing second datatype next come integers since almost algorithms make use arithmetic could conceivably absent communications computers floating point numbers multiple precision vector string operations stage uses specialized lower ones elimi nated except cases handling addresses regular integers addresses per instruction processor state number addresses instruction traditional way describing processors ie isps hence com puter systems containing processor use parts 2 3 separate different processors originally dimension simple one two three fouraddress machines constructed become somewhat complex ﬁone plus oneﬂ machine one address data one determining next instruction distin guished twoaddress machine uses addresses data index registers socalled general registers provide instruction schemes lie somewhere one two address organizations processors admit several instruction formats variablelength instructions matters become even complicated correlated dimension computer space amount processor state number bits exist processor described isp amount informa tion held end one instruction provide processing context next instruction consists number status mode bits modern machines packaged regis originally bendix g20 3although used mostly describe pcs description applies processor 58 part 1 structure computers ters earlier machines simply scattered around proc essor next instruction address accumulator arithmetic registers index registers general registers making ﬁscratchpad memory simpler descriptor isp addresses per instruction since independent number variety instruction formats easy define processor state generally isp difficult define ad dresses per instruction processor state total number bits proc essor since may registers physical system used within interpretation one instruction carry information instructions address registers obtain ing operands mp common ﬁundergroundﬂ ﬁtemporaryﬂ registers others implied distinction defining processor state terms isp rather physical processor correlation processor state number addresses per instruction simple since rests two separate issues first note larger programs perform transformations state mp even ms tios concerned state processor processor state enters decomposing total algorithm series small steps possible efficient make step transformation mp mp basically happens instruction hold enough information spec ify mptomp transformations example one wants add two numbers two operands required instruction must contain least two addresses inter mediate state ie processor state must created hold information additional instructions fetched thus oneaddress organizations require processor state less two threeaddress organizations consideration stops three two operands result elementary operations binary processor state eliminated entirely however since must least instruction address program register maintain con tinuity program second source correlation processor state instructions per address comes differential access time processor registers mp long appreciable differential substantial gain processing power obtained increasing processor state derives struc ture algorithms generate intermediate results used almost immediately afterward interest rapid temporary storage retrieval beneficial conditions thus working higher address organization extra time store mp results need temporary storage thus also index registers general registers almost always imply increased processor state although need logically registers could exist mp still effect instruction format interrupts multiprogramming processor state gains additional significance since amount information saved restored switching programs example honeywell h800 early threeaddress computer processor state per program consisted program counter index registers iohalts occurred processing pc switched immediately another program eight programs could run concurrently total processor state 64 program registers present computers generalregister state often 25 100 words must stored implies appreciable time switching contexts consider briefly different organizations accord ing addresses per instruction show common similarities give fig 4 state diagram used processors common basic idea stored program fetch instruction determine instruction execute fetchexecute cycle part state diagram applicable given processor type shown computer space addressesperinstruction dimension starts zero addresses one address one plus indexing one plus general registers two three variable addresses however expository viewpoint one follow different course starting singleaddress machines indexing two threeaddress machines general registers finally zeroaddress variable address organizations puts common organizations first makes easy relate organizations pl address pl index address pcs constitute first second simple thirdgeneration computers earliest outline structure ias computer chap 4 come known von neumann computer although fundamentally like ias computer edsacs adaptation ap pears closest prototype class although edsac described influenced mits whirlwind significantly chap 6 significant change ias machine addition index register called btubes manchester university machine early 1950s evolution seen compar ing first third generations using whirlwind chap 6 chapter 3 computer space 59 fetch operand fetch read lav r 4 request determines request instruction operand q mp instruction q trom mp store write av w operation opera1 specified address caicuia ion q 0 0vw return string vector data fetch next instructiok multiple results pc2 mp controlled state pc controlled state note state may null state name soqoq saqaq sa ooo sovrovr savrav r solo sovwo w savwav w time state toq taq to0 tov r tav r tov w tav w meaning operation determine instruction q access mp instruction q operation decode operation q operation determine variable address v access mp read variable v operation specified q operation determine variable address v access mpl write variable v fig 4 isp interpretation state diagram ibm 1800 chap 33 looking ibm 7017094 evolution part 6 sec 1 index registers motivated frequent occurrence 1 address systems circuitous address calcula tions involve first computing address eg index array mp planting ahead instruc tion stream order make use address providing set index registers introduces second address struction even though extremely limited function thus classify processors indexing 1 x addresses per instructi0nl alternative view index registers suggests double number datatypes allowing operations vector data elements rather scalars indirect addressing hand add addresses per instruction rather introduces second operation per instruction 1 address processor processor state mps typically consists program counter instruction location counter accumulatorac multiplierquotient registermq exten sion ac one index registersxxr one address instruction one arithmetic register must used temporary results thus effective address integer z computed function address part v part instruction 9 index registers process typically z v xj xj jth index registers specified instruction several forms transmission operators mp 60 part 1 structure computers atz loud immediate mpexi load direct mpmpx load indirect mx c store direct mpmpz store indirect indirect operations convention may required determine address mpz used similarly binary operations x v 0 con catenation etc generally form atabmpz rarely find symmetrical operation form unary operations abs sin cos etc com mon forms atua tu mpz rarely find mpzi mpzi mpz tu cases exclusion operations place results mpz stems added cost including sym metrical function marginal utility function stems result applying u available processing transmission unary binary operators account al operations computers allow stand part mps rather accumulator instructions included inputoutput data trans mission eg mpct tcmp conditional execution branch zero ac ac 0 p c z index registers requires operations process minimum must loaded stored usually mp le mpz x store index x c mpz load index register addressing modes suggested used operand immediate mpz direct mpmpz indirect simple operations x also desirable example xtx 1 x used point access next element vector complex operations carried placing x register via program steps atx load c fa manipulate xta load x operation add k x would atx next aca k next xta instead mpz x next mpz next k next mpz c next x mpzi assumes transmission paths x ideally would like perform operation directly x simply xcxk begins idea x look like main arith metic register doubt one evolutionary path generalregister processors part 2 sec 1 devoted entirely 1 address computers first three generations ﬁmain lineﬂ computer development p2 address p3 address computers part 3 sec 1 instructions contain multiple addresses per instruc tion addresses v specify operands mp fig 4 mps decreases number addresses per instruction increases since operands need held temporarily instruc tions le instruction performs complete operation instruction form 3 address computer b binary operator vl v2 vb addresses specifying operands case unary operations u v2 usually blank case binary operation threeaddress computer states oq aq 00 ovr avr ovr avr 0 ovw chapter 3 computer space 61 avw fig 4 midac chap 14 strela chap 15 typical threeaddress computers 2 address computer necessarily require proc essor state 3 address computer since operations correspond however sometimes extra mps usual rw400 chap 38 accumulator operations generally terminate results primary memory mpv accumulator branch accumulator instructions allows results checked directly without referring mp especially nice instruction 2 address computers transmission instruction specialcase unary operation mpv mpvl ibm 1401 chap 18 two registers laddress baddress hold v1 v2 loaded v1 v2 parts instruction registers point address oper ands contain data remaining processor state instructionaddress 1401 instructions address parts instructions take operand addresses values laddress baddress previous struction 1401 instructioninterpreter state diagram given chap 18 fig 3 statediagram specialization fig 4 roughly oq aq 00 ovrlavr10vr2avr200vw2avw2 ovrlavr10vr2avr200vw2avw2 sequence delimited operation character 1401 operates variablelength strings repeated end string pn 1 address processors n 1 addresses deviate slightly uaddress processors final 1 address explicitly specifies address next instruction used instruction set two reasons 1 addressing used first freedom provided placement instruction within program address space second next instruction address calculated parallel execution current instruction computers cyclic memories part 3 sec 2 1 address allows data next instruction specified independently providing opportunity arrange program data optimum fashion since instruction completion time depends location data desirable next instruction location variable rather implicit next ad dress used processors almost universal practice computers mpcyclic see lgp30 chap 16 exception microprogrammed processors may use 1 address locate next instruction may several next addresses microprogram subroutines tend short intrinsic interpret ing instruction set many jump addresses increased speed compute next instruction address worth added space cost ibm system360 model 30 chap 32 shows use multiple 1 addresses classified according scheme would least micro program 3 1 address pgeneraz register general register processor small array registers used multiple functions fast access compared mp pays much processing possible within since general register array small requires small address 3 8 bits thus instruction format contains fields one general regis ters must still exist addressing mp though never exceeds single address thus classify general registers chines 1 g addresses per instruction organization 1 g system vary something close 1 x organization essentially every instruction involves mp information organization mp instructions transfers mp mps processor state holding general registers two threeaddress instruction set involving mps see cdc 6600 chap 39 data point view mps acts like directly addressable mp processor state general register processor invariably held entirely within general register array rather additional independent registers due part already available mechanism array part need pro gram switching somewhat simplified mps held single homogeneous memory general registers typically perform variety functions 1 arithmetic registers accumulator accumulator ex tension multiplierquotient 2 index registers 3 second index register base register program addresses v short base register needed address area mp 4 subroutine linkage registers 62 part 1 1 structure computers 5 program flag sense registers boolean variables 6 stack pointer p may multiple simultaneously active b binary operators l l etc 7 8 u unary operators 7 ahs 1 ab etc g generalregister array g g g g instruction parts specifying general register g v vl v v3 mp addresses specified function instruction general registers example v address gg v ad stacks address pointers data arrays lists temporary data storage intermediate results 9 temporary program storage short program loops power general register processor obtained registers serve many functions thus operations registers extensive operations need duplicated parts structure example special operations index registers necessary opera tions integers apply universally accumulator index registers course generality requires compromises stack computer faster problems utilize stacks whereas general register pc must utilize mp stacks encoding efficiency pure stack processor see addition assignment reassignment general registers crucial since scarce resource many uses general register organization allows processors high degree parallelism constructed since several instruction subsequences executed concurrently actual number registers rather critical depends algorithms tasks coded also technol ogy multiprogramming interrupt computers program switching time increases number registers thus upper bound number registers cost program switching time would expect find instructions produced fol lowing affects addresseslinstruction dress gg gg ibm system360 general registers thought outgrowth generali zation 1 x processors already suggested alternatively thought evolving 2 3 address structure univac 1103a 2 address processor chap 13 doubt forerunner general register univac 1107 1108 pegasus chap 9 think earliest computer use general registers 1956 part 2 sec 2 discuss four general registers computers pstack 0 addresses per instruction pms viewpoint pstack built around firstinlastout memory mstack part processor state conceptually built around fact computations often sequenced explicit names le addresses required temporary results operations performed top stack partial result computed pushed stack appears participate operand exactly appropriate point later calculation thus stack operates implicit memory intermediate products transfers p mp avoided space instruction mp addresses eliminated instructions system consist operations since operands stack thus instruction format zero addresses per instruction must course addressing mp generalregister organiza tion however addresses mp sit stack instruction contains transfer load store operation address still must exist way getting fresh data stack pstacks least one operation loads address written program stream onto top stack happy correspondence cal culations memory performed stack memories quires little explication rests fundamentally phrase structuring calculation partial result required one one point subcomputation nested program hence result nested stack chapter 3 computer space 63 order occur operand one operation uses several arguments pstack multiple stacks often required part power pstack derived higherspeed mps stack yet top 2 8 registers stack mps mstack overflows mp speed operations become much worse stack simpler implementation example pgeneralregisters fast perhaps general another difficulty stack inability access top full addressing provided organization come almost general register yet another difficulty arises inhomogeneity datatypes especially several packed single word width stack thus stance one stack machine burroughs b 5000 chap 22 completely separate nonstack isp string manipula tion simple numerical computation given table 4 com parison pstack pl address pgeneralregisters pstack probably shown best array indices calculations programflow manipulations involving testing etc criteria measure algorithm encoding space problem running time kinds instructions interpreted pstack typically interpreter state operation sequence example load oq aq 00 ovr avr mstacktop mpv store oq aq 00 ovw avw mpv mstacktop unary operation oq aq 00 ou mstacktop u mstacktop binary operation oq aq 00 ob mstacktop c mstacktop b stacktop 1 variable numbers addresses per instruction although operations require specification three addresses low frequency machine ever built seriously proposed matter three data addresses one nextinstruction address microprogrammed processors one nextinstruction address often several operations parallel one instruction however developed processors variable number operands involve use instruction larger single mp word thus bringing first word instruction contains operation code determines many additional operands needed hence many additional words obtain mp char acterbased system may require several reads per operand wordbased system may one two operands per read gain system higher average density opera tions per instruction bought price extra mp accesses variableaddress processors mixture one two three addresses per instructionsimply mix types already considered fundamental limit variability processor state plus additional withininstruction tempo rary state physical necessity must finite number addresses must yield amount information less total state otherwise processor hold onto process itl thus various processors claim operate higher language see planguages part 4 sec 4 must fact either translate another simpler programming lan guage fortran machine chap 31 become interpreter processes small amount language state ment rest pms structure idea significant higher organization computers relatively new texts logical design computers develop model based arithmetic section inputoutput devices memory holding instructions data single control force components interact pms diagram early model given fig 5 x represents external agent usually man whirlwind manualmodel figure page 10 used chap 1 rather highly developed secondary memory switching figure 6 pms diagram reflects accurate model often computer designers lump devices periphery call inputoutput devices inputoutput terminals secondary memories ms processes large amount information pieces ie sequen tially real time really executing single instruction based addresses decomposed total computation single address organization fig 5 early model stored program digital computer pms diagram 64 part 1 structure computers table 4 comparison stack general registers accumulator pc evaluating expression f bc x e pcstuck stack contents pcgeneral register pc 1 address push load g1 load push b b subtract g1 b multiply e subtract b load g2 inverse subtract c1 push c b c push b c push e b c e multiply b c x e subtract b c x e divide bc x e pop f stores stack multiply g2 e inverse subtract g2 c1 divide g1 g2 store g1 f store temporary load subtract b divide temporary store f location f program size address integerai operation partso 6 ai 40 number mp refer ences data program size hypothetical example 4x6 6 x 18 1 machines 138 program size bits among specific cs b850 1 3 168 6 ai 8 aigr 70 8 ai 80 6 x 18 6 42 1 x 6 2 x 49 182 192 ibm system 360208above1 ibm 7090288above1 224actual 360actual base register overhead 8 x 18 6 0 192 instruction specificexample machines 2assume 16 general registers 3the burroughs corporation 88501 pcstack discontinued 4not completely true since systern360 12bit address uses base registers overhead assumed worst case unreasonable 6 x 32 192bit overhead separate component according function assign control k element finally introduce processor p get structure fig 7 course large part p data operator processor behavioral properties attributed structure fig 5 include control within component get fig 8 fig 7 consider larger structures consisting several mps ps mss ts one might think expand system shown fig 9 connect everything single switch central sufficient power multiple conversations indeed provides maximum generality however although fig 6 early computer model ms pms diagram fig 7 general computer model distributed control pms diagram chapter 3 1 computer space 65 designs proposed system technology economics far prohibited actual realization instead developed general latticelike structure shown fig 10 switch structure connects components one side components opposite side interconnecting ps exception lattice structure fig 10 hierarchical sense mps form inner core one travels toward periphery moving left right movement general decrease data rate highest mpp switch lower one moves right model five switches one switch connects com puters peripheral devices external environment human beings processes etc three switches appear alike way interconnect mpp pk kt ms respectively however usually quite different would expect p connect mp probably would expect one two pios connected given set ks cer tainly one two ks would manage given set mss ts thus structure nearest periphery becomes like tree rather lattice examples provided figs 11 12 last switch fig 10 unlike four provides inter communication among processors multiprocessor struc ture even 1pcnpio must communication among processors switch type organized nonhierarchy appears like conventional telephone exchange since p call another hand amount communica tion measured bits rather low ps usually mps controls associated bothered show ks diagram ks shown provide control ts mss separated figure separated current computer systems made identifiable physical components current technology expensive devices one k per ms economical therefore k needs p p p p tx ms m5 ms x fig 9 general computer model multiple components pmi diagram u periphery lxhurnan computer network lrnechanical process pi0 pia 1 kio k iiik ikk tlkt ms kms 1 kms fig 10 general computer model multiprocessors pms diagram tconsole mppc kstrn ksfx rt fig 8 general computer model without k pms diagram fig 11 treestructured computer 1pc pms diagram 66 part 1 1 structure computers shared among set ts mss one purchases single magnetictape controller say four magnetic tapes shared k also explains one given class devices eg magnetic tapes operate time technology changes especially costs separate ks may disappear nearly computers discussed book fit lattice model fig 10 however unlikely structures built conveniently fit example nova chap 26 fit model nicely although complex illiac iv arithmeticcomputer portion chap 27 values along pms structure dimension computer space generated general model laid order evolution evolution strictly less complex seemingly complex network structures duplexed computers necessarily complex single multiprocessor computer duplex computers used time slow evolution parallel processor structure due primarily limitations technology struc tured computer distributed control expensive tightly integrated design shared function addition multiprogramminga question softwaremust present allow multiprocessing pms structure plays minor role obtaining multi processing parallel processing classical debate building large computers always resolved building single large processor eg cdc 6600 stretch chaps 39 34 proponents multiprocessors say one always add several large processors structure increase per mp mp ik r tt kio ms pi0 u att ce rnernorvdrocessor x switching computer boundary periphery fig 12 treestructured computer 1pc2pio lattice mpp switch pms diagram formance oneprocessor structure part 6 sec 3 discuss ibm system360 advocate multiprocessing today parallel processing form suggested chap 37 include discussion parallel processing bet come future part 5 dedicated moving along pms structure dimension simple 1 pc structure shown fig 11 tree although values information rates nature fixed1 timemultiplexed switches indicates perhaps top two ts one ms one bottom ts active given time fig 12 1 pc 2 pi0 computer given note control one secondary memory kio rather pio kio fetch next instruction mp must rely pc control note necessarily lattice connection 2 mp pc 2 pio kio special cases pdisplays multiprocessors parray wired algorithm parallel processing realized general model fig 10 switching principal issue computer design pms level switch ing indicated preface unfortunately illuminate switching problems book except provide examples switching dimension computer space cor related pms structure seen complex structure complex intercommunication switching required figure 13 shows various logical switches together common implementations switch parameters also given appendix book switching issues discussed turn apply various parts structural model fig 10 reader note fig 13 relatively primitive switches complex switches formed cascading connecting primitives together noncomputer example manner tele phone exchanges constructed interconnected together processormemory switching recently advent multiple processors memoryprocessor switching become important problem mpp switch makes multiprocessing possible determining factor performance reliability structure processormemory switch computers multiple memories multiple processors lattice simultaneous memoryprocessor dialogues allowed cross relative value attribute denotes time switch closed fixed usually denotes time duration 1 iunit transmitted chapter 3 computer space 67 group hierarchical switches connecting comdi bn components 2way conversations logica structures first given followed common physic realizations physical realizations links ar required pairs components physic realizations given assumed roles th bs interchanged allsb la gate switching b 1 al 5 l b b gate switching al sl bl lc gate switching ab sduplex 1 n 2 duplex n b concurrencyl n sgate alb2 bl l sb za duplex radial switching b alf l bp lb lslb 2b duplex radial switching 1 al 1 isb l sb 2 l sb il n 3 2c duplex buschain comonzy used kt c pk interconnection n 3 dualduplex 2a n b concurrrncyl 2 n sgate 7 7 l l 8 jbn ls 3a sdualduplex radial switching b duolez version lss l 3b sdualduplex radial switching duplez version hi hn 3c dualduplex buschain duplex version zc rn 4 timemultiplex crosspoint n b concurrencyl cascale dupzes 1 slb ls n fig 13 logical physical switch structures pms diagrams 68 part 1 structure computers i1 l l si l ami 4b irnemu1 plex crosspaint buschai n crass pa n b 1 n b cancurrencyrninmn x n sgate l lll ill bl bpbn 5a scrosspoint radial links b null al ylili bn b _ bl 2 5b scrasspaint buschain use vpp interconnect rualduplex cross point 1 aj n 0 concurrency ats4 n 6a dualduplex crosspoi nt radial rn n b concurrencyl bl b2 bn group 11 nonhierarchical switching interconnecting components 2way conversations sduplex nonhierarchical ai 8 duplex nonhierarchical concurrencyl als ls l als 9a sduplex nonhierarchical central fig 13 continued chapter 3 computer space 69 l rerundant use keep constant 8b sduplex nonhierarchical buschain 3 9 crosspoint nonhierarchical concurrencymz ml2 sgate c al l1 central nonhierarchical radial x mll2 nodes links alz 3 io sktrunk nonhierarchical rn concurrencyminrn2 k f x rn sgate ts mau extemai fig 13 continued tg tk loa sk trunk central nonhierarchical fig 13 continued point switch provides redundancy used form lattice structure vary fullduplexduplex switch mmemories one processor pprocessors one memory requires components devoted switching buffering arbitration control hence duplex switches used multiprocessor computers processormemory switching possibilities seen nicely fig 13 im portant switch parameters number memories num ber processors number simultaneous processor memory dialogues current designs p always originates dialogue generally taken mean reading writ ing given word mp range complexity roughly snul1 1m 1p concurrency 1i ssimplex1 halfduplex2 fullduplex3 mm 1pilm pp concurrency 1 stimemultiplex crosspoint mm pp concurrency 1 scrosspoint mm pp concurrency minmp duplex used increase number processors connected memory system provide additional switch points memory example cdc 3600 casale 19621 basic s8m 4p concur rency 4 expanded placing another s1m 6p concurrency 1 series give possible overall s8m 24p concurrency 4 scheme used provide multiple processor accesses memories processorcontrol switching first switching problem developed need communicate several inputoutput devices switching hierarchical nature one two processors switch allows communication one direction two ports za switch allows communication either direction one direction time 3a switch allows concurrent communication two ports 70 part 1 structure computers maintain control many ks giving k single instruction task completion task k signals processor task completed switch provides link processor controls secondary memory terminals parameterized number processors number controls number simultaneous conversations originates dialogue switches control information transmission always processor evolution approximately follows 1 snul1 1p 1k concurrency 1 initiator p p k connected data transfers ssimp1ex halfduplex fullduplexduplex 1p 1k concurrency 1 initiator p k k operates independently return request communication p control task com pleted sdua1duplex 2p 1k concurrency 2 initiator p k duplex paths dual ps k reliability scrosspoint pp kk concurrency min pk initiator pk general case multiple ps ks communication among components 2 3 4 early machines used first structure concurrent operation controls possible starting several controls carefully programming timing data trans fers two conditions occurred cause buffering ms associated processor control could signal processor although rather trivial imple ment idea item 2 allowing k signal proc essor occur idea arithmetic processor traps incorporated processors interrupt used method k communicated desire converse p early ibm 709 provided separate independent processor handling communication inputoutput equipment simultaneous processortoinputoutput secondary memory dialogues could take place provided devices connected right processor early computers part control function data buffering associated pc one device could operate time stemmed comparatively high cost registers links established fixed period time com plete block transfer data military computers duplicate set ks provided reliability elaborate switching structures types 3 4 rarely used pios ks thus work peripheral requires use rest com puter dualduplex becoming common provides method offline operation maintaining better component utilization reliable structure controlterminal controlsecondarymemory switching switches link control particular terminal second ary memory generally fairly straightforward normally fixed duplex switch used however dualduplex switch used multiple access paths component required switch links secondary memory control transmission relatively long information units eg records typical ex ample switch bus structure used magnetic tape units connect common control one units operates time although rewinding simultaneously switches far less interesting nearer periphery failure imply failure complete system processor function emergence complex pms structures coincident development functionally specialized processors simple computers figs 5 9 place pc general lattice pc specialized perform inputoutput operations one pios specialized communicate ts mss even organize information mp transshipment additional pios specialized handle graphic dis plays hence pdisplay even ps specialized work spe cific datatypes example parray specific algorithms eg fast fourier transform addition processors may realized microprogramming say isp interpreted specialized pmicroprogram although existence various functionally specialized processors coupled closely pms structure dimen sion processors defined primarily data types process agree entirely com putersystemfunction dimension possibly processorfunction dimension considered simply extension com putersystemfunction dimension hand inclusion microprogrammed processors really extends pms structure dimension p seen cascade two ps processorfunction dimension computer space laid evolutionary way correspondence pms structure clear pmicroprogram put beginning dimension ahead pc occurs earlier evolu tionary development extends pms dimension chapter 3 1 computer space 71 processor ps along dimension attained pmicroprogram actual dimension characterizing total computer must viewed cumulatively similarly datatype dimension thus computer pio also pc parray also ha5 prior ones numerous exceptions small pcs displays hence pios evolutionary ordering correspond complexity num ber datatypes p pc parray complex pi0 pvectormove least make brief comments functional type taking order dimension microprogram processor pmicroprogram term microprogram ming introduced initially ﬁthe best way design automatic calculating machineﬂ wilkes 1951 use ﬁmicro programmedﬂ mean isp defined interpreter program residing internal mp processed internal processor microprogram thus structure really external processor isp defined computer formed p mpinterna1 readonlypmicroprogram operations microprogram processors perform primitive comparison processors task microprocessor interpret instructions isp realizing involves mostly data transfers among registers processor state mps plus simple boolean tests although must handle datatypes larger isp bit fields extracted transferred one register another complex data operations eg multiplication carried units ds fact complex instruction set used pmicroprogram external processor might well implemented directly hardware minimal ps example cpdp8 chap 5 isp essen tially already level microprogram isp shown inclusion instruction microcoded long lag idea microprogramming widespread adoption due several reasons early isps comparatively straightforward microprogram ap proach economically justified interpretation overhead time higher hardwired approach unless complex functions realized time becomes objectionable addition suitable readonly memories developed mid 1060s though imclear whether came effect additional feature using pmicroprogram ability realize several isps within single physical processor ibm exploited feature extensively system360 part 6 sec 3 far ambitious use microprogram ming one argue without additional payoff used ease transition new incompatible computer system providing emulation old system micropro gramming would marginal several pmicroprogram design approaches emerged kampe chap 29 presents design based short word internal processor much like conventional processor extreme ibm system360 chap 32 based long word allows multiple operations coded parallel parallel operations necessary gain accept able performance level thompson ram0 wooldridge called anuyk ﬁstored logicﬂ computer provided ability use primary memory defining isp ibm system36o model 25 page 567 also iises approach hewlettpackard desk calculator chap 20 shows use microprogramming relatively circumscribed complex task central processors pc processors interpret instruction set manipulating arithmetic logical symbolic datatypes simple systems processor thus tasks growth processor specialization described terms relieving pc simpler functions require sub stantial processing time make full use devices within pc arithmetic units crucial issue time takes pc switch one task another recall discussion mps processor state since many jobs extracted specialized processors demand jobs inputoutput removal tasks pc becomes spe cialized pure example pc cdc 6600 chap 39 inputoutput instructions kind pc control management communication transmission ts mss moved pc act initiation removed well placed pios thus 6600 pc engine working arithmetic logical symbolic ad dress datatypes mixture operations performed complex algorithms prevents specialization pc going far eg parithmetic every switch tween capabilities distributed distinct ps must inter communication components introduces overhead cost processing time 72 part 1 structure computers lnputoutput processors pio pi0 specializes manage ment peripherals secondary memories terminals also called peripheral processors data channels channels1 tasks pi0 subordinate peripherals perform transmission information ms mp transmission information extra computer realtime system eg human transmission information outside c via information media eg card reader card punch line printer etc tasks similar often considered though principle quite different task environment management quanta information whether one bit character voice message record file magnetic disk magnetic tape thus pi0 usually change information merely interpreter moving information three exceptions computation required error correction andor detection computation required recoding reformatting done computation required search operations carried ms without pc intervention accomplish tasks requires fairly simple instruc tion set typically contains jump branch data transmission within mp initialize process variables simple counting ability eg control error retries subroutine calling interrupt process handling initializing kms kt testing state kms kt sometimes code conversion data one code format con verted another code thus substantial arithmetic logic facility needed part 4 sec 1 provides detailed discussion pios display processors pdisplay pdisplay complex pi0 processes information display terminals datatype representation complex graphic object eg lines points curves spatially localized text representations vary con siderably system system using various list pointers vector encodings operations datatypes include maintenance display due shortterm persistence crt selective modification representation commands tdisplay pc adding deleting line inserting text etc control tinputs key boards light pens joysticks performance complex spatial transformations translation rotation scale change determination hidden lines terms usually used without distinguishing pin kin whether device interprets sequential program thus capable sustained independent activity decodes single instruction display good example highly complex spe cialized datatype substantial local operations perform interaction needed complex algorithm requires pc users displays wish correct modify transform display geometrically simple ways effect edit view processing graphic infor mation complex algorithms thus graphic display prime candidate development specialized processor dec 338 chap 25 typical processors neither simplest complex eg rotation hidden line elimination instructions array processors parray array processor might considered general pc proposed discussed litera ture time see bibliography chap 27 page 329 information unit processed array one vector two matrix dimensions instructions provided operate data specification algorithms parray based assumption operation carried parallel array elements actually serial sequential parallel concurrent execution implemented structures logical characteristics isp viewpoint may differ execution rate three array processors illiac iv chap 27 nova chap ibm 2038 page 577 discussed part 4 sec 2 page 315 vectormoue processors vectormove processor specialcase parray capable moving word vector loca tion mp location within mp limited instruction set p found computers require constant mp shuffling condition arises either hierarchy mp speeds programs must particular structure interpreted proc essor timeshared computer might require processor multiprogram memory management therefore common find block vector transmission instructions pc ibm sys tem360 piostoragc channel function page 577 special algorithm processors pazgorithm small number special algorithm processors specified andor imple mented high performance almost guaranteed hardwiring specialization time fetch algorithm instruc tion fetch time many references mp temporary data eliminated hardwiring hardwired algorithm easily outperform stored program factor 10 100 lack processors systems stems mainly lack market demand chapter 3 computer space 73 clear special algorithm processors meet criteria processor rather limited func tions perform fact socalled processors ks ds since instruction location counter inter pret single instruction time requesting new instruction superior component algorithms hardwired proposed include fast fourier transform using cooleytukey algorithm crosscorrelation autocorrelation convolution processing polynomial powerseries evaluation floatingpoint array processing neural network simulation language processors pzanguage laqguage ps interpret lan guage designed external criteria procedureoriented language algol fortran list language iplvi thus complexity takes form complex datatype ﬁinstructionﬂ rather complex datatype processing eg floating complex numbers processors extended things pc also would become complex pc however date experimental focus exclusively language interpretation part 4 sec 4 several examples presented worthy note three p1anguages euler chap 32 implemented hardware using pmicroprogram memory access useful classification memories according accessing algorithm2 queue ie access according firstinfirstout discipline stack ie access according first inlastout discipline linear eg tape forward read rewind bilinear eg tape forward backward read cyclic eg drum random eg core content associa tive memories explicitly addressed except stack queue deliver implicitly specified iunit read memory size basic operation times le time constants access algorithm important course distinction made mp ms given technological era existed characteristic sizes speeds chasm macromodular computer analog neuron models molnar 19671 access writing distinguished access reading mem ories conceivable arbitrarily different read write access algo rithms eg random read cyclic write however general two access algorithms tightly coupled normally read access algorithm given memories specified access algorithm variation either linear size eg buying two boxes magnetic core mp versus buying one narrow range costperformance tradeoff data rate magnetic tapes modest increases density tape speed bought substantially increased dollars table 5 shows relative price size performance various mem ories memorysize versus informationrate plot fig 14 shows clustering memories suitability particular function technology standpoint mps constrained either cyclic randomaccess memories although one easily construct type randomaccess memories part 2 sec 1 separated machines according whether used cyclic randomaccess memories early firstgeneration computers used cyclicaccess memories part 3 sec 2 presents cyclicaccess memories similarly mss constrained cyclic linear although quasirandom access achieved disks magneticcard memories random block linear cyclic within block mss part almost computer structure thus large effect ms structure main design features computer systems discussed extent remainder book discussion memory type deals exclusively mp mps stack queue memories mstack mqueue data elements stack queue accessed explicitly noted stack rather unique properties aid com pilation evaluation nested arithmetic expressions although machines employing stacks exclusively primary memory stacks arithmetic processors part 3 sec 5 devoted processors stack memories ie stacks processor state iplvi machine chap 30 computer book entire memory organized list stacks although hardware exists inherently behaves stack queue3 simulated randomaccess memory shift register capable shifting either two directions stack cyclicaccess memories mpcyclic nearly firstgeneration vacuum tube computers mpcyclic mpxyclic acoustic magnetostrictive delay line magnetic drum provided 3small 10 1000 word queue stackaccessed memories espe cially easy build largescale integratedcircuit technology 74 part 1 structure computers table 5 memory characteristics memory size memmy performance module modules access data access size computer time rate memy module function method bits sec bitssec costbit punched paper card magnetic card magnetic tape movinghead disk pack fixedhead disk drum bulk core memory highspeed core integrated circuit thinfilm memory scratchpad memory integrated circuit read content addressable capacitor inductor permanent random 500 1000 archival linear card 1000 cardunit secondary linear 3 x 109 archival constant secondary archival secondary files swapping secondary files swapping secondary swapping primary andor secondary swapping primary primary processor state primary cache processor instructionset definition cyclic linear linear cyclic cyclic cyclic random random random content random random 2 x 10s 2 x 108 5 x 101 1 5 x 107 107 105 io6 103 105 2 x 105 1 5 x 105 12 14 1 16 1 16 1 40 1 10 18 1 16 1 12 1 io0 103 104 2 x 106 2 x 101 15 x 108 04 x lo6 101 100 5 x 105 100 102 04 4 x 106 2 x 107 104 101 100 25 x 106 3 x 106 104 103 106 101 102 5 30 x 103 io6 107 103 002 005 2 10 x 106 106 108 005 025 02 2 x 106 107 10s 107 109 025 10 13 109 107 106 107 10s 109 103 102 first component memory media eg disk pack second component transducer eg disk drive expensive simple producible memory second generation cost mprandom though still expensive mpcyclic equal processor logic incremental cost mprandom large system small whereas performance gain could factor 3000 access time 10 microseconds versus 30 30000 microseconds firstgeneration machines reimplemented using transistors lgp30 became lgp21 new cyclic access machines introduced second generation notable lowcost packardbell pb250 using transistor logic magnetostrictive delay lines derivative bendix g15 npl ace nearly computers use form n 1 addressing memory organized digitbydigit serial basis word eg zebra binary ibm 650 decimal hence arithmetic logic function hardware implemented single digit operation done entire word iterating digits time thus cost serial computer nearly independent word length cyclic synchronous nature mps difficult synchronize secondary memories terminals also synchronous early machines large secondary memories cases magnetic tape used added low performance low density low speed therefore low data rates synchronization problem cases small randomaccess core chapter 3 1 computer space 75 ioﬂ 1 00 109 108 07 r 106 j3 105 2 0 al e 3 104 1 o3 102 10 100 1121 magnetic card l moving head disk 68 l super conductive integrated moving head diskpak 1 unit 1 processor definition 1 read card capacitive drum fixed head disk 321 ms tape drumsdiscmagnetic 128 content addressed integrated mterrnina1 mworking ibm card card reader _ mlogic stepping switches transistor circuits integrated transistor mechanical relays fluid io5 lo6 10 io8 io9 iolo ioﬂ x indicates width informotionin bits effective information rate bitssec fig 14 memory size versus effective information rate memory added provide synchronization two memories example ibm 650 rundoniuccess memories mprandon randomaccess memories used late first generation remained predominant memory second third generations unlikely popularity decline unless content addressable memories constructed sufficiently cheaply earliest firstgeneration randomaccess memories electrostatic depended maintaining charge plates array capacitors common williams tube invented f h williams university manchester works essence like crt beam used charge capacitor array tube face williams kilburn 19491 schemes included array capacitors selected digital logic pilot chap 35 late first generation forrester 1951 invented core memory rapidly became predominant primarymemory 76 part 1 structure computers component unlikely replaced near future likely candidate largescale integratedcircuit arrays flipflops randomaccess memory seems nearly perfect mps present computers course enthusiasm memory may based knowing computers would developed however little effort mrandom stack queue linear cyclic even within limits content associative memory organiza tion hard beat contentaddressable associative memories posdde conceive many exotic accessing capabilities numerous proposals made involving either theoretical structures experimental prototypes since particular varieties become widespread terminology still variable content addressable memories usually taken mean collection cells predetermined size ie fixed iunit one presents ﬁaddressﬂ contents predetermined part cell tag content address contents entire cell retrieved associative memory usually taken mean system presented item informa tion delivers one ﬁassociatedﬂ items information principle association variable yielding different kinds associative memories contentaddressable memories provide form association memories fact thus term ﬁassociative memoryﬂ tends denote forms association different familiar onesforms presumably less sharp con straints imposed structure memory opposed structure information memory examples exist computer contentaddressable memory primarymemory structure however ibm 360 models 67 page 571 model 85 page 574 use 8 1000word contentaddressable memories respectively crease performance cases transparent program cdc 6600 instruction buffer effect small contentaddressable memory three cases con tentaddressable memories vary size position struc ture however pattern use common large slower mprandom behind contentaddressable memory purpose fast small contentaddressable memory hold local current data access made randomaccess memory small prototype associative addressable ms con structed normally based randomaccess memories nnder control special hardware immediate uses contentaddressable memories large informationcontent address example readonly memories microprogram processors use long words principally contentaddressable memories available ideally microprogrammed processor would like look fairly large processor state determine action taken microprogram interesting speculate evolution computers content addressable memory developed place random access memory mp concurrency multiprogramming simultaneous existence multiple independent programs within mp processed sequentially parallel one processors multiprogramming provides user program memory space independent users may provide addition sharing several users independent use communication block mp thus duplicated example operating sys tems software including compilers assemblers loaders edi tors usefully shared ability multiple programs gives rise corre sponding problem communication programs defined correlated dimension computer space interprogram communication discuss next sec tion issues raises opposite raised requirement multiple programs discussed section concerned protecting one pro gram anotherwith assuring unjustified communica tion occurand obtaining appropriate space mp multiple programs run requirement protection obvious two independent programs resident mp time must access others space would access especially writing disastrous consequences programs running would entirely unpredictable undebuggable viewpoint programmer individual program thus requirement absolute ie must highly reliable implies hardware solution although purely software schemes possible special cases requirement appropriate space somewhat sub tle certainly must enough space mp pro grams resident simultaneously must possible find space assign new program make available program finished kind space must single interval mp large enough total program data arid program assembled compiled chapter 3 computer space 77 mp removed temporarily make room another program must brought back exact addresses originally assembled key issue resides kind intercommunications hold within program data determine way program interconnected depends specific mp addresses occupies connections two kinds explicit addresses present program data implict relations addresses due addressing algorithms eg programs laid sequentially mp ele ments array accessed indexing hence must occupy consecutive addresses although purely soft ware solutions space issue exist hardware involved fundamental way thus two main questions program concurrencyl protection space assignmentimply basic design features computer system might seem imply separate fea tures separate dimensions computer space fact proposal solve spaceassignment prob lem also contains particular proposal protection problem thus treat single dimension virtualaddress space mp mapping considering various solutions mp concurrency le values along dimension let us introduce two concepts terms current solu tions understood consider particular program pro gram1 one many might wish reside mp pro gram1 assumes set addresses explicitly implicitly addressing algorithm uses program1 quires memory space addresses satisfy requirements implicit explicit ones care addresses realized let us call address space required program1 virtual memory mv thus program virtual memory might think mp except shall see mp may many times bigger actual mp still entirely feasible actually run program1 requires placed real mp way real addresses mp containing satisfy requirements faithful image virtual memory thus must memory mapping maps actual addresses actual memory program1 placed mp must process takes virtual address occurs processed see also randell kuehner 1968 instruction finds actual address mp correct contents obtained might seem simply complicated abstract way view matters becomes essential soon realize computer hardware memory mappings familiar directaddressing structure mp furthermore mapping given right properties may solve spaceassignment protection problems mp concurrency really done divorce addressing required programs provided physical computer redesign via memory mapping meet new design requirements apparent original randomaddressing schemes created let us make notion memory mapping precise program contains virtual addresses z symbols pro gram denote addresses taken denote addresses mv execution program whenever refer ence address z either explicitly via address calculation implicitly via say getting next instruction computation occurs z obtain actual address mp computation part pc automatic indexing indirect addressing calculation takes input virtual address z information program located mp latter information called map programs map infor mation determined placed mp given run thus using isp notation calling address calculation f get mvz mpfzmap information virtual memory virtual address z information actual memory address whole scheme built permit programs placed mps various ways eg relocated scattered around still make possible run program scheme brings solution protection problem namely values z calculation take place invalid ie mapping z correspond violation protec tion prevented calculations may even permissible f arranged never produces address anyone elses part mp memory map part users program many users must reside mp since enough space mps hold large amount mapping information however program executed part mapping information becomes part mps le least mp address fzmap 78 part 1 structure computers rest map addition map may contain special access control information whether part may read read data written read program map also collect statistical information concerning whether part program used changed written randomaccess memories mp constrain mapping requiring linear addresses form mpop since mapping calculation must economical performed high frequency would consider map structure provides every word mv mapped arbitrary word mp would require map exactly size mv many programs mp would little room anything maps similarly amount processing f calculation must minimal two aspects constrain mapping scheme strongly constraint linear addresses appears force structure virtual memory consist multidimensional array table 6 memoryallocation methods onedimensional mvon twodimensional mvosom could higher dimension need seems felt since within single dimension one multi dimensional arrays one normally regular mp ever twodimensional array also called segmented addresses since taken discrete collection 1 segments 1 linear addresses advantages terms mappings namely segments placed disjointly mp without fear virtualaddress calculations cross one segment another introduction problems multiprogramming look hardware schemes table 6 provides summarization including brief description scheme operates special mapping hardware hardware exists pc accomplish memory address mapping address hurrlioare designution cinaizged order uf tncrmwig hardilcire coinplerity method memory allocation among multiple users limits particular method example use xo relocation mr 5 mp conventional computerno memoryal special hardware completely done inter location hardware pretive programming 1 1 users protection bit protection bit added memory cell bit specifies whether cell written accessed memory cell 1 1 users protection bit protection bit added page see memory page scheme pagelocked memory block memory user number must coincide currently active user number completely interpretive programming required high cost time paid generality johnniac interpret ing joss 1 special user 1 user al lowed user programs must writ ten special locations special conventions loaded assembled place time change bits user job changed makes method nearly useless memory allocation hardware ibm 1800 memory allocation hardware sds sigma 2 general expensive memory reloca tion must done conventions relocation software fixed small number users permitted hardware memory allocation hardware program moved run completion ibm system360 chapter 3 computer space 79 relocation protection mu 5 mp one protection count one field reg ister addresses formed checked logical operations programs written though origin location 0 count register deter mines number highorder bits examined field register com pared identity requested address one set protection relocation reg isters base address limit regis ters also called boundary registers two sets protection relocation reg isters two segments n 2 3 sets protection relocation registers mapping mu 2 mp memory page mapping memory pagesegmentation mapping indirect references descriptor table segments programs written though origin location 0 relocation register specifies actual location user pro tection register specifies number words allowed similar two discontiguous physical areas memory mapped homo geneous virtual memory similar similar page mapping page 26 21 words users vir tual memory corresponding information kept concerning actual physical location primary seconaary memory map primary memory may desir able associative registers processormemory interface remember previous reference virtual pages actual locations alternatively hardware map may placed processor memory transform processor virtual addresses physical addresses additional address space provided beyond virtual memory providing seg ment number segment number ad dresses selects page tables al lows user almost unlimited set ad dresses segmentation page map lookup provided hardware may thought twodimensional addressing data considered part descriptor array referred number descriptor table indexed descriptor number used locate array mp give size memory allocation blocks must power 2 unless blocks size memory utilization poor although faster fol lowing scheme requires hard ware adder inflexibility loca tion size makes restrictive ibm 7040 users enter leave primarymem ory holes form requiring moving users pure procedures im plemented moving impure part adjacent pure part cdc 6600 pdp6 similar simple pure proce dures one data array area implemented univac 1108 pdp10 used conventional computer relatively expensive general following method implementing pure procedures atlas cdc3500 sds940 expensive little experience judge effectiveness ge 645 ibm 36067 indirect reference must made description table mp b 5500 80 part 1 1 structure computers z encountered program information mpz obtained still however two different ways obtain effect virtual memory first one operate interpretively software system taking place hardware programs users nonmachine language eg higher procedureoriented language access language processed software interpreter access made mp clear logical power memory mapping available scheme drawback loss efficiency interpretation may range factor 5 100 conse quently scheme used special circumstances multiuser timeshared conversational algebraic languages second scheme modify code time placed mp given run addresses code corre spond actual mp addresses used assembly translation operation performed time program placed mp advantage scheme address calculations necessary three disadvantages assem bly operations expensive although scheme tolera ble program brought run completion tolerable programs continually swapped mp addition program must laid continuous intervals mp corresponding predetermined segments program assembly occurs static representation program unravel potential effect address algo rithms finally size mv ie addresses used externally must greater mp relative software schemesone interpretive expensive one involving assembly le compilation load ingthe hardware schemes described appear address interpreters cost continuous interpretation made tolerable protection words pages hardware three schemes table 6 provide means protecting one part mp references programs rationale designs two users user classes one user superior assumed perfect program debugged references mp via imperfect program perfected superior part mp forbidden schemes provide method hardware mapping physical addresses virtual addresses simplest scheme ibm 1800 chap 33 protect bit added every word mp mpo 2ls 10 w l protectbit every reference mvz takes place mvz 7mpzprotectbit mpz mpzprotectbit protection violation 1 reference word protect bit causes error two schemes protect basis blocks words protection relocating registers hardware protection relocation register mechanism used four schemes table 6 provide either one concatenated one additive two addi tive n additive register pairs mapping single program one one two n nonadjacent blocks mp authors know schemes three registers used would really akin using general page map generally schemes restrict mv 5 mp additive protection relocation register pair shown fig 15 four users occupying mp07999 user program written occupy continuous address space virtual mv thus isp pc running programs userj address mvz z varying 0 vj 1 map ping uses actual memory action mvz z protection mpz relocation z 2 protection protection violation 1 protection relocation two registers specify map ping implementation scheme generally takes form adding contents relocation register address calculations taken place thus pms might think structure mpkadess translationpc ml protectionrelocation pagemap hardware figure 16 shows memory allocation using page map note 4096 words possible define map range 1024 2047 actually undefined along map containing addresses words actual mp desirable accessor protection control information information might specify 1 restrictions form reading writing take 2 read data 3 read program 4 writing 5 undefined place chapter 3 computer space 81 6 defined located ms 7 page written know whether copy ms updated 8 page accessed scheme essentially generalization n protectrelocate registers hut includes control bits suggested restricts block size note mv greater mp addition parts virtual memory may remain unused two ways scheme usually implemented 1 complete map first considered conventional ex plicitly addressed whose addresses correspond virtualaddress pages given pagememory address contents map specifies address mp map similar indirect reference however map usually 10 times faster 11000 size since keeps track pages words pms structure mpmmappc 2 map retained mp referenced protection relocation register set particular active user order avoid making references mp word reference mv pc small fast mcontent ad dress placed pc mp pms structure ldata kaddress translation laddresses mcontent address 8 16 words pc menloriisegmentation hardware figure 9 page 574 intro duction ibm system360 shows logical mapping process segmented memory provision large two dimensional virtualaddress space scheme discussed exten sively literature arden et al 1966 dennis 1965 gibson 19661 physical implementation similar paging note two levels mapping provided segment map page maps two levels facilitate sharing single segment two jobs hurroughs r 5000 chap 22 later r 8500 mapping closely integrated pc relocation r e3 kz21 protection h uq table user location information 3 0i 2 2 usermemory addresses 1000s words hardware registersi7 user 2 running absolute memory addresses 1000s words fig 15 memory allocation using boundary relocation protection register provide variablesized address space paged within seg ment segments named large number segments exist lntetprogram communication dimension interprogram communication completely cor related multiprogramming dimension previ ously noted problem intercommunication must structure components require communication simplest level dimension represented single program need intercommunication variables r 24 20484095 map locoting userjk virtd memory absolute memory 01023 absolute memory fig 16 memory allocation using page allocation map 82 part 1 structure computers program completely accessible whole program address space essentially uniform second value dimension subroutine calling produces hierarchy communication contexts fixed num ber levels hierarchy since subroutine may call others ad izuuseum subroutines present address names values within subroutine become addresses local part subprogram structuring apparent looking higherlevel languages fortran algol pli explicit statements con trolling names addresses available parts program concept subroutine structure us almost first programs next value dimension relates signaling within single process akin subroutines embedded hardware called extracodes perhaps first suggested atlas chap 23 extracode looked call specific subroutine variables user callers program made available called extracode defined program calling usually accompanied context shift completely different program one used number calling programs takes command interpret struction scheme used systems controlled special software monitor function input output file required main program issues call monitor make transfer theory monitor knows conditions system capability perform complex function central monitor control begin run another program request one would normally halt computer form communication useful supply extra facilities users method knowing users eg equipment better utilized complex program structures directly represented hardware intercommunication complexity also creases beyond simple subroutine call segmentedmemory scheme used problem communicating seg ments solved range ways value range would somewhere ignoring problem hardware providing methods naming addresses communicating segments cases communication among various programs parts programs done explicitly one program another program instruction trap fit view nicely conditions occurring within single process explicitly called cause another part program called typical conditions cause traps arithmetic results outside expected range erroneous program conditions eg trying call someone elses program trap causes change context synchronized process causing trap ping form program interruption trap intraprocess interrupt distinct interprocess interrupts intercommunication two independent processes carried two independent components usually accom plished using program interrupt interrupting process requests program interrupt occur component inter ruptee interrupters request acknowledged inter ruptee change process state occurs interruptee new process run interruptee behalf interrupter program interrupt used among processors multiprocessor system 1pc npios control k may also use programinterrupt request communicate superior pi0 pc example pi0 usually logical capability execute algorithm would decide action taken various error conditions usually interruptee equipped certain logic capable arranging priorities requesting interrupters typical kinds interrupt requests component faults eg parity error timer counted various task comple tions eg program completed tape unit rewound disk arm stopped moving certain record found tape buffer full state diagrams would show communication methods similar one another typical interrupt state diagram shown fig 17 four states normal process interpretation process state saving interrupt process interpreta tion process state restoration sequence follows normal instruction interpretation occurring inter ruptee interrupter requests interrupt delay tacknowledgment state reached part interruptees process state saved tacknowledgment tsave program running interruptee response interrupter interrupt program run tinterrupt completion interrupt program original process state restored interrupter trestore normal processing resumes inter rupter chapter 3 computer space 83 significant attributes system various times quired move state state times directly related amount process state must saved restored switching context intercommunication problem probably least stood dimension computer space rather intimately related isp various calling methods implicitly explicitly depend isp also amount processor state function isp affects response time making context transitions interrupt systems allow several inde pendent classes andor sources interrupters classes arranged priority lowerlevel interrupters ignored higherlevel interrupt programs run completion see chap 42 sds 9109300 series design problems sociated intercommunication implementa tion knowing implemented pms structure part corresponding registertransfer implementa tions intercommunication comparison straightforward processor concurrency concurrency parallelism processor number events logical operations happening given time basic logic technology held constant decreasing processing time increasing power requires increasing number parallel operations exact measure parallelism made terms number nbit operations made per clock pulse parallelism structure also measure complexity highly parallel structure implies control structure gether multiple data paths operations concurrently evoked processor parallelism also necessary overcome mp speed technological boundaries thus difficult isolate completely processor memory flynn 19661 categorized highspeed processors whether single multiple instruction streams whether stream single multiple data streams cdc 6600 ibm stretch examples single instruction stream single data stream illiac iv processor single instruc tion stream multiple data streams thus single instruction stream multiple data stream form array processing instruction performs operation multiple data elements cdc 6600 main processor multiple instructions single stream fetch buffering decoding process given time addition instructions executed parallel interrupt request interruptor interpret instruction mp interpretation interrupted state1 interrupt request restore interrupt program execution fig 17 state diagram interrupt process 10 parallel dataoperations 6600 functionally differ ent data operators although system could exist operators operator much faster single unit could used sequentially depending utiliza tion 10 data units could computer several processors share common set dataoperations 6600s peripheral processors implemented mode whereby several instructions streams processed parallel single processor simplicity shared processor multiprocessing parallel processing thereby provides still another form parallel ism following subsections discuss particular forms paral lelism one end dimension primitive structure serial processor end pipe line processors serial processors elementary level one bit nbit word operated given time concurrency even trivial operations n bits requires time n bitserial processor used first generation cyclic primary memories connected funda mentally bitserial see page 73 although processor memory could made operate parallel basis words available one unit time tradeoff worthwhile relatively long access time mp word lengths serial processors tended relatively long cost independent word length see page 216 parallelb yword processors simple parallelbyword processor common processor first third generation occurred part mp became parallel word within 84 part 1 1 structure computers processor assume almost every internal register transfer operation requires one clock times simple multiply operation usually takes n2 2n clock times mean rule multiple simultaneous internal opera tions within processor exceptions view processors registers easy tell multiple opera tions possible processors one operation time rule simple processor locked primary memory cycle time usually core approximately 2 10 events clock times available within processor example pdp8 chap 5 four events ibm 7090 chap 41 10 events precise measure parallelism would count number operations per clock time given program conditions multiple instruction streams 1 pc example structure book cdc 6600 opportunities structure possible parallel computer suggested lehmann chapter 37 multiple datu streams obvious implementation multiple data streams one instruction streams array processor part 4 section 2 devoted struc tures 1instruction buffer 1instruction buffer form looking ahead instructioninterpretation cycle simplest form parallelism parallelbyword processor single register assigned role holding next instruction interpreted ibm 7094 instruction backup register chap 41 typical case 7094 two instructions fetched time generally next instruction would fetched execution current instruction ninstruction buffering multiple instruction buffering general ization 1instruction buffer take several forms depending algorithms used fetch next instruction ie lookahead organization memory holding instructions stretch chap 34 cdc 6600 chap 39 use instruction buffers small restricted contentaddressable memory holds block instructions simplest case computers block memory relative instruction counter kept local instruction buffer memory lookaside buffering sluve memories lookaside general form instruction buffering instructions com monly accessed data tend migrate faster lookaside memory scheme discussed ibm system360 model 85 page 574 lookaside memory suggested wilkes 1965 contentaddressable memory retaining active recently used memory words pipeline processing pipeline assemblyline concurrency name given system multiple functional units responsible partial interpretation execution struction stream pipeline processor several partially com pleted instructions process one time processor stage operates specific part instruction eg instruction fetch effectiveaddress calculation operand fetching execution opera tion specified instruction results storing pms dia gram pipeline processor given fig 19 thus separate functional unit state suggested state diagram fig 4 must interlocks sequence preserved ie results used available figure 18 shows timefunction diagram pipeline processor least three instructions interpreted simultane ously although extended fig 18 would expect processor sketch operate eight instructions 1 j tq3 instruction 3 toq operation time determine instruction q toq access time determine instruction q ooeratlan tme determine dotum v tov operation tlme instruction operation time determine operation instruction tq total instruction time access time determine datum v fie 18 timefunction diagram pipeline processor chapter 3 computer space 85 mdata instructions t4data instruction fetch data setup execution data restore iu l fig 19 example processor parallelism spatially independent control function pipeline processing pms diagram one time note processor sometimes completes later instructions first model one instruction fetch ing one operand fetching one operand storing unit multiple data operation units particular number type unit obviously fixed structures depends heavily memory system number instruction streams isp processor may require many dataoperation units order avoid bottlenecks unit independent may functionally capable carrying selected tasks multiple dataoperations normally desirable pipeline processor several operations carried time since processing time within processor spent operations eg multiplication division shifting etc conclusions view important aspects stored program computer tried organize parameters dimensions computer viewed point points multidimensional space previous discussion enumer ated values one dimension effect holding values dimensions constant dimensions highly correlated especially cost evolutionary time brief presenting dimensions book pri marily computer examples however one able recognize dimensions values encountered within context particular computer remainder book organized around dimen sions examples lose identity dimensions descriptions points space computers furthermore descriptions especially organized around dimensions based designers view machine references adama60666768 adamc6o arbur66 ardeb66 bowdb53 campr50 casac62 chasc52 coxj68 dennjgs flynm66 forrjfjl gibsc66 knigk66 molnc67 nisen66 randb68 roses69 samua57 serrr62 weikm556164 wilkmsla65 willf49 part 2 instructionset processor mainline computers main line computers family predominates generations predominance probably best measured percentage distinct computers produced within family opposed outside members family need identical especially evolution time tolerated must case moment standard design seen emerging prior standard design within definitions indeed main line computer systems based burks goldstine von neumann memorandum reprinted chap 4 striking characteristic evolution 1 address organization l indexregister 1 x generalregister 1 g organization left outside main line multipleaddress organizations character machines stack machines seems appropriate description even though character machine variablelength character string ibm 1401 probably holds record number machines produced model ibm sys tem360 counted separate computer second characteristic feature pms structure evolved single p pcnpio structure uniform within family since applies larger members small machines pdp8 chap 5 separate pios might seem computer systems within without family evolved way disregards history computer development early fifties seen two main lines potential development scientific computers featuring large computation small inputoutput business computers featuring small computation large inputoutput latter started develop pcnpio structure ibm 702 instead separate line developing scientific computers ibm 704 univac computers adopted powerful inputoutput structure despite success 1401 bred new generation computer systems image either within ibm one might argue overriding consideration uniform series ibms competitors third characteristic main line use binary opposed decimal basic radix machine affects arithmetic whether logi cal processing bit vectors done issue seems almost settled third generation smaller machines binary larger machines multiple datatypes last serious venture large pure decimal machine univac larc delivered 1960 retrospect difference organizations binary decimal machines seems small enough included section number striking features characteristic main line differentiate alternatives actually produced features include storedprogram concept use sequential a7 88 part 2 1 instructionset processor mainline computers instructions operatoroperand variety use word information unit within range 12 64 bits processor state less 100 words alternative organizations conceivable though clearly seemed practical computer designers instance early fifties tempt construct electronic plugboard machine fashion eniac ibm cpc card programmed calculator see new programmed desk calculators part 3 sec 4 yet another organization rather far main line low cost may yet part future main line desk calculators way decimal rather binary section 1 processors one address per instruction section principally concerned isp largest section book reflecting dominance oneaddress organization first two generations machines index registers included machines general registers discussed sec 2 processors store two singleaddress instructions per word fol lowing pattern iasl von neumann machine chap 4 machines short word lengths one singleaddress instruction stored one two words example 16bit ibm 1800 chap 33 12bit pdp8 chap 5 evolution machines seen comparingfirst thirdgeneration machines eg whirlwind ibm 1800 general section arranged increasing word length alternatively complexity performance preliminary discussion logical design electronic computing instrument article chap 4 important historical well tech nical reasons one series written 1946 prior building first fully storedprogram computer although authors engineers written caution responsible implementation rather significant development task major problems computer identified alternatives analyzed rationale decision given computer designers required analyze describe machines fashion prior building would fewer better computers especially enjoyable aspects discussion clude institute advanced study princeton university princeton nj articles series 1 selection word length number base 2 discussion instructions needed 3 concern inputoutput structure idea displays almost reality 4 rationale including floatingpoint arithmetic caution technology 5 lack necessity rather trivial binarydecimal conversion hardware idea cost effectiveness 6 analysis addition multiplication division hardware implementation description includes nice onepage discussion average carry length addition difficult say machines influenced memorandum since idea data instructions stored together homogeneous primary memory basic computers idea singleaddress instruction set format heart machines discussed section however index registers many machines long word length like ias use twoinstruc tionsperword format subsequent machines built minor variations clude ordvac illiac university illinois 40bit electrostatic memory vacuumtube logic avidac oracle maniac weizac silliac besk dask csirac johnniac rand corporation 40bit core memory transistor logic gruenberger 19681 similar com puters include ibm 701 36bit word electrostatic memory vacuumtube logic cdc 1604 48bit word core memory transistor logic possibly fluenced maniac 11 principles large scale computing machines 1946 goldstine von neumann 1963al preliminary discussion logical design electronic computing dec pdp8 pdp8 included chap 5 illustrate effects instrument pt vol l1946 burks goldstine von neumann 19631 planning coding problems electronic computing instrument dt 11 vols 123 194719481 rgoldstme von neumann 19636 1963c 12bit word length given detail using yopdown approach order student may thoroughly understand 1963dl simulating interpreting writing microprograms 89 90 part 2 1 instructionset processor mainline computers section 1 processors one address per instruction emulate making incremental modifications com pletely redesigning pdp8 although first 12bit computer achieved status made first standard small low cost dedicated computers active market com puters size price range marketing culture responded names microcomputer mini computer midicomputer 8 12 12 16 16 24bit wordlength computers respectively2 pdp8 nearly minimal processor state address isp integers 12 bits twelve bits large enough represent data external physical process environments analog signals also right address 4096 word memory system software editors assemblers compilers etc surprisingly fit sized memry processor state 26 bits predecessor pdp5 hardwired state 14 bits pdp8 also discussed part 5 sec 2 page 396 ktcrt display areas2ilo2 in2 kti ight pen ktfilm camera 64 bsw 12 n 2048 w 800io00 ft 30 insec 21 index bchar 100 charin mtoggle switch 8 sw 32 w 16 bw pc50 kops 16 bw instructionw 1 addressinstruction mprocessor state3 w technology vacuum tube 1948 1966 38fixed pc 8 k concurrency 1 4mpoi core 8 vsw 1024 w 16 bw taccess 2 whirlwind computer whirlwind based wilkes edsac manchester univer sity chapter 6 describes computer gives brief descrip tion vacuumtube logic electrostatic storagetube tech nology pms structure whirlwind core memory given fig 1 memory test computer mtc mits lincoln labora tory first computer use core memory mtc built test memory whirlwind received august 1953 subsequent modifications included addition 2048word magneticcore memory september 1953 machines construction technology outstanding effective marginal checking preventivemaintenance test facilities time machine dismembered moved mit use time availability greater 95 percent although whirlwind left mit 1960 chine reassembled operational late 1966 machines pms structure simple 1 pc k mp block transfers via pc oneatatime programmed basis single data transfer initiated particular device thus providing opportunity inputoutput processing concurrency simple structure due high perhaps also one authors gb obvious attachment see computers size range chapter 3 flgure 2 page 43 3concevably corollary parkinsons law programs expand fill every word primary memory computer fig 1 whirlwind pms diagram register costs vacuumtube technology thus single central processor register provided hold buffer data k transmission ms appendix 1 chap 6 programming manual gives instruction set ibm 1800 ibm 1800chap 33 thirdgeneration 16bit computer discussed part 5 sec 2 page 396 aspects logical design control computer case study chapter 7 presents aerospace computer apollo designed mits instrumentation laboratory presented contrast generalpurpose 16bit computers whirlwind chap 6 ibm 1800 chap 33 apollo computer uses mread obviously problem reload pro grams kampes sd2 chap 29 apollo chap 7 controllers similar design constraints ibm 1800 also used control purposes fact computers section including 24bit sds 9109300 series designed control environments however latter machines goal generality present apollo section 1 processors one address per instruction 91 sds 9109300 series sds 9109300 computers illustrative typical second generation 24bit computers computers discussed part 6 sec 2 page 542 chapter 42 also attempts show implementation affects performance series lgp30 lgp21 lgp30 later lgp21 presented chap 16 dis cussed part 3 sec 2 page 216 ibm 650 instruction logic ibm 650 chap 17 one plus one address computer attributes cyclicmemory computer though hardly ap parent isp level discussed part 3 sec 2 page 216 ibm 7094 ii part 6 sec 1 shows evolution ibm 36bit scientific computers ibm 7094 ii chap 41 presented many reasons page 517 among effect later ibm system360 position standard large scientific computer late fifties early sixties univac system ynivac system first delivered march 1951 later known univac univac universal automaticcomputers second computer1 manufactured eckert mauchly computer corporation subsequently division remingtonrand2 univac singleaddress decimal computer 12 digits word two instructions stored per word effect univac decimal version ias computer mp consists 1000 words made 10 wordsdelay line delay line requires 404 microseconds recirculate univac significant important computer early 1950s performance record discussed chap 8 univservo magnetictape system rather advanced 1950 considering performance error checking buffering particularly nice ability parti tion inputoutput system offline printing key punching onelevel storage system 48bit atlas developed manchester university subsequently manufactured ferranti corp part inter national computers tabulators development began 1960 paper written 1962 importance atlas respect current future machines dis cussed part 3 sec 6 page 274 engineering design stretch computer ibm stretch also called ibm model 7030 single address computer chap 34 one earliest computers built provide maximum computing power subject ap parent cost size producibility constraints discussion importance given part 5 sec 2 page 396 lthe eckertmauchly binac apparently first computer manu eckertmauchly computer corporation initially independent remington factured corporation rand chapter 4 preliminary discussion logical design electronic computing instrument1 arthur w burks herman h goldstine john von neumann part 1 11 inasmuch completed device generalpurpose computing machine contain certain main organs relating arithmetic memorystorage control connection human operator intended machine fully automatic character ie independent human operator computation starts fuller discussion implications remark given sec 3 evident machine must capable storing manner digital information needed given computation boundary values tables functions equation state fluid also intermediate results computation may wanted varying lengths time also instructions govern actual routine performed numerical data specialpurpose machine instructions integral part device constitute part design structure allpurpose machine must possible instruct device carry compu tation formulated numerical terms hence must organ capable storing program orders must moreover unit understand instructions order execution conceptually discussed two different forms memory storage numbers storage orders however orders machine reduced numerical code machine fashion distinguish number order memory organ used store num principal components machine 12 13 h taub ed ﬁcollected works john von neumannﬂ vol 5 pp 3479 macmillan company new york 1963 taken report u army ordnance department 1946 see also bibliography burks goldstine von neumann 1962a 1962b 1963 goldstine von neumann 1963a 1963h 1963c 1963d bers orders coding orders numeric form dis cussed 63 memory orders merely storage organ must exist organ automatically execute orders stored memory shall call organ control inasmuch device computing machine must arithmetic organ perform certain elementary arithmetic operations therefore unit capable adding subtracting multiplying dividing seen 66 also perform additional operations occur quite frequently operations machine view elementary clearly wired machine illustrate operation multiplication could eliminated device elementary process one willing view prop erly ordered series additions similar remarks apply division general inner economy arithmetic unit determined compromise desire speed operationa nonelementary operation generally take long time per form since constituted series orders given controland desire simplicity cheapness chine 16 lastly must exist devices input output organ whereby human operator machine com municate organ seen 45 discussed constitute secondary form automatic memory 14 15 2 21 clear size memory critical considera tion design satisfactory generalpurpose computing first remarks memory 92 chapter 4 preliminary discussion logical design electronic computing instrument 93 machine proceed discuss quantities memory store various types computations solution partial differential equations storage requirements likely quite extensive general one must remember initial boundary conditions arbitrary functions enter problem also extensive number intermediate results 22 equations parabolic hyperbolic type two inde pendent variables integration process essentially double induction find values dependent vari ables time one integrates respect x one boundary utilizing data time coefficients contribute defining problem integration must memory sufficient room store intermediate data must provisions whereby data later removed ie end cycle replaced corresponding data 2at cycle process removing data memory replacing new informa tion must course done quite automatically direction control total differential equations memory requirements clearly similar hut smaller discussed problems solved iterative procedures systems linear equations elliptic partial differential equations treated relaxation techniques may ex pected require quite extensive memory capacity memory requirement problems apparently much greater problems one needs store information corresponding stantaneous value one variable tin entire solutions covering values variables must stored apparent discrepancy magnitudes however somewhat overcome use techniques permit use much coarser integration meshes case cases b c 23 reasonable time build machine conveniently handle problems several orders magnitude complex handled existing machines electronic electromechanical consequently plan fully automatic electronic storage facility 4000 numbers 40 binary digits corresponds precision t40 09 x ie 12 decimals believe memory capacity exceeds capacities required problems one deals present factor 10 precision also safely higher required great majority present day problems addition propose subsidiary memory much larger capacity also fully automatic medium magnetic wire tape 3 first remarks control code 31 easy see formallogical methods exist codes abstracto adequate control cause execution sequence operations individually available machine entirety con ceivable problem planner really decisive considera tions present point view selecting code practical nature simplicity equipment demanded code clarity application actually impor tant problems together speed handling problems would take us much far afield discuss questions generally first principles therefore restrict analyzing type code envisage machine must certainly instructions performing fundamental arithmetic operations specifications orders completely given arithmetic unit described little detail must possible transfer data memory arithmetic organ back transferring information arithmetic organ back memory two types must distinguish transfers numbers trans fers numbers parts orders first case quite obvious needs explication second case subtle serves illustrate generality simplicity system consider way illustration problem interpola tion system let us suppose formulated necessary instructions performing interpolation order n sequence data exact location memory n 1 quantities bracket desired functional value course function argument argument probably found result computation machine thus need order substitute number given orderin case interpolation location argument group arguments nearest table desired value means order results computation troduced instructions governing different com putation makes possible sequence instructions used different sets numbers located different parts memory 32 33 94 part 2 1 instructionset processor mainline computers section 1 processors one address per instruction summarize transfers memory two sorts total substitutions whereby quantity previously stored cleared replaced new number partial substitutions part order containing memory location numberwe assume various positions memory enumerated serially memory locationnumbersis replaced new memory locationnumber clear one must able get numbers part memory time treatment case orders however methodical since one least partially arrange control instructions linear sequence consequently control constructed mally proceed place n memory place n 1 next instruction utility automatic computer lies possi bility using given sequence instructions repeatedly number times iterated either preassigned depend ent upon results computation iteration completed different sequence orders followed must cases give two parallel trains orders preceded instruction routine followed choice made depend upon sign number zero reckoned plus machine purposes consequently intro duce order conditional transfer order depend ing sign given number cause proper one two routines executed frequently two parallel trains orders terminate common routine desirable therefore order control either case proceed beginning point common routine unconditional transfer achieved either artificial use conditional transfer introduction explicit order transfer finally need orders integrate input output devices machine discussed briefly 68 proceed detailed discussion machine inasmuch experience shown moment one chooses given component elementary memory unit one also less determined upon much balance machine start consideration memory organ attempting exposition highly integrated device like computing machine find possible however give exhaustive discussion organ completing description final block diagrams anything approaching complete unit achieved 34 35 36 37 time units used follows 1 pec 1 microsecond 10f seconds 1 msec 1 millisecond lop3 seconds 4 memory organ 41 ideally one would desire indefinitely large memory ca pacity particular aggregate 40 binary digits word cf 23 would immediately availablele time somewhat considerably shorter operation time fast electronic multiplier may assumed practical level 100 psec hence availability time word memory 5 50 psec equally desirable words may replaced new words rate seem possible physically achieve capac ity therefore forced recognize possibility con structing hierarchy memories greater capacity preceding less quickly accessible common forms storage electrical circuits flipflop trigger circuit gas tube electro mechanical relay achieve memory n words would course require 40n elements exclusive switching elements saw earlier cf 22 fast memory several thousand words unreasonable allpurpose instru ment hence lo5 flipflops analogous elements would required would course entirely impractical must therefore seek fundamental method storing electrical information suggested one criterion storage medium individual storage organs accommodate one binary digit macroscopic components rather microscopic elements suitable organ would course identified switched usual macroscopic wire con nections functional procedure manipulating organ one device displays property marked degree iconoscope tube conventional form possesses linear resolution one part 500 would correspond twodimensional memory capacity 500 x 500 25 x lo5 one accordingly led consider possibility storing elec trical charges dielectric plate inside cathoderay tube effectively tube nothing myriad electrical capacitors connected circuit means electron beam actually mentioned high resolution concomitant memory capacity realistic conditions tele visionimage storage much less exigent respect chapter 4 preliminary discussion logical design electronic computing instrument 95 reliability individual markings one accept storage computer latter case resolutions one part 20 100 ie memory capacities 400 10000 would seem reasonable terms equipment built essentially along familiar lines present time princeton laboratories radio corporation america engaged development storage tube selectron type mentioned tube also planned nonamplitudesensitive switch ing system whereby electron beam directed given spot plate within quite small fraction millisecond inasmuch storage tube key component machine envisaged report extremely fortunate secured cooperation rca group well various developments alternate form rapid memory organ acoustic feed back delay line described various reports edvac electronic computing machine developed ordnance department us army university pennsyl vania moore school electrical engineering inasmuch device clearly reported papers give discussion still physical chemical properties matter presence electrons photons might considered since none yet beyond early dis cussion stage shall make mention shall accordingly assume throughout balance report selectron modus storage words electronic speeds planned tube capac ity 2 4096 4000 binary digits achieve total elec tronic storage 4000 words propose use 40 selec trons thereby achieving memory 212 words 40 binary digits cf 23 two possible means storing particular word selectron memoryor fact either delay line memory storage tube amplitudesensitive deflection one method store entire word given tube get word picking respective digits serial fashion method store corresponding places 40 tubes one digit word get word memory scheme requires one switching mech anism 40 tubes connected parallel switching scheme seems us simpler technique needed serial system course 40 times faster accordingly adopt parallel procedure thus led con sider socalled parallel machine contrasted serial principles considered edvac edvac 42 43 peculiar characteristics acoustic delay line well various considerations seem justify serial procedure details cf reports referred 41 essential difference two systems lies method performing addition parallel machine corresponding pairs digits added simultaneously whereas serial one pairs added serially time summarize assume fast electronic memory consists 40 selectrons switched parallel com mon switching arrangement inputs switch con trolled control inasmuch great many highly important classes problems require far greater total memory 212 words consider next stage storage hierarchy although solution partial differential equations frequently involves manipulation many thousands words data generally required blocks well within 212 capacity electronic memory second form storage must therefore medium feeds blocks words electronic memory controlled control computer thus integral part system requiring human intervention evidently two distinct problems raised one choose given medium storage teletype tapes magnetic wire tapes movie film similar media still remains problem automatic integration storage medium machine integration achieved logically introducing appropriate orders code instruct machine read write medium move given amount place given characteristics discuss question little fully 68 let us return question properties sec ondary storage medium clearly able store information periods time long enough per cent total computing time spent reregistering information ﬁfading offﬂ certainly desirable although imperative information erased replaced new data medium controlled ie moved forward backward automatically considera tion makes certain media punched cards undesirable cards course printed read appropriate orders machine well adapted problems output data fed directly back machine required sequence nonmonotone spect order cards medium capable remembering large numbers data much smaller price 44 45 96 part 2 1 instructionset processor mainline computers section 1 processors one address per instruction electronic devices must fast enough even used frequently problem large percentage total solution time spent getting data medium achieving desired positioning condition reasonably well met advantages high electronic speeds machine largely lost light electronsensitive film magnetic wires tapes whose motions controlled servomechanisms inte grated control would seem fulfil needs reasonably well tentatively decided use magnetic wires since achieved reliable performance pulse rates order 2500osec beyond lastly memory hierarchy requires vast quantity dead storage storage integrated machine storage requirement may satisfied library wires introduced machine desired time become automatically controlled thus dead storage really nothing extension secondary storage medium differs latter availability machine impose one additional requirement secondary memory must possible human put words wire substance used read words put machine manner human control machines functions clear secondary storage medium really nothing part inputoutput system cf 684 description mechanism achieving another highly important part input output merely mention time namely mechanism viewing graphically results given compu tation course achieved selectronlike tube causes screen fluoresce data put electron beam definiteness subsequent discussions assume associated output selectron flipflop assemblage 40 flipflops term selectron register 46 47 48 49 5 arithmetic organ 51 section discuss features consider desirable arithmetic part machine give tentative conclusions arithmetic operations built machine pro grammed finally schematic arithmetic unit described discussion arithmetical organs computing machine one naturally led consideration number system adopted spite longstanding tradition 52 building digital machines decimal system feel strongly favor binary system device fundamental unit memory naturally adapted binary system since attempt measure gradations charge particular point selectron content distinguish two states flipflop truly binary device magnetic wires tapes acoustic delay line memories one also content recog nize presence absence pulse carrier frequency used pulse train sign pulse discuss ternary possibilities positiveornegative ornopulse system relationship questions reliability checking interesting possibilities carrier fre quency modulation hence one contemplates using decimal system either iconoscope delayline memory one forced binary coding decimal systemeach decimal digit represented least tetrad binary digits thus accuracy ten decimal digits requires least 40 binary digits true binary representation numbers however 33 digits suffice achieve precision lolo use binary system therefore somewhat economical equipment decimal main virtue binary system decimal however greater simplicity speed elementary operations performed illustrate consider multiplication repeated addition binary multiplication product particular digit multiplier multiplicand either multiplicand null according multiplier digit 1 0 decimal system however product ten possible values null nine times multiplicand inclusive course decimal number log2 03 times many digits binary number accuracy even multiplication decimal system considerably longer binary system one accelerate decimal multiplication complicating circuits fact irrelevant point made since binary multiplication likewise accelerated adding equipment similar remarks may made operations additional point deserves emphasis important part machine arithmetical logical nature logics yesno system fundamentally binary therefore binary arrangement arithmetical organs contributes significantly towards producing homogeneous machine better integrated efficient one disadvantage binary system human point view conversion problem since however completely known convert numbers one base chapter 4 1 preliminary discussion logical design electronic computing instrument 97 another since conversion effected solely use usual arithmetic processes reason computer carry conversion might argued time consuming operation however case cf 96 97 part 11 part i1 report issued title planning coding problems electronic computing instrument indeed generalpurpose computer used scientific research tool called upon great number multiplications upon relatively small amount input data hence time consumed decimal binary conversion trivial percentage total computing time similar remark applicable output data preceding discussion tacitly assumed de sirability introducing withdrawing data decimal system feel however base 10 may even permanent feature scientific instrument consequently probably attempt train use numbers base 2 8 16 reason bases 8 16 since 8 16 powers 2 conversion binary trivial since size 10 violate many habits less badly base 2 cf part 11 94 several digital computers built planned country england contain socalled ﬁfloating decimal pointﬂ mechanism expressing word characteristic mantissaeg 12345 would carried machine 01234503 3 exponent 10 associated number appear two major pur poses ﬁfloatingﬂ decimal point system arise fact number digits word constant fixed design considerations particular machine first purposes retain sum product many significant digits possible second free human operator burden estimating inserting prob lem ﬁscale factorsﬂmultiplicative constants serve keep numbers within limits machine course denying fact human time consumed arranging introduction suitable scale fac tors argue time consumed small percentage total time spend preparing inter esting problem machine first advantage floating point feel somewhat illusory order floating point one must waste memory capacity could otherwise used carrying digits per word would therefore seem 53 lsee bibliography goldstine von neumann 1963b 1963c 1963di references chapter report us clear whether modest advantages floating binary point offset loss memory capacity increased complexity arithmetic control circuits certainly problems within scope device really require 240 precision handle problems wish plan terms words whose lengths fixed integral multiple 40 program machine manner give corresponding aggregates 40 digit words proper treatment must consider addi tion multiplication complex operation programmed number primitive additions multiplications cf 9 part 11 would seem considerable extra difficulties way procedure instrument floating binary point reader may remark upon alternate spells radicalism conservatism deciding upon various possible features mechanism hope however agree closer inspection guided consistent sound principle judging merits idea wish incorporate machinein form circuitsonly logical concepts either necessary complete system highly con venient frequency occur influence exert relevant mathematical situations basis criterion definitely wish build machine circuits enable form binary sum two 40 digit numbers make decision addition logically basic notion rather would slow mechanism well operator enormously addition programmed simple operations ﬁandﬂ ﬁorﬂ ﬁnotﬂ true subtraction similarly reject desire form products programming additions detailed motivation much case addition subtraction cases division squarerooting much less clear well known reciprocal number formed desired accuracy iterative schemes one scheme consists improving estimate x forming x 2x ax2 thus new error 1 ux 1 ax square error preceding estimate notice formation x two bona fide multiplicationswe consider multiplication 2 true product since facility shifting right left one two pulse times somehow could guess la precision 25 6 multiplications3 iterationswould suffice give final result good 240 accordingly small table z4 entries could used get initial estimate la way reciprocal la 54 98 part 2 1 instructionset processor mainline computers section 1 processors one address per instruction could formed 6 multiplication times hence quotient ba 7 multiplication times accordingly see question building divider really function fast made operate compared iterative method sketched order justify existence divider must perform division good deal less 7 multiplication times however conceived divider much faster 7 multipli cation times therefore feel justified building especially since amount equipment needed requirements multiplier important course also possible handle square roots iterative techniques fact x estimate all2 x yzx ax better estimate see scheme involves one division per iteration seen detailed examination arithmetic organ include square rooter plans device would involve equipment feel desirable afirst model concerning iterative method squarerooting cf 810 part 11 first part arithmetic organ requires little dis cussion point parallel storage organ receive number add one already also able clear contents transmit contains call organ accumulator quite conventional principle past present computing machines varied types eg desk multipliers standard ibm counters modern relay machines eniac course numerous ways build binary accumulator distinguish two broad types devices static dynamic pulsetype accumulators discussed 511 first necessary make remarks concerning arith metic binary addition parallel accumulator first step addition add digit addend corre sponding digit augend second step perform carries must done sequence since carry may produce carry worst case 39 carries occur clearly inefficient allow 39 times much time second step performing carries first step adding digits hence either carries must accelerated use must made average number carries shall show sum binary words length n length largest carry sequence average excess 210g n let po designate probability carry sequence length u greater sum two binary words length n clearly po po 1 proba bility largest carry sequence length exactly weighted average 55 56 n 1 opn4 po 111 lo average length carry note ro since po 0 n easily inferred n 2 po ul proceed show pv 5 minl n 12l observe first indeed po probability sum two ndigit numbers contains carry sequence length 20 probability obtains adding probabilities two mutually exclusive alternatives first either n 1 first digits two numbers selves contain carry sequence length zo proba bility pg second n 1 first digits two numbers contain carry sequence length 20 case carry sequence length 20 total numbers length n must end last digits total sequence hence must form combination 1 1 next v 1 digits must propagate carry hence must form combination 1 0 0 1 combinations 1 1 0 0 propagate carry probability combination 1 1 x one alternative combinations 1 0 0 1 total probability sequence therefore y42 l remaining n digits must contain carry sequence length 20 probability 1 po thus probability second case l p2 combining two cases desired relation obtains observation pu 0 ii n trivial see help formulas proved pv pv always s1zvl hence sum chapter 4 preliminary discussion logical design electronic computing instrument 99 excess n l2v1 since n 1 terms sum since moreover po probability greater 1 hence finally turn question getting upper bound pv choose k 2k 5 n 5 ekl last expression clearly linear 1 interval 2k 5n52k1 k n zk k 1 n 2k1 ie z21og n ends interval since function 210g n everywhere concave follows expression s210g n throughout interval thus 5 210g n holds k ie n equality wanted prove case n 40 5 log40 53 ie average length 5 longest carry sequence actual value u4 462 discussed addition go subtraction convenient discuss point treatment negative numbers order right desirable make observations treatment numbers general numbers 40 digit aggregates leftmost digit sign digit digits genuine binary digits positional values 2l 2 239 going left right accumulator however treat sign digit binary digit positional value 2oat least functions adder numbers 0 1 clearly right leftmost digit 0 0 place taken represent sign number correctly expressed sign 39 binary digits let us consider one unrestricted 40 binary digit numbers accumulator add digitadding carrying mechanisms functioning normally identically 40 positions one reservation however carry originates leftmost position nowhere go positions left ﬁlostﬂ means course addend augend numbers 0 2 produced sum exceeding 2 accumulator unable express digit positional value 2l would necessary omitted 2 57 sum formed correctly excepting possible error 2 several additions performed succession ultimate error may integer multiple 2 accumulator adder allows errors integer multiples 2it adder modulo 2 noted convention placing binary point immediately right leftmost digit nothing structure adder order make point clearer proceed discuss possibilities positioning binary point somewhat detail begin enumerating 40 digits numbers words left right use index h 1 40 might placed binary point well digits j 1 0 40 note 0 corresponds position extreme left digit h 0 j 40 corresponds position extreme right position h 1 41 j 1 corresponds choice whatever choice j affect correctness accumulators addition equally true subtraction cf multiplication division cf 58 indeed merely multiplied numbers 2ii previous convention ﬁchange scaleﬂ effect addition subtraction however accumulator adder allows errors integer multiples 2i adder modulo 2j mention occasionally convenient think terms convention places binary point right end digital aggregate j 40 numbers integers accumulator adder modulo 24ﬂ must emphasize however ie attribu tions values j purely conventionle solely mathematicians interpretation functioning machine physical feature machine convention necessitate measures made effective actual physical features machineie convention become physical engineering reality come organs multiplication use convention 1 ie numbers lie 0 2 accumulator adds modulo 2 numbers 0 2 used represent numbers modulo 2 real number x agrees modulo 2 one one number x 0 20r quite precise 0 5 x 2 since addition functions modulo 2 see accumulator may used represent add numbers modulo 2 determines representation negative numbers x 0 find unique integer multiple 2 2s 100 part 2 instructionset processor mainline computers section 1 processors one address per instruction 1 2 0 5 2 f x 2s le 2s 5 x 21 represent x digitalization x way however sign digit character leftmost digit lost 0 1 x 2 0 x 0 hence 0 leftmost position longer associated sign x may seem bad deficiency system easy remedyat least extent suffices purposes done follows usually work numbers x 1or quite precise 1 x 1 x 0 5 x 2 differs x integer multiple 2 behaves follows x 2 0 0 x 1 hence x x 0 x 1 left digit x 0 x 0 1 x 0 hence z x 2 1 5 x 2 leftmost digit li 1 thus leftmost digit 3 precise equivalent sign x 0 corre sponds 1 summing accumulator may taken represent real numbers modulo 2 adds modulo 2 x lies 1 1 precisely 1 5 x 1as almost uses machinethen leftmost digit represents sign 0 1 consider negative number x 1 5 x 0 put x 0 1 digitalize x representing x 2 2 1 1 leftmost sign digit x 1 remaining 39 digits complement x 1x1 ie 1 thus led familiar representation negative numbers complementation connection digits x x easily formulated x 5 0 indeed x equivalent 2 x 21 239 39 io x 239 2 2i 239 digit index 1 39 related previous digit index h 1 40 h 1 actually best treat domain included additional value 0indeed 0 corresponds h 1 ie sign digit case expresses positional value digit refers simply h positional value 2i 2h1 note positioned binary point generally 1 discussed positional value would 2hj pointed previously j 1 hence digits obtain subtracting every digit x 1by complementing digit ie replacing 0 1 1 0and adding 1 rightmost position effecting carries may cause note leftmost digit interpreted sign digit gets inverted procedure subtraction x therefore performed accumulator ac follows form x digit 0 1 digit 1 0 respectively add 1 rightmost position last operation performed injecting carry rightmost stage acsince stage never receive carry source positions right light 57 multiplication requires special care entire modulo 2 procedure breaks indeed assume want compute product xy change one factors say x integer multiple 2 say 2 product x 2y obtains differs desired xy 2y 214 however general integer multiple 2 since general integer therefore begin discussion multiplication eliminating difficulties assume factors x lie 0 1 quite precise 0 5 x 1 effect multiplication first send multiplier x register ar arithmetic register essentially set 40 flipflops whose characteristics discussed place multiplicand selectron register sr cf 49 use accumulator ac form store partial prod ucts propose multiply entire multiplicand successive digits multiplier serial fashion course two possible ways done either start digit lowest positionposition 2390r highest positionposition 21and proceed successively left right respectively advantages point view starting rightmost digit multiplier therefore describe scheme multiplication takes place 39 steps correspond 39 nonsign digits multiplier x 0 el 39 0c2 9 enumerated backwards 39 assume k 1 first steps k 1 39 already taken place involving multiplication multiplicand k 1 last digits multiplier 39 kth step involving multiplication kth last digit 40k assume furthermore ac contains quantity p result k 1 first steps k 1st partial product k 1 clearly p 01 form 2p pkl 58 05yl1 ie chapter 4 preliminary discussion logical design electronic computing instrument 101 nothing add according whether 40k 0 1 form p halving 2p note addition 1 produces carry beyond 2 position ie sign digit 0 5 p 1 true h 0 true h k 1 1 extends h k also since 0 1 hence sum 1 20 2 carries beyond 2 position arise hence p obtains 2p simple right shift combined filling sign digit freed shift 0 right shift effected electronic shifter part ac thus process produces product xy desired note xy exact product x since x 39 digit binaries exact product xy 78 digit binary disregard sign digit throughout ever ac hold 39 clearly left 39 digits xy right 39 digits xy dropped ac one one course 39 steps specific 39 right shifts see later right 39 digits xy also conserved cf end section end 512 well 663 left 39 digits remain ac also rounded discuss matter cf loc cit 99 part 11 complete general picture multiplication tech nique must consider sense respective digits multiplier two schemes come ones mind connection one gate tube associated flipflop ar fashion gate open digit 1 closed null would need 39stage counter act switch would successively stimulate gate tubes react efficient scheme build ar shifter circuit enables ar shifted one stage right time ac shifted sense value digit right flipflop ar shifter requires one gate tube per stage need addition counter count 39 steps multiplication achieved six stage binary counter thus latter economical tubes one additional virtue point view discuss next paragraph choice 40 digits word including sign prob ably adequate computational problems situations certainly might arise desire higher precision ie words greater length trivial illustration would com putation places known 700 decimals ie 2300 binaries important instances solutions n linear equations n variables large values n extra precision becomes probably necessary n exceeds limit somewhere 20 40 justification estimate based detailed theory numerical matrix inversion given subsequent report therefore desirable able handle numbers 39k digits signs means program instructions one way achieve end use k words represent 39k digit number signs way 39 digits 40 digit word used sign digits excepting first one apparently wasted cf however treatment double precision numbers chapter 9 part 11 course necessary case instruct machine perform elementary operations arithmetic manner conforms interpretation kword com plexes single numbers cf 98910 part order able treat numbers manner desirable keep 39 digits product 78 discussed detail 663 accomplish end conserving 78 product digits connect via shifter circuit rightmost digit ac leftmost nonsign digit ar thus process multiplication shift ordered last digit ac transferred place ar made vacant multiplier shifted 59 conclude discussion multiplication posi tive numbers note described thus far multiplier forms 78 digit product xy 39 digit multipler x 39 digit multiplicand assumed x 2 0 2 0 therefore xy 2 0 depart assumptions 510 addition ever also assumed x l l ie x binary points immediately right sign digit implied xy one might question necessity additional assumptions prima facie may seem mere conventions affect mathematicians interpretation functioning chine physical feature machine cf cor responding situation addition subtraction 57 indeed r binary point digits 1 left cf discussion 57 dealing j also applies k k k 1 method multiplication would still give correct result xy provided 102 part 2 1 instructionset processor mainline computers section 1 1 processors one address per instruction position binary point xy appropriately assigned specifically let binary point xy digits 1 1 x binary point digits 1 sign digit 0 hence range 0 5 x 2il similarly range 0 5 ekl xy range 0 5 xy 2z1 ranges x imply range xy necessarily 0 xy 21l ekl 21k2 hcnce 1 k 1 thus might seem actual positioning binary pointimmediately right sign digit ie k 1is still mere convention therefore important realize choices k actually correspond real physical engi neering decisions reason follows desirable base running machine sole consistent mathe matical interpretation therefore desirable arithmeti cal operations performed identically conceived posi tioning binary point ac applying principle x gives k hence position binary point xy given j k 1 2j 1 x 21 1 1 ie 1 ensuesthat positioning binary point immediately right sign digit one possible escape place ac left 39 digits xy counting sign digit 0 digits 38 left indeed way position binary point xy 2j 1 j 1 j x procedure means drop left 1 right 40 digits xy hold middle 39 ac note posi tioning binary pointmeans x 2il 2il xy used xy 21l assumptions secure xy 2232 hence xy must 2jl times smaller might thing would secured vanishing left 1 digits drop ac shown wanted use procedure dropped left 1 digits really existing ie j 1 would make physical arrangements conservation elsewhere also general mathematical planning machine would definitely complicated due physical fact ac holds rather arbitrarily picked middle stretch 39 digits among 78 digits xy alternatively might fail make arrangements would necessitate see mathematical planning problem products turn 2il times smaller priori maxima observance impossible indeed similar things un avoidable operations example factor 2 addition positives subtraction opposite sign quanti ties cf also remarks first part 512 dealing keeping ﬁwithin rangeﬂ however involves loss significant digits choice 1 makes unnecessary multiplication therefore make choice 1 ie positioning binary point immediately right sign digit binding follows pass case multiplier x multiplicand may either sign ie combi nation signs would simply extend method 58 include sign digits x also indeed assume 1 5 x 1 1 1 multiplication procedure question defi nitely based 20 interpretations x hence x 0 really using x 2 0 really using 2 hence x 0 2 0 forms 510 x 2y xy 2y x 2 0 0 forms xy 2 xy 2x x 2y 2 xy 2x 2y 4 x 0 x 0 forms since things may taken modulo 2 xy 21 214 hence correction terms 2y 2x would needed x 0 0 respectively either would possible procedure one difficulty xy formed 39 digits multiplier x gradually lost ar replaced right 39 digits xy cf discussion end 58 unless willing build additional 40 stage register hold x therefore x available end multiplication hence use correction 2x xy becomes necessary 0 thus case x 0 handled along lines case 0 nevertheless possible develop adequate procedure proceed throughout procedure maintain assumptions 1 5 x 1 1 5 1 proceed several successive steps first assume corrections necessitated possi bility 0 taken care permit therefore 0 consider corrections necessitated possi bility x 0 let us disregard sign digit x 1 ie replace 0 x goes x x 1 1 x 0 actually behave like x 1 2 x 1 hence multiplication procedure produce xy x ly xy chapter 4 preliminary discussion logical design electronic computing instrument 103 therefore correction needed end note use sign digit x conventional way done correction 2y would necessary seen see therefore consider x 5 0 perform first necessary steps forming xyy 5 0 without yet reaching sign digit x ie treating x 20 time arrives digit x become effectivele immediately became effective 39 shifts cf discussion near end 58at time ac contains say jzl corresponds p 58 form xy note difference last step forming p 39 preceding steps 58 forming p p p39 second disposed possibility x 0 may assume x 2 0 assumption treat 0 since 2 0 brings us back entirely familiar case 58 need consider case 0 let number obtains disregarding sign digit 1 ie replacing 0 acts like 1 like 1 2 1 hence multiplication procedure 58 produce xy xy 1 xy x fore correction x needed note quite similarly saw first case suppression sign digit replaced previously recognized correction 2x present one x observed earlier correction x applied end completed xy since time x longer available hence must apply correction x digitwise subtracting every digit time last found ar way makes effective proper posi tional value third consider x 0 tl t39 e1 t2 t3j 39 digits c1 t39 x lost course 39 shifts multiplication procedure 58 going right left thus operation k 1 k 0 1 38 cf 58 finds t39k rightmost stage ar uses loses concluding right shift ac ar step 39 k 1 38 k steps ie shifts follow hence concluding shift still 39 k shifts come hence positional values 23yk times higher end 39k appear end correcting term x sign positional value 239k3 hence may inject step k 1 shift sign positional value 1 say t3k sign digit however inadmissible indeed 39k might cause carries t39k l would nowhere go sign digit positions left error origin integer multiple 2 39 k subsequent shifts reduce positional value 239k times hence might contribute end result integer multiple 238kjand genuine error let us therefore add 1 sign digit ie 0 1 k 1 0 respectively show procedure arise carries inadmissible kind taking momentarily granted let us see total effect correcting x czl 2i x 1 x hence final correction 1 239 needed since done end shifts may taken modulo 2 say must add 1 239 ie 1 two extreme positions adding 1 rightmost position effect discussion end 57 dealing subtraction equivalent injecting carry rightmost stage ac adding 1 leftmost position ie sign digit produces 1 since digit necessarily 0 indeed last operation ended shift thus freeing sign digit cf fourth let us consider question carries may arise 39 steps process described order let us describe kth step k 1 39 variant kth step described positive multiplication 58 way described original kth step loc cit say let us see formula 1 58 become clearly 2p p 1 40k t4y ie add 1 ys sign digit without sign digit according whether 4nk 0 1 p obtain 2p halving addition 2 produces carries beyond 2 position asserted earlier reason addition 1 58 argue way 0 5 p 1 true h 0 true h k 1 1 extends h k also since 0 5 5 1 hence sum 2 20 2 carries beyond 2 position arise fifth three last observations assumed 0 let us restore full generality 5 0 describe 104 part 2 1 instructionset processor mainline computers section 1 1 processors one address per instruction equations 1 58 valid 2 0 2 valid 0 single formula 2pk pk1 yp 3 ys sign digit 540k 0 without sign digit 540k 1 yl thus verbal formulation 2 applies add ys sign digit without sign according whether 40k 0 1 pk 20 1 addition 3 never originates carry beyond 2o position pk obtains 2p right shift filling sign digit 0 cf however part 11 table 2 another sort right shift desirable explicit form ie order 2 0 xy p 0 xy obtains p injecting carry rightmost stage ac placing 1 sign digit ac sixth procedure applies x 2 0 x 0 also applied since makes use xs nonsign digits end must subtracted result method binary multiplication illustrated examples 515 511 complete discussion multiplicative organs machine must return consideration types accumulators mentioned 55 static accumulator operates adder simultaneously applying static voltages two inputsone two numbers added steadystate operation reached total sum formed complete carries accumulator discussion substantially complete except remarked circuit requires 39 rise times complete carry actually possible duration successive rises proportional lower power 39 first one stage dynamic accumulator consists binary counter registering digit flipflop temporary storage carry counter receives pulse 1 added place causes counter go 1 0 carry occurred hence carry flipflop set remains perform carries flipflop associated gate output connected next binary counter left carry begun pulsing carry gates carry may produce carry process needs repeated carry flipflops register 0 detected means circuit involving sensing tube con nected carry flipflop shown 56 average five pulse times flipflop reaction times required complete carry alternative scheme connect gate tube binary counter detect whether incom ing carry pulse would produce carry cir cumstance pass incoming carry pulse directly next stage circuit would require 39 rise times completion carry actually less cf present time development static accumulator concluded preliminary tests seems add two numbers 5 psec shift right left 1 psec return multiplication operation static accumulator order simultaneously addition multi plicand sign deleted sign multiplicand cf 510 complete carry shift 39 steps dynamic accumulator second kind described order succession addition multiplicand sign deleted sign multiplicand complete carry shift 39 steps dynamic accumulator first kind avoid losing time required completing carry case average 5 pulse times cf 39 steps order addition multiplicand sign deleted sign multiplicand order one pulsing carry gates finally shift contents digit counters carry flipflops process repeated 39 times simple arithmetical analysis may carried later report shows one intermediate stages single carry adequate complete set carries needed end carry complement corrections still without ever ordering complete set carry operations corrections completed roundoff described order complete carry mentioned desirable point discussion consider rules roundingoff ndigits order assess charac teristics alternative possibilities properly par ticular role concept ﬁunbiasednessﬂ necessary visualize conditions roundingoff needed every number x appears computing machine approximation another number x would appeared calculation performed absolutely rigorously approximations refer caused explicitly introduced approximations numeri calmathematical setup eg replacement continuous differential equation discrete difference equation effect approximations evaluated mathematically person plans problem machine direct concern machine indeed handled 512 chapter 4 preliminary discussion logical design electronic computing instrument 105 mathematician handled machine since nature complexity difficulty may kind depend ing upon problem consideration approximations concern us even elementary operations arithmetic mathematical approximationformula tion machine reduce true possibly transcenden tal problem rigorously executed machine machine deals numbers n digits n matter large fixed quantity assumed machine 40 digits including sign ie n 39 sum differ ence two ndigit numbers ndigit numbers product quotient general general 2n wdigits respectively consequently multiplication division must unavoidably replaced machine two different operations must produce ndigits condi tions subject limitation lie close possible results true multiplication division one might call pseudomultiplication pseudodivision ever accepted nomenclature terms multiplication division roundoff creating impression addition subtraction entirely free shortcomings true inasmuch create new digits right multiplication division however create new digits left ie cause numbers ﬁgrow rangeﬂ complication course well known normally met planner mathematical arrangements estimates keep numbers ﬁwithin rangeﬂ since propose machine deal numbers 1 1 multiplication never cause ﬁgrow rangeﬂ division course might cause complication plan ner must therefore see every division absolute value divisor exceeds dividend thus roundoff intended produce satisfactory ndigit approximations product xy quotient xy two ndigit numbers two things wanted roundoff 1 approximation good ie variance ﬁtrueﬂ xy xy small practicable 2 approximation unbiased ie mean equal ﬁtrueﬂ xy xy desiderata must however considered conjunction comments specifically x likely results similar roundoffs directly directly inherent ie x viewed unbiased ndigit approximations ﬁtrueﬂ x values b talking ﬁvariancesﬂ ﬁmeansﬂ introducing statistical concepts approximations considering really statistical nature due peculiarities point view inadequacies arithmetic digital representation therefore actually rigorously uniquely determined seems however present state mathe matical science rather hopeless try deal matters rigorously furthermore certain statistical approach truly justified always given adequate practical results consists treating digits one wish use individually subsequent calculations random variables equiprobable digital values treating two digits statistically independent unless patently false things understood undertake dis cuss roundoff procedures realizing apply multiplication division let x t1 ql q unbiased approxi mations x ﬁtrueﬂ xy tl t2 ﬁtrueﬂ xy a1 www goes ad infinitum approximations xy xy discuss round must know whether ﬁtrueﬂ xy xy unbiased approximations xy xy xy indeed unbiased approximation xy ie mean xy mean x x times mean owing independence assumption made however x closely correlated eg x ie squaring bias order mean square x x ie variance x since x n digits variance 122n digits x beyond n entirely unknown original assumptions give variance 11222n next xy written xyl since already discussed bias product suffices consider reciprocal unbiased estimate yl unbiased estimate ie mean ys reciprocal reciprocal ys mean difference times variance ie essentially order bias found case squaring follows futile attempt avoid biases order magnitude 122n less factor y12 may seem changing order magnitude question however really square root variance matters dy12 03 moderate factor since propose use n 39 therefore 12783 x critical case note possible bias level l23y2 x 1012 times last significant digit hence look roundoff rules n digits ﬁtrueﬂ xy tl tl t2 xy wl www desideratum 1 formulated previously variance small still valid 106 part 2 instructionset processor mainline computers section 1 processors one address per instruction desideratum 2 however bias zero need according enforced terms order roundoff procedures use connection fall two broad classes first class characterized ignoring digits beyond nth even nth digit replaces 1 second class characterized procedure adding one unit n 1st digit performing carries may induce keeping n first digits applied number form vl vvu ad infinitum effects either procedure easily estimated first case may say dealing vl u plus random number form ovv ie random interval 0 12 comparing rounded v1v2 zl therefore difference random interval l2 12 hence mean 0 variance y3 22n second case dealing vl v plus random number form 00v ie random interval 0 12 ﬁroundedoffﬂ value v v creased 0 12 according whether random number question lies interval 0 12 interval 12l 12 hence comparing ﬁroundedoffﬂ value difference random intervals 0 12 0 12l ie interval 12l 12 hence mean 0 variance y1222n number roundedoff form vl vvv v p finite results somewhat affected order magnitude variance remains indeed large p even relative change negligible mean difference may deviate 0 amounts easily esti mated order 12 12p 12ﬂp division first situation xy wl www ie p infinite multiplication second one xy nnl ie p n hence division methods applicable without modification multiplication bias order 122n may introduced seen pointless insist removing biases size therefore use unmodified methods case noted bias case multiplication removed various ways however reasons set forth shall complicate machine introducing corrections thus two standard ﬁroundoff ﬂ methods unbiased extent need variances 122 13 22n 1222n dispersions 1312 058 times last digit 12312 029 times last digit first one requires carry facilities second one requires inasmuch propose form product xy accu mulator carry facilities reason adopt rounding scheme described smaller dispersion ie one may induce carries case however division wish avoid schemes leading carries since expect form quotient arithmetic register permit carry operations scheme accordingly adopt one w replaced 1 method decided advantage enables us write approximate quotient soon know first n 1 digits seen 514 664 procedure forming quotient two numbers always lead result correctly rounded accordance decisions made consider serious fact rounding scheme case division dispersion twice large multiplication since division far less frequent operation final remark made connection possible occasional need carrying n 39 digits logical control sufficiently flexible permit treating k 2 3 words one number thus effecting n 3 case roundoff handled differently cf chapter 9 part 11 multiplier produces 78 digits basic 39 39 digit multi plication first 39 ac last 39 ar must manipulated appropriate manner details cf 663 99910 part 11 divider works 39 digits forming xy necessary even x available 39k digits use 39 digits 39 digit result appear seems convenient use result first step series successive approximations successive improve ments obtained various means one way consists using well known iteration formula cf 54 k 2 one step needed k 3 4 two steps k 5 6 7 8 three steps etc alternative procedure calculate remainder using approximate 39 digit quotient complete 39k digit divisor dividend divide approximate 39 digit divisor thus obtaining essentially next 39 digits quotient repeat procedure full 39k desired digits quotient obtained might mention time complication arises floating binary point introduced machine operation addition usually takes ylo 513 chapter 4 preliminary discussion logical design electronic computing instrument 107 multiplication time becomes much longer machine floating binary since one must perform shifts roundoffs well additions would seem reasonable case place time addition y3 z multiplication rate clear number additions problem important factor total solution time number multiplications details concerning floating binary point cf 667 conclude discussion arithmetic unit description method handling division operation perform division wish store dividend sr partial remainder ac partial quotient ar proceeding let us consider socalled restoring nonrestoring methods division order able make certain comparisons general base 2 3 assume moment divisor dividend positive ordinary process division consists subtracting partial remainder beginning process course dividend divisor repeating former becomes smaller latter fixed positional value quotient wellconducted division need done 1 times precisely k 01 1 repetitions step partial remainder indeed become less divisor digit k put quotient position consideration partial remainder shifted one place left whole process repeated next position etc note comparison sizes needed k 0 1 2 ie step 1 steps 1 2 value k 1 le point step reached wellconducted division may taken granted without test partial remainder become smaller divisor operations position consideration therefore concluded binary system 2 thus one step one comparison sizes step way scheme known restoring scheme requires maximum 1 com parisons utilizes digits 0 1 1 place quotient difficulty scheme machine purposes usually economical method comparing two numbers size subtract one partial remainder r less dividend one would add back r order restore remainder thus every stage unnecessary operation would performed sym metrical scheme obtained restoring method need assume positivity divisor dividend 514 one compares signs rn sign dividend repeatedly subtracted remainder signs become opposite opposite dividend repeatedly added remainder signs become like scheme digits may occur given place quotient evidently kl k2 km l posi tive digits corresponding subtractions negative ones additions dividend remainder thus 2m 1 digits instead usual digits decimal system would mean 18 digits instead 10 redundant notation standard form quotient must therefore restored subtracting aggregate positive digits aggregate negative digits requires carry facilities place quotient stored propose store quotient ar carry facilities hence could use scheme operate decimal system objection applies base digital representation question redundantie 2m 1 2m 1 whenever 2 2m 1 2 hence use register far contemplated division scheme certainly excluded start unless binary system used let us investigate situation binary system inquire possible obtain quasiquotient using nonrestoring scheme using digits 1 0 instead 1 1 rather ask question quasi quotient bear simple relationship true quotient let us momentarily assume question answered affirmatively describe division procedure store divisor initially ac dividend sr wish form quotient ar either add subtract contents sr ac according whether signs ac sr opposite insert correspondingly 0 1 righthand place ar shift ac ar one place left electronic shifters parts two aggregates point interrupt discussion note multipli cation required ability shift right inboth ac ar cf 58 found division similarly requires ability shift left ac ar hence organs must able shift ways electronically since abilities present implicit needs multiplication division well make use explicitly form explicit orders orders 2021 table 1 table 2 part 11 however turn convenient arrange details shifts occur explicitly control orders 108 pari 2 instructionset processor mainline computers section 1 processors one address per instruction differently occur implicitly control multiplication division things cf discussion shifts near end 58 third remark one hand third remark 72 part 11 hand let us resume discussion division process described repeated many times number quotient digits consider appropriate produce way likely 39 40 determine exact number process formed digits 0 1 quotient digit actually ti 1 1 5 2 1 thus difference true quotient z based digits ti quasiquotient z based digits ti time onetoone connection would easy establish algebraical expression connection z z directly seems better part discussion clarifies questions connected process division time first make general remarks first let x dividend divisor assume course 1 x 1 1 5 1 found pres ent process division entirely unaffected signs x hence restrictions score required hand quotient z xy must also fulfil 1 5 z 1 seems somewhat simpler although means necessary exclude purposes discussion z 1 demand z 1 means terms dividend x divisor exclude x assume second division takes place n steps correspond n digits ti pseudoquotient z n yet determined presumably 39 40 assume k 1 first steps k 1 n already taken place produced k 1 first digits ti ekl kth step involving production kth digit assume furthermore ac contains quantity rkl result k 1 first steps k 1st partial remainder k 1 clearly r x form rk 2rk1 7 accord ing whether signs rkl agree ie rk 2rkby signs rkl agree signs rk agree 1x1 let us see carries may originate procedure argue follows lrhl yl true h 0 irl x true h k 1 4 extends h k also since rkl 0 opposite signs last point may elaborated little opposite signs hence always rk 1 therefore afortiori rk 1 ie 1 rk 1 consequently equation 4 one summand necessarily 2 2 21 1 sum 1 l hence may carry operations 4 modulo 2 disregarding possibilities carries beyond 2o position resulting rk automatically correct range 1 1 third note however sign rkl plays important role 4 correctly determinable sign digit number derived 2 1 l cf discussion 57 requirement however met saw rkl necessarily 2rkpi hence sign rkl le sign digit required 4 must sensed rkl doubled understood doubling rkl may performed simple left shift leftmost digit sign digit allowed lostthis corresponds disregarding carries beyond 2o position recognized permissible 4 cf however part 11 table 2 another sort left shift desirable explicit form ie order fourth consider precise implication 4 5 1 0 corresponds le respectively hence 4 may written rk 2rk1 1 2ty ie lrkl 2k 2k1 2kr 2k ky k summing k 1 n gives ie makes clear z 1 2 corre sponds true quotient z xy 2rn absolute value 2 5 2 remainder hence disregard term 1 moment 1 n 1 first digits may used true quotient sign digit part sequence chapter 4 1 preliminary discussion logical design electronic computing instrument 109 fifth wish get involved complicated roundoff procedures exceed immediate capacity available adder ac result suggests put n 1 40 n 39 ti ti9 39 digits quotient including sign digit including rightmost digit rightmost digit taken care placing 1 rightmost stage ac point additional argument favor procedure adopted becomes apparent procedure coincides without need corrections second roundoff procedure discussed 512 remains term 1 since applies final result right shifts follow carries might go beyond 2o position may disregarded hence amounts simply changing sign digit quotient 3 replacing 0 1 1 0 respectively concludes discussion division scheme wish however reemphasize two distinctive features possesses first division scheme applies equally combina tions signs divisor dividend characteristic nonrestoring division schemes case simple known multiplication scheme remembered particular multiplication procedure 59 contain special correcting steps cases either factors negative second division scheme practicable binary sys tem analog base method binary division illustrated examples 515 515 give illustrative examples opera tions binary arithmetic discussed preceding sections although presented difficulties ambiguities seems best begin example addition binary notation decimal notation fractional form augend 0010110011 1795 12 addend 0011010111 215512 sum 0110001010 394512 carries 1111 111 follows show carnes form negative number cf 5 7 complement binary notation 0101 110100 1010001011 1 subtraction cf 57 101000 1 100 binary notation subtrahend 0011010111 minuend 0110001010 decimal notation fractional form 372512 1 140512 decimal notation fractional form 21 551 2 3945 12 complement subtrahend 11001 01000 1 297512 difference 00101 1001 1 179512 110 pari 2 instructionset processor mainline computers multiplications cf 58 59 binary notation mu pl icand multiplier 0011 0101 section 1 processors one address per instruction decimal notation fractional form 58 38 0101 0101 0 product 0001111 binary notation mu pl icand 1101 multiplier 1011 0101 0101 1 101111 correction lt 11 11 10111 correction 2 complement multiplicand 0010 1 0001 11 1 division cf 514 binary notation divisor 1011000 dividend 0001111 0011110 1011000 11 101 10 1101 100 0100111 1 0010100 0101000 101 1000 0000000 0000000 1011000 1011000 0110000 01001 11 1 101 1000 quotient uncorrected 0 10011 ﬂ corrected 1100111 qd3 0 1 1564 decimal notation fractional form 38 58 decimal notation fractional form 1564 58 1 1 3964 2564 sign multiplicand sign multiplier 5 quotient digit chapter 4 preliminary discussion logical design electronic computing instrument 111 note deviates yg4 ie one unit rightmost position correct result consequence roundoff rule forces rightmost digit 1 conditions occasionally produces results unfamiliar even annoying aspects eg quotients like 0y yy formed nevertheless unobjectionable self consistent basis general principles 6 control 61 already stated computer contain organ called control automatically execute orders stored selectrons actually reason stated 63 orders computer less half long forty binary digit number hence orders stored selectron memory pairs let us consider routine control performs direct ing computation control must know location selectron memory pair orders executed must direct selectrons transmit pair orders selectron register must direct execution operation specified first two orders among orders immediately describe two major types order first type begins causing transfer number stored specified memory location selectrons selectron register next causes arithmetical unit perform arithmetical operations number usually conjunction another number already arith metical unit retain resulting number arith metical unit second type order causes transfer number held arithmetical unit selectron register specified memory location selectrons may also latter operation permit direct transfer arithmetical unit selectrons additional type order consists transfer orders 35 orders control inputs outputs machine process described beginning paragraph must repeated second order order pair entire routine repeated end problem clear stated control must means switching specified location selectron memory withdrawing numbers compu tation pairs orders since selectron memory tenta tively planned hold 212 4096 fortydigit words word either number pair orders twelvedigit binary number suffices identify memory location hence switching mecha 62 nism required receiving twelvedigit binary number select corresponding memory location type circuit propose use purpose known decoding manyone function table developed various forms independently j rajchman rajchman 19431 p crawford crawford consists n flipflops register ndigit binary number also maximum 2n output wires flipflops activate matrix inter connections input output wires made way one one 2 output wires selected le positive voltage applied interconnections may established means resistors means nonlinear ele ments diodes rectifiers various methods investigation selectron designed four function table switches required three digit entry eight 23 outputs four sets eight wires brought selectron switching purposes particular loca tion selected making one wire positive respect remainder since forty selectrons switched parallel four sets wires may connected directly four function table outputs since computer operations involve least one number located selectron memory reasonable adopt code twelve binary digits every order assigned specification selectron location orders require number taken selectrons digit positions used though definitely decided many operations built computer le many different orders control must able understand seen presently probably z5 certainly less 26 reason feasible assign 6 binary digits order code thus turns order must contain eighteen binary digits first twelve identifying memory location remaining six specifying operation explained orders stored memory pairs since memory organ used computer orders numbers efficient make length equivalent numbers eighteen binary digits would sufficiently accurate problems machine solve rather accuracy least 2f3 required hence preferable make numbers long enough accommodate two orders pointed 23 used 42 et seq 57 et seq numbers actually 40 binary digits allows 20 binary digits order ie 12 digits specify memory location 8 digits specifying nature 63 112 part 2 instructionset processor mainline computers section 1 processors one address per instruction operation instead minimum 6 referred convenient seen 682 chapter 9 part 11 group binary digits tetrads groups 4 binary digits hence whole word consists 10 tetrads half word order 5 tetrads 3 specify memory location remaining 2 specify nature operation outside machine tetrad expressed base 16 digit base 16 digits best designated symbols 10 decimal digits 0 9 6 additional symbols eg letters f cf chapter 9 part 11 16 characters appear typing printing machine details arrangements cf zoc cit specification nature operation involved order occurs binary form another manyone decoding function required decode order function table six input flipflops two remaining digits order needed since 64 different orders 64 outputs need provided however perhaps worthwhile connect outputs corresponding unused order possibilities checking circuit give indication whenever code word unintelligible control received input flipflops function table described energizes different output wire different code operation shown later many steps involved executing different orders overlap example addition multiplication division going selectrons register include transferring number selectrons selectron register reason perhaps desirable additional set control wires activated particular combination different code digits may obtained taking output wires manyone function table using operate tubes turn operate onemany coding function table function table consists matrix case one input wires activated particular table may referred recoding function table twelve flipflops operating four function tables used selecting selectron position six flipflops operating function table used decoding order referred function table register fr let us consider next process transferring pair orders selectrons control orders first go sr order used next may transferred directly fr second order pair must removed sr since sr may used first order executed yet placed fr hence temporary storage 64 provided storage means called control register cr consists 20 possibly 18 flipflops capable ceiving number sr transmitting number fr already stated til control must know location pair orders get selectron memory normally location one following location two orders executed receives order otherwise control take orders selectrons sequence hence order location may remembered twelve stage binary counter one capable counting 212 one unit added whenever pair orders executed counter called control counter cc details process obtaining pair orders selectron thus follows contents cc copied fr proper selectron location selected contents selectrons transferred sr fr cleared contents sr transferred cr cc advanced one unit control prepared select next pair orders memory however exception last rule socalled transfer orders cf 35 may feed cc different manner cf next paragraph first order fr executed order cr transferred fr executed noted operations directed control itselfnot operations specified control words sent fr also automatic operations required get correct orders since method means control takes order pairs sequence memory described remains consider control shifts one sequence control orders another accordance operations described 35 execution operations relatively simple order calling one operations contains twelve digit specification position control switched digits appear lefthand twelve flipflops fr required shift control transfer contents flipflops cc control goes selectrons next pair orders go location specified number transferred case unconditional transfer transfer made automatically case conditional transfer made sign counter accumulator registers zero report discuss general method means control execute specific orders leaving details later already explained 55 circuit designed accomplish particular elementary operation addition choice must made 65 chapter 4 preliminary discussion logical design electronic computing instrument 113 static type dynamic type circuit design control considered choice arises function control direct sequence operations take place various circuits computer including circuits control consider involved directing operation control must signal operation begin must supply whatever signals required specify particular operation must way know operation completed may start succeeding operation hence control circuits must capable timing operations noted timing required whether circuit per forming operation static dynamic case static type circuit control must supply static control signals period time sufficient allow output voltages reach steadystate condition case dynamic type circuit control must send various pulses proper intervals circuit circuits computer static character control timing circuits may likewise static pulses needed system however though circuits com puter planning static probably hence pulses well static signals must supplied control rest computer many advan tages deriving pulses central source called clock timing may done either means counters counting clock pulses means electrical delay lines rc circuit regarded simple delay line since timing entire computer governed single pulse source computer circuits said operate synchronized system clock plays important role detecting localizing errors made computer one method check ing consideration two identical computers operate parallel automatically compare others results machines would controlled clock would operate absolute synchronism necessary compare every flipflop one machine corresponding flipflop since numbers control words pass either selectron register accumu lator soon soon used suffices check flipflops selectron register flipflops accumulator hold number registered fact seems possible check accumulator cf end 662 checking circuit would stop clock whenever difference appeared stop machine direct manner asynchronous system used every flipflop computer located convenient place fact neons located one panel corresponding neons two machines placed parallel rows one tell glance machine stopped discrepancies merits checking system must weighed cost building two machines may appear expensive since cost scientific computer lies development rather production consideration important might seem experience may show problems two machines need operated parallel indeed cases purely mathematical external checks possible smooth ness results behavior differences various types validity suitable identities redundant calculations etc methods usually adequate disclose presence absence error toto drawback may allow detailed diagnosing locating errors ease problem run first time requires special care error known present locatedonly necessary rule use machines parallel thus used separate machines time essential feature method check ing lies fact checks computation every point hence detects transient errors well steadystate ones stops machine error occurs process localizing fault greatly simplified advantages partially gained duplicating arithmetic part computer following one operation complement operation multiplication division etc since fails check either memory control complicated though largest part machine method localizing errors either without dupli cate machine needs discussion planned design circuits including control computer clock stopped pulses computer retain information flipflops computation may proceed unaltered clock started principle already demonstrated usefulness eniac makes possible machine compute clock operating speed certain maximum long clock gives pulses constant shape regardless spacing pulses particular spacing pulses may made indefinitely large clock provided mode operation emit single pulse whenever instructed operator 13y means operator cause machine go operation step step checking results means indicatinglamps connected flipflops noted design principle exclude use delay lines obtain delays long 114 part 2 instructionset processor mainline computers section 1 processors one address per instruction used time constituent operations single step part determining machines operating repeti tion rate timing coincidences means delay lines excluded since requires constant pulse rate orders control understands may divided two groups specify operations per formed within computer specify operations involved getting data computer present time internal operations completely planned input output operations hence discussed detail latter treated briefly 68 internal operations tentatively adopted listed table 1 already pointed operations logically basic many programmed means others case operations reasons building control already given section give reasons building operations control explain case operation control must order exe cute order precise mathematical meaning symbols introduced follows clearly mind reader consult table end report new symbol addition explanations given text throughout follows sx denote memory location x selectron accordingly x appears sx 12digit binary sense 62 eight addition operations sx ac sx ac sx ah sxt ah involves following possible four steps 66 661 sx ac sx ac sx ah sx ah mi first clear sr transfer number sx second clear ac order contains symbol c clear ac order contains symbol h third add number sr negative le present system complement respect 2l ac order contain symbol use number sr negative according whether order contains symbol order contains symbol use number sr negative according whether sign number sr symbol order agree fourth perform complete carry building last four addi tion operations containing symbol control fairly simple calls one extra comparison sign sr order cf third step requires therefore tubes required first four addition operations containing symbol facts would seem justify adding opera tions question plus minus absolute value noted operations programmed operations table 1 correspondingly orders three absolute value five minus absolute value justification building required absolute value order frequently connection orders l r see 667 minus absolute value order makes detec tion zero simple merely detecting sign j nj jni 2 0 n 0 operation sx r involves following two steps 662 first clear sr transfer sx second clear ar add number selectron register operation r ac merits detailed discussion since alternative ways removing numbers ar numbers could taken directly selectrons well ac could transferred ac parallel sequence sequence parallel recalled numbers go ar come selec trons thus need returned result division righthand 39 digits product appear ar hence operation withdrawing number ar required relatively infrequent therefore need particularly fast therefore considering possibility transferring least partially sequence using shifting properties ac ar transferring number selectron via accumulator also desirable dual machine method checking employed means even numbers checked transit accumu lator nevertheless every number going selectron checked placed 663 operation sx x r f ac involves following six steps first clear sr transfer sx multiplicand second thirtynine steps consist two following parts add rather shift sign digit sr partial product ac add sign digit sr partial product acdepending upon whether rightmost digit ar 0 1and effect appropriate carries b shift ac ar right fill sign digit ac 0 digit ar immediately right sign digit positional value 2l previously rightmost digit ac ways save time merging two operations rightmost digit ar 0 discuss fully third sign digit sr 1 le inject carry chapter 4 preliminary discussion logical design electronic computing instrument 115 rightmost stage ac place 1 sign digit ac fourth original sign digit ar 1 le sub tract contents sr ac fifth partial carry system employed main process complete carry necessary end sixth appropriate roundoff must effected cf chapter 9 part 11 details also explained sign digit arithmetic register treated part roundoff process noted since number held ac begin ning process gradually shifted ar impossible accumulate sums products ac without storing various products temporarily selectrons undoubtedly disadvantage eliminated without constructing extra register moment seem worthwhile hand saving righthand 39 digits answer accomplished little extra equipment since means connecting 239 stage ac 21 stage ar shift operation advantage saving digits simplifies handling numbers number digits computer cf last part 512 number 39k binary digits k integer sign divided k parts part placed separate selectron position addition subtraction numbers may programmed series additions subtractions 39digit parts carry programmed means cc sx cc sx operations 2 stage ac registers negative addi tion two 39digit parts carryover taken place hence 239 must added sum next parts similar proce dure may followed multiplication 78 digits product two 39digit parts kept planned details cf chapter 9 part 11 since would greatly complicate computer make provision holding using 78 digit dividend planned program 39k digit division one ways described end 512 operation division ac sx r involves following four steps 664 first clear sr transfer sx divisor second clear ar third thirtynine steps consists following three parts sense signs contents ac partial remainder sr sense whether agree b shift ac ar left process previous sign digit ac lost fill rightmost digit ac shift 0 rightmost digit ar shift 0 1 depending whether disagreement agreement c add subtract contents sr ac depending alternative fourth fill rightmost digit ar 1 change sign digit purpose timing 39 steps involved division sixstage counter capable counting 26 64 built control counter also used timing 39 steps multiplication possibly controlling ac number transferred tape either direction see 68 three substitution operations sx ap sx ap sx involve transferring part number held ac selectrons done means gate tubes connected registering flipflops ac forty tubes needed total substitutions sx partial substitu tion ap sx ap sx requires lefthand twelve digits number held ac substituted proper places lefthand righthand orders respectively may done means extra gate tubes shifting number ac using gate tubes required sx scheme needs additional elaboration order directing order suffering substitution two successive halves word ie latter already fr time former becomes operative cr substitution effected selectrons comes late alter order already reached cr become operative next step fr various ways take care complication either additional equipment appropriate prescriptions coding discuss detail since decisions respect still open importance partial substitution operations hardly overestimated already pointed 33 allow computer perform operations could wise conveniently perform making use function table stored selectron memory furthermore operations remove sizeable burden person coding problems make possible coding classes problems contrast coding individual problem separately ap sx ap sx available program sequence may stated general form without selectron location designations numbers operated selectron locations numbers operated substituted whenever se quence used example consider general code nth order integration total differential equations p steps independent variable formulated advance whenever prob 665 116 part 2 instructionset processor mainline computers section 1 processors one address per instruction lem requiring rule coded computer general integration sequence inserted statement problem along coded instructions telling sequence located memory proper sx designations inserted orders cu sx etc whenever sequence used computer automatically substitute correct values n p well locations boundary conditions descrip tions differential equations general sequence details particular procedure cf chapter 13 part 11 library general sequences built facilities provided convenient insertion coded statement problem cf 684 scheme used distinctive features problem need coded manner control shift operations cu sx cu sx cc sx cc sx realized discussed 64 needs comment one basic question must decided computer built whether machine socalled floating binary decimal point floating binary point undoubtedly convenient coding problems building computer adds greatly complexity hence choice matter receive careful attention ever first noted alternatives ordinarily con sidered building machine floating binary point vs computation fixed binary point exhaustive hence arguments generally advanced floating binary point limited validity arguments overlook fact choice respect particular operation except certain basic ones building computer using rather building computer programming operations built computer one short reference floating binary point made 513 building floating binary point computer complicate control also increase length num ber hence increase size memory arithmetic unit every number effectively increased size even though floating binary point needed many instances considerable redundancy floating binary point type notation number carries scale factor generally speaking single scale factor suffice possibly extensive set numbers means operations already described report floating binary point programmed additional memory capacity needed probably less required builtin floating binary 666 667 point since different scale factor need remembered number program floating binary point involves detecting first zero occurs number ac since ac shifting facilities best done means terms operations previously described would require taking given number ac performing suitable arithmetical operation multiple right shift multiplication multiple left shift either one division many doublings le additions shift stages however operations inconvenient timeconsuming propose introduce two operations l r order ie single left right shift accomplished directly operations make use facili ties already present ac hence add little equipment computer noted many instances single use l possibly r suffice programming floating binary point two factors multiplication superfluous zeros product one superfluous zero z 1 y4 5 xy 1 similarly true division 4 5 x y2 y2 _i 1 y4 xy 1 addition subtraction numbers growing range treated similarly numbers decrease cases ie develop sequence zeros beginning really mathematically losing precision hence perfectly proper omit formal readjustments event indeed true loss precision obviated formal proce dure different mathematical formulation problem table 1 shows many operations control execute common elements thus addition sub traction multiplication division involve transferring number selectrons sr hence control may simplified breaking operations basic ones timing circuit provided basic operation one circuits involved execution order exact choice basic operations depend upon arithmetic unit built addition timing circuits needed executing orders table 1 two circuits needed automatic operations transferring orders selectron register cr fr transferring order cr fr normal computer operation two circuits used alternately binary counter needed remember used next operations cu sx cc sx first order pair ignored binary counter must altered accordingly execution sequence orders involves using various x 1 z 67 chapter 4 1 preliminary discussion logical design electronic computing instrument 117 table 1 symbolization complete abbreviated operation 1 2 3 4 5 6 7 9 10 11 12 13 14 15 16 17 la 19 20 21 sx 4 ac sx 4 ac sx acm sx 4 ac sx 4 ah sx ah sx 4 ahm sxt ah sx 4 r ra sx x r sx r cu sx cu sx cc sx cc sx sx ap sx ap sx l r x x xm xm xh xh xhm x hm xr xx xi xc xc xcc xcc xs xsp xsp l r clear accumulator add number located position x selectrons clear accumulator subtract number located position x selectrons clear accumulator add absolute value number located position x selectrons clear accumulator subtract absolute value number located position x selec add number located position x selectrons accumulator subtract number located position x selectrons accumulator add absolute value number located position x selectrons accumulator subtract absolute value number located position x selectrons accumulator clear register add number located position x selectrons clear accumulator shift number held register clear accumulator multiply number located position x selectrons num ber register placing lefthand 39 digits answer accumulator righthand 39 digits answer register clear register divide number accumulator number located position x selectrons leaving remainder accumulator placing quotient register shift control lefthand order order pair located position x selectrons shift control righthand order order pair located position x selectrons number accumulator 2 0 shift control cu 4 sx number accumulator 2 0 shift control cu 4 sx transfer number accumulator position x selectrons replace lefthand 12 digits lefthand order located position x selectrons replace lefthand 12 digits righthand order located position x selectrons multiply number accumulator 2 leaving divide number accumulator 2 leaving trons lefthand 12 digits accumulator lefthand 12 digits accumulator register means arithmetic register timing circuits sequence given timing circuit completed operation emits pulse go timing circuit used next since depends upon partic ular operation executed pulses routed according signals received decoding recoding function tables activated six binary digits specifying order section consider must added control direct mechanisms getting data computer also describe mechanisms three different kinds inputoutput mechanisms planned first several magnetic wire storage units operated servo mechanisms controlled computer 68 second viewing tubes graphical portrayal results third typewriter feeding data directly com puter confused equipment used preparing printing magnetic wires presently planned latter consist modified teletypewriter equipment cf 682 684 since already exists way transferring numbers selectrons ac therefore ac may used transferring numbers wire latter transfer done serially make use shifting facilities ac using ac purpose eliminates possibility computing reading writing wires simultaneously however simultaneous operation computer inputoutput 681 118 part 2 instructionset processor mainline computers section 1 processors one address per instruction organ requires additional temporary storage introduces syn chronizing problem hence considered first model since beginning problem computer empty facilities must built control reading set numbers wire operator presses manual switch number read wire ac control must transfer proper location selectrons cc may used count positions sequence since capable trans mitting contents fr detection circuit cc stop process specified number numbers placed memory control shifted orders located first position selectron memory already stated entire memory facilities wires available computer without human intervention means control must able select proper set numbers going hence additional orders required code faced two alternatives make control capable exe cuting order form take numbers positions p p wire k place selectron locations u 0 make control capable executing less complicated operations together already given control orders sufficient programming transfer opera tion first alternative since latter scheme simpler adopt tentatively computer must way finding particular number wire one method arranging number carry location designation method economical wire memory capacity use selectron memory facilities remember position wire example computer would hold number specifying number wire position read control instructed read number position p wire compare p differ cause wire move proper direction number wire passes one unit added subtracted comparison repeated p numbers transferred wire accumulator proper location memory p increased 1 transfer wire accumulator memory repeated iterated p reached time control direct wire stop system control must able execute following orders regard wire start wire forward start wire reverse stop wire transfer wire ac transfer ac wire addition wire must signal control digit read end number reached conversely recording done control must means timing signals sent ac wire counting digits 26 counter used multiplica tion division may used latter purpose timing circuits required former method checking means two computers operating simultaneously adopted machine built operate independently separate inputoutput mechanism process making wires computer must duplicated way work person making wire checked since wire servomechanisms synchronized central clock problem synchronizing two computers wires used arises probably practical synchronize wire feeds within given digit unnecessary since numbers coming two organs ac need checked individual digits arrive prior deposited selectron memory since computer operates binary system means decimalbinary binarydecimal conversions highly desirable various alternative ways handling problem considered general recognize two broad classes solutions problem first conversion problems regarded simple arith metic processes programmed subroutines orders already incorporated machine details programs together complete discussion given fully chap ter 9 part 11 shown among things conversion word takes 5 msec thus conversion time comparable reading withdrawing time word 2 msecand trivial compared solution time problems handled computer noted treatment proposed presupposes decimal data presented received computer tetrads tetrad binary coding decimal digitthe infor mation precision represented decimal digit actually equivalent represented 33 binary digits coding decimal digits tetrads binary digits printing decimal digits tetrads accomplished quite simply automatically slightly modified teletype equipment cf 684 second conversion problems regarded unique problems handled separate conversion equipment incor porated either computer proper associated 682 chapter 4 1 preliminary discussion logical design electronic computing instrument 119 mechanisms preparing printing magnetic wires converters really nothing special purpose digital computers would seem justified com puters primarily intended solving problems computation time small compared inputoutput time class computer belong possible use various types cathode ray tubes particular selectrons viewing tubes case programming viewing operation quite simple viewing selectrons switched function tables switch memory selectrons means substitution operation ap sx ap sx sixdigit numbers specifying abscissa ordinate point six binary digits represent precision one part 26 64 ie 15 per cent seems reasonable component substituted order specify particular one viewing selectrons activated mentioned mechanisms used preparing printing wire first model least modified teletype equipment quite fortunate secured full cooperation ordnance development divi sion national bureau standards making modifi cations designing building associated equipment means modified teletype equipment operator first prepares checked paper tape directs equipment transfer information paper tape magnetic wire similarly magnetic wire transfer contents paper 683 684 tape used operate teletypewriter studies undertaken design equipment eliminate necessity using paper tapes shown 665 statement new problem wire involves data unique problem interspersed data found previously prepared paper tapes magnetic wires equipment discussed previous paragraph makes possible operator combine conveniently data single magnetic wire ready insertion computer frequently convenient introduce data com putation without producing new wire hence planned build one simple typewriter integral part computer means typewriter operator stop computation type memory location go fr type number go ac placed first mentioned location start computation one order control needs execute means computer signal operator computation concluded computation reached previously determined point hence order needed tell computer stop flash light ring bell 685 references burka62a burka6zb craw goldhgsa b c rajcj43 dec pdp8 introduction pdp8 singleaddress 12bitword computer second generation designed task environments minimum arithmetic computing small mp requirements example used control laboratory devices gas chromoto graphs sampling oscilloscopes together special ts programmed laboratory instrument pulse height analyzer spectrum analyzer applications typical laboratory process control requirements machine designed another example serve message concentrator controlling telephone lines typewriters teletypes attached computer occasion ally stands alone smallscale generalpurpose computer recently introduced smallscale generalpurpose time sharing system based work carnegiemellon university dec used ktdisp1ay pdisp1ay 338 c discussed chap 25 pdp8 achieved produc tion status formerly reserved zbm computers 5000 constructed pdp8 differs characteroriented 8bit computer chap 10 unlike 16bit computers ibm 1800 chap 33 pdp8 typical several 12bit computers early cdc160 series 1960 cdc6600 peripheral con trol processor chap 39 sds92 mit lincoln laboratorys laboratory instrument computer linc 1963 washington uni versitys programmed console 1967 scc 650 1966 pdp5 transistor 1963 pdp8 l965 pdp8s serial 1966 pdp81 integrated circuit 1968 pdprl integrated circuit 1968 constitute series computers based evolving technology identical isps pms structures nearly identical components pc mp compatible throughout series linc8338 pms struc ture presented fig 1 cost performance tradeoff took place pdp8 parallelbyword arithmetic pdp8s serial bybit arithmetic implementations pdpss onefifteenth pdp8 onehalf cost performance factors attributed 815 53 mp speed factor 3 logical organization even though 2megahertz logic clock used cases pdp8 67 times pdp5 initials title stand digital equipment corporation pro grammed data processor isp pdp8 pc trivial book data operators namely negate 7 2 x 2 optional x normalize operates words integers boolean vectors however microcoded instructions allow compound instructions formed single instruction computer straightforward illustrates levels dis cussed chap 1 easily look top c pms notation cpdp8 techno1ogytransistors 12 bw descendantspdp8s pdp81 pdp8l antecedents pdp5 mpcore 07 4096 w tc15 pw pcmps2 4 w instruction lengthli2 w addressinstruction 1 operations dataodt 7 negate x 2 2 1 optional operations x normalize datatypesword integer boolean vector operations data access4 pdisp1ay 338 pc linc sio bus 1 pc 64 k msdisk dectape magnetic tape tpaper tape card analog cathoderay tube isp isp presented appendix 1 chapter including optional extended arithmetic elementeae 212word mp divided 32 fixedlength pages 128 words address calculation based references first page page0 current page program counterpc effective address calculation procedure provides direct indirect reference either current page first page scheme allows 7bit address specify local page addresses 215word mp available pdp8 addressing greater 212 words comparatively inefficient extended range two 3bit registers program field data field registers select eight 212ord blocks actively addressed program data array eight registers called autoindex registers resides page0 array autoindexo 1107 m108178o11 possesses useful property whenever indirect reference made 1 first added 120 chapter 5 dec pdp8 121 k k063 teletype 110 180 bs 12l parity bw t03 crt display area io x io inz t03 light pen t03 push buttons console conso e ms 01 lincdape addressable magnetic tape p display 338 tconsol e mp fj07 szscs4 10 chars 8 bchar 64 char kt paper tape reader 300 chars punch 100 chars 8 bchar 3 3 c 16b cha rco 3 1 30 uspoint 01 1005 inpoint 3 kt incremental point plot 300 points 01 c inpoint ktcard reader 2001800 cardmin ktcard punch 100 cardmin line printer 300 linemin 120 colline crt display area io x io in215 x 5 in2 k t1iqht pen k tdataphone 2 48 kbs panalog output 0 10 volts kssl063 analog input 0 10 volts mpcore 15 pw 4096 w 12 ib memory bus 3pc1 2 winstruction data w ibv 12 bw mprowssor statef2i 11 w technolooy transistors 4sl0 bus pc 64 k kii 4 instructions mbufferl char2 w 2 antecedents pdp5 descendants pdpbs pdp81 pdfl fig 1 dec linc8338 pms diagram 122 part 2 instructionset processor mainline computers section 1 1 processors one address per instruction contents side effect referencing thus address integers register select next member vector string accessing instructionsetexecution definition also presented decoding diagram tree fig 2 block represents encoding bits instruction word decoding diagram allows one descriptive dimension conventional linear isp description revealing assignment bits instruction figure 2 still requires isp descriptions mp mps instruction execution effectiveaddress calculation interpreter diagrams fig 2 useful isp design determine instruction numbers assigned names operations instructions free assigned encoded eight basic instructions encoded 3 bits opo2 i02 instructionioll first six instructions 0 5 op 6 4 address operand deter mination modes thus yielding essentially 24 instructions first six instructions data transmission deposit clearaccumulatordca tortad twos complement add accumula principle oddressable instructions op 0 ond operate opr operate microcoded instructions opr1 ij time 112341 6 7 8 9 11 rtl iki tal time 1 ufiq 1 clo sma szo snl invert next 0 hlt eae time 1231 instruction instruction ioll op ib p pageoddress instruction word format extended arithmetic element eae inst ructions fig 2 dec pdp8 instructiondecoding diagram chapter 5 dec pdp8 123 binary arithmetic twos complement add accumu latortad binary boolean program control jumpset program counterjmp accumulatorand jump subroutinejms index memory skip results zeroisz note add instruction tad used data trans mission arithmetic subroutinecalling instruction jms provides method transferring link beginning head subroutine way arguments accessed indirectly return executed jump indirect instruction location storing returned address straightforward subroutinecall mecha nism although inexpensive implement requires reentrant recursive subroutine calls interpreted software rather hardware stack dec 338 chap 25 would nicer inputoutput instructioniot op 6 uses maining 9 bits instruction specify instructions input output devices 6 ioselect bits select 1 64 devices 3 bits ioplbit iopbit iop4bit command selected device conditionally providing three pulses sequence instructions typical io device ioplbit ioskipflagio select pc pc 1 testing condition io device output device input device iop4bit outputdataio select ac iop2bit ac c inputdataio select three microcoded instruction groups selected op 7 instruction decoding diagram fig 2 isp description appendix 1 chapter show microinstruc tions combined single instruction instruc tions operate group 1 op 7 1 i3 operating processor state operate group 2 op 7 i3ll 10 testing processor state extended arithmetic element group op 7 i3ll 11 multiply divide etc within instruction remaining bits 4lo 411 extended instruction opcode bits bits microcoded select instructions way instruction actually programmed microcoded example instruc tion setlink l tl formed coding two microinstruc tions clear link next complement link opr 1 i5 l 0 next i7 l 1l thus operate group 1 instructions clear link complement link set link formed coding instruction57 10 01 11 respectively operate group 2 instruction used testing condition pc state instruction uses bits 5 6 8 code tests accumulator ac skip conditions coded 0 7 never always 0 0 0 20 50 nonredundant useful variations two operate groups available separate instructions manner first seven dca tad etc would approximately 7 120prl lo0pr2 6eae 35 instructions optional extended arithmetic elementeae includes additional multiplier quotientmq shift countersc regis ters provides hardwired operations multiply divide logi cal shift left arithmetic shift normalize eae defined last page appendix 1 interrupt scheme external conditions inputoutput devices request pc interrupted interrupts allowed interruptstate 1 request interrupt clears interruptstate interruptstate 0 pc behaves though jump subroutine 0 instruction jms 0 given special iot instruction instruction 6001 followed jump subroutine indirect 0 instruction instruction 5200 returns pc interruptable state interruptstate 1 program time save mprocessor stateps 6 mp accesses 9 microseconds time restore mps 9 mp accesses 135 microseconds one interrupt level provided hardware multi ple priority levels desired programmed polling required io devices interrupt programcontrolled enable switch interrupt multiple devices approximately 3 cycles 45 ps required poll interrupter pdp8 pms structure pms structure linc8338 consisting pcllnc pcpdp8 pdisplay338 shown fig 1 pdp8 single pc pcl1nc capable pc 124 part 2 1 instructionset processor mainline computers section 1 1 processors one address per instruction instructions main pc available structure interpret programs written clinc computer devel oped mits lincoln laboratory laboratory instrument computer biomedical laboratory applications rather limited isp pc one would hardly expect find components present fig 1 actual configuration mp pc allows eight mps actually smemory bus 8 mp 1 pc p requests timemulti plexed 15 psw thus switch makes mp logically equivalent single mp32768 w two ls con nected pc excluding tconsole lio bus ldata break direct memory access links become switches consider physical structure associated device switch bus links devices lio bus really sio bus time k connects included k simplified pms diagram fig 3 shows structure logicalphysical transformation thus 10 bus sio bus duplex bus timemultiplexed 1 pc 64 k pc controlled k requests t45 psw sio bus pdp5 8 8s 8i 8l hence k used cs 10 bus link ks pccontrolled data transfers word transferred designated pc instruction however 10 bus allows k request pcs attention via interrupt request signal pc polls ks find requesting k multiple interrupt requests occur detailed structure pcmp fig 4 shows lio bus data break connections registers control notation used dec diagram essentially functional block diagram sio bus fig 1 abstract representation tconsole ldata break l pk mpo core lpcl io bus l mp k71s 2 1 u smernory bus l lsk u sio bus fig 3 dec pdp8 pms diagram simplified structure since bus structure expanded ls simple ss shown fig 3 termination l pc given fig 3 corresponding logic k given fig 5 terms logic design elements ands ors fig 5 also shows sio bus structure figs 1 3 operation sio bus shown fig 5 starts pc sends signal select address particular k using ioselect o5 signals form 6bit code k responds k hardwired respond unique code local control kb select signal used form three local commands anded three iot command lines pc ioplbit iop2bit iop4bit twelve data bits transmitted either pc indirectly ks control accomplished using andor gates k data input pc gate data input k data lines connected ac shown fig 4 single skip input used pc test status bit k k communicates pc via interrupt request line k wanting attention simply ors request signal interrupt request signal program polling pc selects specific interrupter normally k signal causing inter rupt also connected skip input ldata break direct memory access provides direct access path p k mp via pc number access ports memory expanded eight using sdmo1 data multiplexer requested p k p k supplies mp address read write access request either accepts supplies data mp accessed word config uration fig l pl1nc p338 connected sdmo1 make requests mp instructions data way pc global control processor programs via sio bus pc issues start stop com mands initializes state examines final state program p halts requires assistance k connected ldata break sdmo1 data multiplexer k accesses mp data complex function ks carry transfer complete block data mp ms example kdectape disk special mode threecycle data break controlled pc k may request next word queue mp mode next word taken queue block mp counter reduced time k makes request scheme word transfer takes three mp cycles one add one block count one add one address pointer one transmit word dectape derived mits lincoln laboratory linctape unit data explicitly addressed blocks variable chapter 5 dec pdp8 125 skip peripherol equipment c io bus data address switches io bus ac k24 doto peripheral data 12 equipment 4 using programmed fronsfers select c code outpd link 6 teletype drivers 1 asr 4 bus model 33 accumulator teletype control ooto 0 1 memory peripheral equipment buffer control register io peripherol equipment using data break facilities peripheral equipment 10 bus program counter contro progrom counter 12 4 register inhibit current address count transfer direction control word count overflow major stote breok stote generotor c address oaepted memory address register 1 control flow direction 4 dec stondord positive pulse 3 volts ground 1 4 dec standard negotive pulse ground 3 volt port isp transfer direction pop8 3 volts pdp 8 around dec standard ground level signal dec standard 3 volt level signal oota break request three cycle breok ground one cycle break 3 volts fig 4 dec pdp8 timing controlelement block diagram courtesy digital equipment corporation 126 part 2 instructionset processor mainline computers iiiiii section 1 1 processors one address per instruction 10pulseplp24 pulse output liosicooupu loololk _____ kuselect ioselect k 1 m4ge iopulaepp kselect used acinputdot0 k i0pulseyp4 hselect used outputudoto kacl next k 5s actual bus structure logical structure fig 5 dec pdp8 sio bus logic pms diagrams convention 128 w thus information block replaced rewritten random operation unlike queue accessed tape conventional ibm format magnetic tape data appended end file control tte1ephone links 64 teletypes type writers pc final k connects line bitserial basis since telephone line sends receives informa tion serially bit special inputoutput instructions pc sample line convert sampled bits coded characters 11 bits transmitted per character although codings use 7 742 75 10 bits per character 11 bits 3 control 1 parity 7 information bits action pc instruction issued 5 x 11 55 times every character control line forming 7bit charac ters instruction good example tradeoff hard waresoftware domain toward almost pure software hardware state associated telephone line ibit register hold state outgoing line single gate sample incoming line state sampling process requires 03 per cent pcmp capacity per active line 10 15 chars general pdp8 hardware controls minimalin turn fairly elaborate control programs must used part computer levels section describe systems levels pdp8 computer top reader already sketchy knowledge pdp8 registers isp exposed wish clarify operates map hierarchy given fig 6 starting pms isp logic design circuit electronics de scription levels subdivided provide organizational detail example registertransfer level de tailed registers data operators functional units macro logic processor whereas next logic level sequential combinational networks sequential combinatorial elements apparent relationship various de scription levels constitutes tree structure organiza tionally complex computer top node descending description level represents increasing detail smaller com ponent size final circuit element level reached simplicity many possible paths structural description tree illustrated example path showing mechanical parts missing path shown proceeds pdp8 computer processor arithmetic unit specifically ac register arithmetic unit next macro logic implementing register transfer operations functions jth bit ac given flipflops gates needed particular implementation shown finally last segment path come electronic circuits components flipflops nand gates constructed chapter 5 1 dec pdp8 127 r lpassive component 1 xi indicates figure number instonce fig 6 dec pdp8 hierarchy descriptions abstract representations figure 6 also lists methods used represent physical computer abstractly different description levels mentioned previously small part pdp8 descrip tion tree represented many documents schematics diagrams etc constitute complete representation even small computer include logic diagrams wiring lists circuit schematics printedcircuit board layout masks pro duction description diagrams production parts lists testing speci fications programs testing diagnosing faults manuals modification production maintenance use discus sion continues abstract description tree reader observe tree conveniently represents constituent ob jects level interconnection next highest level level abstractdescription tree described order pms level simplified pms structure fig 3 reduced fig 1 computer small enough physical delinea tion pms components ks ss less pro nounced larger systems fact case smemory bus iio bus ss actually within k mp shown fig 5 implementation switches within k mp shown fig 5 fig 7 present conventional functional diagram equivalent pms diagram computer pc decomposed k processor state mps functional diagram compo nents characteristic elementary computer model namely k tinput output figures give somewhat general idea processes occur computer information flows apparent least another level needed describe internal structure behavior mp pc look primitives although still together c registertransfer level programming level zsp isp interpretation given appendix 1 chapter specification programming machine addition constrains physical machines behavior particular isp isp discussed earlier chapter registertransfer level c also represented registertransfer level using pms figure 4 dec shows registertransfer level console processor state doto operations arithmetic inputoutput memory logical secondary memory l fig 7 dec pdp8 function block pms diagrams processor functional block diagram b pc pms diagram 128 part 2 instructionset processor mainline computers section 1 1 processors one address per instruction l memory bus l mbo 11 data wtpui broddmslz br rtlsenseuarnplifier old coreustack 12b40w ii 7 mpixl71 pc 1 1 1 r linkl operotionsll0 l1 1 buffermbollflip flop1 ___ mmernorv addressmaoll blnstruction register decode iloac loac x4 rotate acloac xz rotate loac loac x4 rotate acacembacacamb accarry lacmei acacv datswitcherl 1 1 1 mpsvprogrorn caunterpco il flip flop1 linstructlon regster iroz f lip flop 1 ir operations iroirmma oz 11 tj l0 bus1 lac inputoutput 1zbi cl iiouselecto51 mehe iouskipl output iopulreplppp4 k ispmpsio bus1tconsole data clock inputs tm break workingistoteuregisterl console datauswitchesl lrequertdirectioncycleselect01 1 ifaddress occeptedwordoount_w breakstatel 1 cllmeolloutputl lldbaddressoll inputl console lightsl ldbdato 011 input fig 8 dec pdp8 registertransferlevel pms diagram registers operations ls important level still lack information conditions operations evoked figure 8 pms diagram pcmp registers show considerably detail although bother electrical pulse voltages polarities fig 4 declare pc state including temporary register within pc figure also gives permissible data operations permitted registers clear logical design level registers operators easily reached k logic design reached use programming level constraints isp thus defining conditions evoking data operators core memory mp structure given fig 8 detailed block diagram shows core stack twelve 64 x 64 1bit core planes needed diagram though still functional block diagram takes aspects circuit diagram core memory largely circuitlevel details mp fig 9 consists component units two address decoders select 1 64 outputs x axis directions coincident current memory selection switches transform coincident logic address high current path switch magnetic cores 12 inhibit drivers switch high current current plane either 0 1 rewritten 12 sense amplifiers take induced low sense voltage selected core plane switched switched transform 1 0 core stack array m07777011 since time mp mentioned fig 9 also includes associated circuit level hardware needed corememory operation chapter 5 dec pdp8 129 power supplies timing logic signal level conversion amplifiers timing signals generated within pck shown together pcs clock fig 10 process reading word memory 1 12bit selection address established ma0ll address lines 1 10000 4096 unique num bers upper 6 bits 05 select 1 64 groups addresses lower 6 bits 611 select 1 64 groups x addresses read logic signal made 1 highcurrent path flows via x selection switches x directions 64 x 12 cores 2 3 selection current one core plane selected since ix iy iswitching2 current selected intersection ix iy iswitching 4 core switched 0 iswitching amperes 1 present read output plane bit sense amplifiers sense amplifier receives input winding threads every core every bit within core plane 07777 12 cores selected word reset 0 sense time sense amplifier observed tms memory strobe strobe effect creates hlb mma 5 read current turned x select high current signals 01 tis21152 1 low level winding sense signals 1 l _____ 2 current direction controls f mb data inputsc0 112 fig 9 dec pdp8 fourwire coincident current three dimensions corememorylogic block diagram 130 part 2 instructionset processor mainline computers section 1 1 processors one address per instruction clock pulses lt2 tm 1 tl tmd it2 read 1 p 0 5 10 15 time write inhibit 1 memory mma strobe b memory cycle 4 fig 10 dec pdp8 clock memory timing diagram 6 write inhibit logic signals turned bit inhibit signal present depending whether 0 1 respectively written bit highcurrent path flows via x selection switches opposite direction read case 2 1 written inhibit current present net current selected core switching 0 written current 1switching iswitching2 core remains reset inhibit write logic signals turned memory cycle completed 7 8 registers operations fig 8 shows registers pc uniquely assigned single function minimal machine pdp8 functional separation economi cal thus completely distinct registers transfer paths memory arithmetic program instruction flow sharing complicates understanding machine ever fig 8 clarifies structure considerably defining registers pc including temporaries example memory buffermb used hold word read written mp mb also holds one operands binary operations example ac c ac mb mb also used extension instruction registerir instruction interpretation additional registers isp memory buffermboll holds memory data instruction oper ands holds address word mp accessed instruction registeriro2 holds value current instruction performed memory addressmaoll stateregister fetchf stateregister 0 deferdindirect stateregister 1 executee stateregister 2 ternary state register holding major state memory cycle performed memory cycle fetch instruction memory cycle get address operand memory cycle fetch store operand execute instruc tion figure 8 concerned static definition declaration information paths operations state isp interpretation appendix 1 specification physical machines behavior temporary hardware registers added detailed isp definition could given terms time temporary registers instead give state diagram fig 11 define actual pc constrained isp registers temporary registers implied implementa tion time relationship among state diagram isp description logic shown hierarchy fig 6 relationships figures observe isp definition necessary detail fully defining physical pc physical pc constrained actual hardware logic lowerlevel details even circuit level example core memory read destructive process requires temporary register mb hold value rewritten repre sentable within single isp language statement since define nondestructive transfer considered two parallel operations mb mma mma c 0 problem explaining rewriting core using isp also difficult explicit time isp language although define clock events least relative time state diagram fig 11 describes implementation havior using registers register operations fig 8 temporary registers declared implementation fundamentally mptimingbased see state diagram times four clock signals generated fig 10 thus three stateregis ter o12 x 4 clock 12 major states implemen tation use ir obtain two states f2b f3b chapter 5 dec pdp8 131 fetch instruction memory msi irir v 02 1 ljmpvirnsl irloi 511 mb5ll e4 ma040 1 deferlindirect1 nddress 8 xecut ememory memory cycle tmsmbmma1 tms isz vtod v 1 t1 t1 it05 marl7i memb 11 tmd4 mame ac0 mb97774 pcpclll tjmp mb3 11 irns pcsldmb51v mepc mb4pc0901 state eo1 ostote register 0 eo1 note state diagram include doto break interrupt ond ea fig 11 dec pdp8 pc state diagram description stateregister values 0 1 2 corre spond fetching deferring indirect addressing ie fetching operand address executing fetching storing data executing instruction state diagram describe extended arithmetic elementeae operation interrupt state data break states add 12 states initialization procedure including tconsole state diagram also given one observe t2 occurs beginning memory cycle new stateregister value selected stateregister value always held remainder cycle le sequences fo f1 f2 f3 d1 d2 d3 eo el e2 e3 permitted figure 8 alludes pck sequential network used controlling pc inputs present state including clocks determine operations issued registers q tm2bfbiro stoteuregisterol foi ps v dco v iszili maimen logic design level registers data operations proceeding registertransfer isp descriptions next level detail logic module typical level 1bit logic module accumulator bit acj illustrated fig 12 horizontal data inputs figure logic module acj mbj io busj dataswitchj vertical control signal inputs command register operations le transfers labeled respective isp operations example ac c mb ac ac c ac x 2 rotate sequential network pck fig 8 generates control signal inputs logic design level pc control pck sequential network output signals pck fig 8 generated straightforward fashion formulating boolean expressions 132 pari 2 1 instructionset processor mainline computers section 1 processors one address per instruction bus bit ac r acj mbj acj lacac2 rotate ac ac x 2 rot e laccarry acmb acac 1 formed ac12 carry input fig 12 dec pdp8 acj bit registertransfer logic diagram ac0 tl 1r 111 7 mb3 mb4 7 mb6 stateregistero v tl ir 111 mb3 _i mbll mb4 stateregistero v tl ir 111 mb3 n mbll mba stateuregisterov tl ir 011 stateregister 2 tl stateregister 0 ir 111 mb4 mb3 v mbv stateregister 2 ir oh logic equation ac 0 iro ir1 r2 stateregister 2 logic diagram ac0 term derived eae state diagram fig 13 dec pdp8 pck ac 0 signallogic equations diagram 15v direct direct clear directa set ouput direct output clear tlov flipflop circuit combinatorial logic equivalent flipflop table circuit inputoutput 1 0 direct direct 1 0 set clear outputs inputs outputs 0 3 3 3 0 3 3 0 3 3 3 0 3 0 3 0 3 0 0 3 3 0 3 0 3 0 0 3 0 3 0 3 0 3 0 3 setclear flip flop direct setclear flipflop sequential logic element table flipflop inputoutput 1 0 0 direct direct 1 set clear 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 4 0 inputs outputs t1 outputs f _________ note ideal sequential circuit element delay output fig 14 dec pdp8 sequentialelement circuit logic diagrams chapter 5 1 dec pdp8 133 3 000 3 001 3 01 0 3 01 1 3 100 3 101 3 110 0 111 15 voi ts 1 111 1 110 1 101 1 100 1 01 1 1 01 0 1 00 1 0 000 3volts 15vo1ts inputs lnoui nand logic element input logic element node multiple input inverter circuit table circuit table nand table behavior behavior behavior input 1 output input 1 output input output 123 123 123 000 0 03 03 0 0 3 3 3 0 0 3 03 3 3 0 3 3 3 fig 15 dec pdp8 combinational element circuit logic diagrams directly state diagram fig 11 example ac 0 control signal expressed algebraically com binatorial network fig 13 obviously boolean output control signals functions include clock stateregister states arithmetic registers example 0 l 0 etc expressions factored minimized reduce hardware cost con trol interpreter although rather cavalier pck constitutes onehalf logic within pc circuit level final level description circuits form logic functions storage flipflops gating nand gates figures 14 15 illustrate logic devices detail fig 14 direct set direct clear flipflop sequential logic element described terms circuit implementation combinational logic equivalent table behavior algebraic behavior note ideal element cause delay responds directly immediately input idealized sequential logic elements used pdp8 illustrated including rs resetset ttrigger jk dde1ay delay flipflops makes behave way ideal primitives sequential circuit theory outputs require series delay inputs change time outputs change fact pdp8 uses capacitordiode gates flip flop inputs delay inputs figure 15 illustrates combinatorial logic elements used pdp8 circuit selection limited inverter circuit single multiple inputs familiarly called nand gates gates depending whether one uses posi tive andor negative logiclevel definitions conclusion could continue discuss behavior transistor used switchingcircuit primitives leave books semiconductor electronics physics hoped student gained grasp think hierarchical decomposition computers particular levels analysis synthesis 134 part 2 instructionset processor mainline computers section 1 1 processors one address per instruction appendix 1 dec pdp8 isp description pr stnte acd l pcd run n te r rupts tate ioputsel iosulsej iopulse4 appendix 1 oec pdp8 isp description accnmulator link hitkc eriensioq overylcw carry progran counter ihev c intemreting instrurtions runnng 1 ohen fc interrupted programmed control i3 pulses io evies state estended mernorg irclude j mo777i8l0ll pageoo 17i81d mo 177 id autoindexo 7la page0 io i7 id 8 8 smcial array directlg addressed memory registers special arrap ldressed indirectly incrernented bg 8 fc osoie yctnte keys start step coytnue ezmive loa frw memoc4 deposii store merory included data switchesdll instmetion format instructionii0ll op4 2 indi rectb ti b pageobi tp pageadd resso 6 th spageo 4 pco ioselecto5 ioplbit opzb iop4b za sn 1 data enterec via console i42 op code i3 0 direct indirect rnemcry redfererce i4 0 selects page 0 1 selects page isil pcd4 pcoii 1 i38 selects 1 device ili iio id i5 w hit ski myus operate 2 goup i6 hit ror skip zeo ac i7 bit skip ox nm zero link 3 bits control selective generation 3 volts 04 1s pulses io devies fectiue _ aiiress nlczatlcn process zoii 7i b z ib lo8 c z 178 mz mz 1 next b 2 mz zoll ib iz ib imz zoil pageobit thispageopageaddress pageobi onpageaddress p microcoded instruction instruction bits within instruction chapter 5 1 dec pdp8 135 appendix 1 dec pdp8 isp description continued n irterpritati n process run nterruptrequest h interruptstate instruction mpc pc pc next instructionexecution run interruptrequest interruptuslate mo pc interruptustale pc irstruto instr tction exertior rrocess instrctionexecution op 0 ac ac mz tad op loac c loac mzl isz op 2 mr mrl next mzl 0 pc tpc dca op 3 4 mlrl c ac ac 0 jrns op 4 4 mz pc next pc z jmp iot op 5 pc 2 op 6 4 ioplbit iopulsel c next io42bit iopulsez next iopbbit iopulseb opr op 7 operateexecution logical ad two complement ajd iriiex skip zero operiitc insirwetion k0w end instruction ewcution rate instiuc ions operate grour operaie gmup 2 csi e aritmetc ure ricined separate operateexecution cla i4 ac c 0 oprl i3 0 operate groun c11 ic 1 l 0 next p clear link cma id ac 7 ac u complernmt ac cml i7 l l next il compzernent l iac iii lwc rlwc next u ircrement pc ral i810 2 ln4c lmc x 2 rotate u rotate left rtl rar ielo 4 f loac tloac 2 rotate u rotate right rtr i8lo 5 loac tloac z2 rotate clear lr ovn lo operate nstructions iblo 3 loac loac x 2 rotate u rotate twice left u rotate twice raight oprd i311 10 operate group 2 li pc ship test 51ip condition c id 1 pc tpc 1 next skip condition ac 0 v sza ac 0 snl l 11 rrr switche u halt stop nsr i9 1 ac ac v data switches hlt iio run e 0 fae i3li 11 eafinstructionexecution optinvln7 fa 136 part 2 instructionset processor mainline computers section 1 1 processors one address per instruction appendix 1 dec pdp8 isp description continued kt ws ztate fach k map ariy following registers 64 optional pis nputdata 77 814 1 1 otputatao771411 64 outpul huffws iodkipflag lo 7781 iointerruptreques 77 1 1 sipnifies reauest 1f interruntqtate 1 ai 64 innut buffers 64 test conditions interrunt occurs 8 reouests io device 1 nter rupt reques max i0i nterruptreques n83 extended arithmetic eiement eaf optional provides additional arithmetic instructions operators inclucliw x normalize lopical shict arithmetc shift eae state mqq 11 qltirlier quotien scdl shift rounter instruction format data mdsd 11 sa rnds7ll shift count darameter instruction set tae eaeinstructionxecution next mqa i5 ac tac v mq p0 pc sca i6 ac cac v sc sc pc rnql i7 3 mq tac ac next ac pdo clear ic note one nmi shl asr lsr muy vi piven time i810 oom io ooerntion 7 nmi mds mpc pc cpc 1 next muy i810 2 f loacomq mq x mds sc mu 2 tip 7 dvi i8 lo 3 mq loacomomds div r7e loac c loacomq mod mds sc c 0 nmi i810 4 acomq tnormalizeacom nomaliae acm0 sc normal izeexponent acomq shl i8lo 5 loacomq tloacomq x zsl sc asr i810 6 loacomq tloacomq 2l sc isr i810 7 loacomq tloacomq 2s1loqical shift left shft right loqical shift sc 0 1 enij instruction execution chapter 6 whirlwind computer1 r r everett project whirlwind highspeed computer activity sponsored digital computer laboratory formerly part servo mechanisms laboratory massachusetts institute tech nology mit office naval research onr united states air force project began 1945 assignment building highquality realtime aircraft simulator historically project always primarily interested fields realtime simulation control since 7 efforts devoted design construction digital computer known whirl wind wwi computer operation 1 year increasing proportion project effort going application studies applications digital computers found many branches science engineering business although modern gen eralpurpose digital computer applied fields machine generally designed suited particu lar area whirlwind designed use control simula tion work air traffic control industrial process control aircraft simulation mean whirlwind used applications control onehalf available computing time next year assigned engineering scientific calculation including research uses supported onr mit committee machine methods computation control simulation problems result specialized emphasis computer design short register length wwi 16 binary digits control problems usually simple mathematically furthermore computer almost always part feedback rather openended system consequently roundoff errors seldom troublesome register length shortened something comparable sensitivity physical quantities involved perhaps five decimal places less wwi register length 16 binary digits including sign four onehalf decimals register length laieeire conf 7074 1951 chosen minimum would provide usable singleaddress order case five binary digits instruction 11 binary digits address future machine would probably increase register length 20 24 binary digits get additional order flexibility increased numerical precision less important scientific engineering calculation greater 16digit precision often required available set multiple length floating point subroutines make use greater precision easy true subroutines slow bringing effective machine speed ob tained acoustic memory machines much efficient occasionally waste computing time way continuously waste large part storage computing equipment machine providing unnecessarily long register high operating speed wwi performs 20000 singleaddress operations per second con trol simulation problems require high speeds neces sary calculations must carried real time com plex controlled system faster computer must practical upper limit computing speed could used available problems large enough problems one highspeed machine much better two simpler machines half speed communication machines presents many problem communication human beings presents great effort put wwi obtain high speed target speed 50000 singleaddress operations per second parts machine except storage meet requirement actual wwi present operating speed 20000 singleaddress operations per second lower edge desired speed range large internal storage wwi 1280 registers large amount highspeed ternal storage needed since general possible use slow auxiliary storage time factor many cases magnetic drum useful since access time short com 137 138 part 2 1 instructionset processor mainline computers section 1 processors one address per instruction order type numbers basic pulse repetition frequency pared response times real systems even drum considerable loss computing programming efficiency due shuffling information back forth drum computer wwi designed 2048 registers storage recently available 300 registers number small adequate much useful work cently second bank newmodel storage tubes added new tubes operate 1024 spots per tube bringing total wwi storage 1280 registers tubes computer test 2 months active use 2 weeks next months tubes first bank replaced newmodel storage tubes bringing total storage 2048 number lower end project considers desirable computer business needs needed probably always need bigger better faster storage device extreme reliability system much valuable property perhaps many human lives dependent proper operation com puting equipment failures must rare furthermore check ing alone however complete inadequate enough merely know equipment made error unlikely man presumably well suited work normal conditions handle situation emer gency multiple machines majority rule seem best answer selfcorrecting machines possibility appear complicated compete especially provide standby protection characteristics whirlwind computer may capitulated follows register length speed 20000 singleaddress operations per 16 binary digits parallel second storage capacity originally 256 registers recently 320 registers presently 1280 registers target 2048 registers singleaddress one order per word fixed point 9s complement 1 megacycle 2 megacycles arithmetic element tube count 5000 mostly single pentodes crystal count 11000 32 possible operations 27 signed usual types addition subtraction multi plication division shifting arbitrary number columns transfer parts words subprogram conditional subprogram terminal equipment control orders special orders facilitating doublelength floatingpoint operations one way increase effective speed machine provide builtin facilities operations occur frequently problems interest example automatic coordinate transformation order addition facilities affect generalpurpose nature machine machine retains old flexibility becomes faster suited certain class problems march 14 1951 time began keep detailed records november 22 1951 total 950 hours computer time scheduled applications use machine running two shifts total 3000 hours interval twothirds time used applications used machine improvement adding equipment preventive maintenance 950 hours available 500 used scientific engineering calculation group rest control studies limited storage available recently admittedly serious handicap scientific engineering applications people room storage lengthy sub routines necessary convenient use machine largest part time spent training setting pro cedures preparing library subroutines partial list actual problems carried group includes industrial production problem harvard eco nomics school magnetic flux density study magnetic storage work oil reservoir depletion studies ultrahigh frequency television channel allocation investi gation dumont optical constants thin metal films computation autocorrelation coefficients tape generation digitallycontrolled milling machine chapter 6 1 whirlwind computer 139 1h i1 scientific engineering applications time whirlwind organized manner patterned originated dr wilkes edsac group programmers mathe maticians assigned wwi assist users setting problems small problems requiring seconds minutes computer time encouraged applications time assigned 1hour pieces two three times day program debugging allowed machine program errors deduced programmer printed lists results storage contents order sequences previously requested machine operator programmer corrects program rerun within day perhaps within hours every effort made reduce timeconsuming job print ing tabulated results many cases user desires large amounts tabulated data doesnt really know swers wants asks everything users encour aged ask pertinent results form numbers curves plotted machine cathoderay tube auto matically photographed results prove inadequate user gets better idea needs allowed rerun program asking appear significant sults figure 1 shows sample curve plotted computing machine showing calibrated axes decimal intercepts digit trawfer bus fig 1 sample computer output input fig 2 simplified computer block diagram bli c13 v1 6 output wwi system layout figure 2 shows major parts computer wwi major elements computer communicate via central bus system wwi basically simple straightforward standard machine allparallel type unfortunately simple concept often becomes complicated execution true wws control complicated decision keep completely flexible arithmetic element need high speed storage use electrostatic storage tubes terminal equipment diversity input output media needed control ww control divided several parts shown fig 3 central control central control machine master source control pulses necessary central control allows one controls function general overlapping control operation except terminal equipment control one controls operation one time storage control storage control generates sequence pulses gates operate storage tubes central control instructs storage control either read write arithmetic control arithmetic control carries details complex arithmetic operations multiplication division 140 part 2 instructionset processor mainline computers section 1 processors one address per instruction control ri central control arithmetic terminal eouip fig 3 control setup operations plus complete controlling simpler operations addition carried central control terminal equipment control terminal equipment control generates necessary control pulses delay times interlocks various terminal equip ment units program counter program counter keeps track address next order carried considered part control 11binary counter provision reading bus functions subsidiary controls could combined central control major reason designed different times arithmetic ele ment control came first followed central control time central control designed necessary characteristics storage control unknown fact machine de signed parallel highspeed storage could used form terminal equipment control also unknown time since flexibility prime specification felt preferable build separate flexible controls various parts computer try combine needed flexibility one central control new machine would attempt combine control func tions possible hoping enough prior knowledge component needs eliminate subsidiary controls com pletely would still insist large degree control flexibility muster clock master clock consists oscillator pulse shaper divider generate 1 2megacycle clock pulses clock pulse control distributes clock pulses various controls machine unit determines sub sidiary controls actually controlling machine unit also stops starts machine provides pushbutton opera tion operation control operation control see fig 4 designed maximum flexibility minimum number operationdigits conse quently minimum register length completely decoding type operation switch 32position crystal matrix switch receives 5bit instruction bus turn selects one 32 output lines corresponding 32 builtin operations 120 gate tubes output operation control pulses 120 output lines go gate drivers pulse drivers control flipflops machine 120 generous number suppressors gate tubes connected vertical wires cross 32 output lines operation switch crystals inserted desired junctions turn gate tubes used operation 32ptlon switch iiii fig 4 operation control chapter 6 1 whirlwind computer 141 time pulse distributor consists 8position switch driven three binarydigit counter clock pulses input distributed sequence eight output lines control grids output gate tubes connected timing lines output operation control thus 120 control lines appear sequence pulses combination orders combination times central control central control machine shown fig 5 control switch foreground operation matrix right electrostatic storage electrostatic storage shown fig 6 consists two banks 16 storage tubes pair 32position decoders fig 6 view electrostatic storage set address digits read bus storage control generates sequence pulses needed operate gate generators et cetera radio frequency pulser generates high power 10megacycle pulse readout digit column contains besides storage tubes write plus write minus gate generators signal plate gate generator tube tenmegacycle grid pulses used readout order get required discrimination fractional volt readout pulses 100volt signal plate gates storage tube 10megacycle amplifier phase sensitive detector gate tube feeding program register program register used communicating storage tubes information read tubes appears program register information written tubes must placed fig 5 view central control lj h r l v 4 program register 142 part 2 instructionset processor mainline computers section 1 1 processors one address per instruction multiplicand w clock pulse fig 7 arithmetic element arithmetic element arithmetic element see fig 7 consists three registers counter control first register accumulator ac actually consists partialsum adding register carry register accu mulator holds product multiplication second aregister holds multiplicand multi plication numbers entering arithmetic element ar third bregister holds multiplier multiplica tion accnmulator bregister shift right left highspeed carry provided addition subtraction 9s complement endaroundcarry multiplication successive additions division successive subtractions shift orders provide shifting right left arbitrary number steps without roundoff arithmetic element straightforward except special orders high speed operates addition takes 3 microseconds complete carry multiplication 16 microseconds average including sign correction fig 8 shown several digits arithmetic element large panels accumulator digits accumulator bregister aregister test control test control shown fig 9 used present operating trouble shooting computer control includes power supply control meters neon indicators flipflops machine switches setting special conditions manual intervention switches oscilloscopes viewing wave forms probe amplifier system allows viewing wave form computer one scope test control test equipment provide synchronizing stop delay pulses step order program allowing viewing wave forms fly anywhere machine important part test facilities test storage group 32 toggleswitch registers plus five flipflop registers inserted place five toggleswitch registers storage proved invaluable testing control fig 8 view arithmetic element id li r c chapter 6 whirlwind computer 143 fig 9 view test control lr w wpg arithmetic element electrostatic storage available also testing electrostatic storage use test purposes test storage earns keep part terminal equipment system toggleswitches hold standard readin program flipflop registers used inout registers special purposes checking logical checking facilities built wwi rather inconsistent complete bus transfer checking system provided dupli cate checking terminal equipment permitted little else thoroughly checked felt worthwhile thoroughly check substantial portion machine portion would serve prototype studying tube circuitry used throughout machine feel worthwhile check machine procedure requires great deal added equipment logical complexity plus substantial loss computing speed operating experience shown us worthwhile provide detailed logical checking machine new machine would leave transfer checking amount information security given detailed checking system enough warrant expense building maintaining decision based expectation computing machine operate 95 per cent total time better average time random failures order 5 10 hours approximately io9 operations opinion way achieve extremely high reliability needed realtime control problems provide three identical distinct machines thus obtaining error correc tion well detection plus features standby safety damage control even failure probability machine must kept low proper design marginal checking pre ventive maintenance extremely high reliability means reliability far beyond achieved existing machines conveniently represented per cent consider system consisting three machines operable 98 per cent time averaging 10 hours random errors one machine operation y2 hour per day two machines operation 4 hour per month three machines operation 4 minutes per year furthermore undetected random errors might occur aver age year reliability needed systems decision omit detailed checking extend checking devices intended detect programming errors devices check overflow arithmetic element non existent order configurations necessary programmers make many mistakes techniques dealing programming errors important need future development terminal equipment present time whirlwind using following terminal equipment photoelectric paper tape reader mechanical paper tape readers punches mechanical typewriters oscilloscope displays 5 16 inches diameter phos phors various persistencies including computercon trolled scope camera inputs various analogue equipments needed control studies outputs analogue equipment added next year 1 magnetic tape units raytheon one unit integrated machine magnetic drums units engineering research associates inc many analogue inputs outputs 2 3 144 part 2 instructionset processor mainline computers section 1 processors one address per instruction great complexity terminal equipment requires flexible switching system single inout register ior data passes switch set order select desired piece terminal equipment orders put data ior remove data ior inout control provides necessary control pulses go type equipment general computer continues run terminal equipment wait times suitable interlocks provided prevent trouble complete equipment yet fully installed references whirlwind everr51 serrr62 tayln51 edsac samua57 wilkm56 chapter 6 whirlwind computer 145 appendix 1 whirlwind instruction code note operations mr mh dv sir srr srh sf cbr assumed magnitude least significant part ac br ab dm oper ations br treated storage register whirlwind instruction code came comprehensive system manual system automatic coding whirlwind computer published massa chusetts institute technology digital computer laboratory cambridge mass aspects logical design control computer case study1 r l alonso h blairsmith l hopkins summary logical aspects digital computer space vehicle described evolution logical design traced intended application characteristics computers ancestry form frame work design filled accumulation many decisions made designers paper deals choice word length number system instruction set memory addressing problems multi ple precision arithmetic computer parallel single address machine 10000 words 16 bits short word length yields advantages efficient storage speed cost logical complexity connection addressing instriiction selection multipleprecision arithmetic 1 introduction paper attempt record reasoning led us certain choices logical design apollo guidance com puter agc agc onboard computer one forthcoming manned space projects fact relevant pri marily puts high premium economy modularity equipment results much specialized input output circuitry agc however designed tradition parallel singleaddress generalpurpose computers thus many properties familiar computer designers richards 1955j beckman et al 19611 describe problems designing short word length computer way word length influenced characteristics characteristics number system addressing system order code multiple precision arithmetic secondary purpose paper indicate role evolution agcs design several smaller computers structure designed previously one mod 3c apollo guidance computer decision change means electrical implementation coretransistors integrated circuits afforded logical designers unusual second chance belief practitioners logical design designers computers applications evolve time frequent ieee trans ec12 6 687697 december 1963 reason given choice logical next step choice made recent conference airborne computers proc con space borne computer eng anaheim calif oct 3031 19621 affords view designers treated two specific problems word length number system computers word lengths order 22 28 bits use twos complement system agc stands contrast two respects reasons choosing may therefore interest minority view 2 description agc agc three principal sections first memory fixed read portion 24576 words erasable portion 1024 words next section may called central section includes besides adder parity computing register instruction decoder memory address decoder number addressable registers either special features special use third section sequence generator includes portion generating various microprograms portion processing various interrupting requests backbone agc set 16 write busses means transferring information various registers shown fig 1 arrowheads various registers show possible directions information flow fig 1 data paths shown solid lines control paths shown broken lines moty fired erasable fixed memory made wiredin ﬁropesﬂ alonso laning 19601 compact reliable devices num ber bits wired 4 x lo5 cycle time 12 pec erasable memory coincident current system cycle time fixed memory instructions address registers either memory stored either memory 146 chapter 7 aspects logical design control computer case study 147 t1 4 sequence generator lysy instruction microprogram arithmetic unit adder uses l _____ _j control paths data paths fig 1 agc block diagram logical difference two memories inability change contents fixed part program steps word memory 16 bits long 15 data bits odd parity bit data words stored signed 14 bit words using ones complement convention instruction words consist 3 order code bits 12 address code bits contents address register uniquely determine address memory word address lies octal 0000 octal 5777 inclusive address lies octal 6000 octal 7777 inclusive address modified contents memory bank register mb modification con sists adding integral multiplies octal 2000 address interpreted decoding circuitry memory bank register mb addressable address however modified contents transfers memory made way memory local register 6 certain specific addresses word transferred g sent directly modified special gating network transformations word sent g right shift left shift right cycle left cycle central section middle part fig 1 shows central section block form consists address register memory bank register mb mentioned also block addressable registers called ﬁcentral special registersﬂ discussed later arithmetic unit instruc tion decoder register sq arithmetic unit parity generating register adder two registers explicitly addressable sq register bears relation instructions register bears memory locations neither sq ex plicitly addressable central special registers q 2 lp set input output registers properties shown table 1 sequence generator sequence generator provides basic memory timing sequences control pulses microprograms constitute instruction priority interrupt circuitry number scal ing networks provide various pulse frequencies used computer rest navigation system instructions arranged last integral number memory cycles list 11 instructions treated detail sec 6 addition number ﬁinvoluntaryﬂ sequences normal program control may break normal sequence instructions triggered either external events certain overflows within agc 148 part 2 1 instructionset processor mainline computers section 1 1 processors one address per instruction table 1 special central registers octal register address purpose andor properties 0000 central accumulator instructions refer 0 0001 transfer control tc occurred l ql 1 z 0002 program counter contains l 1 l address instruction presently executed lp 0003 low product register register modifies words written shifting special way several registers used sampling either external lines internal computer conditions time alarms several output registers whose bits control switches networks displays may divided two categories counter incrementing program interruption counter incrementing may take place two mem ory cycles external requests incrementing counter stored counter priority circuit end every memory cycle test made see incrementing requests exist next normal memory cycle executed directly time cycles request present incrementing memory cycle executed ﬁcounterﬂ specific location erasable memory incrementing cycle consists reading word stored counter register incrementing positively nega tively shifting storing results back register origin outstanding counter incrementing requests proc essed proceeding next normal memory cycle type interrupt provides asynchronous incremental serial entry information working erasable memory pro gram steps may refer directly ﬁcounterﬂ obtain desired information refer input buffers overflows one counter may used input another property system time available normal pro gram steps reduced linearly amount counter activity present given time program interruption occurs normal program steps rather memory cycles interruption consists storing contents program counter transferring con trol fixed location interrupt line different location associated interrupting programs may interrupted interrupt requests lost processed soon earlier interrupted program resumed calling resume sequence restores program counter initiated referencing special address 3 word length airborne computer granted initial choice parallel transfer words within highly desirable minimize word length memory sense amplifiers high gain class amplifiers considerably harder operate wide margins temperature voltages input signal say circuits made gates best possible furthermore number ferriteplane inhibit drivers equals number bits word case similarly time required carry propagate parallel adder proportional word length present case factor could expected affect microprogramming instructions initial intent short word length possible another initial choice agc ﬁcommon storageﬂ machine means instructions may executed erasable memory well fixed memory data obviously constants case fixed memory may stored either memory turn means word sizes types memory must compatible sense agc easiest form compatibility equal word lengths socalled ﬁseparate storageﬂ solutions allow different word lengths instructions data made work walend ziewicz 19621 drawback three memories required data memory erasable two fixed memo ries one instructions one constants addition found separate storage machines awkward program use memory less efficiently common storage machines three principal factors choice word length 1 precision desired representation navigational vari ables range input variables entered serially counted 2 chapter 7 aspects logical design control computer case study 149 3 instruction word format division instruction words two fields one operation code one address start choice word length 15 bits two previous machines series kept mind satisfactory word length point view mechanization ie number sense amplifiers inhibit drivers carry propagation time etc considered satisfactory act ﬁchoosingﬂ word length really meant whether alter word length time change mod 3c agc particular whether increase influence three principal factors taken turn precision data words data words used agc may divided roughly two classes data words used elaborate navigational computa tions data words used control various appliances system initial estimates precision required first class ranged 27 32 bits 0108ﬂ second class variables could almost always represented 15 bits fact navigational variables require twice desired 15bit word length means much advantage word sizes 15 28 bits far precision represen tation variables concerned doubleprecision numbers must used event doubly signed number representation doubleprecision words equivalent word length 29 bits including sign rather 30 basic word length 15 bits initial estimates proportion 15bit vs 29bit quantities stored fixed erasable memories indi cated overwhelming preponderance former also estimated significant portion computing control telemetry display activities handled economically short words short word length allows faster efficient use erasable storage reduces fractional word operations packing editing also means efficient encoding small integers range input variables control computer agc must make analogtodigital conversions many shaft angles two principal forms conversion exist one renders whole number produces train pulses must counted yield desired number latter type conversion employed agc using counter incrementing feature number bits precision required greater computers word length effective length counter must extended second register either programmed scanning counter register using second counter register receive overflows first whether programmed scanning feasible depends largely frequently scan ning must done cost using extra counter register directly measured terms priority circuit associated agc equipment saved reducing word length 15 bits would probably match additional expense incurred doubleprecision extension many input variables question academic however since lower bound word length effectively placed format instruction word instruction word format initial decision made instructions would consist operation code single address straightforward choices packing one two instructions per word ones seriously considered although schemes packing one half instructions per word possible england 19621 previous computers mod 3s mod 3c 3bit field operation codes 12bit field addresses accommodate 8 instruction order codes 4096 words memory initial coretransistor version agc ie mod 3c 8 instruction order codes reality augmented various special registers provided shift right cycle left edit transfer one registers would accomplish actions normally specified order code see sec 6 registers considered economical corresponding instruction decoding control pulse sequence generation hence 3 bits assigned order code considered adequate albeit generous furthermore seen possible use indexing instruction increase eleven number explicit order codes provided address field 12 bits presented different problem time design mod 3c estimated 4000 words would satisfy storage requirements time redesign clear requirement lo5 words question became whether proposed extension address field bank register see sec 7 economical addition 2 bits word length reasons modularity equipment adding 2 bits word length would result adding 2 bits central special registers amounts increasing size nonmemory portion agc 10 per cent 150 pari 2 instructionset processor mainline computers section 1 processors one address per instruction summary 15bit word length seemed practical enough additional cost extra bits terms size weight reliability seem warranted 14bit word length thought impractical problems certain input variables would restrict already somewhat cramped instruction word format word lengths 17 18 bits would result certain conceptual simplicities decoding instructions addresses would help represen tation navigational variables require 28 bits must represented double precision event 4 number representation signed numbers absence need represent numbers signs discussion number representation would extend beyond fact numbers agc expressed base two accommodation positive negative numbers requires logical designer choose among least three possible forms binary arithmetic three principal alternatives 1 ones complement 2 twos complement 3 sign magni tude richards 19551 ones complement arithmetic sign number versed complementing every digit ﬁend around carryﬂ required addition two numbers twos complement arithmetic sign reversal effected complementing bit adding low order one equivalent operation sign magnitude representation typically used direct human interrogation memory desired ﬁpost mortemﬂ memory dumps example addition numbers opposite sign requires either ones twos complementation comparison magnitude sometimes may use advantage offered efficiency possible exception sign changing requires changing sign bit disad vantage engendered magnetic core logic machines extra equipment needed subtraction conditional recomple mentation ones complement notation advantage easy sign reversal equivalent boolean complementa tion hence single machine instruction performs functions zero ambiguously represented zeros ones number numerical states nbit word 2ﬂ 1 twos complement arithmetic advantageous end around carry difficult mechanize particularly true serial computers nbit word 2ﬂ states desirable input conversions devices pattern generators geared encoders binary scalers sign reversal awkward ever since full addition required process choice case agc use ones complement arithmetic general processing twos complements cer tain input angle conversions since arithmetic done latter case addition plus minus one twos complement facility provided simply suppressing end around carry using proper representation minus one latter stored fixed constant sign reversal required modified ones complement system standard ones complement adder overflow detected examining carries sign position overflow indications must ﬁcaught flyﬂ stored separately acted upon later number system adopted agc advantage ones complement system additional feature static indication flow implementation method depends agcs using parity bit central registers certain modular advantages 16 rather 15 columns available central registers including adder parity bit required extra bit position used extra column virtue 16bit adder overflow 15bit sum readily detectable upon examination two high order bits sum see fig 2 bits overflow different overflow occurred sign highest order bit interface 16bit adder 15bit memory arranged sign bit word coming memory enters two high order adder columns de noted si since significance sign bits word transferred accumulator memory one two signs stored choice store bit standard ones complement sign except event overflow case sign two operands preservation sign overflow important asset dealing carries component words multi pleprecision numbers see sec 5 standard ones complement system series additions may result subtotals overflow yet still produce valid sum long total exceed capacity one word modified ones complement system however sign preserved overflow longer true total may depend order numbers added serious drawback must accounted phases logical design programming chapter 7 aspects logical design control computer case study 151 modified tandar si4321 3 2 1 example 1 operands positive sum positive overflow identical results 0 0 0 0 1 000001 systems 00011 000011 00100 000100 example 2 operands positive positive overflow standard result nega 0 1 0 0 1 tive modified result positive using sz sign answer 0 1 0 1 1 positive overflow indicated si sz 10100 example 3 operands negative sum negative overflow end around 1 1 1 1 0 carry occurs identical results systems using either si sp 1 1 1 0 0 11010 sign answer 1 carry 11011 001001 001011 010100 111110 111100 111010 111011 1 carry example 4 operands negative negative overflow standard result posi 1 0 1 1 0 110110 tive modified result negative using s2 sign answer 1 0 1 0 0 110100 negative overflow indicated si sz 01010 101010 1 carry 1 carry 01011 101011 example 5 operands opposite sign sum positive identical results i1 1 1 1 1 0 111110 systems 00011 000011 00001 000001 00010 000010 1 carry 1 carry example 6 operands opposite sign sum negative identical results 1 1 1 0 0 111100 systems 00001 000001 11101 111101 fig 2 illustrative example properties modified ones complement system 5 multiple precision arithmetic short word computer effective multiple precision routines efficient corresponding share computers word load agcs application enough use multipleprecision arithmetic warrant consideration choice number system organization instruc tion set although limited number order codes prohibits multipleprecision instructions special features associated conventional instructions expedite multipleprecision opera tions independent sign representation variety formats multipleprecision representation possible probably common identical sign representation sign bits component words agree method used agc allows signs components different independent signs arise naturally multipleprecision addition subtraction identical sign representation costly sign reconciliation required every operation example 6 4 4 6 2 2 mixed sign repre sentation 1 8 since addition subtraction frequent operations economical store result occurs reconcile signs necessary overflow occurs addition two components one sign overflow carried addition next higher components sum overflowed retains sign operands overflow termed interflow distinguish overflow 152 part 2 instructionset processor mainline computers section 1 1 processors one address per instruction arises maximum multipleprecision number ex ceeded independent sign method pitfall arising fact every number two representations either one may occur sum numbers one representations exceeds capacity significant component overflow false sense double precision capacity exceeded single word capacity upper component sign reconciliation used case yield acceptable representation problem avoided numbers scaled none large enough produce false overflows restriction necessary however since false overflow condition arises infrequently detected expense time net cost reconcilia tion therefore low multiplication division triple higher orders precision multiplication divi sion become excessively complex unlike addition subtraction complexity linear order precision algorithm doubleprecision multiplication directly applicable numbers independent sign notation false overflow arise treatment interflow simplified automatic counter register incremented overflow occurs add instruction sign counter increment sign overflow incre ment takes place one product components next higher order stored counter doubleprecision division exceptional independ ent sign notation may used operands must made positive identical sign form divisor normalized leftmost nonsign bit one triple precision tripleprecision quantities used agc added subtracted using independent sign notation inter flow overflow features used double precision arithmetic 6 instruction set basic design criteria implicit requirements von neumanntype machine demand facilities exist storing memory negating complementing combining two operands eg addition address modification generally executing struction result arithmetic processing normal sequencing location instruc tion executed corresponds one location whose contents next instruction conditional sequence changing transfer control input output instruction course provide several facilities instance computers instruction subtracts contents memory location accumulator leaves result memory location accumulator instruction fulfills requirements 14 requirement 5 met somewhat primitive manner instructions executed erasable memory met elegantly use index registers still another scheme somewhat similar one used bendix g20 employed agc requirement 6 usually fulfilled instruction location counter contains address next instruction executed incremented one instruction fetched alter natively instruction may include address next instruction often done machines drum memories agc shortword computers former method one singleaddress instruction per word clearly simplest cheapest requirement 7 generally met examining condition sip accumulator condition satisfied either incrementing instruction location counter skipping using address included instruction next instruction conditional transfer control uncon ditional transfer control usual necessary since desired condition forced machines special inputoutput instructions satisfy requirements 8 9 agc however since input output addressable registers input subsumed fetching memory output storing memory counter incrementing pro gram interruption aid functions also criteria major goals agc efficient use memory reason able speed computing potential elegant programming effi 1 fetching memory chapter 7 aspects logical design control computer case study 153 cient multiple precision arithmetic efficient processing input output reasonable simplicity sequence generator constraints affecting order code whole word length ones complement notation parallel data transfer characteristics editing registers ground rules governing choice instructions arose goals constraints three bits instruction word devoted operation code b address modification must convenient efficient c multiply instruction yielding double length product treatment overflow addition must flexible e boolean combinatorial operation available f instruction need devoted input output shifting list means complete gives good indication kind computer agc following para graphs ways instructions fulfill require ments described details instruction set listing follows l denotes location instruction k denotes data address contained instruction paren theses mean ﬁcontent ofﬂ leftward arrow means register named arrowhead set quantity named right l tc k transfer control qcl 1 go k primary method transferring control stated location thus meets part requirement 7 setting return address register q renders complex subroutines feasible tc q may used return subroutine tcs binary number ﬁl 1ﬂ binary word ﬁtc l 1ﬂ virtue tc code zeros tc behaves like ﬁexecuteﬂ instruction executing whatever instruc tion q follows address pattern see table 1 l ccs k count compare skip k 0 c k 1 skip k 0 0 skip l 2 k 0 1 k skip l 3 k 0 0 skip l 4 instruction fulfills remainder requirement 7 provides several features clear machine 3bit operation code one code devoted entirely branching possible inefficient program zero test using sigmtesting code even inefficient pro gram sign test using zerotesting code instruction therefore designed test types conditions simultane ously fourway branch since one address per instruction follows ccs must skipping type branch function k delivered diminished absolute value dabs serves two primary purposes work generating absolute value apply negative increment contents loopcounting register ccs properties tix ibm 704 l index k index using k use l 1 k next instruction shortword machine room instruc tion word specify indexing indirect addressing code meets requirement 5 way far superior forming instruction placing erasable memory execution index operates whole words operation code well address may modified may used recursively consider implications several indexs succession assuming operation codes modified finally permits 8 operation codes specified 3 bits since overflow indexing addition detectable l xch k exchange instruction meets requirements 1 2 8 k fixed memory simply datafetching clear add code use erasable memory aids efficiency reducing need temporary storage xch also important input instruction machine addressable counters incremented response external events input medium counter read reset zero desired value xch chance missing count ak l cs k clear subtract cs primary means signchanging logical negation fulfills requirements 1 3 since clear add instruction usual operation nondestructive readout erasable memory simple data transfers addition arithmetic required usually programming arranged complementing transfer accept able otherwise cs followed cs storing l ts k transfer storage k includes overflow c 51 skip l 2 c k 154 part 2 instructionset processor mainline computers section 1 processors one address per instruction instruction primary means transfers memory output satisfying requirements 2 9 also convenient method testing overflow since central registers two sign positions overflow indication retained central register ts always stores tests whether overflow present k erasable memory central register lowerorder sign bit si transmitted process overflow correction positive overflow indication present ts skips next instruction sets 1 1 denotes octal 000001 negative overflow present ts skips next instruction sets 1 1 denotes octal 177776 otherwise unchanged sequence ts k xch zero zero fixed memory suffices store k overflowcorrected word multiple precision sum leave interflow next higherorder part ts skips either type overflow present leaves 16 bits unchanged finally computed transfer control may achieved ts z z program counter loworder 12 bits significant address instruction control transferred overflow case affect transfer sets 51 l ad k add k final includes 2 overflow ovctr ovctr tl addition frequently used combinatorial operation requirement 4 property ovctr used chiefly devel oping doubleprecision products quotients partly additions processes less susceptible false overflow multipleprecision additions l mask k mask combinatorial boolean instruction may n k used cs generate boolean function ex tracodes agc instruction set carried large part ancestor mod 3c alonso et al 19611 instructions mod 3c retained agc modifications additions adopted substantial increase computing power could obtained small cost mod 3c instruction set like one described agc two major exceptions first instead mask instruction mod 3c multiply struction second transfer storage instruction clude property skipping overflow although properties aided masking design mod 3c completed discovered index instruction could used expand instruc tion set beyond eight instructions producing overflow instruction word following index example addition octal 47777 instruction word ﬁcs kﬂ course index instruction cause negative overflow producing mp k multiply instruction operand address k order implement extracodes agc necessary provide path highorder 4 bits adder unaddressable sequence selection register sq part path unaddressable buffer register b requirements helped suggest benefits retaining two sign bit positions central registers principle eight additional instruction codes obtained causing overflow feel obliged use every extracode must indexed instructions chosen class two properties degree normally indexed take long enough cost indexing without address modification small extracodes com binatorial therefore relate requirement 4 l mp k multiply upper part lp lower part k two words product agree sign determined strictly sign bits operands experience mod 3c showed worthwhile making completely algebraic selfcontained multiply instruction especially doubleprecision multiplication whose oper ands independent signs agc multiply much faster mod 3c limited adder carry propagation time rather coreswitching time l dv k divide quotient q 1 remainder 1 ak lp nonzero number sign quotient many facets agc design originally adopted reasons combined make divide instruction inexpensive foremost nature editing registers standard erasable memory special wiring special properties registers supplied shift cycle word written memory local register g address editing register selected central loop dv selects address inhibits memory operations left shifts required division accomplished g register editing register remains unchanged microprogrammed nature order construction makes restoring chapter 7 aspects logical design control computer case study 155 algorithm efficient nonrestoring one quotient delivered sign determined according normal algebraic rules signs k sign available lp aid determining correct sign remainder divisor quotient case quotient absorbed subsequent processing dv usually indexed pays large benefits space time especially doublepre cision division cost extracode indexing negligible divisor less magnitude dividend zero quotient correct sign general maximum magnitude infinite loop results case l su k subtract c k final includes 2 overflow ovctr ovctr 21 primary justification instruction allows multipleprecision addition subroutines changed multi pleprecision subtract subroutines merely changing indexing quantity occasions middle involved calcula tions clumsy construct subtraction comple mentations additions especially sign overflow interest since su differs ad operand memory read complement side buffer register b rather direct side cost virtually zero last necessarily true using coretransistor logic twos complement notation 7 expansion memory addressing agcs 12bit address field insufficient specifying directly registers memory predicament seems increas ingly afflict computers either indirect addressing assumed necessary evil start case earliest estimates memory requirements wrong factor two three method indirect addressing arrived uses bank register mb important modification 5bit number stored mb effect unless address range octal 6000 7777 mb register contents interpreted higherorder bits address interpreted integers specify bank 1024 words meant event address part instruction ambiguous range overall map memory shown table 2 unambiguous fixed memory addresses domain come known ﬁfixedfixedﬂ interesting method extending addressing capability result trying improve upon conventional methods almost consequence phys table 2 address part instruction word decimal 03071 30724095 fixed erasable memory unambiguous addresses fixed memory ambiguous address contents mb used resolve ambiguity 32 banks possible ical difference fixed erasable memory since data constants concentrated erasable memory exempt modification mb register alternative arrangement whereby addresses instruc tions opposed addresses within instruction word modified would deficient would allow instruc tions stored banks would way refer constants stored banks use bank addresses store argu ments arithmetic operations possibility using two bank registers worthy serious consideration casale 19621 occur us addition addresses erasable necessary exempt addresses interrupting programs ie addresses program interrupt transfers control influence mb register clear would valuable large body unambiguous addresses use executive dispatcher programs frequent critical applications bank changing agcs interpretive mode programs relevant navigation written parenthesisfree pseudocode notation economy storage interpretive program executes pseudocode programs performing indicated data accesses subroutine linkages format notation permits two macrooperators eg ﬁdoubleprecision vector dot productﬂ one data address stored one agc word thus data addresses appear full 15bit words potentially capable addressing 32768 registers address examined interpreter contents bank register changed necessary preparation also made subsequent return subroutine call made structure interpretive program relationship computer characteristics discussed paper taken except point parenthesisfree notation particularly valuable shortword computer agc permits substantial expansion address pseudo operation fields without sacrificing efficiency program storage muntz 19621 156 part 2 instructionset processor rnainline computers section 1 processors one address per instruction conversion 15bit address bank number ambiguous 12bit address follows top 5 bits correspond directly desired bank number remaining lowerorder 10 bits logically added octal 6000 form proper ambiguous address 15bit address less octal 6000 however address erasable fixedfixed memory case logical addition octal 6000 suppressed possible program one bank call closed subroutine another bank control returned proper place bank origin done means short bank switching routine fixedfixed memory one potential awkwardness method extending memory addresses possible requirement routine one bank access large amounts data stored another many programming solutions problem obviously cost operating speed better solution would two bank registers problems nature yet material ized however references alonr63 alonr6o alonr61 alonr62 reckf61 casac62 englw62 hopka63 muntc62 richr55 walew62 proc conf spaceborne cm puter eng anaheim calif oct 3031 1962 appendix 1 name memory size aute f xed number number purpose features incorporated completed e erasable hits instructions design stage mod 1 f448 11 parity 4 plus involuntary feasibllity prototype counter increments 1960 e 64 interrupts background agc design coretransistor logic pulse rate outputs editing registers wiredin fixed memory interpretive programs 23 parity 16 plus indirect unmanned space probe ﬁextended operationﬂ subroutine linkages instance mod 2 4000 total built mod 3s f 3584 1962 e 512 15 parity 8 earth satellite mod 3c f greater 104 15 parity 8 involuntary apollo guidance 1962 e greater 103 agc f greater 104 15 parity 11 involuntary apollo guidance 1963 e greater 103 modified ones complement parallel adder addressable central registers ccs index multiply structions overflow counter bank switching dv su msk instructions editing memory buffer transistor logic instead coretransistor logic extracodes parenthesisfree interpreter univac system1 j presper eckert jr jumes r weiner h frazer welsh herbert f mitchell organization univac system march 1951 first univac2 system formally passed acceptance tests put promptly operation bureau census since univac first computer handle alphabetic numerical data reach fullscale operation far operating record review types problems applied provide interesting milestone everwidening field electronic digi tal computers organization univac functions directly require main computer performed separate auxiliary units power supply thus keyboard magnetic tape punched card magnetic tape tape typewritten copy operations delegated auxiliary components main computer assembly includes units directly concerned main central computer opera tions block diagram arrangement shown fig 1 elements shown contained within central computer casework except supervisory control desk sc uni servos2 lines upper right section diagram connect supervisory control addition necessary control switches indicator lights contains input keyboard also cabled supervisory control typewriter operable main computer means two units limited amounts information inserted removed either operator programmed instructions inputoutput circuits operate data entering leav ing computer input output synchronizers properly time incoming outgoing data either uniservos tape devices supervisory control devices input output registers 0 60 word 720 characters temporary storage registers intermediate main com puter inputoutput devices highspeed bus amplifier switching central azeeire conf 616 december 1951 2registered trade mark data must pass transfer arithmetic register main memory memory inputoutput registers arithmetic registers shown along bottom diagram connected high speed bus system l f x aregisters one word 12 character capacity directly concerned arithmetic operations v yregisters 2 10word capacity respectively used solely multiple word transfers within main memory associated arithmetic registers algebraic adder aa comparator cp multi plierquotient counter h4qc additionsubtraction instructions additionsubtraction operations performed conjunction comparator since niimerical quantities absolute magnitudes algebraic sign attached either addition subtraction performed two quantities one already aregister either memory xregister depending upon particular instruction compared magnitude sign adder inputs switched always produce noncomplemented result operation choice adder input arrangement fore control comparator comparator also determines proper sign result according usual algebraic rules one additional function performed comparator addi tion subtraction control complementer deter mination based upon operation indicated whether signs like unlike subtract instruction sign subtrahend reversed entering com parator comparator compares signs quantities order determine whether two quantities subtracted added multiplication instruction multiplication process requires services adder comparator multiplierquotient counter four arith metic registers first step multiplication xreg 157 158 part 2 1 instructionset processor mainline computers section 1 processors one address per instruction r 1 standard pulses units 1aaaia iiiiii uniservos cycllwg unit input output control units circuits control signals gates l r check circuits control circuits 1 time 1000 words __ instruction mem location olglts olglts control input output tsigs static register distributor line input regs units signal signal 3 legend information signals control signals 8 pulses fig 1 block diagram univac chapter 8 univac system 159 ister receives multiplier memory comparator determines sign final product comparing signs multiplier multiplicand next three steps multiplicand stored lregister previous instruction transferred three times aregister algebraic adder result three times multi plicand stored fregister next 11 steps multiplication successive multiplier digits beginning least significant transferred xregister multiplierquotient counter multiplierquotient counter determines whether particular multiplier digit less three greater equal three former lregister releases multiplicand aregister via adder multiplierquotient counter stepped downward one unit multiplier digit equal greater three multiplierquotient counter sends signal fregister releases three times multiplicand aregister multiplierquotient counter stepped three times thus multiplier digit seven would processed two transfers fregister aregister one transfer lregister aregister total three transfers multiplierquotient counter reaches zero next multiplier digit brought xregister areg ister containing first partial product shifted one position right final step multiplication sign attached product built aregister one several available multiplication instructions causes least sig nificant digits shifted beyond limits areg ister transferred xregister replace multiplier digits moved multiplierquotient counter thus 22 place products obtained well 11 place division instruction division operation performed nonrestoring method divisor stored lregister previous instruction dividend brought memory put aregister first step division instruction multiplica tion signs two operands compared comparator time sign quotient stored comparator pending completion division operation principal stages division consist transferring divisor lregister aregister complementer adder many times required produce quantity less zero aregister dividend first shifted one position left multiplierquotient counter counts transfer thereby building first quotient digit soon quantity aregister neglecting original sign goes negative digit multiplierquotient counter counting transfer causes remainder go negative trans ferred xregister remainder aregister shifted one place left divisor added aregister quantity becomes positive time multiplierquotient counter must give complement number transfers real quotient digit special comple menting readout gates provide method interpreting multiplierquotient counter xregister therefore collects quotient digit digit multiplierquotient counter full 11 digits obtained quotient transferred aregister sign comparator cp affixed final stage divide instruction internal operations univac include many transfer instructions words may moved among registers memory without clearing extraction instruction certain digits word may extracted another word according parity corresponding digits extractor word shift instructions special control instructions breakpoint transfer control explained subsequent paragraphs stop basic operating cycle basic operating cycle univac founded upon single address instructions specify memory location one word case arithmetic instructions require two operands one operands must moved proper register previous instruction order control sequence instructions special counter called control counter cc retains memory location succeed ing instruction word obtained time new instruction word received memory quantity control counter passed adder unit added therefore normal sequence refer successive memory locations successive instruction words initially control counter cleared zero first group instructions must therefore placed memory locations zero upward transfer control instruction enables programmer change control counter reading whenever desired thus shift one sequence another transfer control takes place new number control counter increased unity time new instruction word obtained memory 160 part 2 instructionset processor mainline computers section 1 1 processors one address per instruction transfer control instructions transfer control instructions three types uncon ditional transfer changes control counter reading question two conditional instructions require either equality specific inequality exists words aregister lregister former case quan tities must identical transfer control occur latter quantity aregister must greater quantity lregister control counter reading changed since univac handle alphabetic well numerical data conditional transfer instructions useful alpha betizing determine certain iterative arithmetic process performed often enough come within specified numerical tolerances control register since six characters intermixed alphabetic numerical sufficient specify instruction 12 characters per word instruction word represent two independent structions 1word register called control register cr provided stores instruction word comes memory thus one memory referral sufficient pair instructions control register stores halves second instruction available soon first com pleted general term control circuits includes elements work together process instruction routine instruction word reaches control register first half passed immediately static register sr static register drives main function table memory switch instruction digits translated function table appropriate control signals instruction called memory switch selects location called memory location digits opens proper memory channel high speed bus system proper time since memory con structed 100 channels holding ten words memory switch combination spatial temporal selection cycle counter implicit within instruction translated function table ending signal causes computer move next instruction key sequence cycle counter cy advanced ending pulse cycle counter 2stage 4position counter connected function table virtue relation cy develops signals addition developed instruction ex ample cause control register transfer second half instruction word static register first half completed similarly second half instruction finished cycle counter causes reading control counter pass memory location section static register thus cause next instruction word transferred memory control register word reaches control register cycle counter also causes control counter reading increased unity four cycles designated first four greek letters transfer cc sr 8 transfer memory cr perform first instruction perform second instruction program counter multistage instructions multiplication guided various steps program counter pc program counter four stages 16 positions multistage instructions performed within number steps checking circuits checking circuits univac two main types oddeven checkers duplicated equipment comparison circuits oddeven checker depends upon design pulse code used within computer code provides seven pulse positions every character six seven positions significant actual code seventh oddeven channel number pulses ones within first six chan nels character even one placed seventh channel make total odd thus total number ones across seven channels always odd means binary counter gates oddeven checker constructed examines every seven pulse group passes high speed bus amplifier connection mention must made periodic memory check interrupts operation every five seconds pass entire contents memory high speed bus system consequently oddeven checker discrepancy immediately signalled super visory control operation ceases duplicated equipment type checking consists dupli cating essential part arithmetic circuits controls producing simultaneously independent results compared equality type checking f x lregisters algebraic adder comparator multi chapter 8 univac system 161 plierquotient counter high speed bus amplifier dupli cated memory duplicated checked periodic memory check mentioned previously various sections con trol circuits duplicated program counter cycle counter timing pulse generator cycling unit timing pulse generator cycling unit cu source basic timing signals throughout computer timing pulses occur 225 megacycles per second cycling unit subdivides rate character rate word rate character rate one seventh basic pulse rate since seven pulses character 12 characters per word space 13th character included word time called space words time used switching purposes cycling unit therefore develops word signals y7 x yl3 ys1 basic pulse rate within cycling unit cu numerous duplications comparisons ensure com plete reliability inputoutput circuits operation inputoutput system dovetailed effi ciently possible operation arithmetic circuits whenever possible parallel operations allowed proceed minimize time lost internal operation slower inputoutput operations taking place principal inputoutput instructions handled man ner identical internal operations except function table develops signals bring inputoutput control circuits operation information supplied inputoutput control circuits function table includes following 1 2 ten possible uniservos called whether read write input output operation ﬁreadﬂ direction tape move 3 inputoutput control circuits therefore begin testing whether uniservo indicated use already use everything else waits uniservo free next inputoutput control circuits test determine whether uniservo selected last moved backward forward previous direction agree new direction called inputoutput control circuits generate proper signals prepare uniservo move opposite direction instruction rewind uniservo inputoutput control circuits direct center drive selected uniservo rewind tape beginning stop soon instruction proceeded point inputoutput control circuits need information function table instruction ending signal generated internal circuits proceed next instruction even reading writing rewinding continues univac process input output several rewind operations simultaneously carrying internal computation far method words transferred iregister memory mentioned opera tion combined certain read instructions manner immediately obvious two instructions read tape iregister one causing tape move forward causing move backward two input instructions similar mentioned additional operation first reading iregister memory reading new group 60 words tape iregister thus first type input instruction reads tape iregister must followed second type instruction order first clear iregister read second block 60 words output instructions operate way instead read directly memory 0register tape one instruction third type checking circuit occurs inputoutput control circuits counts number characters transferred tape block since must always 720 characters per block 720 checker signals discrepancy supervisory control one phase inputoutput operation concerns two supervisory control inputoutput instructions one permits single word typed input keyboard causes single word typed automatically auxiliary equipment two principal auxiliary devices mentioned earlier unityperl converts keyboard operations tape recording uniprinterl converts magnetic recording type written copy lregistered trade mark 162 part 2 instructionset processor mainline computers section 1 processors one address per instruction unityper simple block diagram unityper shown fig 2 keyboard operation pulses input encoding func tion table turn drives appropriate heads record ing particular combination tape simultaneously pulse triggers motor delay flop operates tape motor interval sufficient move tape across head distance required record one character however punched paper loop system associated unityper purpose providing typist various guideposts individ ually set problem loop control system serves three distinct control functions first allows programmer set various numbers characters individual items entered given problem typist ever enters specified number characters loop control signals error although basic word length 12 characters pro grammer may subdivide group words suit length item loop punched called ﬁforce checkﬂ punches whenever typist completes correctly en tered item must operate release key entering next item forced check released early error created additional character typed forced check released error similarly indicated second function loop control erase opera tion erase operation way error recalled erase key operated loop tape keyboard el l encoding function table recording head relays fig 2 simplified block diagram unityper stepped backward stop punch usually associated forced check encountered thus entire erroneous item erased much higher rate backspace key operated backspace incidentally cancel error indication used correct wrongly typed character typist recognizes third function loop system enter automatically various fillin characters one system operation loop control records characters behest oper ator function useful individual entries personal names fill space allotted operation fully automatic loop assumes full control record example group fillin characters later replaced computed data within central computer block diagram therefore shows loop motor connected delay flop steps tape motor signal moves two motors also sets second delay flop df2 produces delayed probing pulse probing pulse exam ines paper loop photoelectrically new combination third delay flop df3 produces another probing pulse relays associated loop photocells time set automatic function indicated photocells probing pulse passes interpreting relays enters encoding function table generate fillin characters thus starts cycle automatic functions take place 22 characters per second numerous oddeven checks introduced unityper provide checks tape loop motion recorded code combination uniprinter uniprinter shown simplified block diagram fig 3 operation simple cycle initiated start button start button triggers motor flipflop mff motor pulls tape across reading head combina tion detected presence pulses seven lines reading head relay decoding function table sufficient restore motor flipflop mff stop tape motion simultaneously print delay flop df1 triggered delay flop interval decoding relays given time set delay flop recovers pulse sent relay table reappears one typewriter magnetic actuators typebar reaches platen printer action switch pas operated pulses motor flipflop starts new search next character tape oddeven properties univac pulse code utilized checking purposes chapter 8 univac system 163 fig 3 simplified block diagram uniprinter engineering aspects entire univac system constructed circuits conservative consistent desired reliability speeds operation circuits designed building blocks entire computer constructed around blocks one important blocks pulse reshap ing circuit consists timing pulse gate fast acting flipflop generates pulse envelope equivalent gated timing pulses two polarities timing pulse used one capable tripping flipflop one state polarity tripping state deteriorated pulse envelope applied timing pulse gate input either one polarity pulse always gated flipflop therefore produces sharpened correctly timed output waveform gating switching circuits central computer constructed germanium crystal diodes include main subordinate function tables registers circulating delay type using mercury tank one two ten wordtimes delay except static register latter composed 27 flipflops required maintain static signals applied function tables least entire wordtime switching time allowed seven pulsetimes space words general sufficient new func tion table excitation stabilize therefore timeout system used successfully binac also employed univac whenever ending pulse generated pulse indicates new set control signals required function table interval one wordtime introduced allow function table signals reach equilibrium timeout terval controlled single fastacting flipflop gates attached function table signals critical opening closing inhibited timeout flipflop time regardless presence function table signals gate operate timeout flipflop leases thus burden speed imposed short space words shifted single flipflop accommodate needs entire computer univac uses excessthree pulse code system requires second binary adder main binary adder order provide excessthree correction addition side ledger complementing operation sub traction division much simplified since substitution ones zeros vice versa sufficient form complement excessthree part pulse code occupies four least significant digit positions next two positions beyond excessthree digits used zone indicators digits zero last four positions interpreted numerical quantity nonzero alphabetic punctuation symbol indicated seventh channel check pulse channel adder provided alphabetic bypass circuit allows alphabetic letter enter one input emerge un scathed provided numeral enters input thus additive numerical constants combined instruction words adjust memory location part instruction without affecting alphabetic instruction symbols power supply computer separately housed placed reasonable distance central computer almost rectification done dry disc rectifiers power supply provides ac dc potentials central computer supervisory control directlyconnected printer uniservos complete fusing system included serves protection shortcircuit isolating means section 39 locally fused enabling engineer locate short within 12 chassis rather total 468 automatic voltage monitoring system may used test every dc voltage rate one per second meter movement relay signals discrepancy standard similarly overheat thermostats detect unfavorable temperature condition bays mercury tanks cooling power supply central computer provided three blowers local cooling uniservos provided small fans unit operating statistics univac follows 164 part 2 1 instructionset processor mainline computers section 1 1 processors one address per instruction tape reading recording pulse density 120 per inch tape speed 108 inches per second input block size 60 words 720 characters tape width z inch 8 channels internal operations memory capacity 1000 words 12000 characters memory construction 100 mercury channels 10 words channel access time average 202 microseconds maximum 404 microseconds word length 12 characters 9 pulses include space words 7 pulses basic pulse rate 225 megacycles addition 525 microseconds subtraction 525 microseconds multiplication 2150 microseconds division 3890 microseconds times shown include time obtaining instructions operands memory applications univac types problems univac applicable true name universal automatic computer univac system capable handling data processing calculation virtually fields human endeavor particularly well suited applications requiring large volumes input output data convenience classification applications univac treated four headings scientific statistical logistical commercial scientific problem usually though al ways relatively small amounts input output data emphasis computation statistical problem relatively large volumes input data small volume output data simple processing procedures commercial logistical problems relatively large amounts input output data processing requirements varying slight relatively great number problems four fields studied found suited solution univac system several field actually processed com puter scientific problems generalpurpose matrix algebra routine designed add sub tract multiply reciprocate matrices orders 300 prepared applied number matrices inverses calculated three different matrices orders 40 50 44 error matrices first two inverses also calculated largest error term order 1w8 triple product matrix formed component matrices ranging 5 40 40 40 check product obtained reversing sequence multiplications verifying original product within 2 units 11th place computer time required calculations 1 hour 15 minutes calculate inverse order 5045 minutes determine error matrix calculations proportionately shorter work magnetic tapes used temporary storage bulk matrix elements involved high speed tape reading units kept computers need data mathematical checks overall check mentioned included computation selfchecking features system making completely unnecessary second computationthat obtaining six different specific solutions system 385 simultaneous equationswas com pleted 27 minutes computer system equations arose second order nonlinear differential equation gas flow turbine error terms resulting sub stitution computed unknowns basic equation order third example 2dimensional poisson equation using 22 22 mesh iteration required 13 seconds produced maximum separation successive surfaces order 10 approximately 300 iterations statistical problems second major field statistical computation census problem prime example census problem produces part second series population tables 1950 decennial census second series contains 30 types tables covering statistics populationage sex race country birth edu cation occupation employment income tables compiled every county every city rural farm rural nonfarm area within county preparation tables univac system requires three major steps 1 tabulation individuals characteristics groups 7000 chapter 8 1 univac system 165 2 3 arranging groups cities counties assembling tabulations data required table raw data prepared form punched card individual united states data enumeration cards transcribed onto magnetic tape tapes computer processes data sequentially three steps producing output tapes tables printed uniprinters manual operations encountered entire procedure handling original punched cards mounting demounting tape reel equivalent 9700 cards removal printed tables uniprinters important feature present procedure elim ination handling sorting tremendous quantities punched cards handling card stacks source potential error delay univac memory permits simultaneous accumulation 580 tallies describe population local area studied univac system commercial problems commercial field univac system handled premium billing life insurance company program produces pre mium notices dividends commissions particular example worked approximately 1000000 bills 340000 dividends 100000 commissions produced monthly necessary information processing particular policy contained 240 digits special cases 480 compactness made possible logical system 40 symbols comprising alphabetic numeric characters denote 90 definitions uni vac processes policies directed symbols policy dates policy numbers problem includes inserting 250000 changes month handling done step policies processed selected file 1500000 items next list produced cases symbols indicating special notices must sent policyholders following calculation dividends commissions additional lists pro duced one group contains information pertaining commissions agents another contains information regarding dividends finally listing option changes later insertion policy files policies requiring premium notices edited notices automatically printed data contained magnetic tapes univac time needed program proportion 135 hours month average computer time per policy processed less 05 second average time change insertions printing calculations unityping 9 seconds per item logistical problems field logistics five major studies conducted four resulting actual problems executed com puter first type computation basic purpose determine quantitively whether given operational mobi lization plan logistically supported ultimate desired find calculation optimum program carrying plans time writing small model actually run univac full size models run within next weeks two computations executed one set three tables thousands lines giving detailed breakdown machine deployment fuel requirements haul requirements problem computation amounts critical raw materials required construct given number type equipment requirements phased quarters 2year period fourth problem actually computed sample similar calcu lation every pound critical raw material required month ultimate construction complete building pro gram computed univac program prepared capable accommodating every type equipment individually tailored construction schedules detailed hills materials running millions items determining actual amounts alloy elements based thousands tables percentages many alloys employed demonstration showed computation 400 pieces equipment given type could executed three hours computer time last problem field yet run study shown entire gamut stock control large supply office covered computer approximately 3 weeks time program involves maintenance stock balances hundreds thousands stock items many service points provides preparation stock transfer orders purchase requisitions critical lists summary reports performance record univac acceptance tests acceptance tests prepared jointly bureau standards bureau census fully discussed following paper dr alexander mr mcphers0nl however comments lpaper included book see mcpherson alexander 1951 166 part 2 instructionset processor mainline computers section 1 processors one address per instruction concerning engineering point view appro priate census computer given two tests first test computational ability second test inputoutput system particularly stressed tape reading recording abilities central computer acceptance test consisted two parts part 1 every available internal operation except inputoutput operations performed among operations addition subtraction comparisons division three different types multiplication operations arith metic operations handled pair 11decimal digit quantities altogether 2500 operations routine yet entire routine required 126 seconds routine performed 808 times 17 minutes making total 2000000 operations second part test included solution heat distribution equation short routine involving inputoutput device sorting routine sorting routine arranged ten numerical quantities containing 12 decimal digits correct numerical order 02 second three routines took total 1 minutes perform performed twice test added part 1 made total 20 minutes unit test acceptance test b examined inputoutput tape devices uniservos first part test b 2000 blocks 14 million digits included every available character numeric alphabetic recorded tape read back computer tape moving backward information read back compared original data read recording operation required 4 minutes reading back comparison required 8 minutes sec ond part test b consisted recording reading one spot tape 700 passes order determine readability tape wears test required 13 minutes com bined part 1 made total approximately 25 minutes test b test repeated 19 times first test run passed 66 hours minimum theoretical time 60 hours second test passed 947 hours minimum theoretical time 745 hours 202 hours time 145 hours accumulated one time remaining 058 hours spread rest test uniprinter test required block information 60 words printed 200 times tabular form minimum time printing five hours test passed 616 hours cardtotape test required ten good reels tape produced 12 hours certain restrictions reading accuracy criteria reproducing ability defined ﬁgoodﬂ reels 10 hours converter prepared 15 reels 14 reels tested 11 14 found satisfactory converter accepted payment although test run one two converters bureau census put cardtotape machines operation six months use acceptance test run second cardtotape converter test differed extent first test census bureau satisfied reading ability machines require digitby digit verification information however new stipulation added engineers checked converter preparatory running test converter used actual operation eight hours remainder test engineering intervention two portions test first part run friday october 5 1951 device remained idle saturday sunday turned monday morning complete test passed flying colors preparing ten acceptable reels ten reels plus two decks check cards slightly less 7 hours cardtotape converters washington remainder system operation bureau census eckertmauchly premises philadelphia reliability factors affecting performance first univac system operating approxi mately 8 months time much learned univacs operated maintained situation somewhat complicated shake equip ment customers possession certain faults system engineering production stand points could become apparent course time actual operation conditions example weak tubes faulty solder joints reveal presence time installation another type difficulty became apparent certain duty cycle conditions imposed various types problems certain problems present particular duty cycle troubles remained machine causing inter mittent stoppages could tracked patient isolation elimination problems occurred conditions operation infre quently encountered powerful though sometimes painful proving ground engineering group charged sponsibility experience depth judgment acquired group course performing work become unmistakably apparent already noted improved performance following univacs generally advanced ability predict chapter 8 1 univac system 167 realize performance large scale complex apparatus character troubles encountered interesting study detail rather complicated routine requiring use number uniservos ran smoothly 15 minutes time one uniservos executing backward read somewhere middle reel stop end block con tinued run ran end tape much work shown cycling unit signal overloaded used multiplication instruction backward read occurring simultaneously input precessor loop cleared result count pulses coming tape thereby lost trouble found simple remedy another rather interesting case occurred intermittently extended period normally reading memory contents cleared occasionally however reading memory also caused contents cleared trouble remained period seconds minutes somewhat difficult localize course parasitic oscillations sort suspected fact trouble traced actual source logical basis source high power cathode follower showed evidence oscillation problem remedied various combinations para sitic suppressors tried trouble would vanish perhaps week return oscillation finally cropped maintenance shift found suspect tube 100 megacycles eliminated rather easily types troubles occurred include intermittent parasitic oscillations circuits bounce uniservo relay circuits various mechanical problems uniservos time constants consistent longest duty cycle signals various types noise input circuits tubes initially bothersome stabilized point two tubes per week average stop computer computation troubles others discussed contributed lost computing time univac however influence future operation reasons found eliminated fact troubles occur future univacs emphasized strongly contract bureau census eckertmauchly computer corporation maintains census installation system operated 24 hours day seven days week except four 8hour preventive maintenance shifts week allows approximately 32 hours regular maintenance 136 hours operation 21 79 per cent respectively table 1 shows engineering time spent computer system typical weeks operation figures given hours per centages nonscheduled engineering time well preven tive maintenance time shown sum two gives total engineering time spent computer per week noted actual engineering time include time computer may shut waiting engineer report according maintenance contract must within half hour regular working hours within two hours times attention given fact preventive maintenance time total exactly 32 hours week due part halfhour period morning devoted checking cleaning mechanical portions uniservos expected work taken univac operators since procedures techniques involved quite simple addition one extra shift required week ending june 3 three extra shifts week ending october 7 1951 shifts required incorporate engineering changes developed period time could incor porated equipment normal preventive main table 1 btd week nomcheduled precentiue engineering rrcentuge nonscheduled ending enginvering muintenunce tinw 1951 zlours per cent hours per cent hours per cent engineering june 3 189 26 205 july 14 147 21 194 28 392 aug 4 262 sept 2 288 9 161 16 226 23 423 30 218 oct 7 159 14 140 21 104 28 208 nov 4 404 11 101 18 305 25 137 dec 2 148 9 196 113 122 88 116 233 156 171 96 135 252 130 95 83 62 124 240 60 182 82 87 117 40 238 34 202 33 196 345 205 345 205 33 196 345 205 345 205 33 196 345 205 345 205 56 333 345 205 345 205 33 196 345 205 345 205 345 205 345 205 345 205 345 205 589 545 477 539 737 592 633 506 556 768 563 719 485 449 538 749 446 65 48 493 541 351 148 32 153 28 109 32 145 438 294 352 194 377 216 30 121 33 167 457 317 335 163 428 142 289 105 267 78 32 154 446 303 265 76 387 22 286 10 293 126 322 147 168 part 2 instructionset processor mainline computers section 1 1 processors one address per instruction tenance time nonscheduled engineering time varied little 101 hours 6 per cent 423 hours 25 per cent last column table shows amount nonscheduled engineering time compared allowable operating time total time less preventive maintenance time variation 76 317 per cent average weeks shown 169 per cent believed figures good first months operation new piece equipment show definite improvement next year although opportunity prove disprove following theory operation presented believed logical optimum use univac equipment might obtained means scheduling preventive maintenance times indicated judgment competent operators words many occasions preceding scheduled main tenance shift system performing well times extremely inefficient shut operation order provide maintenance many reasons however impossible operate maintain first system way hoped operation possible following installations realized univac system requires super visor caliber one required large punched card installation however large group operating personnel would replaced small group welltrained extremely competent people thoroughly familiar details computer associated equipment time spent providing high degree training people repaid increased operating efficiency consequently higher work put example situations arise course running prob lem correct operational decision save hours elapsed computation also competent operator recognize malfunc tions sufficiently early prevent serious delays capable deciding whether continue machine operation stop diagnose second univac system ready installation washington operated group engi neers trained operation maintenance procedure believed result univac system maximum benefit air comptrollers office evaluation univac design checking features maintenance univac vastly simplified use duplicate arithmetic control equipment checking methods many factors would led undetected errors virtue duplication immediately stopped computer although checking means inverse operations provide operational checks arithmetic circuits ques tion whether provides good check duplication however connection oddeven codes may conceivably comparable remembered however operational standpoint maintenance standpoint control equipment considered difficult visualize check good duplicated equipment checks ed univac include periodic memory check intermediate line function table checker function table output checker memory switch checker 720 checker explained earlier paper periodic memory check accomplished reading memory channels sequen tially performing oddeven check digit passes high speed bus amplifier period check repeated may varied large interval present set 5 seconds check taking 52 milliseconds 1 per cent computing time function table check input bringing check pulse character oddeven error occurs control register static register order set computer grind halt input sets properly error occurs farther table ahead intermediate lines linear set input combinations decoded error caught point intermediate lines broken groups way error indicated one line set one group entire set exception groups error indicated checker one line set within group allowed cases shown setting two lines cause checker checkers indicate trouble error occurs beyond intermediate lines output checker comes play checker makes oddeven count number gates used instruction dummy lines added count normally always odd memory switch tank selector checker ensures one one memory channel selected instruction checks two digit positions separately indicating either error 720 checker counts digits coming tape either less 720 one block computer stops examining indicators supervisory control console operator determine number digits actually chapter 8 1 univac system 169 read means rather simple manipulations operator reread block without losing place routine information read correctly may start computer routine procedure may followed oddeven error made reading tape many checks mentioned built univac basis operating experience engineers recommend strongly use builtin checking facilities faith put results obtained unchecked computer comparable size univac writers opinion exceedingly low however methods univac checked extreme usefulness trouble shooting duplication circuits amply repaid increase space number components required checking system general comments evaluating univac performance period eight months overall picture univac design minds designers extremely good certain phases design exceeded expectations course phases disappointing first eight months actual operation taught years experimentation laboratory models many improvements already conceived experience continuing daily increase reliability major factor influencing computer design cost duly considered univac design met plans continuing fullscale production univac sys tems production techniques developed concurrently engineering design details univac becomes realization hope long minds designers economical completely reliable commercial com puter performing routine mental work world much automatic machinery taken routine mechanical work manufacturer references mcphj51 section 2 processors general register state processors described section processor state consisting registers used multiple ie general purposes perhaps better name might processors state consisting register arrays following machines fairly similar isp structure pegasus chap 9 dec pdp610 sds sigma 5 7 univac 1107 1108 however computers includ ing 8bit character computer chap 10 cdc 6600 chap 39 also use arrays registers general register organization appears compromise 1 2 address organizations avoids extra instructions shuffling data inherent 1 address system avoids taking space full additional address index register organization also compromise one specialized address calculations general register organization moves toward full 2 address organization without much additional cost assumes small relative cost small amount memory sig nificantly faster larger mp design philosophy pegasus quantityproduction computer chapter 9 describes pegasuss logical organization technology implemented technology includes vacuum tubes cyclic memory dynamic logic based delay lines pegasus nicest isp processor structure discussed sectionperhaps book included probably first machine use array general registers accumulators multiplierquotient regis ters index registers etc isp organization com pared ibm system360 chap 43 note multipleregister organization independent mpcyclic organization improves performance generality structure system360 part ioutline logical structure ibm system360 described part 6 sec 3 included mainly large number systems built 8bitcharacter computer computer chap 10 invented authors show composite features small characterwordoriented computer reality 8bit machines turn look either like 16bit machines mp size accessed usually 28 words like characterstring processors primitive nature machine possible alternative larger complex microprogrammed processors defining complex isps parallel operation control data 6600 cdc 6600 described chap 39 three arrays eight registers two arrays used rather generally third array used access words mp design cdc 6600 classic computing power provides also worth studying example pc assigned exclusively data operation concern larger pms structure located pios discussion given part 5 sec 4 page 470 170 chapter 9 design philosophy pegasus quantityproduction computer1 w elliott c e owen c h devonald b g maudsley summary paper gives historical account development packaged method construction computers advantages method discussed packages used computer pegasus described electronic mechanical point view specification machine given arguments led specification discussed detailed logical design procedure leading specification wiring lists described method maintenance reliability fipres given introduction development standard plugin unit circuits packages digital computers began country england 1947 advantages method discussed earlier papers elliott 1951 johnston 1952 elliott et al 1952 elliott et al 19531 advantages start design stage new computer project follow production com missioning maintenance design stage known logical design sepa rated engineering design packages designed electronic engineers rules inter connection laid logical designers usually necessarily mathematicians begin organizing packages various computers carry different functional requirements electronic mechanical design work invested packages thus drawn one computer design computer assembled stock parts without engineering effort design time cost fore much reduced production whether consider one design computer several designs using packages costs time also much reduced quantity production lines relatively types standard package set common different computer designs thus reducing inspection planning costs standard cabinet work designed pegasus prjc iee pt 3 vol 103 supp 2 pp 188196 1956 taken stock established production lines make computers commissioning computer packages pretested power first applied complete machine known large part already faultfree remains detect errors may made interconnections perhaps even important consideration ease speed maintenance test programmes usually indicate part machine fault occurring several monitor sockets located front package inspection faulty package speedily found replaced package method criticized grounds cost questionable reliability plugs sockets redundancy components authors believe many advantages far outweigh cost plugs sockets present trend use copper etched printed circuits fall naturally plugin unit idea plug contacts part printed wiring trouble pegasus plugs sockets component redundancy pegasus 10 diodes resistors cost redundant components 2 150 electrical design packages circuits used arithmetic switching operations historical previous dataprocessing machine elliott et al 1952 elliott et al 1956bl used 330 kcs serialdigital circuits originally designed 1 mcs operation 330 kcs waschosen suit anticipationpulse cathoderaytube store frequency retained present time suits magnetostriction delayline store fairclough 19561 magneticdrum store merry maudsley 19561 experience data processor led work commenced 1951 new set circuits elliott et al 19521 particular emphasis 171 172 part 2 1 instructionset processor mainline computers section 2 processors general register state laid flexibility use ability work without error high electrical interference fields circuits form basis pegasus operations carried following wellknown opera tions used build logical structure computer operation may carried two input serial trains pulses produces output train pulses occur pulses present time inputs operation produces output train pulses occur times pulse present number inputs 1s changed 0s 0s 1s achieved inverting pulse train digit delay passing pulse train digit delay produces pulse train similar input pulse one pulse position later timing restandard ized shape b c operations computer including addition subtraction staticizing carried combinations elements circuit specifically addition general flipflops often used staticizing storing single digit similar philosophy arrived independently designers seac dyseac elbourne witt 19531 bnt detailed working considerably different digit wavefoms timing digit pulses throughout chine controlled common clock waveforma 3 micro sec square wave fig la positivegoing portions define digit positions digit pulses routed machine ap plied logical circuits generally form shown fig lh generated leading edges well advance clock pulse greater amplitude means considerable distortion pulse tolerable since portion coincides positive clock pulse conse quence digit pulse trains clocked operation clock entry storage system digitdelay circuit inverted pulses also employed illustration consider operation b pulses b fig 1 two lines nominal timing wish form b symbolic representation b pulse b inverted forming b b used gate pulse prevent passage inverted pulse little late b also may later shown fig ic thus b anded together spike may pro duced shown fig le spike however lies clock pulses rejected clocking pulse system used allows several logical operations performed cascade without loss nominal timing easing problem logical design particularly permitting thoughts maximum number logical operations performed 2 3 volts j 15 sec 10 11 volts fig 1 basic waveforms chapter 9 design philosophy pegasus quantityproduction computer 173 b zoo volts t200 volts 200 voi ts 470 kfi input clock zoo volts zoo volt 330ksz clock 150 volts ai ﬁ2 output 1 output 2 bl reset 150 150150 ﬁdits yolts yolts fig 2 digitdelay circuit cascade pegasus five though 12 could performed special circumstances logicul circuits logical packages one circuit unit circuit unit defined part package input output pins connections parts package supplies may make following generalizations h unit gate input unit cathodefollower output half 12at7 valve unit additional output via germanium diode making gate connections c note exceptions c one package type three possibilities part circuit unit input gate output cathodefollower namely digit delay half 12at7 valve inverter half 12at7 valve direct connection space permit description circuits proposed deal digit delay circuit shown fig 2 typical waveforms shown fig 3 input circuit two forms namely 3input gate two gates outputs ored together cases gating clock pulse clocked digits gate input circuit applied grid vi anode voltage falls building current l vi cut end digit current flows diodes charges storage condenser c discharged end next clock pulse reset pulse applied reset pulse supply common computer supply whose amplitude phasing relative clock pulse shown fig 3 noted reset pulse also present time v cut current inductor charge storage condenser merely effect deferring charging c end reset pulse 10 volts c approximate fig 3 digitdelay waveforms 174 part 2 instructionset processor mainline computers section 2 processors general register state current meantime continuing flow diodes little loss stored energy l since voltage across l low time output cathodefollower v caught 10 volts negative direction diode safeguards crystaldiode circuits driven event failure ht supply v removes residual ripple bottom input waveform thus reduces back voltage hence leakage diodes gates driven output second output diode used conjunction similar outputs circuits resistor pins 3 4 make 16way general output circuit two available load resistors disposed direct outputs according set rules applied case number units driven output vary three 16 according circumstances driven rules allow use made booster cathodefollowers available one packages examples use logical circuits two examples given first simple arrange mentthe staticixorwhich used frequently second complicated arrangementthe addersubtracterwhich used infrequently symbols used indicate circuit units shown figs 2c 5h staficizor function staticizor remember fact digit occurred particular time indefinite period method generally used pegasus shown fig 4 digit delay twin gate input output con nected one inputs turned gate 1 causes digit circulate long inputs gate 2 remain positive staticizor turned either leads negative staticiror set leads positive r fig 4 staticizor xy xy delayed one carry add subtroct suppression cathode inverter digit gate follower delay b fig 5 addersubtracter normally turned inverted pulse 0 following series 1s one gate 2 inputs addersubtracter figure 5 shows addersubtracter unit inputs x output x sum x difference two input control leads marked add subtract add lead held positive subtract lead held negative unit acts adder subtract lead held positive add lead negative unit acts subtracter carry suppression controlled lead marked carry suppression carries allowed propa gate lead held positive negative signal lead snppress carry table 1 gives digits appearing outputs logical elements addersubtracter unit combinations input carry digits unit operating adder arrangement circuits bused packages required base logical circuits oii standard size package could also used circuits eg nickel line 1word store fairclough 19561 unit could accom modate three valves 32way plug decided chapter 9 design philosophy pegasus quantityproduction computer 175 table 1 set add combinations input carry digits digits various internal points addersubtracter unit present digits internal points digit b c def inputs digits carry sum next xy z carry 00 00 01 01 10 10 11 11 0 1 0 100 1 1 0 110 1 1 0 110 0 1 1 010 1 1 0 101 0 0 1 111 0 0 1 111 1 1 1 011 notea care grids digit delay units problem arrange various circuits way enable computer designed using minimum total number packages without many types five types arrived shown fig 6 example factors involved consider package types ww note clock connections shown implied whenever delay symbol used u 1 2 circuit units based package type 1 perform functions type 2 however many uses digitdelay circuit single gate input package type 2 since three units kind instead two 2 andgate input delay based one package saving effected pegasus saving amounts 32 packages considered well worth extra package type addition five logical packages 16 types three peculiar computer required numbers used various functions given number type 1 113 type 2 64 logical types type 3 55 type 4 45 type 8 37 61 38 17 14 total 444 nickel line 1 word store drumstore packages 8 types inputoutput packages 3 types clock reset waveforms 3 types fig 6 contents logical packages arrowhead output lead denotes presence crystal connection 176 part 2 instructionset processor mainline computers section 2 processors general register state magneticdrum store circuit packages used described another paper merry maudsley 19561 nickelline store fairclough 19561 mechanical design packages general form standard package consists three main parts namely valve panel component panel plug valve panel aluminium pressing three typesa 3valve type 2valve type blank package type number marked panel two dots according standard resistor colour code component panel houses 100 components including small transformers chokes coils panel handle made one piece sheet insulating material design provides minimum resistance airflow valves gives ample protection valves accidental dam age plugs sockets used multiples eight connec tions packages four plugs providing 32 connec tions 64 possible package plug contacts made brass heavily silverplated socket uses proprietary valveholder contact readily replaced damaged sockets plugs fig 7 standard package combination plug socket consistently low contact resistance 0003 ohm 1 amp insertion drawal force 4 oz per contact wiring packages present packages wired soldered hand wiring pointtopoint within limitations layout efficient performance wire lengths standardized mass production automatic wirecutting stripping machines symmetry eyelet positions makes possible use components preformed standard pitch would allow automatic preforming insertion components experimental packages produced photoetched wiring dip soldering specification computer pegasus summary specijication detailed specification would cover ground program ming manual pegasus programming manual ferranti ltd london would place pegasus binary serialdigital computer word length 42 binary digits 39 digits used number sign negative numbers represented complements respect two one digit used parity check two gap digits length order 19 binary digits one word may consist two orders remaining digit stopgo digit stopgo digit v computer stop obeying orders word proceed unhindered digit 1 2level store magnetic drum holding 5120 words immediateaccess computing store 55 singleword magnetostriction delay lines order made seven ndigits three xdigits six fdigits three mdigits ndigits significant mdigits least significant ndigits allow 128 addresses immediateaccess store 63 used reg isters store shown fig 8 xdigits refer one accumulators registers corresponding naddresses 07 thus order code 2address code one address referring limited part store fdigits indicate function order list functions correspond ing f values given appendix chapter mdigits indicate modifier order select one accumula tors modification process add certain parts contents selected accumulator order chapter 9 design philosophy pegasus quantityproduction computer 177 e 8 z 8 9 name address notes register register block trwyers main store 1 0 always zero single word transfe accumulators 2 orxregister 3 4 registers 5 used 6 modification 7 double length hand switches 20 digits i1 inputoutput checked 5 digits special iﬁ l7 unchecked 5 digits bcock 0 block 1 block2 block3 block4 block 5 always 10 always tl0 registers 32 33 always always 213 07 10 rogrammers notation fig 8 allocation addresses store obeyed part chosen depending function order modified figure 9 gives schematic representation modification process effect modifying order depends function order make effective order length 22 digits extension necessary specifying address main store transfers information take place computing store main store vice versa either single words blocks eight words singleword transfers register address 1 computing store involved block transfers address drum first word block must divisible eight registers computing store involved one discrete blocks indicated fig 8 input output means punched paper tape exter nal conditioning order included code enable choice input output equipment made standard machine two tape readers used stored information checked read means parity digit total number 1s correctly stored word odd input output decimal characters tape checked similar process considerations led specification logical design main features design use computing store orders numbers taken computing provision multiple accumulators provision special orders facilities dealing easily red tapel b c computing store use fastaccess store numbers orders taken increases speed machine eliminates need optimum programming computing store makes possible use inexpen sive magnetic drum relatively long access time main store yet machine fast relatively simple programme hand programmes red tape simple singlelevel storage transfer levels blocks eight words simplification saves time one block holds reasonable amount programme blocks hold data four blocks 32 words would sufficient pegasus originally de signed number design subsequently modified six blocks quite adequate conjunction seven accumulators increase size com puting store would achieved increasing size number blocks economic balance usefulness cost computing store ﬁred tape expression nonarithmetic orders programme shaded portion added order full 13 dlglts always appear x registers significance sionifiunt digit corresponds 2i least significant 213 functions 0037 functions 4061 funcllons loli7413 functlons 7131671 0 fig 9 ordermodification process 178 part 2 1 instructionset processor mainline computers section 2 processors general register state procision several accumulators novel feature logical design pegasus generally agreed simplest order code users aspect 3address code orders form b c examination form code however shows many cases two ad dresses order takes 2address form h 4 examination shows large propor tion cases address confined addresses leads suggestion code form n xt x x covers small part store n covers whole store advantage yielding reasonably short order pegasus two orders incorporated one word leaving sufficient digits specify modification register mancunian bline order extreme case code course singleaddress code x confined one address accumulator ever experience convinced programmers collaborating design pegasus singleaddress codes large number orders concerned 50kly transfers numbers one register another single accumulator restriction numbers must pass operations performed manchester university computer blines serve two valuable distinct purposes allow order modification rudimentary arithmetic counting done without disturbing accumulator felt fuller arithmetic logical facilities blines would extremely valu able seven accumulators pegasus used modification arithmetic development bline concept special facilities dealing red tape difficulties asso ciated 2level storage system greatly reduced ordermodification procedure depends function order fig 9 method modifying orders used conjunction order 66 code unitmodify order enables counting blocks information done relative ease use group4 orders code enables counters set conveniently constant 127 placed accumulator constant value ndigits order order 67 unitcount order enables counting cycles operations dealt simple way jump another part programme programmed take place automatically required number cycles performed large number jump instructions greatly helps organizing programme particular one order enables jump made depending condition accumulator zero example another order complementary con dition zero one orders available necessary think ahead see whether correct condition satisfied although eight jump instructions included code felt initially enough suggested programmers even orders would helpful logical shift orders 52 53 also included simplify red tape particular used packing unpacking words holding several items information result including various orders order code pegasus quite large worth remarking however sensible grouping orders code remembering code simple task sensible arrangement code tends reduce amount equipment needed engineer example equipment dealing group 0 code allocated groups 1 4 require addition three gates facilities checking programmes features mentioned make computer easier programme facilities pegasus make easier check develop new programmes include causing machine stop obeying orders either programme control programme error particular machine stops order writing main store reached overflow indicator set aid testing new programmes automatic punching mainstore addresses appearing block transfer orders information examined indication course programme readily obtained punching inhibited switch return fullspeed running needed machine rhythm logical design pegasus built around nucleus deals simple arithmetic orders groups 0 1 4 code nucleus contains control section ie order register order decoding equipment mill orders executed design nucleus could begin basic rhythm dealing extraction computing store execution pair determined outline nucleus clear equipment dealing remaining orders code designed fit chapter 9 design philosophy pegasus quantityproduction computer 179 following arguments led basic rhythm since orders groups 0 1 4 similar many respects definiteness sufficient consider particular order 11 code say order takes two numbers computing store replaces one sum would take prohibitive amount equipment extract numbers add together least significant digit sum available replacing store digit time least significant digits two components taken store practice four digit times least would needed sequence operations thus would im possible return sum store word operands extracted without entry point register different timing normal circulation entry produce two entry points register would mean equipment associated register considered uneconomical use extra equipment instead decided delay sum could enter register computing store next word time standard timing involves one common delaying circuit instead one every register order therefore takes two word times execute may argued second word time could made overlap first word time next order two reasons oppose new contents register changed might required next order two different sets equipment selecting storage register would needed numbers extracted one replaced another register word time thus execution pair orders taken comput ing store requires four word times reasons opposing overlapping execution two orders also oppose extrac tion order pair previous pair dealt five word times therefore needed process extracting obeying pair simple arithmetic orders time may needed orders code basic 3beat rhythm thus established h c obey second order extract order pair computing store obey first order pair duration beat one word time beats b c two word times long orders groups 0 1 4 6 code may longer orders times typical operations times various arithmetic operations millisec addition subtraction 03 multiplication 20 division 54 times include allowance time extract orders times standard subroutines millisec exponential function 29 sine function 24 logarithmic function 34 finally give indication time typical prob lem set 50 simultaneous equations single righthand side takes 10y4 min time 3 min 8 sec input 7 min 17 sec calculation 18 sec output realizing specification detailed logical design would take long describe fully detailed logical design one aspect worth mentioning however namely avoidance exceptions results orders example exception consider overflow indicators set whenever final result order outside permissible range numbers multiplication occur multiplier multiplicand 1 likely occur infrequently rather provide equipment sense infrequent case easier put footnote program ming manual overflow indicator described pointing exception felt however exceptions avoided even expense extra equipment extra com plication reasons concerned facilitating machine use logic pegasus quite complicated endproduct detailed logical design series diagrams symbols corresponding circuit units packages shown example fig 5 inputs outputs units diagrams correspond pins sockets packages plug thus wiring lists connections pins produced logical diagrams first step production lists allocate position 180 part 2 1 instructionset processor mainline computers cabinets logical circuit way reduce amount wire needed layout completed last stage producing wire lists proceed general construction machine main units shown fig 10 package frame unit simple lightalloy frame sup porting diecast lightalloy frame racks back socket panels fixed packages slide grooves rack plug sockets back polarizing feature preventing insertion package upside electrical magnetic section 2 processors general register state screening necessary packages special metal plate inserted slots cast rack fixed single screw back panel coded aluminium strips containing coloured plastic studs identify position package fixed front casting arrangement packages 200 packages per cabinet arranged ten horizontal rows 20 units per row metal valve panels placed edges almost touch com ponent panel unit register unit corre sponding position rows thereby providing vertical chimneys cooling components secured bay loglc packages 8av 2 oglc packages bay 3 input equipment fig 10 main units chapter 9 design philosophy pegasus quantityproduction computer 181 panels warm air main source heat valves prevented valve panels reaching tempera turesensitive components diodes secured com ponent panel back panel wiring locating long signal wires sockets system plastic strips used hold wires definite positions given instructions wiring lists exact route every wire predetermined thus making wiring inspection reliable fault finding mainte nance easier final assembly completely wired frame assembled cabinet already fitted control auxili ary supply circuit unit heater transformers fuses cooling assembly cablefornis work connecting cableforms heaters earths done relatively unskilled labour working clearly written instructions diagrams cooling system cabinet cooling system integral part construction therefore difficulty cooling cabinets added existing computers two axialflow turbo blowers mounted base beneath airtight pressure chamber providing 300 ft3min air total pressure head 1 water gauge maximum temperature rise 10ﬂ c power supply separate cubicle houses metal rectifiers shunt stabilizing valves control circuits power obtained mains motoralternator set output stabilized 2 main purpose set act buffer switching surges mains voltage variations valve heaters computer energized stabi lized alternator output expected extend valve life maintenance general digital computers far fault rate ignored best done choice components circuits mechanical construction attention must paid following points get best machine rapid fault location b getting machine working soon possible locating fault c preventive maintenance fault location paritychecking circuits main high speed stores errors single digit stores stop machine fault quickly located examination monitors faults general method run test programme assuming fault main control indicate area fault detailed examination carried monitors outputs circuit units readily accessible monitoring sockets front package addition 80 points directly selected switches monitoring position include store lines number key wave forms faultfinding normally matter tracing 0s 1s machine reference logical diagrams rather electronic circuit diagrams variety triggers selected monitor timebases including trigger word position within drum revolution 128 different times selectable switches trigger word time selected order h triggers monitoring facilities pro duced 19 standard packages found well worth extra equipment fault repair faulty package located machine got working immediately replacement package spare repair faulty package done leisure aid package tester equipment package quickly given series standard tests selected switches performance measured either observation meters builtin oscillograph commissioning one case found first machine one would expect logical diagram except cases incorrect wiring preuentiue maintenance machine ht supplies reduced test programmes run marginal testing shows incipient faults deterioration valves crystal diodes resistors machine present kept good running order 10 margins 182 part 2 instructionset processor mainline computers 30 31 32 33 34 35 36 37 section 2 processors general register state allocated supplies normally controlled 1 nominal although correct running 20 reduction ob served 55ﬂ hours running majority package replacements done routine maintenance packaged method construction computers proved great advantages design construction operation conclusions first machine computing regularly months regular preventive maintenance 1 hour per day weeks errorfree runs 30 hours common time writing error references elliw56a lbo53 elliw51 52 53 56b fairj56 johnd52 merri56 pegasus programming manual ferranti ltd london pegasus mainte nance manuals ferranti ltd london 40 x c 41 xxc 42 x e 44 xcx 45 xxc 46 xxc 43 appendix c 238 pegasus order code 00 x n 01 xxn 02 x n 03 xxn 04 xnx 05 x x n 06 x xn 07 allocated 10 n x 11 nnx 12 n x 13 nnx 14 nn 15 n n x 17 allocated 16 nnfx order assumes overflow due opera tions 7 clears overflow unless n overflows 23 nq n 23xy 0 2 pn 1 unrounded division 25 y2 5 pn z rounded division 26 q 238 x y2 5 pn y2 rounded single 27 allocated n length division note x x singlelength arith metical shifts 50 x znx 51 x 2lvx rounded 53 shift x n places shifts 52 shift x n places singlelength logical note p p q q ifno doublelength arith metical shifts 54 pq 2npq 55 py 2npq un rounded chapter 9 1 design philosophy pegasus quantityproduction computer 183 56 normalize pq 2ppq either 1 y4 5 pq z 1ipsn1 57 allocated 60 jump n x 0 61 jump n xo 62 jump n x 2 0 63 jump n x 0 64 jump n overflow staticizor clear clear overflow staticizor 65 jump n overflow staticizor set clear overflow staticizor 66 unitmodify x xm 1 jump n x 0 mod 8 67 unitcount x x 1 jump n x 0 70 single word read accumulator 1 71 single word write accumulator 1 72 block read main store 1 1 u b 73 block write main store 74 external conditioning ﬂnot 76 allocated 77 stop h u notation used follows n first address register address order x accumulator specified order n word n obeying order x word x obeying order p q words 6 7 obeying order pq p 238q 2 0 doublelength number x n p 9 corresponding values obeying b block main store drum u block computing store p position number word within block ovr overflow indicator xm modifier x ie integer represented digits xc counter x ie integer represented digits order 1 13 x 14 38 x chapter 10 000 001 010 011 loo 101 8bitcharacter computer 10 101 50 so1 amra amrarrl mrda mraa rrl ir ori srd aid 251 251 3 31 odl sui br bld 11 111 2 31 cbr cbd cr cnd 0 11 11 11 qim qrtim r qmd rrfl r r p r pdrp frinzcp fsdl 2 31 2 3 11 1 11 11 ad odc sb sbc dar aa r c aa r atarc mu muf dii dif aaxri a8axrffr aari aa r fr 111 1 1 11 introduction present chapter result exercise design bit computer although rather trivial machine without interest either manipulator variablelength character strings interpreter complex computers role similar microprogrammed pc latter role readonly memory could used mp speed pc computer typical bit characteroriented computers among similar machines interdata model 3 rca 1600 ibm system360 model 25 data machines inc dmi 520i processor type rarely stands alone used fixed program following ways control larger c control laboratory complex instrument microprogrammed processor interpret 1spl processor must perform fixedlength operations bit characters 16bit addresses address double length operations necessary performance reasons almost programs operate address integers example see program page 185 thus extending generalizing operation length three four characters comparatively inexpensive noted processor might allow operation length specified 1 perhaps 28 256 characters much general capability limit directly addressa ble mp 216 65384 characters alternative design might allow maximum addressable mp zz4 words alter natively could variable although 24bit operations defined implementation might expensive aligning 24bit words 32bitword boundaries would simplify address calculation hardware 110 111 isp basic information unit 8bit character instructions general one character length however instructions data formats variable length instructions 1 2 34 5 characters long data 123 4 characters long pc state contains 35 characters organized dealt eight 8 16 24 32bit registers shown xo cmpr 1 11 1 1 aa ar aa r aa r n2ar id st shift si l r aa x 2 bcr r 0 1 1 11 structure compared elaborate microprogrammed ibm system 3bomodel 30 chap 32 isp description appendix 1 chapter registers first register 0 taken special accumu lator pc state contains operands addresses operands instructions load store register mp without incrementing general register use general registers twocharacter address pointer general register may loaded stored direct mp binary arith metic logical operations register accumu lator leave result accumulator ie form b rr instruction execution opxxxyyzl instructions formots format chorocler length __ name behavior 047 1 parameters 0 2 address integer relative lop irt 5 b 0 7 15 iop r 1 j c 3 direct address 07 23 0 7 15 23l31lpz 25 immediate doto 1 r 77 1 encloses instruction length characters shown formats toble see stote diogrom fig 2 fig 1 instruction coding 8bitcharacter computer 184 chapter 10 8bitcharacter computer 185 00100011 1 character r 10101001 00000111 instruction lengths 2 chorocters 3 characters instruction lengths 2 chorocters 3 characters operotton specified instruction q 0q q 0v operation determine variobles specified instruction q av access obtain variables return result variables operation determine location instruction q access obtain instruction q fig 2 8bitcharactercomputer instructioninterpretation state dia gram parameters b integer relative address c direct ad dress immediate data general registers discussed similar general register processors since assumed type processor might used interpret another isp 1 1 instructions provide string stack memory opera tions instructions microprogrammed p 10 devices defined example 16way branch instruction branched one 16 locations based 4 bits accumulator might facilitate writing interpreter isp given appendix 1 chapter pc state organized small scratchpad memory although mp could used instead instruction formats operation code assignments shown fig 1 instructions behave illustrated state diagram fig 2 example instruction ﬁhi 3 a907ﬂ coded instruction xor 3 l 2 coded effect r0023 r0023 r3023 examples behavior iri xor specified state diagrams fig id la respectively open subprogram perform ncomponent vector 16bit addition start sl 2 1 lri 4 iri 5 b iri 6 c lri 7 2 x n loop la1 5 st 3 la1 6 ad 3 stl 4 sul 7 cnr 4 loop set register length 2 set vector pointers locutions b c mp set count ut 2n fetch b storc b temporarily fetch c add store decrement n count brunch negative n program loop nine characters long program loop ibm systern360 16 characters long setup 13 characters opposed 6 16 characters 360 conclusions violated principle showing ﬁrealﬂ computers designing computer think typical small processor slightly interesting length specified register l 186 part 2 1 instructionset processor mainline computers section 2 processors general register state appendix 1 8bitcharacter computer isp description appendix 1 8 bit character computer isp description pc state following array 8 general registers r mapped first 8 x 6 x illl ihi cells register length first register array rolis accumulator md special properties ro710 8 x l mo70l107 a48 x l ro638 x l 1 mo71 03107 rqo 7 14 31 aq031 rq0031 rto 71023 mo71 102107 ato23 rt01023 ro 0 7 14 15 mo71 01107 ad015 rdolo15 rseo 71g 7 m071 ooiul7 aso7 rsolop general registers length illi x 8 bits accumulator igeneralzyj quadruple registers quadruple accumulator triple registers triple accumulator double registers double accumulator single registers single accumulator following flags set result arithmetic logical instructions accumulator form connected n negative resu2t flag 2 zero flag set register contains zero c anzco8 x l 1 nozocoao x l 1 lo 1 carry flag set carry borrow bit 0 addition 2 bit register indicate character length operations 1234 sdtq l14 po 1 5 program counter mp state mo177777810h primary memory instruction format 0 410 n op04 014 4 ro2 io5h sop i1 i12 i608 x l illdp 1 5 character instruction op code register address signed integer shifts address integer variable length innnediate data instruction interpretation process instructiono4jd cmppk p p 1 next fetch op oil v op 111 v op 1001 4 p p 2 op 1mo v op 1010 cp p op 010 4 p p l next instruct ionexecut ion execute chapter 10 8bitcharacter computer 187 instruction set instruction execution process instructionaxecution la op 0 mcrdrll toad la1 op mrdr next ror rorl l load zncrement sa op 2 mrdcrli sal op 3 mrdr next rdr ror l lri op 4 rr e im ari op 5 3 rr im rr srd op 6 md rr ird op 7 rr tmd ad1 op oiooo rrl crr l sui op olool 3 rrl rr l br op 01010 p rr bld op ololl p cd rr p cbr op 01100 cond 0 ip cp cbd op ollol cond 0 tp cd cnr op olllo cond 0 ip tp 5 cnd op ollll cond 0 p cd cond r h nozoc ad op 10000 rr adc op 10001 rr c sb op 10010 rr sbc op lool1 3 rr c mui op 10100 3 x rr muf op 10101 3 ca x rr dii op ioiio rr dif op iolli rr op 11000 rr op ilool v rr xor op 11010 ea rr cmpr op iioll no2 rr id st op illol fdrl shift op 11110 ax 2 s1 op 11100 trrl op 11111 f l r 1 store store increment load register innnediate add register innnediate store register load register add register subtract register branch return branch link direct conditional branch relative conditional branch direct conditional branch relative conditional branch direct add add carry suhtract subtract carry integer multiply fraction multiply integer divide fraction divide logical logical exclusive compare used n z load store shift right left set operation length end instructionexecution instructionset processor level variations processor part discuss computers whose isps variations mainline computers part 2 variations represent historical computers remained viable judgment computer engineering community responses particular technology explorations either advanced time still exist open options section 1 processors greater 1 address per instruction mostly historical comparative interest general register organization large mps hence large addresses almost surely dominate section 2 processors constrained cyclic primary memory describes response historical feature mp technology use drum delay line disk matter necessity rather choice better random access core memories available drum ceased primary memory component section 3 presents processors variable string data processors longer built original form however successful ibm 1401 furthermore string datatypes incorporated later proc essors section 4 presents two desk calculator computers although often dismiss devices mere desk calculators facilities qualify general purpose stored program computers unlike computers production cost constraint calculator computers cleverly designed section 5 processors stack memories describes organization never reached main line state nevertheless idea stack memory gradually assimilated example dec pdp6 pdp10 computers use general registers stack pointer control suggested chap 3 page 62 sec 6 ideas multiprogramming presented ideas recent yet adequately incorporated main line designs undoubt edly standard features next generation although exact form yet known 189 section 1 processors greater 1 address per instruction multipleaddress instruction formats exist several reasons addition explicit address determine next struction occurs cyclic mps make efficient section 2 devoted case considered processors known n 1 address second reason many operations one operand b v b seems efficient encoding put instruction third reason many operations need followed writing result memory permit pc used operations data thus coupling operation address result stored seems advantageous however evalu ating complex arithmetic expressions instruction bits memory references required singleaddress com puter also unary operators one address field unused seems fair say isp organizations two three addresses proved competition main line 1 1 index 1 general register organiza tions however definitive demonstration inefficiency technological conditions exists worth studying microprogrammed processors multipleaddress instruc tions allow high degree parallelism obtained single instruction multipleaddress formats survive form pilot ace national physics laboratorys pilot ace first several cyclic memory computers designed provide optimum coding instructions subsequent machines influenced include nearly identical english electric deuce bendix g15 packard bell pb250 pms structure strictly follow lattice model page 65 deuce pms structure given fig 1 32word block mpdelayline transferred msdrum one instruction transfer time 1024 ps another capability h huskey involved design ace g15 pb250 undoubtedly idea carrier ace allows perform operations vectors 32 elements 1 instruction ace structure chap 11 common con tains much processor state mp many locations used processor state store programs direct execu tion diagram page 198 chap 11 describes struction execution process implementation alan turing credited basic design ace see introduction page 193 turings biography turing 19591 zebra simple binary computer zebra illustrates organizational details another serial arithmetic computer mpcyclic zebra like ace allows user construct instructions hardware almost directly interpreted ace zebra little decoding built machine large instruction set available since instructions microcoded computers programming problem complex user wishes large number different instructions micro stconsole kms moving head drum 8192 w 32 bw 16 tracksposi tion 32 wtrack 16 posi ions mpdelay line cyclic 32 1024 psw 32 w 32 bw pctechno1ogy vacuum tubes 1955 1961 21 address instruction ancestors npl ace fig 1 english electric deuce pms diagram 191 192 part 3 instructionset processor level variations processor coded lgp30 chap 16 contrast basic instruction set hence problem coded one two ways zebras performance 60 percent memorycycle utiliza tion rather outstanding raises possibility ran domaccess primary memories may necessary univac scientific 1103a instruction logic univac 1103a chap 13 twoaddress computer computer designed initially engineering research asso ciates era st paul univac acquired era 1952 scientificcomputer division evolution 1103a later yielded 1107 1108 general register processors reader compare 1103a ibm 704 series chap 41 time used clear computer better third series started era 1101 1102 section 1 processors greater 1 address per instruction rw400 new polymorphic data system rw400 chap 38 twoaddress binary computer discussed part 5 sec 4 page 470 instruction logic midac university michigans midac michigan digital auto matic computer based national bureau standards seac standards electronic automatic computer midac threeaddress binary computer presented chap 14 instruction logic soviet strela arrow russian strela presented chap 15 since used illustrate threeaddress organization chapter con sists instruction set chapter 11 pilot ace1 j h wilkinson introduction general description machine almost identical pilot ace first designed staff mathematics division suggestion dr h huskey stay national physical laboratory 1947 based earlier design dr turing principal object provide experi ence construction equipment type intended would used extensive programme computation hoped would give practical experi ence production subroutines would serve useful guide design full scale machine attempt build pilot model dr huskeys stay unsuccessful year later formation electronics section npl combined team consisting section four members mathematics division started construction pilot model design taken almost unchanged earlier version machine first worked sense carried automatically simple sequence operations may 1950 end year reached stage successful press demonstration held successful application machine solution number problems made apparent spite obvious short comings capable converted powerful com puter comparable existence much faster accordingly small programme modifications em barked upon early 1951 machine functioning satisfactorily november year month continuous operation transferred electronics section mathematics division since use 13hour day first year full scale operation achieved 65 serviceability figure based strict criterion performance second year far considerably better pilot ace serial machine using mercury delay line storage working pulse repetition rate 1 megacyclesec high speed store consists 11 long delay lines stores 32 words 32 binary digits corresponding circulation period 1024 microseconds 5 short lines storing one word circulation period 32 microseconds two delay lines storing two words inevitable design machine originally intended experimental purposes riding consideration given minimization equip ment rather making machine logically satisfying whole reflected certain extent code adopted machine arithmetic facilities gen eral fairly rudimentary design machine also de cisively influenced attempt overcome loss speed due high access time long storage units machine fact uses usually known system ﬁoptimum codingﬂ code pilot ace pilot ace may said ﬁthreeaddress codeﬂ though form classification particularly appropriate instruction calls transfer information one 32 ﬁsourcesﬂ one 32 ﬁdestinationsﬂ selects eight long delay lines provide next instruction third address necessary consecutive instructions occupy consecutive positions placed relative positions far possible instruction emerges minor cycle current instruction completed unusual feature instructions transfers describe may last number consecutive minor cycles one thirty two instruction word contains three main elements known wait number timing number iautmatic iil cmputaton til physical laboratory teading ton england pp 514 march 1953 characteristic together determine transfer starts stops instruction selected instruction 193 194 part 3 instructionset processor level variations processor section 1 processors greater 1 address per instruction source next obeyed structure instruction word follows next instruction source digits 24 source digits 59 destination digits 1014 characteristic digits 1516 wait number digits 1721 timing number digits 2529 go digit digit 32 remaining digits spare coding problem takes place two parts first source destination period transfer specified last function characteristic wait number timing number second part detailed cod ing elements added sources destinations simplest among sources destinations associated short delay lines six oneword delay lines given numbers reasons associated history machine 11 15 16 20 26 27 usually referred temporary stores tss used store temporarily numbers operated upon frequently stage computation general tsn associated source source n destination des tination n instruction type 1516 preliminary stage coding represents transfer copy contents ts15 via source 15 tsl6 via destination 16 taken place stores contain number originally ts15 period transfer mentioned coding transfer one minor cycle irrelevant transfers one minor cycle hence period transfer specified unless greater one minor cycle associated tss number functional sources destinations tsl6 instance two destinations 17 18 associated addition destination 16 number transferred destination 17 added contents tsl6 number transferred destina tion 18 subtracted contents ts16 ts16 may said functions associated accumulator orthodox machine period transfer destinations 17 18 important thus 1517 n minor cycles effect adding contents ts15 n times contents ts16 prolonged transfer used way give small multiples 32 numbers similarly may 1518 n mc instruction 1617 n mc special significance effect adding content tsl6 minor cycle transfer gives multiplication 271 left shift n binary places ts26 associated number functional sources source 17 gives ones complement number ts26 source 18 contents divided 2 source 19 contents multiplied 2 instruction 1826 n mc thus effect dividing contents ts26 2n right shift n places similarly 1926 n mc gives left shift n places two functional sources give composite func tions numbers ts26 ts27 source 21 gives number ts26 ts27 source 22 gives number ts26 f ts27 number sources give constant numbers frequent use computation source 23 gives number zero everywhere except 17th position usually known p17 source 24 gives p32 source 25 gives p1 source 28 gives zero source 29 gives number consisting 32 consecutive ones sources valuable provide numbers access time one minor cycle thus almost useful several extra tss use number tss arithmetic facilities distributed among makes possible take advantage placing instructions appropriate positions long chapter 11 pilot ace 195 storage units emerge required coding trivial example illustrate uses tss asso ciated sources required build successive natural numbers squares cubes simultaneously natural store values tss may suppose ts15 contains n ts20 n2 ts26 n3 instruction description 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 28 15 zero ts15 ie 0 2820 zero ts20 ie 02 initial values 2826 zero ts26 ie 03 2616 ts16 contains n3 2017 3rnc ts16 contains n3 3n2 1517 3rnc ts16 contains n3 3n2 3n 25 17 ts16 contains n3 3n2 3n 1 1626 ts26 contains n 1s 2016 ts16 contains n 1517 2rnc ts16 contains n 2n 2517 ts16 contains n 2n 1 1620 ts20 contains n 12 1516 ts16 contains n 2517 ts16 contains n 1 1615 ts15 contains n 1 next instruction 4 3 instructions set instructions 1 3 set initial conditions instruction 4 15 effect changing contents 15 20 26 n n2 n3 n l n 12 n l3 remarked earlier instruction selects next instruction instruction 15 selects instruction 4 next instruction prelimi nary coding usually denoted using arrow must catered detailed coding correct choice timing number shown branching programme achieved use two destinations destination 24 destination 25 transfer made source destination 24 next instruction one two according number transferred positive negative similarly transfer made destination 25 next instruction one two according number transferred zero nonzero preliminary coding bifurcation denoted use arrows thus detailed coding effect number transferred destination 24 negative timing number increased 1 similarly destination 25 two possible next instructions consecutive store two double word stores numbered ds12 ds14 ds12 source 12 destination 12 associated ds14 addition source 14 destination 14 number functional sources destinations source 13 gives contents ds14 divided 2 transfers destination 13 effect adding numbers transferred ds14 specifying transfers double length stores time transfer must specified ie whether takes place even odd minor cycle thus transfer 1214 odd minor cycle usually written 1214 0 represents transfer word odd positions ds12 odd position ds14 1214 2 minor cycles represents transfer words 12 corresponding positions 14 operation 1314 2n gives us method shifting contents ts14 n places right 1413 2n produces shift n places left machine equipped fully automatic multiplier multiply two numbers b together must sent ts20 b ds14 odd zero ds14 even transfer source irrelevant made destination 19 product produced ds14 2 milliseconds b treated positive numbers corrections must made answer b signed numbers make multiplication fast made possible perform operations multiplication pro ceeding thus corrections necessary b signed numbers may built ts16 multiplication signed multiplication takes little two millisecs course therefore subroutine fast one amount equip ment associated multiplier small main part store consists long storage units known dl1 dl2 dl11 source destination number dl number words dl numbered 0 31 nth word dlm usually denoted dlm transfers long lines preliminary coding denoted thus 196 part 3 instructionset processor level variations processor 8 16 transfer nth word dl8 ts16 817 add words 8 8 ie n 1 con secutive words dl8 ts16 detailed coding second stage coding true instruction words derived preliminary coding fairly automatic process recent experience shown carried satisfactorily quite junior staff timing instruc tion given relative position instruction store incidental feature code arose attempts minimize equipment would dropped future machine favour absolute timing system struction occupies position dl wait number w timing number transfer always begins minor cycle w 2 next instruction always minor cycle 2 selected next instruction source period transfer depends value characteristic characteristic zero transfer lasts whole period w 2 2 w 1 minor cycles characteristic one transfer one minor cycle minor cycle w 2 charac teristic three transfer two minor cycles w 2 w 3 characteristic value two used characteristic value zero gives prolonged transfer peculiar pilot ace characteristics 1 3 analogous facility edsac whereby full length llength words may transferred pilot ace transfer single double length words facility invaluable double length floating complex arithmetic definitions numbers w 2 etc interpreted modulo 32 general timing wait numbers simpler appear definitions frequently zero corresponding transfer one minor cycle detailed coding problem given earlier illustrate procedure instructions dll next instruction source always one key headings following table mc nis next instruction source source destination c characteristic w wait number timing number minor cycle position instructions dli section 1 processors greater 1 address per instruction last column gives position next instruction dl1 given 2 first 4 instructions occupy minor cycles 0 2 4 6 takes two minor cycles gives transfer one minor cycle next instruction occupies minor cycle number 8 requires transfer lasting 3 minor cycles simplest fastest way getting w 0 2 giving transfer 2 0 1 minor cycles next instruction position 8 2 2 minor cycle 12 reach instruction minor cycle 31 viz 2517 transfer one minor cycle required simplest way w 0 0 makes next instruction occupy position 31 0 2 ie position 33 position 1 position 1 already occupied value could chosen order land unoccupied position order ensure transfer one minor cycle took place characteristic could made 1 appreciated choice c w far unique whenever possible 0 w 0 chosen gives highest speed operation besides simplest instruction occupying position 1 special interest last instruction cycle needed build square cube must select next instruction first cycle position number 6 achieved making 3 giving next instruction mc 1 3 2 6 incidentally gives transfer lasting four minor cycles since transfer one ts another functional source destination use prolonged transfer produces harmful effect prolonged transfer avoided characteristic could taken 1 seldom necessary use characteristic zero transfers tss transfers made dls characteristic values 1 3 almost universal 12 instructions comprise repeated cycle computation take total time one major cycle exactly 32 minor cycles last instruction cycle specially designed get back beginning cycle contrast position machine using optimum coding 12 major cycles would necessary quite apart fact multiplications factors 3 2 uses one instruction would normally need one instruction prolonged transfer available figure 1 gives simplified diagram machine sequence events obeying instruction ns cwt 2 16 2c 0 8 10 occupying dl1 example follows starting time last instruction completed instruction chapter 11 pilot ace 197 minor cycle minor cycle position next position instructions instruction charac wait timing next dll source source destination teristic instruction 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 28 16 28 28 26 20 15 25 16 20 15 25 16 15 25 15 15 20 16 16 17 17 17 26 16 17 17 20 16 17 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 2 2 0 0 0 1 0 0 0 0 dl1 passed special ts marked ts count minor cycle number 2 end minor cycle number 3 switch number 16 also n switch number 2 contents tsl6 passing highway dl2 instruction highway beginning minor cycle number 12 ie 2 8 2 switch number 20 go ts20 stop recirculating number highway pass ts20 transfer continue minor cycle 14 ie 2 10 2 switch number 20 switch back beginning minor cycle 14 switch x count go number instruction highway minor cycle dl2 pass count end minor cycle 14 x switch close dl2 trapped count cycle events complete count associated counter counter determines wait timing characteristic numbers trapped instruction x switches go back input output part instruction word described go digit go digit one instruction carried high speed zero machine stops proceed manual switch operated go digit omitted strategic instructions programme tested also 198 part 3 instructionset processor level variations processor 1s ts 27 ds 14 os ta etc c fig 1 simplified diagram showing sources destinations nextinstruction sources serves purpose synchronising input output facilities high speed computer input machine means hollerith punched cards cards passed reader numbers card may read row row passes set 32 reading brushes row card reading brushes number punched row regarded number 32 binary digits available source 0 order make certain reading takes place row position rows transfers source 0 go digit omitted arranged hollerith reader effect operating manual switch time row comes position passage card reader called transfer source destination 31 transfer information card takes place unless appropriate instruction using source 0 obeyed passage card output machine also provided section 1 processors greater 1 address per instruction hollerith punch passage card punch called transfer source destination 30 card passing punch 32 digit number may punched row transfer destination 28 syn chronisation ensured omitting go digit instructions calling transfer destination 28 arranging hollerith punch effectively operates manual switch row comes position reader feeds cards rate 200 cards per minute punch rate 100 cards per minute speed input binary digits 200 x 32 x 12 per minute 1280 per second output speed 640 digits per second data may fed decimal requires conversion subroutines computation involved conver sion done rows card 30 decimal digits per card may translated speed conversion possible use optimum coding facility carrying computation rows cards used extensively particularly linear algebra matrices exceeding storage capacity machine involved matrices stored cards binary form one number 12 rows card computation done either rows reading punching times comparable possible matrices stored memory often achieved way computation uses high percentage available time rows 80 time may safely used initial input initial input instructions achieved choosing destination 0 special manner transfer made destination 0 instruction transferred becomes next obeyed next instruction source ignored source 0 already chosen specially since provided row card instruction consisting zeros effect injecting instruction punched row card machine next obeyed machine started clearing store starting hollerith reader contains cards punched appropriate instructions destination 0 also used instruction built arithmetic unit ready obeyed miscellaneous sources destinations destination 29 controls buzzer nonzero number trans ferred destination 29 buzzer sounds source 30 used indicate last row card position reader punch source gives nonzero number last row position operation arithmetic facilities ds14 may modified transfer chapter 11 1 pilot ace 199 destination 23 transfer odd characteristic made source destination 23 ds14 haves though two single length accumulators series means carries suppressed end single words condition persists transfer made destination 23 using even characteristic ds14 behaves accumulator double length numbers least significant parts even minor cycles significant parts odd minor cycles operation ts20 modified transfers destination 21 transfer odd characteristic made destination 21 ts20 ceases independent existence fed continuously dl10 source 20 gives con tents dll0 one minor cycle later source 10 ts20 reverts former condition transfer even char acteristic made destination 21 facility used move 32 words dllo round one position word minor cycle n available minor cycle n 1 assessment optimum coding detailed assessment value optimum coding means simple roughly speaking subroutines average 4 5 times fast orthodox machine using pulse repetition rate main tables somewhat lower factor usually achieved factor 4 5 would exceeded less advantage given optimum coding used overcome disadvantages due rudimentary nature arithmetic facilities pilot ace even bald statement average ratio speeds full justice value optimum coding pilot ace value springs much fact made possible programmes computing done rows cards also high output speed decimal numbers binary decimal conversion routines punching several decimal numbers simultaneously card also decimalbinary conversion routines reading several numbers achieve ratio something like 14 1 machine used extensively scientific computation commercial basis immense importance future programme engineered versions pilot model construction english electric company machines similar pilot model little highspeed store automatic divider two quadruple length stores subtrac tive input double length accumulator besides several minor modifications including rationalization numbering stores addition magnetic drum intermediate store equivalent 32dls storage capacity added full scale machine probably soon development employing 4 address code typical instructions form akb c select next source instruction code economical instruction storage space since single word stores become complete accumulators facilities except multiplication possible take much fuller advantage optimum coding sources destination next instruction sources sources des tinations next instr sources 0 input 1 dl1 2 dl2 3 dl3 4 dl4 5 dl5 6 dl6 7 dl7 8 dl8 9 dl9 10 dllo 11 dlll 12 ds12 13 ds14 2 14 ds14 15 ts15 16 ts16 17 ts26 18 ts26 2 19 ts26 x 2 20 ts20 21 ts26 ts27 22 ts26 ts27 23 p17 24 p32 25 p1 26 ts26 27 ts27 28 zero 29 ones 0 instruction 0 dlll 1 dl1 1 dl1 2 dl2 2 dl2 3 dl3 3 dl3 4 dl4 4 dl4 5 dl5 5 dl5 6 dl6 6 dl6 7 dl7 7 dl7 8 dl8 9 dl9 10 dllo 11 dlll 12 ds12 13 ds14add 14 ds14 15 ts15 16 ts16 17 ts16add 18 ts16 subtract 19t multiply 20 ts20 21 modifies source 20 22 23 modifies source 13 destination 13 24 discriminate sign 25 discriminate zero 26 ts26 27 ts27 28 output 29 buzzer 30 last row card 30t punch 31 31t read independent source used references wilkj53 turis59 chapter 12 zebra simple binary computer1 w l van der poel summary computer zebra computer based following 15 bits akqlribcde vxxzxi w test bits operation part ideas 1 2 3 4 5 6 5 bits 00000 fast store address logical structure arithmetic control units machine simplified much possible even builtin multiplier divider separate bits instruction word used functionally put together combination conventional two stage operation setup execution aban doned unit time interval used arithmetical opera tions small number fast access registers used temporary storage time registers serve modifier registers blines optimum programming almost automatically done great extent percentage word times effectively used usually greater 60 instruction repeated modified repeated using accumulator next instruction source address counter counter done without special hardware resulted machine simple structure hence contains moderate number components giving high relia bility easy maintenance functional bit coding programming extremely flexible fact machine code sort microprogramming fulllength inultiplication halflength mnltiplica tion half time easy require different micro programme minimum latency programming together effec tive use word times lost systems results high speed operation compared basic clock pulse frequency introduction dr neher laboratory dutch postal telecom munications services logical design computer called ze bra developed computer engineered constructed standard telephones cables ltd england logical system different computers worth devote special lecture time limited proc icip unesco pp 361365 june 1959 technical details questions dimensions capacity discussed found literature van der poel 1956 van der poel 19521 main idea machine economise far possible number components simplifying logical structure example multiplication division built must programmed course system work appropriate internal code enough properties execute basic arithmetic logical routines effectively fact inter nal machine code less system microprogramming wilkes stringer 19531 chapter 12 1 zebra simple binary computer 201 arithmetic control unit store store arithmetic el store store fig 1 main units computer arithmetic unit control way kbit controls interconnection fast store arithmetic unit control unit interconnections seen fig 1 seen k 4 possible combinations case 1 0 k 0 called adding jump fig 2a new instruction coming control drum arithmetic unit time operation operand coming fast store fastest type operation following instruction placed next location drum waiting time 32 instructions type executed per revolution one revolution 10 ms one word time 312 ps case 2 0 k 1 called double jump fig 2b stores used giving information control ie making jump since fast store used control instruction coming drum modified con tents fast register way bline facility often called realised case 3 1 k 0 called double addition fig 2c stores connected arithmetic unit control must take care using address counter stepped 2 time thus enabling type instruction reach number lying two successive instructions without waiting time constants particular always taken optimum places drum case 4 1 k 1 called jumping addition fig 24 drum used arithmetic unit address counter modified fast register control may thus passed instruction next instruction ebits functional bits e control direction flow infor mation 0 means read drum e 0 means read fast store 1 means write drum e 1 means write fast store possible instructions given written code drum address always written 3 digits absence abit indicated letter x necessary input programme recognize ginning new instruction a2005 add 200 contents address 200 5 accumulator step address counter 2 take next instruction 200 jump 200 store contents accumulator 5 jump 200 store previous contents ad dress counter 5 amounts placing link instruction return subroutine take next instruction 200 modify 5 thus making variable instruction x200e5 x200ke5 x200k5 arithmetic bits remainder function bits arithmetic meanings shall briefly indicate different actions b use accumulator significant accumulator b accumulator ic id1 fig 2 possible combinations kbits 202 part 3 1 instructionset processor level variations processor c clear accumulator specified b storing addition serial machine like zebra auto matically case cf fig 3 subtract instead add q add one unit least significant place baccu mulator l shift accumulators one place left r shift accumulators one place right accu mulators always coupled together shifting except c present examples given a200bce25 store b 5 clear b add 200 b jump 200 store b 6 put 1 b qibc shift accumu lator one place left shifting b prevented presence c jump 200 shift right copy 3 b register 3 address b accumulator means shifted b static take instruction 200 modify contents b accumulator register 3 put 1 b afterwards x2wqlibce6 x200rbc3 x200ksqibc drum store fast store store fig 3 accumulator section 1 1 processors greater 1 address per instruction seen many complicated operations composed elementary possibilities separate bits accumulator simplified block diagram one accumulators shown fig 3 shifting effected looping accumulator one place less one place double addition contents drum store fast store first added together pre adder possibly augmented unity b accumulator q present result added accumulator sub tracted case clearing gate controlled c interrupts recirculation previous contents control unit control unit two shifting registers cregister receives next instruction executed dregister counter block diagram shown fig 4 new instruction come c taken parallel form e interword time remains e next instruction coming c let us explain action control short programme examples programmes 100 x101e5 101 ac102 102 constant 103 etc actions several registers x1007 x101e5 x102 l const x103e5 suppose xl00 c start take 100 c c 2 another jump comes c taking 101 storing 5 c 2 gives x103e5 note operational part kept counter necessary constant 102 becoming available next instruction taken 103 immediately following constant stored 5 e5 still active coming back chapter 12 zebra simple binary computer 203 store fig 4 control unit important aspect machine instruction address counter comes back ainstruction something useful surprise found many cases first suspected second action could used effectively computers time access next instruction lost nothing done concurrently arithmetic unit another example action control jump subroutine suppose following piece pro gramme 100 x200ke5 jump subroutine starting 200 place return jump 5 102 etc subroutine returns action follows c instruction taken 100 x1007 x200ke5 x102 x200ke54 c xl00 2 ke5 stores 5 thus 5 x102 subroutine 200 executed ends xk5 jump 5 200 xk5 take instruction 5 xi02 102 etc main programme proceeds 102 ending subroutine 220 x221k5 221 1 return two one location ie x221k5 takes next instruction 5 1 x101 5 contains instruction drum modifier test bits digits v x4 x2 x1 dealt extensively different combinations 4 digits represent different types test example v1 attached instruction instruction executed negative skipped altogether positive zero harmless ainstruction executed instead test tached jump giving conditional jump well ainstruction giving conditional addition wbit far digit w mentioned w present instruction drum address used instruction kept waiting immediately executed drum completely disregarded help digit w jumps made instructions fast store eg xk5w takes instruction 5 drum deliver number use type instruction peculiar consequences let us take following example 100 xlolke6 5 arw 101 x8186ksrw 102 etc 6 filled return instruction action follows take instruction 100 xlolke6 x102 jump 101 store return instruction x102 6 x8 186k5wr 1 right shift 42 arw x8188ksrw another right shift arw drum address counted active register address remains hence instruc tion 5 repeated 204 pari 3 1 instructionset processor level variations processor 22 x8188k5rw repeating instruction well repeated instruction shifted one place 1 f3 arw x8190k5rw right 25 arw xoook6rw drum address overflows fast store address repeating instruction becomes x8192k5rw xoook6rw taking next instruction 6 24 x8190k5rwb 1 26 xoook6rw 2ya x102 6 x102 repetition returns main programme accumulator shifted 7 places instruction arw thus repeated p times drum address repeating instruction 8192213 way repeating instruction made possible multipli cation division block transfers table look many small basic repetitive processes simple way special hardware present machine counting neces sary repetition counting done normal address counter last example shall give programme summa section 1 1 processors greater 1 address per instruction tion block locations 200 300 store involves 101 locations programme reads 100 alolbc 101 a200q 102 x103ke4c put a200q b b address 3 put return jump x104 4 clear advance repeat a200q 101 times a200q standing b q augments struction every repetition hence successively 200 201 etc added end sum left programme proceeds 104 103 x7990k3w 104 etc left reader work action diagram example programmed minimum waiting supplying repeating instruction x7990k3w q step repeated instruction a200q 2 every time first instruction located even locations follow ing emerging drum right time odd numbered locations must summed second similar repeti tion references vandw59 vandw52 56 wilkhls3a chapter 13 oc 6 bits univac scientific 1103a u v 15 bits 15 bits instruction logic1 john w cam ill univac scientific computer 35 0 02 binary machine option 27 8 0 arithmetic unit contains two 36bit x exchange q quotient registers one 72bit register accumulator negative numbers represented ones com plement notation inputoutput via highspeed paper tape reader punch direct card reader punch uniservo magnetic tape units may connected peripheral punched card readers punches highspeed printer addition information may recorded magnetic tape directly keyboards use unitypers communication external equipment via bit ioa register s6bit iob register information sent registers controls magnetic tapes well input output equipment program address counter pak contains present instruction address storage 12288 locations magnetic core storage along directly addressable drum 16384 locations instructions twoaddress form six bits operation code two fifteenbit addresses 11 v following information taken univac scientific manual univac scientific electronic computing system model 1103a form el3381 definitions conventions lnstruction word e grabbe ramo e wooldridge eds ﬁhandbook automation computation controlﬂ vol 2 chap 2 pp 7783 john wiley sons inc new york 1959 2carrs triplet notation fractional significant digits digits exponent digits left radix point oc operation code u first execution address v second execution address instructions form jn jk replaces u ad dress others form k replaces v address j n k onedigit octal number modifying instruction fourdigit octal number designating number times struction performed sevendigit binary number designating number places word shifted left address allocations octal 0000007777 4096 0000017777 8192 0000027777 12288 36bit words q 3100031777 1 36bit word 3200037777 172bit word md 4000077777 16384 36bit words fixed addresses f 00000 40001 f 00001 f 00002 f 00003 arithmetic section registers q x 36bit exchange register 72bit accumulator shifting properties righthand 36 bits lefthand 36 bits 36bit register shifting properties note parentheses denote contents example means contents 72bit word q means contents q 36bit word q 205 206 part 3 instructionset processor level variations processor section 1 processors greater 1 address per instruction inputoutput registers ioa 8bit inout register iob 36bit inout register twr 6bit typewriter register hpr 7bit highspeed punch register word extension 72bit word whose righthand 36 bits word address u whose lefthand 36 bits leftmost bit word u 72bit word whose righthand 36 bits word address u whose lefthand 36 bits zero 72bit wordrighthand 36 bits register q left hand 36 bits leftmost bit register q dq except left 36 bits zero dar sar similarly defined lqu 72bit wordlefthand 36 bits zero righthand 36 bits bitbybit product corresponding bits q word address u 72bit wordlefthand 36 bits zero righthand 36 bits bitbybit product corresponding bits complement q word ad dress v lqv transmit instructions 11 13 12 15 16 35 36 22 transmit positive tpuv2 replace v u transmit negative tnuv replace v comple ment u transmit magnitude tmuv replace v absolute magnitude u transmit uaddress tuuv replace 15 bits v desig nated vl vz9 corresponding bits u leaving remaining 21 bits v undisturbed transmit vaddress tvuv replace righthand 15 bits v designated vo vi4 corresponding bits u leaving remaining 21 bits v undisturbed add transmit atuv add du replace v ar subtract transmit stuv subtract dli replace v ar left transmit ltjkv left circular shift k places j 0 replace v al j 1 replace v ar octal notation mnemonic notation qcontrolled instructions 51 qcontrolled transmit qtuv form number lqu replace v ar 52 qcontrolled add qauv add number lqu replace v ar qcontrolled substitute qsuv form quantity lqu plus lqv replace v ar effect replace selected bits v corre sponding bits u places corresponding 1s q final v final ar 53 replace instructions 21 replace add rauv form sum du dv replace 11 ar replace subtract rsuv form difference du minus dv replace 11 ar controlled complement ccuv replace ar u leaving al undisturbed complement bits ar correspond ones v replace u left shift lauk replace du left circular shift k places replace u ar u first step omitted initial content shifted left shift q lquk replace q u left circular shift q k places replace u 0 23 27 ar 54 55 split instructions 31 split positive entry spuk form su left circu lar shift k places split negative entry snuk form complement sii left circular shift k places split add sauk add su left circular shift k places split subtract ssuk subtract su left circular shift k places 33 32 34 twoway conditional jump instructions 46 47 sign jump sjuv 1 take u ni 0 take v ni ni means next instruction zero jump zjuv 4 zero take u ni zero take v ni chapter 13 univac scientific 1103a instruction logic 207 44 qjump qjuv q35 1 take u ni q35 0 take v ni either case left circular shift q one place oneway conditional jump instructions 41 index jump ijuv form difference du minus 1 1 continue present sequence structions 0 replace u ar take v ni threshold jump tjuv du greater take v ni continue present sequence either case leave initial state equality jump ejuv du equals take v ni continue present sequence either case leave initial state 42 43 oneway unconditional jump instructions 45 manually selective jump mjjv number j zero take v ni j 1 2 3 correspondingly numbered mj selecting switch set ﬁjumpﬂ take v ni switch set ﬁjumpﬂ continue present sequence return jump rjuv let represent address ci obtained replace righthand 15 bits u quantity plus 1 take v ni interpret ip let represent address ci obtained replace righthand 15 bits f quantity 1 take f ni 37 14 stop instructions 56 manually selective stop msjv j 0 stop computer operation provide suitable indication j 1 2 3 correspondingly numbered ms selecting switch set ﬁstopﬂ stop computer operation provide suitable indication whether stop occurs v ni program stop psstop computer operations provide suitable indication 57 external equipment instructions 17 external function efv select unit external equip ment perform function designated v 76 external read erjv j 0 replace righthand 8 bits v ioa j 1 replace v iob external write ewjv j 0 replace ioa righthand 8 bits v j 1 replace iob v cause previously selected unit respond infor mation ioa iob print prv replace twr righthand 6 bits v cause typewriter print character corre sponding 6bit code punch pujv replace hpr righthand 6 bits v cause punch respond hpr j 0 omit seventh level hole j 1 include seventh level hole 77 61 63 arithmetic instructions 71 72 73 74 multiply mpuv form 72bit product u v leaving q multiplier u multiply add mauv add 72bit product u v leaving q multiplier u divide dvuv divide 72bit number u putting quotient q leaving nonnegative mainder r replace v q quotient remainder defined u q r 0 5 r iui ai denotes initial contents scale factor sfuv replace du left cir cular shift 36 places continue shift a5 replace righthand 15 bits v number left circular shifts k would neces sary return original position ones zeros k 37 u left unchanged first step instead replaced da sequenced instructions 75 repeat rpjnw instruction calls next instruc tion called niuv executed n times u v addresses modified according value j afterwards program continued execution instruction stored fixed address f exact steps carried replace righthand 15 bits f address w execute niuv next instruction program n times b 208 part 3 1 instructionset processor level variations processor c j 0 change u v j 1 add one v execution j 2 add one u execution j 3 add one u v execution modification u address v address done program control registers original form instruction storage unaltered completing n executions take fj next instruction f normally contains manually selec tive jump whereby computer sent w next instruction repeat repeated instruction jump instruction occurrence jump terminates repetition instruction threshold jump equality jump jump address v occurs q replaced quantity j n r r number executions taken place e floating point instructions 64 65 66 add fauv form q normalized rounded packed floating point sum u v subtract fsuv form q normalized rounded packed floating point difference u v multiply fmuv form q normalized rounded packed floating point product u v 67 01 02 03 04 05 section 1 processors greater 1 address per instruction divide fduv form q normalized rounded packed floating point quotient u v polynomial multiply fpuv floating add v floating product qi u leaving packed normalized rounded result q inner product fiuv floating add qi floating product u v store rounded normalized packed result q instruction uses mc location f4 00003 temporary storage fjf qi subscripts f represent ﬁinitialﬂ ﬁfinalﬂ unpack upuv unpack u replacing u u replacing v u complement u negative characteristic portion u contains sign bits sign portion mantissa portion v set zero note subscripts c denote mantissa characteristic portions normalize pack npuv replace u normalized rounded packed floating point number obtained possibly unnormalized mantissa u biased characteristic v note assumed u binary point uz7 uz6 u scaled 227 normalize exit nej j 1 normalize without rounding master clear instruction exe cuted 0 references univac scientific electronic computing system model 1103a form el 338 chapter 14 instruction logic midac1 john w cam iii midac michigan digital automatic computer carr 19561 constructed basis design seac national bureau standards instruction code particularly interest incorporates index register concept threeaddress binary instruction numbers machine 44 0 02 fixed points word length 45 binary digits serial operation word structure data address positions instruction labeled j3 positions contains twelve binary digits represented externally three hexadecimal digits four binary digits one hexadecimal digit used convey instruction modification relative addressing information next four binary digits single hexadecimal digit represents operation portion instruction final binary digit halt breakpoint indi cator use instruction example 45binarydigit word 00000110010000001100100000010010l100000001011 considered instruction would interpreted p abcd op halt 000001100100 000011001000 o00100101100 0ooo 0101 1 external hexadecimal form would written 064 0c8 12c 0 5 binary word equivalent machine representation following instruction ﬁtake contents hexadecimal address 064 add contents hexadecimal address 0c8 store result hexadecimal address 12c modification 12binarydigit address locations given e grabbe ramo e wooldridge eds ﬁhandbook automation computation controlﬂ vol 2 chap 2 pp 115121 john wiley sons inc new york 1959 2carrs triplet notation fractional significant digits digits exponent digits left radix point instruction upon completion operation stop machine proper external switches energizedﬂ binary com bination represented 5 operation code addition data addresses addresses given twelve binary digits three locations designate machine individual acoustic storage cells blocks eight magnetic drum storage cells addresses 0 1023 decimal 000 3ff hexadecimal correspond acoustic storage cells addresses 1024 4095 decimal 400 fff hexadecimal correspond mag netic drum storage blocks certain operations however addresses 0 15 decimal 0 f hexadecimal represent inputoutput stations rather storage locations twelvebinarydigit groups cases modified machine order yield final twelvebinarydigit address method processing depend values instruc tion modification digits modification final result interpreted control unit machine address instructions namely perform change control operations involve cycling counting rather simple arithmetic operations numbers 3 positions instruction considered addresses cases used instead counters tallies instructions require three addresses one two p position considered address cases oddness evenness 3 address used differentiate tween two operations operation code digits parity binary digit p22 used extra function designator instruction modification digits four binary digits p9p6 used instruction modification relative addressing digits normal function relatively simple nevertheless possible exceptions general rule make behavior complicated four digits labeled 209 210 part 3 instructionset processor level variations processor b c digits ordinarily digit associated position b digit position c digit position instruction binary digit p22 p position used instnic tion represent extra operation information instruction modification digit b ignored case input output instructions various address positions represent machine address locations drum inputoutput stations block lengths modification addresses desired case corresponding relative addressing digits ignored purpose instruction modification digits tell machine whether modify twelve binary digits making corresponding address position instruction addition contents one two counters normal case b c digit zero twelve binary digits corresponding position interpreted unchanged binary representation machine address number word processed instruction one b c digits one contents one two auxiliary address counters added corre sponding twelve binary digits yield final address usually differ ent given original twelvedigit portion instruction word addresses said relative counter two counters involved address modification feature midac known instruction counter base counter normal case fourth instruction modification digit zero contents instruction counter added contents various twelvedigit addresses dependent values b c digits processing instruction digit one digit zero contents instruction counter added address similarly b digits p address etc digit one contents base counter normally added contents twelve digits b positions dependent values b c digits processing results digit one digit one contents base counter added address etc marized follows effect instruction modification digits may sum contents two counters designated c 0 1 c contents instruction counter c contents base counter section 1 1 processors greater 1 address per instruction modified addresses b related addresses appearing instruction following ac p 1xd cc b c 0 1 certain instructions addresses relative one two counters may prohibited thus particular instruction n may relative instruction counter instruction ac matter whether digit 0 1 location whose address b notation b used indicate word stored instruction counter instruction counter twelvebinary digit modulo 4096 counter contains binary representation address instruction control unit processing process normal operation change control opera tion processed contents instruction counter increased one completion instruction thus normally next instruction processed stored acoustic storage cell immediately following cell contains present instruction change control operation one selects next struction stored sequence acoustic storage completion instructions contents instruc tion counter increased one instead changed en tirely base counter base counter second twelvebinarydigit counter modulo 4096 physically identical instruction counter con tains binary representation base number tally unlike instruction counter however base counter se quence automatically remains unchanged change base instruction processed counter serves two primary purposes dependent usage put 1 may contain address initial word group thus serving base address integers representing relative position given word group words may added using address modification digits chapter 14 instruction logic midac 211 2 may contain counter tally increased base instruction instruction makes use address modification digits change counter count number traversals particular cycle instructions instruction types instructions used midac divided three categories change information change control transfer informa tion first category subdivided arithmetic logical instructions arithmetic instructions included addition subtraction division various forms multiplication power extraction number shifting number conversion instruc tions sole logical instruction extract modifies infor mation nonarithmetic fashion transfer information data transfer instructions include transfers individual words blocks words acoustic storage drum magnetic tape control possible change control instructions includes two com parisons provide different future sequences dependent differences two numbers compare numbers algebraic comparison difference algebraic signed one compare magnitudes absolute comparison difference one absolute values two instructions file base perform tasks beside transferring control file instruction transfers control unconditionally file instruction files stores contents base instruction counter specific address position particular word storage base tally instruction provides method referring addresses automatically relative address given base counter irrespective contents base instruction also gives conditional transfer control nineteen midac instructions described function ally follows change information add p placed result must less 1 absolute value subtract p placed result must less 1 absolute value multiply low order least significant 44 binary digits x p placed multiply high order significant 44 binary digits x p placed 5 6 7 8 9 10 11 multiply rounded significant 44 binary digits x p k 1 245 placed 1 245 added x p positive subtracted x p negative divide significant 44 binary digits da placed note inversion order p result must less 1 absolute value power extract number n 244 placed n number binary 0s left signifi cant binary 1 b digit ignored p may even number zeros zero placed shift number 44 binary digits immediately right radix point 2p2 placed result equivalent shifting n places n 244 p 11 positive indicates shift left n negative shift right in1 2 44 zero placed extract logical transfer binary digits including sign digit whose positions correspond 1s p replaced digits corresponding positions decimal binary conversion operation may interpreted two ways considered binary codeddecimal integer times 244 converted equivalent binary integer times 237 result placed b considered binarycoded decimal fraction converted intermediate binary fraction ri bi x loll x 237 result placed obtain b true binary equiv alent bi must multiplied x 237 ever since factor greater l therefore represented machine two operations must performed example b x 1011 x 237 1 b b bi bj b digit ignored p may eoen number binarytodecimal conversion considered binary fraction converted equivalent elevendigit bi narycodeddecimal fraction result placed b digit ignored 3 may odd number change control 12 compare numbers relative instruc tion counter 2 p contents instruction counter increased one normally done end instruction b contents instruction counter set 212 part 3 instructionset processor level variations processor 13 14 15 compare magnitudes relative instruc tion counter 1 2 p 1 contents instruc tion counter increased one normally done end instruction 1 p 1 contents instruction counter set base tally digit ignored p may relative base counter instruction counter 2 p contents base counter set zero contents instruction counter increased one usual 3 contents base counter set contents instruc tion counter note comparisons made addresses contents file p may odd number may relative instruction counter 0 contents instruction counter creased one placed position instruction counter set 1 contents base counter placed position instruction counter set addition b 1 contents base counter set zero b 0 contents base counter changed transfer information 16 17 section 1 processors greater 1 address per instruction 16 alphanumeric read digit must 1 b digit ignored p range 0 7 decimal 000 007 hexadecimal characters read acoustic storage inputoutput station 3 first character read placed second 1 etc character occupies six significant digit positions register read positions set zero operation may used read words drum acoustic storage alphanumeric read digit must 1 c digit ignored starting p read consecutive char acters acoustic storage inputoutput station must range 0 7 decimal 000 007 hexadecimal operation may used read words acoustic storage onto drum move tape forward b c digits ignored 3 may even number must range 0 15 decimal 000 oof hexadecimal magnetic tape inputoutput station moved forward n blocks 17 18 a1 nt 1 one plus integral part yx number blocks include words 19 move tape backward b c digits ignored 3 may odd number must range 0 15 decimal 000 oof hexadecimal magnetic tape inputoutput station moved backward n blocks read digit must 0 b digit ignored p range 0 7 decimal 000 007 hexadeci mal words read acoustic storage putoutput station p first word read placed second 1 etc p range 1024 1791 decimal 400 6ff hexadecimal words read acoustic storage drum starting first word drum block whose address p first word placed second 1 etc read digit must 0 c digit ignored starting p read consecutive words acoustic storage inputoutput station range 0 7 decimal 000 007 hexadecimal drum starting beginning drum block whose address range 1024 1791 decimal 400 6ff hexadecimal references leina54 references carrj56 seac computer references ainse52 alexs51 elbor53 grees52 53 hauer52 pikej52 serrr62 shupp53 slutr51 dyseac computer a1 ti 1 one plus integral part yx number blocks include words chapter 15 instruction logic soviet strela arrowl john w caw iii typical general purpose digital computer using threeaddress instruction logic strela arrow constructed quantity leadership iu la basilewskii soviet academy sciences described detail kitov 1956 com puter uses 35 6 02 binary floating point number system instruction word 43 digits contains sixdigit operation code three 12digit addresses one breakpoint bit octal notation two digits represent operation four addresses one bit breakpoint machine operates 2048 words highspeed cathode ray tube storage inputoutput ordinarily via punched cards punched paper tape ﬁstandard program libraryﬂ attached com puter well magnetic tape units termed ﬁexternal accumula torsﬂ note computer different besm described lebedev 19561 ural reported basilewskii 19571 apparently somewhat lower performance besm since arithmetic ordinarily floating point ﬁspecial instructionsﬂ perform fixed point computations instruction modifications ordinarily instructions written octal notation external machine operation symbols written mnemonic code twodigit numerals octal instruction equivalent arithmetic logical instructions 01 cy 3 algebraic addition p result 02 3 special addition used increasing ad dresses instructions command added number 3 result sent cell address e grahhe ramo e wooldridge eds ﬁhandbook automation computation controlﬂ vol 2 chap 2 pp 111115 john wiley sons inc new york 1959 carrs triplet notation fractional significant digits digits exponent digits left radix point rule address instruction changed corresponds address 03 3 subtraction signed numbers number subtracted number p result sent 04 cy 3 difference absolute value two numbers iai ipi vi 05 x 3 multiplication two numbers result sent 06 3 1ogical multiplication two numbers cells p instruction used extraction given number instruction part defined special number p 07 v cy 3 logical addition two numbers p sending result cell instruction used forming numbers commands parts 10 sh 3 shift contents cell number steps equal exponent p exponent p positive shift proceeds left direction increasing value negative shift right addition sign number shifted cell lost 11 cy 3 special subtraction used decreasing addresses instructions cell found instruction transformed cell p specially selected number ordinarily addresses identical 12 3 comparison two numbers p means digital additions numbers compared modulo two cell placed number possessing ones digits inequivalence results numbers compared control instructions 13 c cy 3 0000 conditional transfer control either instruction instruction p depending results preceding operation operations addition sub traction subtraction absolute values appraises sign 213 214 part 3 1 instructionset processor level variations processor result positive zero result transfers control command negative results command p result operation multiplication dependent relationship unity transfer made command case result greater equal one command p smaller one conditional transfer operation comparison transfer instruction made case equality binary digits p inequivalence operation logical sequential multiplication conditional transfer command jumps instruction result different zero instruction p equal zero forced comparison given c 0000 third address command used place put zero 14 10 0000 0000 instruction executed paral lel code operations guarantees bringing working position good time zone external ac cumulator magnetic tape unit address 15 h 0000 0000 0000 instruction executes ab solute halt group transfer instructions special instructions group transfer serve accomplish ment transfer numbers accumulators second address instructions stands integer desig nating quantity numbers group must trans ferred group transfers always produced increasing sequence addresses cells storage 16 0000 n instruction guarantees transfer given input unit punched cards perforated tape etc storage third address instruction indi cated initial address group cells storage numbers written punched paper tape punched cards variables written sequence beginning first line 17 0000 n instruction guarantees transfer group n numbers input unit external accumulator zone 20 n instruction guarantees linebyline sequence transfers n numbers zone external accumulator cells storage beginning cell address section 1 1 processors greater 1 address per instruction 21 n 0000 instruction guarantees trans fer inputoutput unit punched paper tape punched cards group n numbers storage beginning address record punched paper tape punched cards rule begin first line therefore positive indication addresses record required 22 n instruction guarantees transfer group n numbers one place storage initial address another place storage initial address 23 n instruction guarantees transfer group n numbers storage initial address external accumulator address 24 n 0000 instruction serves transfer n numbers zone external accumulator address inputoutput unit instructions performed concurrently machine operations standard subroutine instructions certain instructions strela although written ordinary instructions actually ﬁsyntheticﬂ instructions call subroutine computation function involved amount machine time number basic instruction cycles itera tive process depends required precision computed function figures given based approximately tendigit decimal numbers desired precision one tenth place 25 3 standard subroutine serves exe cution operation division number divided number p quotient sent cell 7 actual operation division executed two steps initial obtaining value inverse divisor dividend multiplied computation inverse given usual newton formula originally used edsac wilkes et al 19521 yn1 ynp yn4 x 2p z 1 first approximation taken 2p standard subroutine takes 8 10 instructions executed 1820 machine cycles execution time one typical command 26 0000 instruction guarantees obtaining value value x sending result cell initially l computed iteration formula chapter 15 instruction logic soviet strela arrow 215 first approximation taken zpz 0 bracket indicating ﬁintegral part ofﬂ result multiplied x obtain 6 standard subroutine contains 14 instructions executed 40 cycles 27 ex 0000 instruction guarantees formation l value x sending result cell computation produced means expansion ex power series standard subroutine contains 20 instructions executed 40 cycles 30 lnx 0000 instruction guarantees forma tion function x value x sending sult location computation produced expansion x series subprogram contains 15 instructions executed 60 cycles 31 sinx 0000 instruction guarantees execu tion function sin x sending result location computation produced two steps initially value argument translated first quadrant value function obtained series expansion subroutine contains 18 instructions executed 25 cycles 32 db n instruction performs conversion group n numbers stored locations 1 bi narycoded decimal binary sending result loca tions l subroutine contains 14 instructions executed 50 cycles number 33 bd n instruction performs conversion group n numbers stored locations 1 binary system binarycoded decimal sends loca tions l subroutine contains 30 instructions executed 100 cycles number 34 ms n instruction storage sum ming instruction produces formal addition numbers stored locations beginning address result sent location numbers instructions added fixed point sum may compared previous sum control storage accuracy references basii57 kitoa56 lebes6 wilkm52 section 2 processors constrained cyclic primary memory processors use one extra 1 address specify address next instruction obviously address used allow complete freedom location operands next instructions optimum manner ibm 650 1 1 address computer straightforward un derstand ace zebra subtle microcoded instructions achieve powerful instruction sets lgp30 lgp21 simple 1 address instruction format interlace sev eral logical addresses physical addresses help optimum location operands olivetti underwood programma 101 desk calculator programma 101 desk calculator computer implemented cyclic mp cyclic memory apparent users viewpoint response adequate less 01 sec simple arithmetic operations programma 101 discussed part 3 sec 4 page 235 zebra simple binary computer zebra presented chap 12 discussed part 3 sec 1 page 190 lgpso lgp21 lgp30 chap 16 firstgeneration 31bit computer mpcyclic simple isp computer appears characteristic smallscale drum computers first generation think class computer little power compared example ibm 701 however power mostly related drumbased tech nology 026 1666 millisecond access times pilot ace npl pilot ace presented chap 11 relationship computer space discussed part 3 sec 1 page 190 univac system univac described chap 8 discussion given part 2 sec 1 page 91 design philosophy pegasus quantityproduction computer pegasus cyclic memory general register computer chap 9 discussed part 2 sec 2 page 170 ibm 650 instruction logic ibm 650 1 1 address format complete instruction set long word length 10 decimal digits would consider general utility 650s high performance achieved using fast drum 6 millisec ondsrevolution characteristics given chap 17 present machine first introduced 1954 later versions provided options floating point arithmetic index regis ters 96word core buffer also added disk mag netictape buffering machine structure simple 1 pc without concurrent processing inputoutput transfer abil ity although 650 large word initially processed fixed point integers nova listoriented computer nova chap 26 specialized computer processing array data discussed part 4 sec 2 page 315 216 chapter 16 lgp30 lgp21 lgp30 small computer mpdrum distinct first succeeding generation computers using mprandomaccess described using pms dia gram fig l lgp21 direct descendant lgp30 isp also described fig 1 since one addressinstruction method needed optimal allocation operands otherwise instruction might wait complete drum disk revolution time data reference made lgp30 provides operand location optimization interlacing logical addresses drum two adjacent addresses eg 00 01 separated nine physical locations spaces allow operands located next instructions use 64 tracks 64 words sectors word accessed track address 6 bits word address 6 bits sequence words sectors within track 00 57 50 43 36 29 22 15 08 01 58 51 44 37 06 63 56 49 42 35 28 21 14 0700 time two adjacent physical words approxi mately 0260 millisecond time two adjacent addresses 9 x 0260 2340 milliseconds actual maximum taccess 1666 rns2 half instruction 15 bits unused could used extra instructions indexing indirect addressing second 1 address locate next instruction increase preformance lthe lgp21 space 18 words 2the later lgp21 appears lower performance lgp30 factor 3 lgp30 technology 113 vacuum tubes i350 diodes power 1500 watts weight roo pounds number produced 320 490 tdelivery september 1956 descendant lgp21 pcl address 1 instructionw data wbvifr mps 2 w operations x ax 2 mpdrum tcycle 260 usw taccess 260 166 ms rate 234 msw contiguous addresses 4096 w 31 space bw tflexowriter paper tape lgp21 technology 460 transistors 375 diodes power 300 watts weight 90 pounds number produced 150 tdelivery december 1962 mpfixed head disk cyclic tcycle 400 usw taccess 0 52 ms irate 726 msw contiguous addresses 4096 w 311 space bw t132 flexowriter paper tape analog crt card fig 1 lgp30 lgp21 pms diagrams isp given appendix 1 chapter straightforward book 16 instructions program state less two words although perform ance limited mpcyclicaccess mpran domaccess would serve make isp fairly similar faster computers eg ibm 701 217 218 part 3 1 instructionset processor level variations processor section 2 processors constrained cyclic primary memory appendix 1 lgp30 lgp21 isp description appendix 1 lgp30 lgp21 isp description pc state ad 302 c48 2324 29 ov run pc console state 0p481632 tc accmtator propram counter register overflow lcp21 lcp30 machine stops overflow break point switches transfer control switch 8 state mo778o778o30 primaru memory 212 w track sector word state following input output devices synchronization rescription variables lcp21 lcp30 flexowriter inputdevi ce lo 31 11 6 stop code condition signifying input devce read special code outputjeviceo31 16 instruction format i030 opajj i4215 td5 i1823 tal4 tl5 sd5 iq429 skip condition tt43 instruction interpretation process bp 0 run tmc c tc next lnstructiongxecution instruction set instruction execution process instruct iongxecut ion 2 op 0 oooooe run skip condition c tc 1 ia ov ov c 1 b op 1 mtll op 2 mtls1829a1829 r op 3 mts11829 cc 1 op 4 7 iaj t62 ta x z6 logical ia t62 x z4 logical 7 iaj tf62 f inputbbit id t62 inputhjit instruction operation code track select bit mp innutoutput select lcp21 sector setect hit w fetch execute stop sense bp transfer sense overflow transfer bring memory store address set return address shifts input chapter 16 lgp30 lgp21 219 appendix 1 lgp30 lgp21 isp description continued 6 inputdubit ca x 2 logical next k253cd inputdevicetl next haov stop code inputbit input4bit ax z4 logical next a273cd input devicetllb next haov stop code inputy4bit op 5 0va rounda mctlsl n op 6 ax mtlsl sinteqer op 7 ta x mtlsl sfraction p op lo8 i4 outputdevicetll6 tad5 ou tpu tdev ce 6 c ad ioloo e op 118 mtls u op 12 c tos op 13 id acu v tc c c t0s ti f c tos h op 14 mtlsl c op 15 mcticsl next op 16 ovoa mtsl 5 op 17 ovoa mtl51 input processes wait divide multiplly save right multiplu save left print 6 bit print 4 bit extract unconditional transfer transfer control conditional transfer hold store clear add subtract end innstructionexecution chapter 17 10 9 8 7 6 5 4 2 3 1 data next instruction op code address address ibm 650 instruction logic1 0 sign john w cam iii basic ibm 650 magnetic drum 100 02 decimal computer inputoutput instructions oneplusone address instruction logic storage 1000 2000 10digit words plus sign addresses 00000999 00001999 extended versions equipment builtin floating point arithmetic index accumulators basic machine described three arithmetic regis ters addition standard program register program counter information drum arithmetic unit passes signed 10digit distributor twentydigit ac cumulator divided lower upper part 10 digits sign addressable distributor 8001 lower accumulator 8002 upper accumulator 8003 accumula tor may cleared zero separately ibm 650 terminology ﬁresetﬂ entire 20digit register considered unit part separately affecting case carries 10digit instruction broken following form one particular instruction table lookup allows automatic table search one particular element table stored corresponding functional value inputoutput via 80digit numerical punched cards ﬁalphabetic deviceﬂ allows limited alphabetical entry cards certain 10word groups magnetic drum available input output following information taken ibm 650 manual type 650 magnetic drum dataprocessing machine manual operations much inputoutput handled via board wiring de scribed detail twodigit pair represents machine code brd branch digit operation used special board wiring tell certain specific card punches exist iin e grabhe ramo e wooldridge eds ﬁhandbook automation computation controlﬂ vol 2 chap 2 pp 9398 john wiley sons inc new york 1959 carrs triplet notation fractional significant digits digits exponent digits left radix point 70 rd read operation code causes machine read cards twostep process first contents 10 words read buffer storage automatically transferred one 20 40 possible 10word groups read general storage group selected determined address read instruction secondly card moved reading brushes information read entered buffer storage next read instruction 71 pch punch operation code causes card punch ing two steps first contents one 20 40 possible 10word groups punch storage transferred punch buffer storage group selected specified address punch instruction secondly card punched infor mation buffer storage 69 ld load distributor operation code causes contents address location instruction placed distributor 24 std store distributor operation code causes contents distributor distributor sign stored location specified address instruction contents distributor remain undisturbed addition subtraction instructions io au add upper operation code causes contents address location added contents upper half accumulator lower half ac cumulator remain unaffected unless addition causes sign accumulator change case contents lower half accumulator complemented also units position upper half accumulator reduced one 15 al add lower operation code causes contents address location added contents lower half accumulator contents upper half accumulator could affected carries 11 su subtract upper operation code causes contents address location subtracted 220 chapter 17 1 ibm 650 instruction logic 221 contents upper half accumulator contents lower half accumulator remain unaffected unless subtraction causes change sign accumulator case contents lower half accumulator complemented also units position upper half accumulator reduced one 16 sl subtract lower operation code causes contents address location subtracted contents lower half accumulator contents upper half accumulator could affected carries 60 rau reset add upper operation code resets entire accumulator plus zero adds contents address location upper half accumulator 65 ral reset add lower operation code resets entire accumulator plus zero adds contents address location lower half accumulator 61 rsu reset subtract upper operation code resets entire accumulator plus zero subtracts contents address location upper half accumulator 66 rsl reset subtract lower operation code resets entire accumulator plus zero subtracts contents address location lower half accumulator accumulator store instructions 20 stl store lower memory operation code causes contents lower half accumulator accumulator sign stored location specified ad dress instruction contents lower half accumulator remain undisturbed important remember address store instructions must 00001999 8000 series address accepted valid machine store instruc tions 21 stu store upper memory operation code causes contents upper half accumulator accumulator sign stored location specified address instruction stu performed division operation another division multiplication reset operation takes place contents upper accumulator stored sign remainder divide operation opcode 14 contents upper half accumulator remain undisturbed 22 stda store lower data address operation code causes positions 85 distributor replaced con tents corresponding positions lower half ac cumulator modified word distributor sign distributor stored location specified address instruction 23 stia store lower instruction address operation code causes positions 41 distributor replaced contents corresponding positions lower half accumulator modified word distributor sign distributor stored location specified address instruction contents lower half accumulator remain unchanged sign accumu lator transferred distributor modified word mains distributor upon completion operation absolute value instructions 17 aabl add absolute lower operation code causes contents address location added contents lower half accumulator positive factor regardless actual sign operation completed distributor contain address factor actual sign 67 raabl reset add absolute lower operation code resets entire accumulator zeros adds contents address location lower half accumulator positive factor regardless actual sign operation completed distributor contain ad dress factor actual sign 18 sabl subtract absolute lower operation code causes contents address location subtracted contents lower half accumulator positive factor regardless actual sign wnen operation com pleted distributor contain address factor actual sign 68 rsabl reset subtract absolute lower operation code resets entire accumulator plus zero subtracts contents address location lower half accumulator positive factor regardless actual sign operation completed distributor contain address factor actual sign multiplication division 19 mult multiply operation code causes chine multiply 10digit multiplicand may multiplied 222 part 3 1 instructionset processor level variations processor 10digit multiplier develop 20digit product multiplier must placed upper accumulator prior multiplication location multiplicand specified address instruction product developed accumulator beginning loworder position lower half ac cumulator extending left upper half accumulator required 14 div divide operation code causes machine divide without resetting remainder 20digit dividend may divided 10digit divisor produce 10digit quotient order remain within limits absolute value divisor must greuter absolute value portion dividend upper half accumulator entire dividend placed 20position accumulator location divisor specified address divide instruction 64 div ru divide reset upper operation code causes machine divide explained operation code 14 div however upper half accumulator con taining remainder sign reset zeros branching instructions decision operations 44 brnzu branch nonzero upper opera tion code causes contents upper half accumulator examined zero contents upper half accumulator nonzero location next instruction executed specified address contents upper half accumulator zero location next instruction executed specified address sign ac cumulator ignored 45 brnz branch nonzero operation code causes contents entire accumulator examined zero contents accumulator nonzero location next instruction executed specified address contents accumulator zero location next instruction executed specified address sign accumulator ignored 46 brmin branch minus operation code causes sign accumulator examined minus sign accumulator minus location next instruction executed specified address sign accumulator positive location next instruction executed specified address contents accu mulator ignored 47 brov branch overflow operation code section 2 1 processors constrained cyclic primary memory causes overflow circuit examined see whether set overflow circuit set location next instruction executed specified address overflow circuit set location next instruction executed specified address 9099 brd 110 branch 8 distributor position 110 operation code examines particular digit position distributor presence 8 9 codes 9199 test positions 19 respectively test word code 90 tests position 10 8 present location next instruction executed specified address 9 present location next instruction executed specified address presence 8 9 stop machine shift instructions 30 srt shift right operation code causes con tents entire accumulator shifted right number places specified units digit address shift instruction maximum shift nine positions possible data address units digit zero result shift numbers shifted right end accumulator lost 31 srd shift round operation causes contents entire accumulator shifted right number places specified units digit address instruction 5 added 5 accumulator negative twentyfirst blind position amount accumulator data address units digit zero shift 10 places right rounding 35 slt shift left operation code causes con tents entire accumulator shifted left number places specified units digit address instruc tion maximum shift nine positions possible data address units digit zero result shift numbers shifted left end accumulator lost however overflow circuit turned 36 sct shift left count operation code causes 1 contents entire accumulator shifted left nonzero digit significant place 2 count number places shifted inserted two loworder positions accumulator instruction aid fixedpoint scaling table lookup instructions 84 tlu table lookup operation code performs automatic table lookup using address location chapter 17 ibm 650 instruction logic 223 first table argument address address next instruction executed argument search made must distributor address table argument equal higher equal exists argument given placed positions 85 lower accumulator search argument remains unaltered distributor miscellaneous instructions 00 noop operation code performs opera tion data address bypassed machine automatically refers location specified instruction address noop instruction 01 stop operation code causes program stop provided programmed switch control console stop position programmed switch run position 01 code ignored treated manner 00 noop references type 650 magnetic drum dataprocessing machine manual operations hughe54 serrr62 section 3 processors variablelengthstring data although two computers described section reader might refer computers book handle variablelength strings ibm system360 processes string whose length specified instruction burroughs b 5000 nice string data isp simple power ful variablelength strings imply method specify struction execution time actual length character strings processed method used substan tial effect isp resulting machine note worthy wide variety devices tried without apparent consensus yet appropriate mechanism 1 extra bit character mark string bound ary ibm 1401 2 special terminal character mark string boundary ibm 702 3 field variable instruction specify string length ibm system360 4 register variable processor specify string length 8bitcharacter computerchap 10 5 fixed number characters head string specify length data type string used extensively variablelength records tape disk though know isp uses ibm 1401 1401 ibms popular computer measured quantity produced prior 11301800 system360 however authors book unable find technical papers design design philosophy 1401 based earlier businessoriented computers fig 1 page 225 evolved great deal seen number features appended improve successors 1440 1460 also improvements assumed early computers mainly influence successor computers within organization 8bitcharacter computer 8bitcharacter computer chap 10 suggested authors restricted computer processing string data illustrates another approach string defini tions string length specified variable proc essor 224 chapter 18 ibm 1401 secondgeneration transistortechnology ibm 1401 included large number produced differs common fixed word length binary deci mal computers ibm 1401s used business dataprocessing applications requiring variablelength character strings fields rather limited calculating ability two specific applications card processor making transition plugboard programmed calculators fullscale automatic computations converting data one medium another example card tape 1401 little used scientific engineer ing scientific business dataprocessing communities probably limited mp size low overall processing speed lack concurrent 10 operation smaller configura tions however achieve considerable use standalone cio c7090 installations perhaps speed quality t1403 line printer although undoubtedly influenced machines outside ibm organization ibm 1401 derived primarily ibm 702 705 variable word length decimal machines relationship various ibm decimal computers one another shown fig 1 rcas early computers2 also use combination fixedlength variablelength 7bit character strings may influenced 1401 ibm 1401s isp first adopted another company honeywell defined h200 isp superset ibm 1401 isp isp h200 complex increases performance organizing mp characters words ibm 1401 1440 1460 ibm computers completely characterstring oriented instruc tions data stored variablelength character strings strings addressed pointer register string ad dress integer fixed three characters encoding process addresses given appendix 1 chapter 3char acter address 3 x 6 bits assigned 3 x 4 bcd characters encoding addresses 0999 2 x 2 bits selecting 16 x 1000 addresses 2 bits selecting one three index registers ibm 1620 processes variablelength data strings although 1966 1401s produced model esti mated 7500 1401s 1500 1401 gs cardonly system 3600 144os 1500 1460s produced 1800 1620s produced 2rca 301 501 601 instruction length fixed 12digit string corresponding word mp 1620 though identical 1401 almost member family 1401 evolved figure 1 shows evolution features created new computers 1401s optional features mainly design afterthoughts sometimes increase perform ance sometimes make certain operations possible sometimes provide substantive change approximately 19 features 1401 memory expansion beyond anticipated 4000 characters index registers required encoding field bits b addresses store aaddress store baddress register f fixed lengih instructon variable character string doto 1 honeywell h200 7070 7074 7072 tt 1 1620 1710 1620 ill 702 705 705 111 7080 core vocwk tubes 1 vtdrum xrdishmognetic tope fixed length instruction flied length doto 603 6086101 ti l technalogyvocuum felectromechncil tubest tt plugboard ond punched cpc 607 604 ci1cylators card progrommed miczoo digit tlrr geeroio 1 choneyse1i hzoo data wchor hrlng 2 pschor1401 comdotible cl141010zl80 hchar45prchor mpo 115 x5ehorl1401 comdotlble cl7olo 4ouloo ichor 1 2 pilchor doto wchoirtring 14011410 compohblc cl403 416 kchorllspischor 8 blehor2 addrerrmpsb8 char cl7070 6psr510 hwilo1signldlw5bld iddre4s1nstructionmpr 199xrli c17074 6psw5 30 hw cl7072 4piw 5 30 hw cc1620 2060 kohor 6 blchor 20pichor2 chorinstructlon storogem rtoroge mrfrocrms cit4606p0chrl ci1440 l1tpchm z oddieilnltrycfion c11620 111 inferrupf copobltyl 1 addrerslinstruction mpsi512 char11 cl702 2060 kchor 23pschar 6 blchar 5 charinstruction ci650 drum 124 hn t1 address nrtruction 10 t1 sign dw 5 bd fig 1 ibm decimal characterstring computer relationships 225 226 part 3 instructionset processor level variations processor instructions necessary subroutinesthe store address regis ter feature indexing feature multiplydivide feature high lowequal compare feature read release punch release feature column binary feature earlycardread feature processing overlap feature etc pms structure 1401 pms structure fig 2 early 1 pc structure diagram show sfixed pc interconnection structure ms pcmslt interconnection restricts concurrency ms optional processing overlap feature provides link mp allow tcard read punch run concurrently pc processing peripheral devices operating without processing overlap feature pc dedicated data transmission link k earlier computers device k connected directly pc example msdisk magnetic tape data transfers use main registers pc tie full time data transmission careful programming several devices synchronized thus run concurrently communicating pc k pc interrupt system thus peripherals way communicating pc subsequent models 1440 1460 added interrupt capability made easier control multiple simultaneous data transfers among peripheral ks pc tconsol msl405 disk mp2 pt1402 card readerpunch t1403 11404 line printer t1407 console inquiry station typewriter paner tape reader msl 6 magnetic tape pcstring 1 8 charinstruction mprocessor state 7 16 char technology vacuum tubes 19601965 descendants1440 1460 mpcore 115 pschar 4000 16000 char 7l parity bchar fig 2 ibm 1401 pms diagram section 3 processors variablelengthstring data isp structure ibm 1401 isp given appendix 1 chapter instruc tion strings data strings delimited special f bit character character mp form1 ccheckfba 8 4 2 1 ncharacter string co c1 cn 11 would stored mpjj n 11 first character head instruction must contain wordmark flag f bit head instruction interpreted next held mpij succeeding characters instruction mpi 11 mpi 21 etc correctly defined instructions 1 2 4 5 7 8 characters long un defined instruction lengths 8 characters also inter preted without error condition interpretation algorithm presented isp description explain action instructions incorrect length actually 1401 reference manual go details general instruction interpretation dwells correct operation table 1 presents correct instruction lengths formats take instruc tions table set variable length fixed six sizes instruction set including inputoutput instructions presented table 2 table also provides hint implementation since execution times given terms memory cycles isp state unlike conventional processors temporary operand storage eg accumulators isp state registers point operands state machine see appendix 1 basically mp instruction location counter indicators miscellaneous bits three 3character blocks mp reserved index registers two registers aaddress baddress point data operands instruction interpretation three principal state types processing instruction oq instruction formed ov operands accessed results stored mp 0 operation specified instruction carried state transition corresponds essentially memory access three instruction types fig 3 particular states types 1 2 process variablelength see appendix 1 chapter meaning bits character renamed arid b bits b avoid confusion registers chapter 18 ibm 1401 227 table 1 ibm 1401 instruction formats 1 coi noop halt single character specify chained instruction 2 wl 311 dcharacter used specify addi tional instruction information eg select card stacker 4 coi c1 2 31 unconditional branch instruction sin gle address arithmetic fma 5 coi c1 2 31 c41 conditional branch instruction c4 se lects specific test 7 col c1 2 31 c4 5 61 two address instruction mb mb b eg add sub tract 8 col c1 2 31 c4 5 61 wi conditional branch based mpb char acter dcharacter test character eg branch character equal function instruction characters co op code always contains wordmark flag f bit c1 2 31 branch address 1address register first operand address aaddress register c1 c4 c7 dcharacter used single character additional operation code information character comparison select test c4 5 61 primary operand baddress register specification character strings charstring state diagram accounts strings characteratatime basis add instruction fig 3 oversimplifies execution implies character b operand accessed addition per formed result restored according baddress register complex description must account b strings unequal length case getting number must recomplemented wrong sign complementation process requires reverse scan find end b string forward scan recomplement character b figure 4 detailed state diagram add execution process states isp description appendix 1 within structioninterpretation process correspond three state types described singleinstruction characterfetch operation fetchoperandaddresses remainder instruction instructionexecution instructionexecution given detail example execution add defined ﬁaﬂ op 110001 ovomb c mb charstring state diagram fig 4 presents execution detail note isp description omit telling reader b address registers point next lowest variablelength string operation performed allow definition variablestring operation example charstring imply action processor state instructions defined single character called chained instructions chained instructions take previous values pointer registers b address registers operand addresses add instruction exam ple either 1 chained 4 7 characters forms instructions appear table 1 4character add instruction places address field b address registers thus effect instruction double string add data ndecimaldigit numeric data string represented cn 11 cn 21 cl c0 cm underlined characters cn 11 cm flag bit present cn 1f 1 cmf 1 n characters stored locations mp jl mp j 11 mpj 228 part 3 instructionset processor level variations processor table 2 ibm 1401 instruction set excluding input output section 3 processors variablelengthstring data instruction op execution time codet memory cyclest length du tu char ty pe add recornplernent li 3 la lb 1 4 7 add recomplement li 3 la 4lb 1 4 7 branch b li 1 4 branch bit equals w li 2 8 branch character equal b li 2 8 branch indicator b li 1 5 branch word mark andor zone v li 2 8 clear word mark li 3 1 4 7 compare c li 1 la lb 1 7 divide aver li f 2 7lrlq lq 7 halt li 1 1 load characters word mark l l 1 2la 4 7 modify address5 j l 9 4 7 move characters edit e li 1 la lb l 7 move characters record word marks p li 1 2la 7 move characters suppress zeros z li f 1 3la 7 move insert zeros x li 1 2zla zlz 7 move numeric li 3 1 7 move zone li 3 1 7 mu ply aver operation n lr 1 1 set word mark li 3 4 7 store aaddress registers q li 5 4 store baddress registers h li 4 4 subtract recomplement li 3 la lb 1 4 7 subtract recornplernent li 3 la 4lb 1 4 7 zero add li 1 la lb 1 4 7 zero subtract li 1 la lb 14 7 clear storage li 1 lx 14 7 move characters b word mark li 1 2lw 4 7 li 3 2lc 5lclm 7lm 7 alphanumeric code used specify instruction mtcycle 115 pschar optionalfeature instructions abbreviations symbols used timing la length afield characters lb length 6field lc length multiplicand field l length instruction lm length multiplier field l length quotient field lr length divisor field ls number significant digits divisor excludes highorder os blanks lw length bfield whichever shorter lx number characters cleaned ly number characters back rightmost 0 control field lz z number fields included operation number os inserted field char string char string 3 char 1 3 char 1 3 char 1 3 char 1 3 char char string 1 char char string char string char string 3 char char string char string char string char string char string 1 char 1 char char string 1 char 3 char 3 char char string char string char string char string chapter 18 ibm 1401 229 character q operotion complete type 1 type 2 mcblf mcalmcblchor string mcblfmca1cchor string note time state roughly 1 memory cycle q instruction q 0q operation memory access determine instruction q correct length instruction 1 2457 8 characters oy operation memory access fetches determine operand 0 operation specified instruction q requires time 0v operand memory access stores restore result operand fig 3 ibm 1401 instructioninterpretation state diagram n 11 values string based bcd value 8 4 2 1 bits digit magnitude integer cn 11 x 10n1 cn 21 x ion co x 10 sign sign lcoa cob llcoia cib string addressed accessed via aaddress bad dress pointer registers point tail least significant digit c0 string instructionexecution state diagram variablestring add shown fig 4 state diagram assumes b address registers set accord ing fig 3 thus fig 4 detailed description states ov ov 0 0v horizontal pair states fig 4 corre sponds single scan states type 1 instruction ov ov 0 0v fig 3 transition among states 2 3 correspond characterbycharacter scan string b added together result string placed b states 4 5 define string addition string terminated ie con sidered zero states 7 8 9 10 define recomple mentation process b string recomplemented condition occurs operand signs differ afield result greater b field results tens complement form states 7 8 define bfield scan return find least digit b states 9 10 define recom plementation character thus add operation may quire three scans b string 1401 isp appendix 1 chapter four parts state declaration instructioninterpretation process instructionexe cution process operand addressregister calculation proc ess operand addressregister calculation process analogous effectiveaddress calculation conventional pcs elaborate part instruction interpretation operand address registers aaddress baddress part pc state must retained instructions end instruction registers point character next lowest data string mp character cn implementation 1401 small pc state registers implementations figure 5 shows registers interregister transfer paths data operations make register initiol stote operand oddressee auaddress buaddress registers pointing b str8ngs corrymemb mry chor string addition string terminated recomp elf b string hor terminated 8 go head result string b must 1 7 e stmg 1 meiftrbbi wrong slgn fig 4 ibm 1401 addinstructionexecution state diagram 230 part 3 instructionset processor level variations processor l section 3 processors variablelengthstring data 11 inhibit milve adder storage logic 4 4 4 f 1 f 4 aux b b aux 0 address address address admiess address address 1 1 address op modifier reg decode f 1 f f f aux address address address op modifier decode 1401 process overlap fig 5 ibm 1401 system data flow registers structure courtesy international business machines corporation c transfer level primitives complete computer together several options options course increase complexity concurrency without overlap feature example data accessed mp via pcs address registers register pairs consisting 3character memory address access register 1character data register memoryaddress memorydata register pairs aaddress adata baddress bdata 1address operationop overlap address overlapdatao implementation straightforward instruction times table 2 show implementation registertransfer level example instruction read pc prior instruction execution new character taken ex amined instructionterminating flag bit flag bit present instruction complete ready executed character next instruction saved picked previous instruction executed chapter 18 ibm 1401 231 appendix 1 ibm 1401 isp description appendix 1 tbm 1401 isp description following description highly simplified description ibm 1401 line corresponds three page description reference manual 1401 tions transfer character strings fixed blocks primary memory chstringchs b strings end operations aspect operation describedbut implied string operations pc pc console io device control states example edit instruction given onr include inputoutput instruc character strings denoted characterstring characterstring operations aaddressa brrddressb registers contain pointer next 134a8421 laddress register instruction location pointer laddress register laddress register string data pointer registers b point least significant digit end variable length string memory see mp state definition ech6 0perationsb normally result string length defined word mark f last character b string pointer significant digit instruction two additional bits check field bits mp normally b decreased one move significant end varinble length string string word mark shorter b string remaining string taken zero although pc register characters ba8421 bits checkparitybit wwordarkffielbit digit last digit variable length numeric integer string ba8421 bits bed digit 0 b sum modulo 2 fba8421 bits bit defines beginning instruction f bit also defines significant numeric data represented 8421 bits used 6 bit character encoded bits sign encoded least significant digit numeric data minus sign encoded bu combinations ab represent plus sign f xr 1 31 3la1a842li m8789929497996at8421 3 three character optional inder registers stored mp nd ca tors 0 631 set 31 status bits possible 64 used external c status io status e indicators assignment pc state logical bit array encoding f state including ia bl cleare set instruction control indicators indicators selected testing bu character instruction unconditional 1 alqus 1 sensegwi tchd bc e fg unequa icompare ba set 7 covrsole keus equa1compare ra lowcompare hi ghdompare r r overflow set bg arithmetic overflow cleared branch instruction set indicator array partially encoded indicator oooooo unconditional indicator ioooi senseswi tcha nd ca tor 0 io00 unequa1compare indicator 011001 overflow mp state md15999checkfba8421 addressxl 31b 8421115 primaru memoru address encoding 1 0f 16000 3 char value repis ter x ivdexing described 232 part 3 instructionset processor level variations processor appendix 1 ibm 1401 isp description continued section 3 1 processors variablelengthstring data xb x 4000 xlb1 x iooo x 1r 47 ibcd tri nq instruction format op6bta8421 instruction register specifyivq operation dlhar4 ba8421 dcharpresent additional character usid tn eome instructions indicates djhar used current instruction active aaddresspresent badd res sup sent indicates instructiori strinp still fetched indicates address nart instruction indicates r iddress part instruction vove load store instruction types control initialization e mdve load store bmls move characters edit opl v load characters word mark opl v move characters b idords mark op v move characters suppress zeros op v move numerical od v move zone opl v store address register opl v store r address register opll lnstruction internretation process run op c next fe chope randa dd res ses next instruct onlexecut ion fetch operation fetch addresses r execute address calculation process 1401 calculates explicit effective addresses first setting r address riigisters instructionxerution respectively char char address address char b address gp address e address char operands fetched 12457 8 character instructions op following operands folloiuinp process defines operation correct lenpth irstmctions fetchoperandaddresses dharpresent 0 mid active 0 1 char instruction yid active rnls b next proceed pet il adr7ress active dchar getchar next al dchar address set un dchar dcharpresent next m1s ai next active a2 getchar next mls b2 a2 next active getchar next next active adddressupresent 1 record alhether address present mls f e active aaddresspresent 0 next aaddresspresent dcharpresent 0 add index register a2ba 0 xra2ba1 ichl 7 mir b 0 next f adress set dchar active dchar getchar next bl dchar dcharpresent 1 active b2 getchar next active b getchar next active baddresspresent active baddressupresent 0 next baddresspresent f record 1ihether r addres oresent add index wgister b dcharpresent 0 el2b1a 0 b cb xrbzba 3chj chapter 18 ibm 1401 233 appendix 1 ibm 1401 isp description continued 7 16 active 4 dlhar getchar 7 mlh active run fnal hchar dcharpresent 1 next halt 8 char instruction end fetchoveranhaddresses get character subprocess used fetch new character instruction tf f found charazter process terminates qetcharb1a8421 7 mlf active mi mir active eo value present character value terminate rnstruction set instruction ezecution process lnstructionxection character stringchs movement clear memory move characters p b biord mak character string ichsi moue characters sutmress zero op iooioo mb cma z op ollool mb cma chs chz1 next mb cfmb chs l op ioooll mb cma ch51 load characters word mnrk e op ilolol mb cfmamb chs moue characters edit instruction moues field string b field string control edit character stmng original r field op oloool f mb c0 chsmod1001 bdddresspresent f baddresspresent character string chsi arithmetic op 110001 ovmb mb chsl j op 010010 ovmb cmbl mia chs 1111 op 101010 mb e0 chs op ll1010 mb e0 ch5 op 001100 0vme mb x ch op oliloo ovme tmb ich5 op oololl mb emb 3chl b cb 3 3 branches halt nooperation n op 100101 op llloll run eo laddressupresent aaddresspresent ib op 110010 l baddresspresent 1 baddresspresent dcharpresent c dcharpresent indicator fdchar nd cator f dchar 1 0 bgddresepresent dcharpresent b cb 1 e dchar clear storage ipnores 100 address clear storage clear storage antbnanch mark moves next modulo add subtract zero subtract zero add multiply full length product u b special harduare odtion divide auotient remainder end ud mbl vacifi address ooeration halt halt branch branch branch incicator branch char eaual 234 part 3 1 instructionset processor level variations processor appendix 1 ibm 1401 isp description continued section 3 processors variablelengthstring data op 010101 fb cb 1 mbddchar ic op ilooll indicators tma mb chs subroutine calling q op 101000 za a13 3 h op 11 1000 4 2a b13 3 single character operations op olloll f madcl mbpcl 1 b tb ig op ll1100 maf mrf ca 1 b tb 0 op 110100 mbg3421 tmad421 1 b tb 1 op 011000 mbba tmabla ta 1 b tb branch uod mark andor zona compare store address register store b address register set word mark clear word mark move nwnerical move zone end instructionexecution section 4 desk calculator computers keyboard programmable processors small memories stored program computers interesting features example keyboard utilized several ways 1 tconsole mode conventional console entering data response stored program program entry mode device creating stored pro grams desk calculator mode part arithmetic data element issuing direct instructions thus obtaining results directly independent program 2 3 uses 2 3 internally externally programmed data types decimal fixed floating intimate interface require user calcu lators interpret nested parenthesized algebraic expressions calculators easily meet definition stored program computer apparent designers know great deal general purpose storedprogram computers machines cleverly designed make efficient use hardware possess eventually may computers conventional stored program computers reader note ﬁelectronic desk calculatorsﬂ computers electronic versions mechanical electromechanical ancestors ollvettl underwood programma 101 desk calculator programma 101 chap 19 limit call stored program computer sufficient instruction set classified computer storage temporary data constants programs limited machines struction set interesting memory addressed explicitly jump example executed scanning program particular marker named jump instruction programma 101 uses mpcyclic program library programma 101 extensive provides indication capability hewlettpackard model 9100a computing calculator hp 9100a chap 20 like programma 101 chap 19 desk calculator stored program computers programma designed simpler accounting statistical tabulation tasks fixedpoint decimal data programma 101 costs somewhat less hp9100a operates fixed floatingpoint decimal data scalar rectangular polar coordinate vectors designed engineering scientific calculations thus according measure based data types operators hp 9100a complete computer book operations given pms diagram fig 1 mpreadwrite core 368 w 6 bw consol e keyboard c tconsolecrt display numeric decimal mixed floating datascalar rectangular coordinate vector polar co 1 ordinate vector fixed floating decimal operations x cos sin tan sin cos tanh sinhl coshi tanhi log abs e sqrt integer partrectangular coordinate vector c polar co ordinate vector polar coordinate vector c rectangular coordinate vector tan sinh cosh c 6 bprogramtep 3 tnumer cgri nter p ot ter lexternal device ltm magnetic card 2 programs 196 programtepsprograrn mi croprogramrned h processor state 40 b 1 pc mpread 512 w 64 bw pmicroprogrammed prnicroprogrammed mpcontro1 read 800 nsw 64 w 29 bw fig 1 hewlettpackard model 9100a computing calculator pms diagram 235 236 part 3 instructionset processor level variations processor implementation approximately 362 kb memory including readonly readwrite parts design physically outstanding use microprogramming superb reader note two levels mread could draw pms structure pc pmicro programmed within pmicroprogrammed hp rightfully gards two isps 29bit 64bit word proprietary carefully avoids discussing points article chap 20 might noted ibm system360 model 30 requires 29 milliseconds floatingpoint square root whereas hp 9100a requires 19 milliseconds way evidence outstanding packaging cost fiveeighths pdp81 amount physical hardware cost difference though trulydifficult compare partially result design instrument maker hewlett packard versus design computer manufacturer dec tvlike construction hp 9100a important les son computer manufacturers learned section 4 desk calculator computers keyboard processors small memories words henry ford yet emerge computer field guess may come japan whereas many computers book included typical points computer space hp 9100a included innovative worthy note one engineers computer design experi ence cochran programming prior experience circuitry instrumentation programmer training larger mp might required way comparative evidence ibm 1800 floatingpoint arithmetic functions x sin cos tan fl log exponential tanh binary decimal decimal binary require approxi mately 1425 16bit words 23 kb hand focal1 interactive calculator program 4096word pdp8 49 kb provides user polarrectangular coordi nates hyperbolic functions complete program editing capability text handling control structure 1600character mp similar scope dartmouths basic chapter 19 ollvettl programma 101 desk calcu latorl programma 101 manufactured olivetti underwood corporation cost programma 101 3500 1968 several thousand currently use unlike conventional stored program computers instructions exe cuted directly commands keyboard instructions stored program interpreted processor processor uses decimal representation mixed numbers decimal point location controlled manually although informa tion stored character strings maximum length 22 digits 24 instructions register program 120 characters long stored continuous string internal encoding character 8 bits absolute addresses instructions jump instructions programmed placing labels references string transfer programma 101 composed following elements memory memory stores nnmeric data program instruc tions keyboard keyboard four functions used operator control calculator power etc manual mode instructions executed immediately conventional desk calculator eg add keys write programs instructions memory instructions executed program run numeric data may entered running program printing unit serial printing right left 30 characters per second unit prints keyboard entries programmed output instructions magneticcard readerrecorder device permits instructions constants program stored retrieved magnetic cards control arithmetic units control unit administrative section computer receives incoming information determines computation performed directs lthe description partially taken programma 101 programming manual arithmetic unit find information operation perform pms diagram shown course simple conforms closely classic diagram digital computer looks like mppc tmmagneticcard tt ltprinter ltkeyboard primary memory processor memory memory 10 registers eight general storage two used exclusively instructions character several meanings depending register use two instruction registers 1 2 store 24 instruc tions instruction one character long eight storage registers r b c e f capacity 22 decimal digits plus decimal point sign sign decimal point require character space alterna tively e f hold 24 instructions r operating registers take part arithmetic operations considered arithmetic unit register median distributive register keyboard figure entries held register distributed registers instructed register functions arithmetic unit form accumulator arithmetic results developed retained register result 23 digits produced register r register retains complete results addition subtraction complete product multiplication remainder division remainder square root b c e f storage registers split two registers capacity 11 digits plus decimal point sign storage registers split right portion split register retains original designation left side identified corresponding lowercase letter thus registers become 237 238 part 3 1 instructionset processor level variations processor section 4 1 desk calculator computers keyboard processors small memories b b c c e f f f lowercase designation obtained first entering corresponding uppercase letter depressing key example c g c registers e f splits additional capability storing either instructions constants used within programs thus store 1 signed 22digit number 2 signed 11digit numbers 1 signed 11digit number 11 instructions 24 instructions programs 120 instructions stored internally fig 1 registers e f splits used instructions free store constants intermediate results relationship memory keyboard printer magnetic card shown fig 1 registers referenced explicitly pro grams use explicit addresses instruction thus special marker characters placed instructions serve jump reference addresses program labels fig 2 programma 101 courtesy olivetti underwood corporation structure calculator parts described briefly parts corre spond numbers fig 2 lettered keyboard fig 3 following parts effect console keys used control calculator used either programmed instructions commands executed directly following section discusses instruction function onoff key 1 dualpurpose switch positions note position automatically clears stored data instructions error red light 2 lights computer turned whenever computer detects operational error eg exceeding capacity division zero general reset key 3 key erases data instruc tions computer turns error light correctperformance green light 4 light indicates computer functioning properly steady light indicates computer ready operator decision flickering light indicates computer executing programmed instructions keyboard locked decimal wheel 5 determines number decimal places 0 1 15 computations carried register decimal places printed output 1 programma 101 functional block diagram courtesy f oli vetti underwood corporation except results r register 22 decimal digits may developed printed r register chapter 19 ollvettl programma 101 desk calculator 239 fig 3 programma 101 keyboard courtesy olivetti underwood corporation record program switch 6 switch commands pressed keyboard executed directly switch directs computer store instructions either memory keyboard onto magnetic program card memory record program switch must load instructions magnetic program card memory print program switch 7 switch directs computer print instructions stored memory present location program next stop instruc tion whenever print key 20 depressed magnetic program card 8 plastic card ferrous oxide backing used record programs external storage card inserted magnetic readerwriter 9 record instructions andor constants computer memory inserted card may removed computer 10 without disturbing stored instructions note magneticcard readerwriter uses half magnetic card time consequently two sets 120 instructions andor constants may stored single card keyboard release key 11 key reactivates locked keyboard two keys depressed simultaneously keyboard lock indicate misoperation opera tor know entry accepted computer touching keyboard release key clear entry key 16 must depressed complete figure reentered tape advance 12 advances printing paper tape tape release lever 13 enables adjustment changing tape rolls routine selection keys v w 2 keys direct computer proper program subroutine numeric keyboard keys 0 1 9 keyboard allows entry signed mixed decimal number keyboard entries automatically stored register clear entry key key clears entire keyboard entry keying program depression clear key erase last instruction entered memory printing tape spaced start key key restarts computer programmed operation used code stop instruction keying programs register address keys b c e f r keys identify corresponding registers operating register keyboard identification since computer automatically lates instructions register unless otherwise instructed split key key combined register exam ple c divides register two equal parts storage registers split right portion split register retains original designation left side identified tape corresponding lowercase letter example c g c print key 0 key prints contents addressed register clear key key clears contents addressed register computer operated manually depression key print number register clear transfer keys keys perform transfer opera tions storage registers operating registers arithmetic keys x 6 keys perform indicated arithmetic function keyboard storedprogram operations following keys used direct instructions le manually record program switch alternatively 240 part 3 1 instructionset processor level variations processor section 4 1 desk calculator computers keyboard processors small memories record program switch keys specify instruction recorded program memory finally descriptions specify instructions behavior executed within pro gram start instruction used creating program directs computer stop release keyboard entry figures selection subroutine figure entry program restarted touching start key program also restarted touching routine selec tion key instruction stops program computer may also operated manual mode without disturbing program instructions memory figures entered keyboard depression start operation key printed automatically clear clear operation directs computer clear selected register r registers cleared instruction computer operated manually key cause print contents selected register r r datatransfer operations j instruction containing operation j directs computer transfer contents addressed register r retaining original register contents r affected previous contents destroyed instruction containing operation directs computer transfer contents addressed regis ter retaining contents registers r unaffected instruction original contents addressed register destroyed r exchange instruction containing operation directs computer exchange contents register contents addressed register contents affected except exchange contents r register affected tr r dr exchange rs instruction rs directs computer exchange contents registers contents r register r r instruction special use multicard programs store temporarily contents dd register r new card read continue program tem porary storage instruction affecting r register executed decimal part instruction directs computer transfer decimal portion contents r register retaining entire contents original contents register destroyed r register affected instruction fractionparta arithmetic operations arithmetic operations performed operating registers r arithmetic operation performed two phases contents selected register automatically transferred register register selected automatically register indicated operation carried r registers 1 2 programma 101 perform arithmetic operations x fl absolute value figures accepted computed algebraically negative value entered depressing negative key time entry figure negative indication computer accept figure positive subtract operation key separate numeric key board used exclusively subtraction negation addition instruction containing operation directs computer add contents selected register addend contents register augend addition executed two phases 1 2 transfer contents selected register addend add contents contents augend ob taining sum truncated according setting decimal wheel complete sum r contains addend r next r next frdeci malwheel multiplication x instruction containing operation x directs computer multiply contents selected register multiplicand contents register multi plier 1 2 transfer contents addressed register multiply contents contents obtaining product truncated according setting decimal wheel complete product r contains multiplicand r next r x next fr decimalwheel chapter 19 ollvettl programma 101 desk calculator 241 subtraction instruction containing operation directs computer subtract contents selected register subtrahend contents register minuend 1 transfer contents selected register subtrahend subtract contents contents minu end obtaining difference truncated according setting decimal wheel complete difference r contains subtrahend r next r next frdecimalwheel 2 division instruction containing operation directs computer divide contents selected register divisor contents register dividend 1 2 transfer contents addressed register divide contents contents obtaining quotient truncated according setting decimal wheel decimally correct fractional remainder r contains divisor c r next rca mod syuare root instruction containing operation r directs computer 1 2 transfer contents selected register extract square root contents absolute value obtaining result truncated according setting decimal wheel r register contains nonfunctional remainder end operation contains double square root cr next mr sqrtabsm x 2 next c fm2 decimalwheel absolute value ai absolutevalue instruction changes contents register negative positive absa jump operations jump operation directs computer depart normal sequence stepbystep instructions jump pre selected point program instructions provide internal external manual decision capability useful create ﬁloopsﬂ allow repetitive sequences program executed routines subroutines performed discretion operator automatically ﬁbranchﬂ alternate routines subroutines according value register jump process consists two related instructions char acters 1 reference point label 1 program begins jump start sequence restarted point label effect interpreted jump instruction specifies label instruction sequence 2 two types jump instructions unconditional jumps conditional jumps unconditional jumps jumps executed whenever instruction read labels reference points unconditional jumps l corresponding jump instructions j given lj permissible jump labels jump constructions avv aww ayy azz bvcv bzcz evdv ezdz fvrv fzrz programs must begin reference parts uncondi tional jump instruction reference points av aw ay az used program sequences started touching routine selection keys v w z conditional jumps contents register greater zero program jumps corresponding reference point label zero less program continues next struction sequence labels reference points conditional jumps l corresponding conditional jump instruction cj given lcj permissible jump labels jump instructions avv azz bvcv bzcz evdv ezdz f vrv fzrz constants instructions onedigit constant gener ated special instruction results instruction place digit digit value constant must follow instructions data register instruction considered data therefore used constant instruction another technique allows computer interpret 242 part 3 1 instructionset processor level variations processor data null instructions data reading writing instructions stored register exawlpzes program take values numbers b c keyboard print value expression b x cd would written follows instruction av j jm1 xm tm a0 v comments label allow program started key v wait enter keyboard value goes register wait enter b keyboard register contains b wait enter c keyboard register xc b x c wait enter keyboard register expression print register jump back beginning label recalculate ex pression new variables 1 implied left blank following program computes prints n n entered keyboard n 2 1 integer program started pressing key z section 4 1 desk calculator computers keyboard processors small memories comments program start label stop enter n keyboard n holds n n x n 1 x atnaholdsnn1n1 1 label generate 1 aca 1 ntn 1 test n 2 0 print result get next n keyboard begin update n label holds n holds n 1 execution holds n x n 1 x holds n holds n 1 execution return compute n 2 conclusion many algorithms written programma 101 coded impressively small space techniques sometimes borrowed conventional computer programming example multiple card programs operate using chains way large fortran programs significant fact reader programma 101 calculator nicely de signed stored program computer chapter 20 hp model 9100a computing calculator1 richard e monnier thomas e osborne david cochran new electronic calculator computerlike capabilities operations two numbers one x one appear many daytoday computing problems faced scientists engineers require complex calculations involve moderate amount data therefore machine calculator capability less computer cost great deal offer time must easy operate program minimum amount effort required solution typical problems reasonable speed necessary response individual operations seems nearly instan taneous hp model 9100a calculator fig 1 developed fill gap desk calculators computers easy interaction machine user one important design considerations development prime guide making many design decisions crt display one first basic problems resolved concerned type output used people want printed record printers generally slow noisy whatever method used one register displayed difficult follow happening sequence calculations numbers moved one register another therefore decided cathoderay tube displaying contents three registers would provide greatest flexibility would allow user follow problem solutions easily ideal situation crt showing one register printer tached accessory figure 2 typical display showing three numbers x register displays numbers entered keyboard one digit time called keyboard register register called accumulator since results arithmetic __ register z register particularly convenient register use temporary storage numbers one important features model 9100a tremendous range numbers handle without special atten tion operator necessary worry place decimal point obtain desired accuracy avoid register overflow flexibility obtained numbers stored floating point operations performed using floating point arithmetic floating point number ex pressed decimal point following first digit exponent representing number places decimal point movedto right exponent positive left exponent negative chapter compilation three articles monnier 1968 osborne 1968 cochran 19681 reprinted hewlettpuckurd journul vol 20 1 pp 39 1013 1416 september 1968 fig 1 new hp model 9100a calculator selfcontained capable performing functions previously possible larger computers 243 244 part 3 instructionset processor level variations processor section 4 1 desk calculator computers keyboard processors small memories explained key codes listed simple examples provided assist using machine first time refresh memory infrequent user questions garding operation model 9100a answered card data entry calculator keyboard shown fig 4 numbers entered x register using digit keys v key enter exp key enter exp key allows powers 10 entered directly useful large small numbers 602 x loz3 entered 0 enter exp key first key number entry 1 auto fig 2 display fixed point decimal wheel set 5 register reverted floating point number large properly displayed unless digits called decimal digits setting reduced 4398 364 291 x 004 398 364 291 operator may choose display numbers floating point fixed point floating point mode allows numbers either positive negative 1 x lopgg 9999 999 999 x 10gg displayed stored machine fixed point mode displays numbers way commonly written decimal digits wheel allows setting number digits displayed right decimal point anywhere 0 9 figure 2 shows display three numbers decimal digits wheel set 5 number register 5336 845 815 x 105 533 6845815 big displayed fixed point without reducing deci mal digits setting 4 less number big decimal digits setting register involved reverts automatically floating point avoid apparent overflow fixed point display number displayed rounded full significance retained storage calculations improve readability 0s displayed number unentered 0s following number blanked floating point digits right decimal grouped threes pullout instruction card pullout instruction card fig 3 located front calculator keyboard operation key briefly fig 3 pullout instruction card permanently attached calcula tor contains key codes operating instructions chapter 20 1 hp model 91wa computing calculator 245 functions available keyboard group keys far left keyboard fig 4 gives good indication power model 9100a common mathematical functions available directly keyboard except function keys operate number x replacing function argument numbers z left unchanged located another group keys convenience operates way circular functions operate angles expressed radi ans degrees set switch keyboard sine cosine tangent angle taken single keystroke restrictions direction quadrant number revolutions angle inverse functions obtained using 0 key prefix instance two key depressions necessary obtain arc sin x angle obtained standard principal value radians fig 4 keys four groups keyboard according function matically entered mantissa thus two keystrokes suffice enter 1000000 chg sign key changes sign either mantissa exponent depending upon one presently addressed numbers entered way regardless whether machine fixed point floating point key digit key decimal point chg sign enter exp terminates entry necessary clear entering new number clear x sets x register 0 used mistake made number entry control arithmetic keys add subtract multiply divide involve two numbers first number must moved x second entered x two numbers entered appropriate operation performed case divide dividend entered divisor x 0 key pressed causing quotient appear leaving divisor x one way transfer number x register register use double sized key 0 left digit keys repeats number x leaving x unchanged number goes z number z lost thus squaring cubing number necessary follow 0 q 0 0 key repreats number z leaving z unchanged number goes x number x lost key rotates number x registers number z x rotates numbers z number x z interchanges numbers x using two roll keys numbers placed order three registers _ n sin x 5 2 2 0 5 cos x 5 7 tan x 2 2 71 __ hyperbolic sine cosine tangent obtained using key prefix inverse hyberbolic functions obtained three key depressions tanh x obtained arc hyper keys prefix keys column log x x obtain log base 10 log base e respectively inverse natural log obtained e key keys useful raising numbers odd powers shown one examples pullout card fig 3 two keys group useful programs 0 takes integer part number x register deletes part number right decimal point example int31416 3 forces number register positive storage registers sixteen registers addition x z available storage fourteen 0 1 2 3 4 5 6 7 8 9 b c used store either one constant 14 program steps per register last registers e f normally used constant storage since program counter cycle 246 part 3 1 instructionset processor level variations processor section 4 desk calculator computers keyboard processors small memories special keys located block left digit keys used identify lettered registers store number x register key used parenthesis indicates another key depression representing storage register necessary complete transfer example storing number x register register 8 requires two key depressions x register remains unchanged store number register key used contents alpha registers recalled x simply pressing keys b c e f recalling number numbered register requires use key distinguish recall procedure digit entry key interchanges number register number register indicated following keystroke alpha numeric also useful programs since neither number involved transfer lost clear key sets x z display registers f e registers zero remaining registers affected f e registers set zero initialize use 0 keys explained addition clear key clears flag arc hyper conditions often makes useful first step program coordinate transformation complex numbers vectors complex numbers easily handled using keys column far left keyboard figure 5 defines variables involved angles either degrees radians convert rectangular polar coordinates x x press display shows 0 r x r sin 0 fig 5 variables involved conversions rectangular polar coordinates converting polar rectangular coordinates 6 placed r x pressed display shows x x acc acc allow addition subtraction vector components f e storage registers acc adds contents x register numbers already stored f e respectively acc subtracts rcl key recalls numbers f e registers x illegal operations light left crt indicates illegal operation performed happen either keyboard running program pressing key keyboard reset light running program execution continue light remain program completed illegal operations division zero fi x 0 x x 5 0 log n x 5 0 six1 x 1x1 1 c0si x xi 1 cosh x x 1 tanh x 1x1 1 accuracy model 9100a calculations using floating point arith metic twelve digit mantissa two digit exponent two least significant digits displayed called guard digits algorithms used perform operations generate functions chosen minimize error provide extended range argument usually inaccuracy contained within two guard digits certain cases accuracy appear displayed number one example functions change rapidly small changes argu ment tan x x near 90 glaring insignificant inaccuracy occurs answer known whole number least significant guard digit one count low 2000 000 000 n 1999 999 999 accuracy discussed fnrther internal programming section chapter simple summary answer result ing operation function lie within range true values produced variation il count tenth digit argument programming problems require many keyboard operations easily solved program particularly true chapter 20 hp model 9100a computing calculator 247 operations must performed repeatedly iterative technique must used program library supplied model 9100a provides set representative programs many different fields program found library solve particular problem new program easily written since special experience prior knowledge programming lan guage necessary key keyboard remembered calculator program step except step prgm key used debug program rather operation program many indi vidual program steps sin x polar comparatively powerful avoid need subroutines functions programming space subroutines require registers 0 1 2 3 4 5 6 7 8 9 b c store 14 program steps steps within registers numbered 0 registers numbered programs start 196 possible addresses however 00 usually used first step address dd last available program counter cycles back 00 registers f e normally used storage constants one constant register constant storage required recommended registers c b etc used starting bottom list lettered registers used first frequently recalled constants constants stored easily recalled register used store one constant 14 program steps branching bank far right keyboard fig 4 contains program oriented keys used set program counter two sets parentheses indicate key followed two key depressions indicating address program step desired program step go unconditional branch instruction causes program branch address given next two program steps keys group conditional branch instructions numbers contained x registers compared indicated condition tested met next two program steps executed first alphameric second must also two steps interpreted branching address condition met next two steps skipped program continues also useful conditional branching instruction tests yes condition inter nally stored calculator condition set yes set flag keyboard calculator display mode program program step flag set condition either asking flag program clear instruction keyboard program data input output data entered use program machine display mode screen blank program running program stopped several ways key halt machine time operation performed completed returning display mode program step stop stops program answers displayed new data entered end must last step program listing signal magnetic card reader encoun tered program step stops machine also sets program counter 00 program step pause causes brief display pro gram execution nine cycles power line frequency countedthe duration pause 150 ms 60 hz power line 180 ms 50 hz power line pauses used sequence longer display desired program running pause key held stop machine comes next pause program pause provides particularly useful way user machine interact might instance used program convergence desired result observed means input output involve peripheral devices xy plotter printer print key activates printer causing print information display register program step print interrupt program long enough data accepted printer program continue printer attached print program step act stop fmt key followed keystroke provides 62 unique commands peripheral equipment flexibility allows model 9100a used controller small systems sample programn simple program calculate n demonstrates model 9100a programmed figure 6 top shows flow chart com pute n fig 6 bottom shows program steps program 60 takes less z second compute program entry execution program written entered model 9100a keyboard program counter set address 248 part 3 1 instructionset processor level variations processor section 4 1 desk calculator computers keyboard processors small memories store n np2 fig 6 flow chart program compute n top step shown bottom display register new value n entered end program since end automatically sets program counter back 00 first program step using go key run program switch switched run program program steps entered sequence pushing proper keys step entered x register displays address key code shown fig 7 keys codes listed bottom pullout card fig 3 program entered steps checked using step prgm key program mode explained fig 7 error fig 7 program step address code displayed x register steps entered program entered step checked using step prgm key display step 2d 36 code multiply made step corrected using key without reenter rest program run program program counter must set address first step program starts 00 keys depressed simply since key auto matically sets program counter 00 continue start program execution magnetic card readerrecorder one convenient features model ylooa magnetic card readerrecorder fig 8 program stored model ylooa recorded magnetic card fig 9 fig 8 programs entered calculator means magnetic program card card inserted slot enter button pressed chapter 20 hp model 9100a computing calculator 249 fig 9 magnetic programming card record two 196step programs prevent accidental recording new program one saved corner card cut shown size credit card later program needed quickly reentered using previously recorded card cards easily duplicated programs common interest distributed mentioned earlier end statement signal reader stop reading recorded information card calculator reason end used middle program since programs start location 00 reader automatically initializes program counter 00 card read magnetic card reader makes possible handle programs long held memory one time first entry steps calculate intermediate results stored preparation next part program since reader stops reading end statement stored intermediate results disturbed next set program steps entered stored results retrieved program continued linking programs made convenient part execute end finishes set program counter 00 necessary press continue entry program steps hardware design model 9100a calculator keyboard functions model 9100a implemented arithmetic processing unit figs 10 11 arithmetic unit operates discrete time periods called clock cycles specifications hp model 9100a hp model 9100a programmable electronic calculator performs opera tions commonly encountered scientific engineering problems log trig mathematical functionsareeach performed single key stroke providing fast convenient solutions intricate equa tions computerlike memory enables calculator store instructions con stants repetitive iterative solutions easilyreadable cathode ray tube stantly displays entries answers inter mediate results operations direct keyboard operations include arithmetic addition subtraction mul tiplication division squareroot logarithmic log x x ex trigonometric sin x cos x tan x sinlx cosx tanlx x de grees radians hyperbolic sinh x cosh x tanh x sinhlx coshlx tanhlx coordinate transformation polarto rectangular rectangulartopolar cumulative addition subtraction vectors miscellaneous singlekey opera tions includetaking absolute value number extracting integer part number enter ing value r keys also available positioning storage operations programming program mode allows entry program instructions via keyboard program memory programming consists pressing keys proper sequence key keyboard available program step program capacity 196 steps language codeconversions required self contained magnetic card readerre corder records programs program memory onto walletsize magnetic cards storage also reads programs cards program memory repetitive use two programs 196 steps may recorded reusable card cards may cascaded longer programs average times total performance typical operations including decimal point placement speed add subtract 2 milliseconds multiply 12 milliseconds divide 18 milliseconds squareroot 19 milliseconds sin cos tan 280 milliseconds x 50 milliseconds ex 110 milliseconds times include core access 16 microseconds general weight net 40 ibs 18l kg shipping power 115or230v k 1050to60hz dimensions 8ﬁ high 16ﬂ wide 19ﬂ 65 ibs 295 kg 400 hz 70 watts deep courtesy loveland division 250 part 3 1 instructionset processor level variations processor section 4 desk calculator computers keyboard processors small memories j memory activate read e 825 ns clock mm cc 00 mm cc e 22 cy cy activate read write cafiity program activate read 512 word description 64 bitiw address flip flops control word cornotiol 64 word 800 ns 29 biriw control logic address flip flop coincident current memory 1 core 368 words 6 bitw f 1 high order memory 1161 flip dat flops 11 address 1 loworder memory flip flops fig 10 arithmetic processing unit block diagram system marriage conventional reliable dioderesistor logic 32000bit readonly memory coincident current core memory operations synchronized clock shown top center fig 10 clock connected control read memory rom coordinates operation program read memory coincident current core readwrite memory former fig 11 arithmetic unit assembly removed calculator contains information implementing keyboard opera tions latter stores user data user programs internal operations performed digit digit serial basis using binary coded decimal digits addition example requires least significant digits addend augend extracted core added sum replaced core process repeated one bcd digit time significant digits processed also substantial amount housekeeping performed aligning decimal points assigning proper algebraic sign floating point normalization although implementation keyboard func tion may involve thousands clock cycles total elapsed time millisecond region clock cycle 825 ns long program rom contains 512 64bit words pro gram rom activated signals microinstructions corresponding bit pattern word sent hard wired logic gates shown bottom fig 10 logic gates define changes occur flip flops end clock cycle microinstructions act upon data flip flops others change address registers associated program rom chapter 20 1 hp model 9100a computing calculator 251 control rom coincident current core memory next clock cycle control rom may ask new set micro instructions program rom ask read written coincident current core memory control rom also ability modify address register issue microinstructions hard wired logic gates flexibility allows control logic rom execute special pro grams subroutine unpacking stored constants required keyboard transcendental functions control logic control logic uses wire braid toroidal core read memory containing64 29bit words magnetic logic type extremely reliable pleasingly compact crystal controlled clock source initiates current pulse trapezoidal waveform directed one 64 word lines bit patterns generated passing threading selected toroids word lines toroid threaded acts transformer turn transistor connected output winding toroid signals transistors operate program rom coincident current core selected microinstructions coincident current core readwrite memory 2208 6 x 16 x 23 bit coincident current memory uses wide temperature range lithium cores addition x inhibit drivers temperature compensated current drive sources make core memory insensitive temperature power supply variations arithmetic processing unit includes special circuitry guarantee information lost core memory power turned power supplies arithmetic processing unit operates single 15 volt supply even though power supply highly regulated circuits designed operate voltage range 135 165 display display generated hp electrostatic cathode ray tube 11 inches long flat rectangular face plate measures 3y4 x 4l3 inches tube specifically designed gener ate bright image high contrast obtained using low transmissivity filter front crt ambient light usually tends wash image attenuated twice filter screen image attenuated displayed characters pieces eight sixteen differ ent symbols obtained intensity modulating figure 8 pattern shown fig 12 floating point numbers partitioned groups three digits numeral 1 shifted improve readability zeros left significant digit insignificant zeros right decimal point blanked avoid confusing display fixed point numbers automati cally rounded according decimal wheel setting fixed point display automatically revert floating point notation number large displayed crt fixed point multilayer instruction logic board hard wired logic gates synthesized instruction logic board using timeproven dioderesistor logic diodes resistors located separate rows fig 13 diodes oriented direction resistors value maze interconnections normally associated back plane wiring computer located six internal layers multilayer instruction logic board solder bridges acci dental shorts caused test probes shorting leads beneath components eliminated interconnections two outside surfaces multilayer board instruc tion logic board also serves motherboard control logic board two coincident core boards two flip flop boards magnetic card reader keyboard also contains connector available rear calculator connecting peripherals flip flops model 9100a contains 40 identical jk flip flops threshold noise immunity 25 volts worst case design tech niques guarantee flip flops operate 3 mhz even though 12 mhz maximum operating rate fig 12 displayed characters generated modulating figures digit 1 shifted center pattern fig 13 printedcircuit boards make arithmetic unit left right top side board control logic flip flop core drivers core sense amplifiers inhibit flip flop side board large board lower left multilayer instruction board program rom right magnetic card reader associated circuitry bottom 14 i2 k chapter 20 1 hp model 9100a computing calculator 253 program read memory 32768 bit read program memory consists 512 64bit words words contain operating subroutines stored constants character encoders crt modulating patterns 512 words contained 16 layer printercircuit board drive sense lines orthogonally located drive line consists reference line data line drive pulses inductively coupled reference line data line sense lines signals data line either aid cancel signals reference line producing either 1 0 output sense lines drive sense lines arranged achieve bit density rom data board 1000 bits per square inch program rom decoderdriver circuits located directly rom data board thirtytwo combination sense ampli fier gatedlatch circuits located side rom data board outputs circuits control hard wired logic gates instruction logic board side boards program rom printed circuit board instruction logic board interconnected side boards preliminary signal processing occurs keyboard keyboard contains 63 molded plastic keys markings wear lettering imbedded key body using double shot injection molding process key switch assembly specifically designed obtain pleasing feel proper amount tactile aural feedback key operates single switch gold alloy contacts contact closure acti vates matrix encodes signals six data lines generates initiating signal signal delayed avoid effects contact bounce electrical interlock prevents errors caused pressing one key time magnetic card reader two complete 196 step programs recorded credit card size magnetic program card recording process erases previous information card may used program may protected accidental erasure clipping corner card fig 9 page 249 missing corner deactivates recording circuitry magnetic card reader program cards compatible among machines information recorded four tracks bit density 200 bits per inch sixbit program step split two time multiplexed threebit codes recorded three four tracks fourth track provides timing strobe information read card recombined six bit codes entry core memory magnetic card reading circuitry recognizes end program code signal end reading process feature makes possible enter sub routines within body main program enter numeric constants via program card end code also sets program counter location 00 probable starting loca tion latter feature makes model 9100a ideally suited linking programs require 196 steps packaging servicing packaging model blooa began giving hp indus trial design group volume estimate electronics package crt display size number keys keyboard several sketches drawn best one selected electronics sections specifically designed fit case much time effort spent packaging arithmetic processing unit photographs figs 11 14 attest fact time well spent case covers die cast aluminum offers durability effective rfi shielding excellent heat transfer characteristics convenient mechanical mounts removing four screws allows case opened locked position fig 14 procedure exposes important diagnostic test points adjustments keyboard arithmetic processing unit may freed removing four seven screws respectively component failures isolated using diagnostic routine special tester faulty assembly replaced sent service center computer assisted diagnosis repair reliability extensive precautions taken insure maximum relia bility initially wide electrical operating margins obtained using worst case design techniques production transis tors aged 80 rated power 96 hours tested used model y100a subassemblies computer tested actual operating margins monitored detect trends could lead failures data analyzed corrective action initiated reverse trend addition calculator operated environmental chamber 55c 5 days prior shipment customer precautions allow hewlettpackard offer one year warranty field 90 days accepted standard 254 part 3 1 instructionset processor level variations processor fig 14 internal adjustments calculator easily accessible removing screws lifting top 100 internal programming 9100a calculator extensive internal programming designed hp model 9100a calculator enable operator enter data perform arithmetic operations necessary engineering scientific calculation single key stroke single program step following operations hardware subroutine called key press program step basic arithmetic operations addition subtraction multiplication division extended arithmetic operations square root exponentialex logarithmicln x log x vector addition subtraction section 4 1 desk calculator computers keyboard processors small memories trigonometric operations sin x cos x tan x arcsin x arccos x arctan x sinh x cosh x tanh x arcsinh x arccosh x arctanh x polar rectangular rectangular polar coordinate transformation miscellaneous enter ti absolute value integer value x evolution internal programming model 9100a calculator first step development flow charts function digit entry fig 15 seemingly trivial function complex mathematical functions functional description detailed program written uses microprograms incremental instructions calcu lator also program must married programs make hardwired software model 9100a mathematical functions similarly programmed defining stepbystep procedure algorithm solving desired mathematical problem calculator designed lowerorder subroutines may nested level five higherorder functions instance polar rectangular function uses sin routine uses multiply uses add etc addition subtraction elementary mathematical operation algebraic addi tion even relatively complexit requires comparing signs complementing signs unlike numbers model 9100a processed true floating point numbers exponents must subtracted determine proper decimal align ment one numbers zero represented calcu lator allzero mantissa zero exponent difference two exponents determines offset rather shifting smaller number right displaced digitbydigit addition performed must also determined offset greater 12 resolution limit although display shows 10 significant digits calculations performed 12 significant digits two last significant digits guard digits absorbing truncation roundoff errors registers core memory eliminating need large number flipflop registers even display fixed point mode every computed result storage 12 digits chapter 20 hp model 9100a computing calculator 255 entry 0 functions register exp clear clear keyboard register shift exponent digits left store digit store digit least significant significant exponent location 1 location point set 1 yes exponent exponent rea0 digit location significant 1 exit significant digit location location fig 15 flow chart simple digit entry flow paths used calculator operations greater hardware efficiency multiplication multiplication successive addition multiplicand deter mined multiplier digit offset digit position flipflops increased one completion additions multiplier digit exponents added completion product product normalized justify carry digit might occurred division division involves repeated subtraction divisor dividend overdraft occurs subtraction without overdraft quotient digit incremented one digit position iteration overdraft occurs dividend restored adding divisor division digit position incremented process continued exponents subtracted quotient formed quotient normalized square root square root model ylooa considered basic operation done pseudo division method used extension integer relationship 52i 1 n2 square root divisor digit incremented iteration shifted overdraft restore occurs fast algorithm square root equal speed division circular routines circular routines sin cos tan inverse circular routines arcsin arccos arctan polar rectangular rectangu lar polar conversions accomplished iterating transformation rotates axes angle may repre sented angle 0 1 radian plus additional infor mation number times m2 added sub tracted sign basic algorithm forward circular function operates angle whose absolute value less 1 radian prescaling necessary indicate quadrant obtain scaling constants argument divided 2m integer part discarded remaining fraction circle multiplied 257 m2 subtracted absolute value angle less 1 radian number times m2 subtracted original sign argument sign upon completion last subtraction make scaling constants preserve quadrant information scaling constants stored core memory il 256 part 3 1 instructionset processor level variations processor algorithm produces tan 0 therefore model 9100a cos 8 generated 1 ditgx sin8 tan 8 vtfiz sin0 could obtained relationship sin8 example use tangent relationship preserves 12 digit accuracy small angles even range 0 1012 proper signs functions assigned scaling constants polar rectangular functions cos 0 sin 0 com puted multiplied radius vector obtain x coordinates performing rectangular polar function signs x vectors retained place resulting angle right quadrant prescaling must also precede inverse circular functions since routine operates arguments less equal 1 inverse circular algorithm yields arctangent functions making necessary use trigonometric identity coslx desired arcsin relationship used scaling constant adds m2 completion function arguments greater 1 arccotangent negative reciprocal found yields arctangent m2 added exponential logarithms exponential routine uses compound iteration algorithm argument range 0 natural log 10 10 therefore able handle argument within dynamic range calculator necessary prescale absolute value argument dividing 10 saving integer part used exponent final answer fractional part multiplied 10 exponential found number mantissa previously saved integer part power 10 exponent becomes final answer section 4 desk calculator computers keyboard processors small memories exponential answer reciprocated case original argument negative use hyperbolic functions hyperbolic functions following identities used e e sinh x ___ 2 natural logarithms exponential routine reverse used routine natural logs mantissa operated upon exponent multiplied 10 added answer routine also yields loglo hyperbolic functions x 10 loglox coshlx lnx dm tanhlx lnp 1x sinhlx relationship abdve yields reduced accuracy negative values x therefore model ylooa absolute value argument operated upon correct sign affixed completion accuracy seen discussion algorithms extreme care taken use routines accuracy commensu rate dynamic range calculator example square root maximum possible relative error 1 part lo1 full range machine many algorithms determining sine angle points high error sine routine model 9100a consistent low error regardless quadrant marrying full floating decimal calculator unique mathe matical algorithms results accuracy better 10 displayed digits section 5 processors stack memories zero addresses per instruct ion section contains computers use stack memory pc hence denoted pcstack although im plementation details differ based common idea stack described chap 3 page 62 several theory languagebased processorsiplvi euleruse stack mp however languagebased machines stack main design theme computers table 1 fact data iplvi organized chap 30 lists general data structure stacks stack permits push pop operations performed top stack list permits push pop operations performed cell list called insert table 1 pcstack computers company basis disclosure delivery relative computer name autea date ancestry power references english electric kdf 9 60 463 georgec allmr62 davig60 burroughs paoli pa hambc62 6 1 andej62 d825 d830 extended performance b 85ooe 466 developed labora d825 tory producing d825 0830 burroughs pasadena calif b 5000 b 5500 b 6500 b 7500 theory language based iplvi euler algol plvc argonne laboratory 62 167 2030 263 1164 1 68 67 successor b 5000 b 5500 based improved multi sharedprogrammed mapping extended performance b 6500 language ipliv v language eu leralg0l 1anguagealgol 1 2 allrnr62 bartr61 bock r63 ca rlc63 1178198 lonew61 hauce68 56 10 shawj58 beh 67 w rt n 66a b andej61 language iplv hodgd64 first edition manual paper appearance adoms computing characteristics quarterly hstill evolving b 8501 discontinued 1968 george university new south wales interpreter using polish notation stack circa 1957 hamblin 19621 dproduced command control military applications b 8500 system name pc b 8501 reported actual delivery unknown p dual processor 2 57 258 part 3 instructionset processor level variations processor tconsole mp07k3 dcab ikio14s4 ktconsole typewriter kti 2 card reader kt12 paper tape reader ktcard punch ktiz line printer kmsi 2 drum kms116 magnetic tape mpcore 4 psw 4096 w 483 bw pcstack 12 bsyllable 6 bchar data sisfbvwchar string 2 syllableinstruction mps 4 w ante cedents algol language descendants 6 5000 b 6500 b 7500 technology transistor 41961 1963 sfrom 2 pc k 8 mp concurrency 4 4sfrom 4 kio ktkms concurrency 4 fig 1 burroughs b 5000 pms diagram section 5 1 processors stack memories zero addresses per instruction delete respectively thus list like nested set overlapping stacks euler chap 32 uses stack store temporary data subroutine calls compiling interpreting compiled program however lan guagebased machines still studied profitably stack mind following comments directed pstack com puters manufactured english electric burroughs three basic pstack computer families b 5000 b 5500 4 b 6500b 7500 d825 d830 b 8500 kdf9 root member made available time burroughs pasadena calif burroughs paoli pa english electric ibm corporation later responded proposed pcstack machine never entered produc tion phase pcstack major alternative main line organi zation 1 address per instruction augmented index reg isters general registers tries capitalize hierarchi cal character computation avoid give memory shuffling instructions explicitly chap 3 page 64 gave comparison trivial computation using stack generalregister organization order make clear case patconsole pcb3sconsoie lreal time device kl 4c4skl 4sk1 set mpcore 12 usw thin film 6 psw 16 kw 51 bw s32 mp 4pcks concurrency 4 3pstak technology integrated circuits 1969 data sfdficharstring boolean vector address integer 468 bchar 4 data communi cat ions processor identical peripheral structures possible two switches 6see figures 3 4 5 kioinputoutput mu1 tiplexor kiorea1 time adapter fig 2 b 6500 b 7500 pms diagram section 5 processors stack memories zero addresses per instruction 259 l ks b 1 k 2 msdisk lkk7s2k 5x1 l k c 2 k 5 msdisk lto kioinputoutput multiplexor kdisk peripheral controller x ke1ectronics unitsms154 46 ms 2161395 kbys 1 fig 3 burroughs b 6500 b 7500 ms disk pms diagrams stacks however attempt analysis asserted amdahl et al 1964al pcstack derives power fastworking mem ory pc thus dominated generalregister organization feeling compile compiled program execution times pcstack indeed impressive however definitive analysis published far know pcstack iscertainly organization rates serious study computer designer pms structure examples pms structure diagram b 5000 b 6500b 7500 figs 1 5 compared burroughs structure representation chap 22 page 268 d825 structure similar given chap 36 page 447 burroughs computers table 1 multiprocessor structure burroughs probably first computer company take matters structure organization seriously d825 hardware software designed military command control applications demand high uptime availability various computer components structures fail continuous operation possible reduced level failsoft design however knowledge published account exists well design works practice performance reliability viewpoint philosophy details d825 software hardware discussed chap 36 structures b 6500 especially allow kios freely assigned ms thereby achieving better equip ment utilization s16 mp 16 p probably overdesigned burroughs b 6500 computers structures generally maximum 4p kio although design based 16p kio kios chap 22 may overdesigned since k capable controlling simple tcardreader also control complex msdisk msmagnetictape pms structure english electric kdf9 fig 6 fairly simple 16 ks direct memory access appear lk2s3 07 maqnetic tape 9 144 kchars 6lr bchar 200155618001 1600 charin forward reverse motion 1 k 8 msrnagnetic tape s2 k io msms09 magnetic tape lk lki b 2 k io msmagnetic tape l k s4 k 16 msms015 magnetic tape l k l l k c 4 k 16 msmagnetic tape l kio nputoutput mu1 ipl exor kperiphera1 controller 3s1k 8 ms bus fig 4 burroughs b 6500 b 7500 ms magnetic tape pms diagrams 260 part 3 1 instructionset processor level variations processor l ktconsole keyboard printer l __ kcard reader l __ ktcard punch f l k tpaper tape reader l __ k tpaper tape punch l k tcrt display l k tline printer f l kio small peripheral control fig 5 burroughs b 6500 b 7500 peripheral kt pms diagrams overdesigned overly general limit 16t ms components small especially considering kdf9 timeshared several consoles isp examples comparison pcstack pcladdress pcgeneralreg isters page 64 makes assumption unlimited ki sms magnetic tape ttypewri ter tpaper tape mpcore 6 psw 4 32 kw 48 bw 2s16 mp 16pk concurrency 1 3pcstack 8 bsyllable 0 1 addressinstruction 6 bchar technology transistor data syllable char w bv si di sf df hw 13 syllablesinstruction operators x v icharstring1 mp stack stack mp mps subrouti ne jump nesting storeco 7n 1 stack nest nq store 0 l50 47 athmetic stack qstoreo150171831 3248 store used indexing contains counter increment modifier 1 fig 6 english electric kdf9 pms diagram section 5 processors stack memories zero addresses per instruction hardware stack resides pc b 5500 local mstack pc 4 words size number stacks use software important iplvi machine number stacks since front list stack kdf9 fig 6 two independent stacks one arith metic expression evaluation one holding subroutine return addresses dec 338 pdisplay chap 25 uses stack storing subroutine return addresses unfortunately able include discussion cactus stack b 6500 data structure like list hauck dent 19681 hauck dent paper describes relationship pcstack relevance program mapping memory management multiprogramming cd825 parameters given fig 7 d825 isp differs pcstack computers data operations either two places stack mp consider unary binary operations c burroughs d825 mu1 processor structure scrosspoint 16 ibpckio mp433 jlsw 65 kw 48l parity bw scrosspoint 4 kio 64 tms tconsole paper tape printer card time communication link msdrum disk magnetic tape kiol 4 pc12 12 bsyllable stack 0 3 addressesinstruction multiprogrammed data integer floating single char acter fractional precision word boolean vector opera tions x v 7 round si c sf abs negate abs instructionsize 7 syllable operationcodesize 512 syllable addresssize 712 0 6 syllable operation forms d3 dl b d2 d2 tu dl variable addresses stack mpcsyllable barmpsyllable bar xa x e x c mps stacks index registers 15xi 151 index comparison limit registers1151 base address registersbar program address registerpar program counterpc fig 7 burroughs d825 pms diagram section 5 processors stack memories zero addresses per instruction 261 tu dtdlbd2 either cases top stacks mpaddress base address xindex registers abc flexibility allows pc behave 0 1 2 3 address per instruction processor 6 5000 conventional d825 use stacks see references table 1 load store push pop instructions transfer data tween mp one stack actually b 5000 several im portant features make worthy study 1 stacks 2 datatype specification data type declared placing type identifier data thus example one add operation fixed floating point data telling addition take place 3 multiprogram mapping descriptors used access variables scalars vectors arrays indirect addressing technique allows multiprogramming ever reader note data pro tected accesses corrected b 6500 failure pcstack character processing b 5000 character mode allow processing string data stack used mode effect separate string processing isp incorporated pc multiprocessing b 5000 two pcs command structure complex information processing iplvi chap 30 discussed part 4 sec 4 page 348 languagebased processor microprogrammed implementation euler ibm system360 euler chap 32 discussed part 4 sec 4 page 348 microprogrammed languagebased processor chapter 21 design arithmetic unit incorporating nesting storel r h allmark 1 r lucking summary paper describes arithmetic unit computer whose order code based reverse polbh algebraic notation order code realised causing arithmetic unit operate data stored accessible registers nesting store registers transistor flipflop type backed sixteen fast magnetic core registers functions performed microprogrammes trans fers registers arithmetic unit necessary arrange ment transfer paths logical gates arithmetic circuits described number system binary using twoscomplement representation negative numbers automatic floatingpoint operations included use autonomous unit perform shifts required introduction arithmetic unit general purpose digital computer contains circuits perform least basic operations addition sub traction multiplication division many machines possi ble use registers arithmetic unit temporary storage partial results arising calculation thus accumulator oneaddress machine used store result last arithmetic operation arithmetic unit de scribed paper uses nesting store operating last infirstout principle storage data partial results nesting store consists stack cells accessible supply data arithmetic unit results automatically returned accessible cells original operands erased less accessible information moved cells made vacant operation computer order code reverse polish algebraic notation contains four groups operations b transfers arithmetic unit main store arithmetic logical manipulative functions data nesting store conditional unconditional jump instructions used interrupt normal sequencing instructions instructions controlling operation various peripheral devices may attached machine c main store transfers include instructions transferring half fulllength words accessible cell nesting store information already stack retained transfer less accessible cells contents accessible cell stack may stored main store automatically erased stack information moved less accessible cells accessible position arithmetic operations also feature transfer data nesting store operands destroyed results left accessible cell cells data involved operation moved fill vacated cells thus programme evaluating f bc de may written fetch fetch b subtract forming b accessible cell arithmetic unit part general purpose synchronous system working parallel mode main core storage 32 768 48bit words provision time sharing 4 programmes order code computer based proc ifip congr 62 pp 694698 1962 erasing b stack fetch fetch e forming de erasing e thus leaving b second accessible cell 262 chapter 21 design arithmetic unit incorporating nesting store 263 fetch c add forming c de divide forming f store f1eaving nesting store state fetch instruction instructions 48bit word divided 6 sylla bles eight bits treated continuous sequence variable length instructions arithmetic operations specified single syllable instructions main store transfers require three syllables accommodate address address modifying information word refer jump instructions also three syllables twosyllable instruc tions include peripheral transfers instructions process ing address modifiers performing shifts first syllable every instruction contains two bits whose values specify length instruction redundant case used differentiate main store transfers jump instructions first syl lable instruction contains enough information specify arithmetic unit operation required thus machine instruction treated two controls first store control organising fetching storing information advance second arithmetic unit control completes struction information first syllable range functions allocation bits instructions described allows 64 possible functions 59 used specify wide range operations needed general purpose computer well normal singlelength fixedpoint arithmetic oper ations functions provided addition subtrac tion doublelength numbers simplify programming multilength operations well giving increased accuracy normal scientific engineering calculations automatic float ingpoint facilities available single length word may repre sent floatingpoint number 40bit fractional part f 8bit characteristic c value number f2c128 fractional part limited range 1 5 f y2 1 f 2 y2 f 0 c also zero floatingpoint opera tions assume operands standard form give correctly rounded results standard form functions addi tion subtraction doublelength floatingpoint numbers provided give increased accuracy stability many matrix operations increase operating speed saving instructions effected use instructions reorder position information accessible cells nesting store cluding reversing cycling operations normal logical oper ations provided arithmetic operations arithmetic unit carried binary numbers using twoscomplement notation nega tive numbers instructions provided conversion binary information stored 6bit characters radix systems convenience programmer double length numbers stored arithmetic unit significant half accessible cell sign less sig nificant half ignored set positive doublelength operations nesting store although concept nesting store similar rifle magazine addition cartridge displaces already movement information occurs three accessible cells nesting store transistor flipflop registers forming part arithmetic unit less accessible cells core registers addressed sequential manner reversible counter reading cores reduces count one thus selecting next word readout de structive cores correct state subsequent writing operation reverse read access time cores reduced providing separate counters reading writing mechanisms odd even numbered rows cores thus reading writing odd rows addressing mechanism next even row set available immediate use thus simple one core per bit system suc cessive reads made 1 pec intervals writes 2 pec intervals operations performed parallel functioning arithmetic unit times increase time required complete functions arithmetic unit shown fig 1 six full length transistor flipflop registers arithmetic unit also two 8bit registers used performing floatingpoint operations main facili ties associated registers follows w1 w2 w3 three accessible cells nesting store transfers core part nesting store 264 part 3 instructionset processor level variations processor main transfers au control pulses counter _ set ones iclfar 1 store control stope control clear auxiliary transfers shlfts right shifts 012s8 or8 characteristic modifier fig 1 block diagram arithmetic unit full lines represent infor mation transfers dotted lines represent control pulses registers 48bits long unless otherwise stated made via w3 w1 w2 together b1 b2 form doublelength shifting register may used two inde pendent singlelength shifting registers b1 b2 inputs 48bit adder whose output may routed w1 w2 characteristic difference register cd adder contains 13 carryskip stages reduce carry propagation time maximum 150 nsec subtraction per section 5 processors stack memories zero addresses per instruction formed adding minuends complement subtrahend carry inserted rightmost adder stage nb acts buffer store control arithmetic unit together b1 b2 used nearly every function arithmetic unit control interprets instruction se quence timed pulses along lines activate various transfers etc registers sequences constructed many operations performed simultaneously reducing overall time minimum thus function sin glelength fixedpoint add performed transferring w1 w2 w3 b2 b1 nb respectively simultaneously commencing read nesting store clearing carry inserted rightmost adder stage switching adders output w1 adding simultaneously transferring nb w2 ii step takes 05 psec end last step w3 refilled core nesting store speed multiplication division functions carried separate unit employing stored carry principle results finally assimilated within arithmetic unit similar arithmetic unit operating singlelength num bers could designed using four fulllength registers least five registers required perform function inter changes contents two accessible cells nesting store next accessible pair sixth register enables doublelength arithmetic operations performed without writing information back nesting func tion would complicated sequences increased time functions determining arrangement transfer paths various registers found sufficient consider doublelength functions required complicated lengthy sequences particular function adding two doublelength hoating numbers great influence overflow indication set fixedpoint addition sub traction sign result differs expected floatingpoint operations characteristic exceeds maximum allowable shifting may also cause overflow shift control shifting operations effected transfers w1 andor w2 b1 andor b2 back shift transfer paths w b registers provide right shifts 0 1 2 5 chapter 21 1 design arithmetic unit incorporating nesting store 265 8 places left shift 8 places paths b w registers provide shifts reverse direction two sets shift paths used alternately w registers used first shifts terminated using path w registers shifts large number places accom plished series shifts eight places appropriate direction number places remaining less eight necessary number transferred back w regis ters remaining shifts whole shift number places less eight completed transfer b registers back using two appropriate paths shifts avail able extension b registers two bits rightmost end enables shift performed without loss accuracy doublelength arithmetic shifts sign digit less sig nificant word bypassed shift performed number places type shift transferred semi autonomous unit called shift control supplied string command pulses arithmetic unit control shift control reroutes pulses perform transfers necessary obtain shift performing floatingpoint addition subtraction shifts required equalize characteristics two numbers amount shift calculated modified subtraction oper ating characteristic positions two numbers addition shift required restore result standard form determined logical circuits interpret pattern bits w1 shift information number shifts performed standardising operation made available arith metic unit control use forming correct characteristic result character conversion operations binary accomplished shift control using method involving successive shifting character word adding subtracting portions radix word examples sequences illustrate working arithmetic unit two sequences described ie subtract doublelength fixedpoint number w1 w2 number w3 accessible core register nesting store transfer w1 w2 w3 b2 b1 nb respectively simultaneously reading core nesting store ii dummy pulse iii iv 2 vi transfer complement w2 b2 setting sign b2 positive transfer w3 directly b1 w3 filled fresh data switch adders output w2 inserting carry right adder stage read nesting store add transfer complement w1 b1 nb b2 switch adders output w1 insert carry rightmost adder stage w2 negative add simultaneously clearing sign w2 b f ie add two singlelength floating numbers w1 w2 ii iii iv 21 vi vii viii ir x transfer complement w1 b1 transfer w2 b2 switch adders output register cd store characteristic w1 eightbit register c add clear characteristic positions w1 simultane ously transferring cd shift number register shift control latter operation shift register contains minus difference charac teristics clear characteristic w2 w1 shifted determined sign digit cd replace contents c characteristic b2 thus c contains larger characteristic supply control pulses shift control thus perform required rightshift eight w1 w2 completed shift transfer w1 w2 w3 b2 b1 nb respectively simultaneously switch ing adders output w1 clearing carry rightmost adder stage reading core nesting store add fractional parts simultaneously transferring nb w2 supply control pulses shift control cause enter standardization procedure perform shifts required store complement number leftshifts performed viii characteristic position b2 transfer c characteristic position b1 switch adder w1 perform special add operation affects characteristic positions w1 sum thus formed w1 rounding answer carried using two special control pulses complete floating point operations call logic deal cases rounding operation necessitates restandardization sult 266 part 3 1 instructionset processor level variations processor conclusions advantages machine incorporating nesting store arithmetic unit ii machine simple programme using machine language programmes faster since many main store transfers eliminated access time nesting store virtually zero compact less infor mation required specify many instructions section 5 1 processors stack memories zero addresses per instruction iii operation arithmetic unit largely inde pendent main store controls may readily separated allows store control process instructions whilst arithmetic unit control processes prior instruc tion thereby leading faster execution programme main disadvantage increase order complexity involved references allmr62 davic60 halea62 chapter 22 design b 5000 system1 william lonergan paul king computing systems conventionally designed via hardware route subsequent design systems handed programming systems people development programming package facilitate use hardware contrast b 5000 system designed start total hardwaresoftware system assumption made higher level programming languages algol used virtual exclusion machine language programming system largely used control operation hardwarefree notation utilized design proc essor desired word symbol manipulative capabilities subsequently model translated hardware specifica tions time cost constraints considered design objectives fundamental design objective b 5000 system reduction total problem throughput time second major objective facilitation changes programs system configurations toward objectives following aspects total computer utilization problem considered statement problems higherlevel machineindependent languages efficiency compilation machine language speed compilation machine language program debugging higher level languages problem setup load time efficiency system operation ease maintaining making changes existing programs ease reprogramming changes made system configuration design criteria early design phase b 5000 system following principles established adopted program independent location unmodified stored object time data independent location addressing memory within program take advantage contextual addressing schemes reduce redundancy provisions datamation vol 7 5 pp 2832 may 1961 made generalized handling indexing subroutines full complement logical relational control operators provided enable efficient translation higherlevel source languages algol cobol pro gram syntax permit almost mechanical translation source languages efficient machine code facilities provided permit system largely control operation inputoutput operations divorced processing handled operating system multiprogramming true parallel processing requires multiple processors facilitated changes system configuration within certain broad limitations require reprogramming system organization b 5000 system achieves unique physical operational modularity use electronic switches function logically like telephone crossbar switches figure 1 depicts basic organization system well showing maximum system master control program master control program provided b 5000 system stored portion magnetic drum normal operations small portion mcp contained core memory portion handle large percentage recurrent system operations segments mcp called magnetic drum time time required handle less frequentlyoccurring events system situations whenever system executing master control program said control state entries control state made via interrupts special operation provided executed system control state permit control return object program executing time interrupt occurred following typical occurrences cause automatic interrupt system inputoutput channel 267 268 part 3 instructionset processor level variations processor section 5 1 processors stack memories zero addresses per instruction fig 1 organization b5000 system available inputoutput operation completed indexing operation attempted violated storage protection features built system addition processing interrupt conditions master con trol program handles fundamental parts total system opera tion initiation inputoutput operations tanking inputoutput areas required file control allocation memory scheduling jobs priority ratings system requirements object program present system configuration considered maintenance operations log maintenance system description operating modes b 5000 either operate fixedlength words variablelength fields two modes operation called word mode character mode certain operations processor operating words desirable opera tions variable field length mode operation desirable combining abilities one processor processor operate mode desirable operation hand b 5000 system even possible one processor operat ing word mode character mode operating word mode standard format data word used illustrated fig 2 note standard word octal floating point word however mantissa treated integer rather fraction heretofore reverse common practice provides two benefits first integer internal repre sentation unnormalized floating point correspondent second range numbers expressed rather s64 863 876 s51 first feature eliminates chapter 22 1 design b 5000 system 269 first char acter integer part second third fourth fifth sixth seventh eighth char char char char char char char acter acter acter acter acter acter acter fflag 1 bit sesign exponent 1 bit exponent 6 bits fig 2 data word word mode sosign operand 1 bit integer part 39 bits need fixedtofloating point conversion integers floating point numbers mixed arithmetic calculations second expands range trouble range often en countered namely numbers extremely large magnitude flag serves dual purpose function flag depends program references data word data word single variable element array flag identi fies word operand data word word element array flag may used identify particular element element data proc essed normal program example boundary point mesh calculations operating character mode data word consists eight alphanumeric characters illustrated fig 3 programs character mode address character word fields start position word processor single opera tion operate fields length 63 characters long operations fields greater length easily programmed example two 57 character fields could compared single operation two instances character mode operates words type used word mode operations provided character mode converting numeric information alphanumeric representation standard word type word mode vice versa instances length alphanumeric fields converted word mode type word greater eight characters long conversion fields greater length easily pro grammed purpose word mode provide advantages highspeed parallel operations floatingpoint abilities inherent information density possible binary machine first case economically feasible provide parallel operations word machine cost parallel operations variable length fields would prohibitive last case given size memory contain twenty percent numeric informa tion information expressed binary rather binary coded decimal eighty percent information expressed sixbit alphanumeric representation purpose character mode provide editing scan ning comparison data manipulative abilities although addi tion subtraction also provided type editing facili ties provided obviate need artificial ﬁaddshiftextract storeﬂ type editing example operations provided generalized insertion editing symbols blanks decimal points floating dollar signs etc substitution sup pression unwanted characters interested new area information processing languages character mode particularly well suited list structures program organization programs b 5000 composed strings syllables syllable basic unit program twelve bits length term ﬁsyllableﬂ used rather instruction distinguish conventional singleaddress multiaddress instructions program word contains four syllables executed sequentially lefttoright order within pro gram word sequentially word branching allowed syllable within word delving details internal operation b 5000 processor necessary discuss stacks polish notation program reference table stack internal organization singleaddress computers forces wasting programming running time storage recall intermediate results sequence compu tation data must placed proper registers memory cells operation executed contents must often completely rearranged next operation performed multiaddress computers con structed make execution selected operations efficient expense building inefficiencies rest automatic programming aids attack problem indirectly relieve programmer need laboriously code 270 part 3 1 instructionset processor level variations processor executed way around machine design still must provide object coding accomplish storage recall functions brief conventionally designed computers without automatic programming aids require wasteful expenditure program ming effort memory capacity running time overcome limitations internal organization problem attacked directly b 5000 incorporation ﬁpushdownﬂ stack completely eliminates need instructions coded compiled store recall intermediate results b 5000 processor stack composed pair regis ters b registers memory area operands picked programs placed register register already contains word information word transferred b register prior loading operand register b register also occupied information word b stored memory area defined address register word transferred b operand brought register new word coming stack pushed information previously held registers pushdown occurs address register automatically increased one information con tained registers last information entered stack stack operates ﬁlast infirst outﬂ principle information operated stack operands eliminated stack results operations returned stack information stack used operations performed possible cause ﬁpushupsﬂ ie word brought memory area addressed register address register decreased one eliminate unnecessary pushdowns pushups b registers indicators used remembering whether registers contain information empty operand placed stack either registers empty pushdown memory occurs also operation leaves one registers empty automatic pushup occurs polish notation polish logician j lukasiewicz developed notation allows writing algebraic logical expressions require grouping symbols operator precedence conventions example parentheses necessary grouping symbols expression ab c convey desired interpretation expression expression bc normal interpretation bc rather bc convention section 5 processors stack memories zero addresses per instruction operator higher precedence operator righthand polish notation used b 5000 based placing operators right operands b becomes ab polish notation b c written either ab c abc expression abc first operator says add operands b c second operator says add sum b c returning first examples ab c written bc ax abc x polish second example written bca abc exten sion polish notation handle equations shown follow ing example conventional notation zabcde polish notation abc x de z stack use illustrate functioning stack two simple examples shown figs 4 5 examples letters p q r represent syllables program cause operands p q r picked placed stack symbols x represent syllables cause add multiply operations occur two examples represent different ways writing pqr polish notation first example fig 4 require pushdowns pushups second example shown fig 5 requires pushdown execution syllable r pushup execution syllable x columns table represent contents various registers execution syllable listed first column independence addressing one goals set design b 5000 make programs independent actual memory locations program data order provide really automatic polish notation qr p x fig 4 chapter 22 1 design b 5000 system 271 syllable executed p q pushdown execute r polish notation pqr x contents register register b register cell 101 100 p 100 p empty q empty q 101 p r q 101 p x 100 fig 5 program segmentation automatic program segmentation possible program size practically independent size core memory systems analyst programmer intending multiprocessing longer faced difficult task planning jobs run together order system storage capacities exceeded achieving independence addressing solution requiring large contiguous areas memory deemed satisfactory segment program data area com pletely relocatable without modification program possible load segments program programs onto drum load time call segments available space core memory needed run time segment program overlaid subsequent segment program segment program destroyed core memory still available drum called needed due high program densities b 5000 availability high capacity drum storage every system automatic segmentation minimum b 5000 system capa city program programs equivalent approximately 40000 60000 single address instructions course installation normally ran large programs system would likely minimum system however installation occasional need run large programs prevented storage capacity processing speed becomes function size core memory large programs run system small core memory time consumed recalling program segments drum core core memory expanded less time spent activity program programs speeded reprogramming required program reference table means achieving independence addressing b 5000 called program reference table prt prt 1025 word relocatable area memory used primarily storing con trol words locate data areas program segments also control words describing inputoutput operations control words called descriptors contain base address size data areas program segments inputoutput areas descrip tor specifying inputoutput operation also contains desig nation unit used type operation performed operands may also stored prt providing direct access single values indices counts control totals etc word mode b 5000 every item data con sidered either single value element array data single value obtained directly indexing descriptor contained prt program segments described program descriptors addition core base address program descriptor contains location drum storage program segment indication program segment currently core memory starting address specified descriptor entry program segment made via program descriptor contained prt program segment core memory entry made program segment however entry attempted program segment whose descriptor indicates segment core memory automatic entry master control program occur desired segment brought drum notice moving one segment another necessary know whether segment entered currently core memory branching within program segment self relative ie distance jump either forward backward specified address jumped result keeping actual addresses data program prt program contain addresses references prt specify one 1024 posi tions prt requires 10 bits contributes greatly high program density achieved b 5000 since prt relocatable references prt contained pro gram relative locations thus completely freeing program dependence whatsoever actual memory locations 272 part 3 instructionset processor level variations processor section 5 1 processors stack memories zero addresses per instruction word mode program 3 indexing descriptor item operand obtained indexed address descriptor action indexing case 4 subroutine entry occurs subroutine addressed word three previous types may left word mode b 5000 processor four types syllables second item stack occurs perand sy1lable syllable distinguished two highorder bits 12bit syllable types syllable identification bits 00operator syllable 01literal syllable 10operand call syllable 11descriptor call syllable first operator syllable causes operations performed remaining ten bits operator syllable operation codes approximately sixty different operations word mode operations requiring operand operands processor checks sufficient operands regis ters pushups stack memory occur automatically literal syllable used placing constants stack used operands ten bits literal syllable transferred stack allows program contain inte gers less 1024 constants operand call syllable descriptor call syllable ad dress locations program reference table purpose operand call syllable place operand stack purpose descriptor call syllable place address operand descriptor stack four situations arise depending word read program reference table 1 2 word operand word descriptor containing address operand word descriptor containing base address data area operand resides word program descriptor containing base ad dress subroutine 3 4 l operand call syllable completed action placing operand stack descriptor call syllable cause construction descriptor operand replacing operand constructed descriptor 2 operand call syllable reads operand cell addressed descriptor call syllable completed action registers upon return subroutine instance actions described take place depending upon type syllable initiated subroutine essentially four types action occur operand call syllable obtaining operand directly indirectly array computation sometimes use call syllables known type action occur particular syllable program created particu larly true call syllables subroutines programs word mode consist strings syllables follow rules polish notation variable length strings call syllables literal syllables place items information stack followed operator syllables perform operations information stack indexing features b 5000 allow generalized indexing time provide complete storage protection data areas program segments different programs may inter mingled program prevented storing outside data areas method indexing allows 1024 words program reference table considered index registers multilevel indexing provided ie indices arrays selves elements arrays subroutine control provided b 5000 allows nesting subroutineseven recursive nesting subroutine subrou tine itselfarbitrarily deep dynamic allocation storage parameter lists temporary working storage simplify use subroutines storage automatically allocated deallocated required character mode program character mode b 5000 processor one type syllable called operator syllable program segments character mode constructed strings syllables character mode designed provide editing formatting comparison forms data manipulation processor uses two areas memorythe source desti nation areas program switches word mode char acter mode two descriptors containing base addresses areas supplied source area destination area may chapter 22 1 design b 5000 system 273 changed time character mode program may act several areas parts last part specifies peration performed conclusion burroughs b 5000 system designed integrated memory space required store equivalent object programs character mode perator two hardwaresoftware package offers benefits savings first part pecifies number times peration multiprocessing parallel processing identical performed operations provided transferring deletion comparison insertion characters bits also operations allow repetition syllable strings quite useful complex table lookup operations editing information contains repeated patterns programs systems different size memories different system configurations loss individual system references lonew61 bartr61 bockr63 carlc63 maher6l section 6 processors mu ti programm ng processors section features allow multi ple programs exist primary memory time programs executed alternately single processor without wait new programs input cost changing processor state involves instructions one instruction systems cdc 6600 since programs subject numerous unpredictable delays within single run inter change external environment either via ms substantial increases pc utilization achieved multi programming single processor access mp system called multiprocessor system timeshared computers generally multiprogrammed alternatively timeshared systems implemented swapping programs one time primary memory interpretation berkeley timesharing system chap 24 uses multiprogramming program swapping burroughs b 5000 chap 22 early computer multiprogram capability idea multiprogramming fundamental among first concepts understood student computing systems nice review memory mapping storage allocation presented paper dynamic storage allocation systems randell kuehner 19681 atlas atlas one important machines described book prototype originally designed con structed manchester university atlas 1 atlas 2 produced ferranti corp prior becoming part 1ctl atlas 1 interesting incorporates features atlas prototype lincoln laboratory tx2 clark 19571 influenced atlas features multiple index registers interrupt processing inputoutput devices atlas detailed internal structure described paper sum ner et al 19621 international computers tabulators u k two original features onelevel storage extracodes copied many machines onelevel store com mon new computers timeshared multi programmed scheme memory paging sds 940 essentially atlas extracodes feature allows ordinary machine operation codes used call subroutines commonly used complex instructions sin cos monitor calls written common operating system accessible users initially subroutines stored readonly memory isp straightforward extremely nice extra code idea appears sds 900 series used sds 940 system defining commonuser instructions ibm systeml360 svc supervisor call instruction adapta tion extracode atlas earliest computer designed software operating system idea user machine mind operating system nicely described kilburn et al 19611 evaluated morris et al 19671 letter authors book f h sumner makes following comments atlas initial ideas preliminary research atlas computer system started department computer science uni versity manchester 1956 team direction professor kilburn later supplemented several members ict computer research department prototype machine working department autumn 1961 first production model became operational january 1963 significant features system summarised 1 provision virtual address field greater real address space 2 implementation onelevel store using mixture core store drum store 3 interrupt system method peripheral control 4 realisation design stage would complex operating system provision hardware specific features assist operating system 274 section 6 processors multiprogramming ability 275 method peripheral control permitted attachment large number online peripherals rapid response entry operating system peripheral requiring attention together multiprogramming features makes design ideal attachment keyboards provision multi access operation original design provision several online typewriters made production stage decided remove economy measure view subsequent development online operation rather unfortunate decision atlas computer university continuous operation four years expected provide major part universitys computing needs 1971 period operation provision extensive monitoring logging information permitted behaviour system studied detail results studies extremely valuable design successor atlas design b 5000 system burroughs b 5000 computer described part 3 sec 5 page 257 chap 22 user machine timesharing system berkeley timesharing computer fig 1 based sds 930 chap 24 hardware modifications sds 930 together operating system software sold scientific data systems sds 940 operating system hardware modifications multiprogramming make 940 one first commercially available combined hardware software timesharing computers description chap 24 concerned machine appears user hardware oper ating system software presented context contribute form user machine 940 uses memory map almost subset atlas modest ibm 36067 arden et al 19661 ge 645 dennis 1965 daley dennis 19681 number instructions apparently built via programmed operator calling mechanism based atlas extracodes chap 23 softwaredefined instructions emphasize need hardware features example float ingpoint arithmetic needed several computerbound programs run sds 945 successor 940 slightly increased capability lower cost timeshared computers consist hardware complex software operat ing system adams compute chamcteristics quarterly lists deliveries gen eralpurpose timeshared computers dec pdp6 hardware october 1964 software early 1965 sds 940 hardware berkeley software april 1966 ge 635 645 hardware may 1965 mits project multics software around 1969 ibm system360 model 67 hardware march 1966 software around 1968 mcontent addressable flip flop mp0344 mp 3 pk imapfc2s kmsmagnetic tape ltpaper tape kst teletype kmsdrum 2 dw 13 x 10 w kmsmoving head disk 15 x 10 w 6 e pi0 mpcore 175 usw 16384 w 24l parity bw pcmodified sds 930 see chgpter 42 fig 1 university california berkeley timesharedcomputer pms diagram chapter 23 onelevel storage system1 kilburn b g edwards j lanigan f h surnner summary brief survey basic atlas machine paper describes automatic system principle applied combination two storage systems combination regarded machine user single level actual system described relates fast core storedrum combination effect system instruc tion times illustrated tape transfer system also introduced since fits basically hardware scheme incor porates ﬁlearningﬂ program technique greater impor tance future computers requisite transfers information taking place automatically number additional benefits derived scheme adopted include relative addressing routines operate anywhere store ﬁlock facility prevent interference different programs simultaneously held store 2 basic machine 1 introduction universal highspeed digital computer necessary largecapacity fastaccess main store efficient oper ation computer achieved making store one type step scarcely practical storage capacities considered example atlas possible address lo6 words main store practice first instal lation manchester university total lo5 words provided though technically feasible make one level much economical provide core store 16000 words drum 96000 words combination atlas machine operates peripheral equipment time division basis equipment ﬁinterruptingﬂ normal main program requires attention organization peripheral equipment also done program many pro grams contained store machine time technique also extended include several main programs well smaller subroutines used controlling peripherals reasons well fact orders take variable time depending exact numbers involved really feasible ﬁoptimumﬂ program transfers infor mation two levels store ie core store drum order eliminate long drum access time 6 msec hence system devised make core drum store combi nation appear programmer single level storage arrangement basic machine shown fig 1 available storage space split three sections private store used solely internal machine organization central store includes core drum store words addressed store available normal user finally tape store conventional backingup large capacity store machine private store main core store linked main accumulator bstore barithmetic unit however drum tape stores acces5 latter sections machine via main core store machine order code single address type comprehensive range basic functions provided normal engineering methods also available programmer number extra functions termed ﬁextracodesﬂ give auto matic access subsequent return large number builtin subroutines routines provide 1 number orders would expensive provide machine terms equipment also time extra loading certain circuits example order shift accumulator contents n places n integer complex mathematical operations eg sin x logx etc control orders peripheral equipments card readers parallel printers etc 2 3 ire truns ecii vol 2 pp 223235 april 1962 4 inputoutput conversion routines 276 r 1 ii fig 1 trysut idc mrelrina 5 special programs concerned storage allocation different programs run sknuftaneously monitoring routines fault finding costing purposes detailed organization drum tape transfers information permanently required hence kept part private store termed ﬁfixed storeﬂ kilburn grimsdale lwa operates ﬁread onlyﬂ basis store consists woven wire pattern small ﬁlinearﬂ ferrite slugs inserted represent digitai information information content changed manually tend differ detail different versions atlas computer muse store arranged two units 4096 words unit consisthg 16 columrrs 256 words word 50 bits access time word one column 04 psec change column address required figure increases 1 pec due switching wents read amprs stbsequent accsssssin new cthru revert 04 pec store operates mnj subsidiary core store 1024 words provides working space bed store programs cycle time 18 pec certain safeguards aght normal machine user addre either part privstc store thcwgh effect makes use stom rot extracode facility central store madthe consists dnun core store combination whiuh bas maxi edclpcssoble oopcity 10s weds n rue central store cpaoi2y itw words ferred ha blah 81 w wads main core stom four mpuate stacks stack hwbg wpadty 4088wonaa ip system provides veay large capacity baddag store machine user aua e transfers vkr lpmaunts informwon store eatad om octual fa suoh ansfen ord fixedstcue program initiates c transfers blocks 512 wqlcdio ween ob 4 drums part afthis cbn trans main core store ﬁhe system cpn simaly prodwgor dem thus pmymad onr sither mcke tfig drum tape systepl tbse addrema priority system allocate addesses core stom dhlsm top prbxity sbce delhrsrs word every 4 pet trpe next prioitv since rdsopncuise every 11 pec h 8 ddcs u6es core stre reat available system newswily takes time establish ea cinnn ar tapa request thus madhe slowed dmm payway aodnug tape trunshs take place thtt aad tape traders machine speed given appendix 1 simplty aontrol commands given drum tip pbzfpherpaaqutphient tbs msrchiae rdtm take b b b identification te mquired eonmaad register pvkd address type storpgeis daatly widely soaapered e machine termed collecthly vstm en ilye ontnh machine e main accumulator conbins fast umar uhrn et 1thhij builtin nrrtwplication nnd divijicih ties ft cwn dasal fked hating poi numbers operation completely independent bstore c unit tbe bstore fast core store cycle time 07 pee qf 1w twentyfour bit words operating wosd selected fast b lines ueolso provided ia hm flipflo thwe uwd cmol lines terbped mojn extrscode inter rupt con raapectively arrangement advantage td hnmbers maatpwby e mwmai type orders existence three controb permits machine switb wpidiy one another without transfer emtd rs core store main control used pridty ead 90 e bwn fslwlg0d thoz 00 btb 8 81y partial flw wwitclbing mock edwards et al 278 part 3 instructionset processor level variations processor exponent v8 bits including sgn central machine obeying current program extra code control concerned fixed store subroutines interrupt control provides means handling numerous pe ripheral equipments ﬁinterruptﬂ machine either require providing information remaining ﬁfastﬂ b lines mainly used organizational procedures though b124 floating point accumulator exponent operating speed machine order 05 x lo6 instructions per second achieved use fast tran sistor logic circuitry rapid access storage locations extensive overlapping technique latter procedure made possible provision number intermediate buffer stor age registers separate access mechanisms individual units core store parallel operation main accumulator barithmetic units word length throughout machine 48 bits may considered two halfwords 24 bits store transfers central machine drum tape stores parity checked parity digit associated halfword case transfers within central store ie main core store drum parity digits associ ated given word retained throughout system tape transfers parity checked information transferred main core store tape check sum technique involving use two closely spaced heads used form instruction allows two bmodifica tions allocation address digits shown fig 2a half addressable store locations allocated central store identified zero significant digit address see fig 2b address subdivided block address line address block 512 words least significant digits 0 1 make possible address 6 bit characters half word digit 2 specifies half word function number split several sections section relating particular set operations listed fig 2c machine orders fall two broad classes 1 b codes involve operations b line specified ba digits instruction core store line whose address modified contents b line determined b digits total 128 b lines one bo always contains zero lines 90 available machine user 7 special registers previously mentioned 30 used extracode orders codes involve operations accumulator core store line whose address doubly 2 mantissa x 40 bits lncuding sign section 6 1 processors multiprogramming ability 0 23 22 2120 19 18 17 46 15 14 i3 12 1i1 io 9 8 7 6 5 4 3 2 line address odblock address core store drum 1 0 o1 0 0 0 0 ocolumnllineaddress 1 mesha address 1 mesh8 address fixed store 1 address subsidiary store ___ _______ address vstare signilicant hall word 0 least significant halfword mast significant character 0 0 least significant character 47 46 45 44 43 42 41 40 39 38 0000888888 ___ 0001 b codes 0040 8 test codes 001 codes of00 oioi 10 01 i1 4 codes extrocode return 0 os 8 il86 __ 8 codes extrocode return __ b type extracode type extrocode c fig 2 interpretation word form instruction b allocation address digits c function decoding floatingpoint number x8 modified first contents b contents ba fixed floating point orders provided latter case numbers take form xsy digit allocation x shown fig 2d fixed point working occurs use made x digits 3 0rrclkiwltoreconobpt choice system fast access store large scale computer governed number emdicting factom include speed ard size requirements eapnomic technical difficulties previously probkm bas resow two ex treme cuses either provision large core store eg 25 mebit papian 19571 store mit use small core store 40000 bits eapanded 10000 bits dnun store ferranti mercury lonsdale warburton 19 kilbwn et al 19561 computer methd disadvantages first case expense snd second case inconvenience user obliged program traders information two types stom time consuming instances wble expert mechine user mge program thnt amwnt time lost transfers twolevel storage mangemcbt significant sort optimtun pqpmaing aot desirable suitable interpretative coding brooker 19601 permit twolevel system appear one level effect however accompanied effective loss machine speed programs dependhg details machine design quite varying typically example tween one three twolevel storage sake obvious economic advan tages bconvenience machine user ellminated g transfer arrangements completely automatic atlas comphdy automatic system provided td niques minimizing transfer times way core drum merged iato appbpent single level storage good performance moderate cost details ar rangement muse provided central store subdivided blocks 512 words shown ttre address arrangeumnts fig b main cere store also partitioned blocks size identifiuation purposes called pages assodated core store page positions ﬁpage address registerﬂ par contains address block information present occupying page position access w01d central store required digits demanded block address compared contents page address registers ﬁequiva lenceﬂ indication obtained access particular page position permitted since b block occupy one 32 page positions core store necessary modify digits demanded block address conform page positions equivalence obtained thaw processes necesearily time consum provid ing bypass procedure instruction acoews since genera instntctioa loops amtained ia wne block tim cpn overlapped ueem pﬂtion machine corn store rhythm thia wsly infomation core store available mschine full speed e awe store rarely overall machine speed rrffeeted delays equivdwoe circuitry p ﬁnot equivalenceﬂ indication obtakred de manded kk address colipd contets pars en tht address may bn bmodiibe first stored register acd iiw vstore thip permits central machine easy access ad dress ﬁintemptﬂ also occurs swikcherr operntion machine te interrupt control wbidh fh ciwe tbc intarnapt en thtp htace enters bd store routisk ta organize necessary trmdbm infonaation dkun core store dficnrtm drcun one track used identify absolute bloak psi tions around dnmr periphery records tracks read b registers accd lines vstore permits present anglular ckum pition detmmbd though dy units one blook way ti ildeded tmnsbr mock reading hoin e drwns dfnrn malation time l2 msec ad actual transfer time 2 msec time writing transfer drums hss redd writing bld idormation ht wailable empty bloak pitian oa dmm thus access time drum elhind pvkkd masorable number empty blocks dnun means however transfers tofrom drtffn carried refesenoe direc tory stored subsidiary store updated ever transfer occurs st action determine absolute position dmm required block order given carry transfer empty page position core store transfer occurs automatically soon drum reaches correct angular position page address regirtsr vacant ion core store set specific block number dram transfers technique sim plifies engineering regard provision number anbetimeuiebetmsen2and14mgeine whrta dwm transfer routine eatered 280 part 3 instructionset processor level variations processor drum also provides safeguard transferring wrong block soon order asking read transfer drum given machine continues drum transfer program concerned determining block transferred back core store drum necessary ensure empty core store page position next read transfer required block core store transferred carefully chosen minimize number transfers program optimization process carried learning program details given sec 5 opera tion program assisted provision ﬁuseﬂ digits associated page position core store interchange information core store drums two transfers read write drum necessary done sequentially could occur either order technique vacant page position core store permits read transfer occur first thus allows time learning program overlapped either waiting period read transfer transfer time time remaining completion learning program entry made overall supervisor program machine decision taken concerning machine drum transfer completed might involve change different main program program could ask access information page position drum tape transfer taking place page prevented atlas use ﬁlock outﬂ lo digit provided page address register lock digit set 1 access page permitted address provided either drum system tape system interrupt control latter case permits trans fers paper tape punched card peripheral equip ments handled without interference main program transfer block completed organizing program resets lo digit zero access page section 6 processors multiprogramming ability position made central machine clear lo digit also used prevent interference tween programs several different ones held machine time sec 3 stated addresses demanding access core store could arise three distinct sources central machine drum tape accesses complicated 1 equivalence technique 2 lock digit various cases action takes place summarized table 1 provision page address registers equivalence circuitry learning program permitted core store drum legarded ordinary machine user one level store system additional feature ﬁfloating addressﬂ operation le block information stored absolute position either core drum store minimum access time information store obviously limited core store arrangement discussed b core store arrangement core store split four stacks individual address decoding read write mechanisms stacks combined way common channels machine address read write digits time shared various stacks sequential address positions occur two stacks alternately page position contains block 512 sequential addresses thus arranged across two stacks way possible read pair instructions consecutive ad dresses parallel increasing size read channel permits two instructions completely obeyed three store ﬁaccessesﬂ choice particular storage arrangement discussed appendix 2 coordination four stacks done ﬁcore stack coordinatorﬂ features discussed starting operation single stack table 1 comparison demanded block address contents pars resultant state equivalence lock circuits equivalence lock 0 sourw address leq1 equivalence neq equioalence lock 1 eq 6 lo 1 central machine access required page position enter drum transfer routine available program 2 drum system access required page position fault condition indicated fault condition indicated 3 tape system access required page position fault condition indicated fault condition indicated c operation u e rtedr corc8rt0rc storage system employed cdncident currant mit system arranged give paralkl read 50 digits reading opera tion detmctbe read phase stack cycle fol lowed write phase infonnaton read ont may rewritten achieved set digit stptizors loaded read phase ad control inhibit current drivers dwkg write phase new information written store similar sequence followed except digit staticizors loaded mw information read phase diagram indicating different types stack cycle shown fig 3 strobe lg phose 0 stp7 r rood phase 1 write strobe u write phase 1 wol stnrk write strobe u write phose lr b ic r occess time rc cyclic time wo woit oddrens decoding loading oddreu register ww woit release write hold rg 3 bask types rtldr cycle road orckr b rmteonkr c roadwrit w small delay w n 100 mpec ﬁstack requestﬂ signal sr start rtwd phase allow setting address stab decodbg output informath store appears read strobe period towards end read phase general write phase starts soon ul read phase ends however start write phase may held new information available central machine delay shown w fig 3c interval stack request read strobe termed e stack access time practice approxi mately one third cycle time tn functions storage ryatem resuming w zero typical values 07 19 pc respectively holdup gate request channel prevents next stack request occurring end preceding write phase opsrclh muin wm store wit umtral machine scheme diagram essentials main core store con trol system shown fig 4 control signals sa sa indicate whether address presented single word pair sequentially addressed instructions assuming flipflop f reset condition either signals results loading buffer address register bar loading done signal baba also indicates buffer register central machine become free dealing 5st request block address digits bar compared contents page address registers one indications summarized table 1 indicated fig 4 obtaimd assuming access required store stack permitted set csf signal given resets flipflop f occurs next access request arises speed system storelimited cases set csf generated equivalence operation demanded block address complete read phase appropriate stack stacks swed time information held bar must allowed change fig 5 fmv diagram shown various cases single address request accepted necesrary obtain ﬁequivalenceﬂ indication form page location digits ttze stack request generated set csf sippnrl thm occies soon read phase starto zf ﬁnot equiva lentﬂ equivalent locked outﬂ indication stack request generated contents 4ar copied line e vstore set csf pneratd access pair addresses reqwsted e instruc ariseinpmctice 282 part 3 instructionset processor level variations processor page oddress reg 0 page oddress reg 1 equivalence eo neq eqeilo instruction address 1 instruction addressbl register cornporison circuit stock 0 stack 1 7wj main core store 1 stack fig 4 main core store control tion pair stack requests generated assumption instructions located page position last pair requested le page position digits taken page digit register see fig 4 way time required obtain equivalent indication form page location digits included overall access time system assumption normally true except crossing block boundaries latter cases detected corrected com paring true position page digits obtained result section 6 1 processors multiprogramming ability equivalence operation contents page digit register ﬁright pageﬂ ﬁwrong pageﬂ indication obtained see fig 4 wrong page accessed indicated central machine read inhibited true page location digits copied page digit register required instruction pair obtained next requested read central machine also inhibited ﬁnot equivalentﬂ ﬁequivalent locked outﬂ indications fig 5 waiting time indicated immediately stack request generated arise number reasons 1 2 preceding write phase stack yet finished central machine yet ready either accept infor mation store supply information sa1 sa2 1 walt core store free 1 wait equivalence ond formotion page diglts equivalent equivolent ond locked woitlsee text1 copy vline bar request stack set csf start read dhose wolt equivalence formalion page digits woit see text l equivalent compare page equivalent locked requests 1 digits contents page digit 1 set csf copy pede digits page digit set csf set csf set csf fig 5 flow diagram main core store control 3 necessary ensure certain minimum time eppromate times various iastrustiono given successive read strobes om core store scscks dow table 2 figures relate times completing mtisfactov operation pafity ckcuib take instructions long sequence type instruction reduced posisible get condition practice obng one instruction overlapped time part instruction timing part three instructions makes detailed thought economical proposition timing complicated timing sequence developed 04 pec chwk information thip time could ideal necessary basic machine timing discussed 4 instruction times highspeed computers one main factors limiting speed operation store cycle time number tecbnlques eg splitting core store four separate stacks extracting two instructions single cycle adopted despite fast basic cycle time bf 2 pec order alleviate situation time taken complete instruetion dependent upon 1 type instruction defined function 2 exact location instruction operand core fixed store since em affect access time 3 whether operand address modified 4 case floating point accumulator orders actus1 numbers 5 whether dnun andor tape transfers taking place git4 slowly first considering instructions obeyed one another convedient make instructiow sequemce floating point additions instruction operand core store operand address single bmodiw obey instruction central machine makes two quests core store one instruction second operand instruction received machine function part dscaded tlm operand address modified contents one b registers operand request made finally operand obmned actual accumulator addition takes place complete instruction time beginning end one instruction 605 pec approximate timing schedule follows table 3 action permitted time required complete instruction steps 1 8 table 3 different sections machine uw used inefliciently eg accumu lator adder used less 11 pec however orga nization computer different sections store stacks accumulator mthmetic unit operate floating point addition floating point multiplication floating point division add store line index register 0 1 2 14 16 203 0 1 2 47 0 1 2 136 0 1 add index register store line rewrite 0 store line 1 153 1 163 18 165 165 19 47 136 165 185 165 17 12 12 19 47 136 1t5 185 284 part 3 instructionset processor level variations processor table 3t operands core store timing sequence floating point addition instructions time interval total steps time sequence elsec pec 1 add 1 main control 0 2 make instruction request 03 addition time 03 transfer times equivalence time stack access time 175 3 receive instruction central machine 205 4 function decoding complete 225 5 request operand 310 load register decode 02 single address modification 085 transfer times equivalence time stack access time 175 load register 01 6 receive operand central machine 485 7 start addition accumulator 495 average floating point addition including shift round stand rd se 11 8 instruction complete 605 step 4 time single address modification times modification two modifications 025 psec 155 psec respectively time way several instructions started first finished effective instruction time considerably reduced course certain safe guards example instruction dependent way completion preceding instruction time sequence previously tabulated far longest time request central machine core store receipt central machine infor mation store effective access time 175 psec made shown table 4 reduced practice provision two buffer registers one central machine core stack coordinator allow equivalence transfer times overlapped organi zation requests central machine way provided machine arrange make requests fast enough effective access time reduced 08 pec since three accesses needed complete two instruc tions one instruction pair one two operands theoretical minimum time instruction 12 psec 3 082 becomes store limited reference section 6 1 processors multiprogramming ability table 3 shows arithmetic operation takes 12 psec complete average capabilities store accumulator well matched another technique reducing store access time instruc tions also adopted permits read cycles two stacks start assuming page referred previous instruction pair course normally true sufficient time take corrective procedures page changed limit 12 psec per instruction reduced technique possibility reaching limit conditions enhanced schematic diagram practical timing sequence floating point addition orders shown fig 6 overlapping perfect time successive instruction pairs computer obeying four instructions 25 per cent time three 56 per cent two 19 per cent therefore expected practical time complete order greater theoretical minimum time fact approxi mately 16 psec certain types functions reading next pair instructions completing instructions first pair would incorrect eg functions causing transfer control situations recognized function decoding request next instruction pair held suitable time sequence floating point addition orders operand addresses unmodified limit 12 psec time obtained 14 pec accumulator orders actual accumulator operation imposes limit excess 2 psec actual time equal limit perhaps realistic way defining speed com puter give time typical inner loop instructions frequently occurring operation matrix work formation scalar product two vectors requires loop five instructions table 4 effective store access time total time sequence jc 1 request central machine 0 3 equivalence complete request made selected 2 request core stack coordinator 025 stack 095 4 information core stack coordinator 165 5 information central machine 175 chapter 23 1 onlovel storage syskm 285 1 fylj accumulator busy acc stack request read flyj accumulator busy 1 operand request equivalence 21 start second pair operand occ stack request lfl bmodificatmn reqrest equivalence read f acwnulator busy 3 occ start instruction stock operand stack next pair request 131 request function request request equivalence read decode bmodification equivalence start second pair 4 5 ifdzl 8 modification 6 start instruction next pair request 11 equivalence fig 6 timing diagram sequence floating point addition orders singleaddress modification 1 element first vector accumulator operand bmodi fied multiply accumulator element second vector oper bmodified 3 add partial product accumulator 4 copy accumulator store line containing partial product 5 alter count select next elements repeat 2 time loop instructions operands core store 122 psec value overlapping technique shown fact time starting first instruction finishing second approximately 10 psec drum tape systems transferring information core store rate obeying instructions also use core store affected affect dis cussed detail appendix 1 degree slowing dependent upon time drum tape request occurs relative machine requests also depends stacks used drum tape used central machine approximate slowing factor 25 per cent drum transfer 2 per cent active tape channel see appendix 1 5 drum transfer learning program organization drum transfers described sec 2a transfer required block drum core store initiated organizing program examines state core store empty pages still exist action taken however core store full necessary arrange empty page made available use next non equivalence selection page transferred could made random could easily result many additional trans fers occurring page selected could one current use one required near future ideal selection would minimize total number transfers could made programmer make ideal selection programmer would know 1 precisely program operated always case 2 precise amount core store available program instant latter information generally available core store could shared central machine programs almost certainly fixed store program organizing input output information slow peripheral equipments amount core store required fixed store program continuously varying kilburn et al 19611 way ideal pattern transfers approached transfer program monitor behavior main program attempt select correct pages transferred drum techniques used monitoring subject condition must slow operation program extent offset reduction number transfers required method de scribed occupies less l per cent operating time reduction number transfers sufficient cover 286 part 3 1 instructionset processor level variations processor part transfer program organizes selection page transferred called ﬁlearningﬂ pro gram order program data operate machine designed supply information use made different pages core store program monitored page core store associated ﬁuseﬂ digit set ﬁ1ﬂ whenever line page accessed 32 ﬁuseﬂ digits exist two lines vstore read learning program reading automatically resetting zero frequency digits read governed clock measures real time number instructions obeyed operation main program clock causes learning program copy ﬁuseﬂ digits list subsidiary store every 1024 instructions use instruction counter rather normal clock measure ﬁtimeﬂ learning program due fact operations main program may interrupted random random lengths time operation peripheral equipments instruction counter temporal pattern blocks used successive runs part program essential learning program make use pattern minimize number transfers nonequivalence occurs transfer required block arranged learning program adds current values ﬁuseﬂ digits list uses list bring date two sets times also kept subsidiary store sets consist 32 values one page core store value length time since block page used value length last period inactivity block accuracy values governed frequency ﬁuseﬂ digits inspected page written drum selected appli cation turn three simple tests values 1 2 page 1 page 0 max 3 page 0 first rule selects page currently use longer last period inactivity page probably ceased used program therefore ideal one transferred drum second rule ignores pages 0 current use selects one pattern use maintained section 6 processors multiprogramming ability required program longest time first two rules fail select page third ensures page finally selected wrong immediately required case twill become zero mistake repeated blocks drum list values kept values set block transferred drum time transfervalue transferred page block transferred core store value used set value time transfervalue block length last period inactivity block transferred drum set 0 order make decision learning program update two short lists apply three simple rules easily done 2 msec transfer time block required result nonequivalence learning program uses fixed subsidiary store addresses slowed period drum transfer overall efficiency learning program known complete atlas system working however value method used investigated simulating behavior onelevel store learning program mercury computer manchester university done several problems using varying amounts store excess core store available one problem forming product two 80th order matrices b c three matrices stored row row one extending 14 blocks 14 pages core store assumed available method multiplication b x 1st row c partial answer 1st row b x 2nd row c partial answer second partial answer etc thus matrix b scanned matrix c 80 times row matrix 80 times several machine users asked spend short time writing program organize transfers general matrix multipli cation problem case method applied problem fewer 357 transfers required program written specifically problem paid great attention distribution rows matrices relative block divisions required 234 transfers learning program required 274 transfers gain human programmer chiefly chapter 23 1 onelevel storage system 287 due fact learning program could take full advantage occasions rows existed entirely within one block many problems involving cyclic running single multiple sets data simulated case learn ing program require transfers experienced human programmer prediction drum transfers although learning program tends reduce number transfers required minimum transfers occur still interrupt operation program 2 14 msec initiated nonequivalence interrupts time loss could avoided organizing transfers advance experienced programmer sole use core store could arrange transfers way unnecessary ones ever occurred time ever wasted waiting transfers completed would require great deal effort would worthwhile program going occupy machine long time using data accumulated learning program possible recog nize simple patterns use made program various blocks onelevel store way prediction program could forecast blocks required near future organize transfers recording success failure forecasts program could made selfimproving matrix multi plication problem discussed pattern use blocks containing matrix c repeated 80 times considerable degree success could obtained simple prediction program 6 conclusions specific system making coredrum store combination appear single level store described actual system built atlas machine principles involved applicable combinations types store exam ple tunnel diodefast core store combination even faster machine alternative considered atlas attractive economically fast coreslow core store combination system extended three levels storage indeed 106 words total storage provided would economical provide third level store file drum automatic system require additional equipment introduces complexity since necessary overlap time taken address comparison store machine operating time introduce extra time delays simulated tests shown organization drum transfers reasonably efficient advantages accrue efficient allocation core storage different programs store lock facilities also invaluable matter intelligent programmer may never know many programs peripheral equipments operation program running advantage automatic system takes account state machine exists particular time furthermore normal use sort regular machine rhythm even several programs possibility making sort prediction regard transfers necessary involves hardware done program however stage probably left results actual system obtained seen system useful flexible modified extended manner previously indicated thus despite increase equipment advantages derived completely justify building automatic system appendix 1 core store organization access requests three sources access requests core store namely central machine drum tape systems deciding sequence requests three sources serialized placed sort order number facts considered 1 three sources asynchronous nature 2 drum tape systems make requests fairly high rate compared store cycle time approxi mately 2 psec example drum provides request every 4 pec tape system every 11 pec 8 channels operative 3 drum tape systems stopped multiples block length ie 512 words means system devised accessing core store must deal average rates drum tape requests specified 2 central machine tolerate requests stopped time length time facts request priority stated drum request b tape request c central machine request 288 part 3 1 instructionset processor level variations processor 1 stack request stored rnochine order machine request accepted core store place available accept core store information cycle inhibited requests held case successive division orders time long 20 psec case 5 drum requests could made avoid excessive amount buffer storage drum two techniques possible drums tapes operative permit chine requests accepted place available put information h store machine request permit drum tape request latter scheme adopted accommodated conveniently saves small amount time central machine using private store desirable drum tape transfers core store interfere slow central machine way central machine drum tape sharing core store loss central machine speed roughly proportional activity drum tape systems means drum tape requests must ﬁbreak normal machine request channel required system accommodates points dis cussed whenever drum tape request occurs inhibit signals applied request channel core stack coordinator also stack request channels coordinator results ﬁfreezingﬂ state flipflop f fig 5 state inspected fig 7 point x state ﬁbusyﬂ means machine order stopped somewhere loading buffer address register bar stack request normally time interval vary 05 pec stack request holdups 20 psec case certain accumulator holdups either case sufficient time al lowed inspection ensure equivalence operation completed equivalence indication obtained information relevant machine order ie line ad dress page digits stacks required type stack order stored future reference use made page digit register provided allow bypass equivalence circuitry instruction accesses core store made free access drum tape core store found free inspection procedure omitted f flipflop frozen 1 xp inspect state f flipflop 1s stored machine order 7 busy wait equivalence completed 1 1 store machine order free f flipflop drum tape access core store drumtape priority remove stock request inhibit signals stock request drum top drumtape request hmrt stack request inhibits reapply adpy inhibits stack request channels machine request channels already applied 1 stack request 0 stored machine order stopped rlx fig 7 drum tape break systems drum tape access decided priority circuit core store occurs removes inhibits stack request channels stack request drum tape cycle initiated inhibits allowed reapply stage fig 7 point stored machine order allowed proceed possible inhibits machine request chan nels removed stack request stored machine order occurs stored machine order done chapter 23 onelevel storage system 289 immediately central machine allowed access core store however another drum tape request arise stack request stored machine order occurs particular latter order may still held central machine case drum tape allowed immediate access attempt made complete stored machine order drum tape stack request occurs stored machine order operand content page digit register correspond location operand next machine request instruction pair almost certainly result ﬁwrong pageﬂ indication prevented arranging next instruction pair access bypass equivalence circuitry effect machine speed drum tapes transferring information core store dependent upon two factors first upon proportion time buffer register core coordinator busy dealing machine requests secondly upon particular stacks used central machine drum tape computer obeying program instructions operands fixed subsidiary store rate obeying instructions un affected drum tape transfers drum tape interrupt occurring bar free prevents machine address accepted onto buffer 10 psec however bar busy next machine request core store delayed 18 psec interrupt different stacks used 34 psec interrupt stacks machine obeying program instructions operands core store slowing drum transfers factor two instructions operands drum requests use stacks also possible machine unaffected effect particular sequence orders seen considering one discussed sec 4 illus trated fig 6 sequence instructions stacks 0 1 operands stacks 2 3 drum tape transferring alternately stacks 0 1 effect interrupt within 32 psec instruction pair increase time 05 34 pec depending upon interrupt occurred average increase 18 psec tape transfer interrupts every 88 pec computer obey instructions 98 per cent normal rate drum transfers interrupts occur every 4 psec would suggest slowing 60 per cent normal however regular sequence orders requests core store machine drum rapidly become synchronized result particular case machine still operate 80 per cent normal speed appendix 2 methods division main core store maximum frequency requests dealt single stack core store governed cycle time store store divided several stacks cycled independently limit imposed speed machine core store reduced degree division chosen dependent upon ratio core store cycle time machine opqrations also upon cost multiple selec tion mechanisms required considering sequence orders instruction operand core store single stack store limit imposed operating speed store two cycle times per order le 4 psec atlas significantly larger limits imposed sections computer sec 4 store divided two stacks instructions operands separated limit reduced 2 pec still rather high provision two stacks permits ad dressing store arranged successive addresses alternate stacks therefore possible making requests stacks time read two instructions together reducing number access times three per instruction pair unfortunately arrangement store means operands always stacks instruction pairs limit imposed cycle time still 2 pec per order even two operand requests instruction pair different stacks occur time division number stacks addressing system working stack turn reduce limit 2 psec since successive instructions normally occur successive addresses therefore stack however four stacks arranged two pairs reduces limit 1 psec operands always arranged different stacks instruc tion pairs order reduce limit 05 psec necessary eight stacks arranged two sets four read four instructions would increase complexity central machine limit 1 pec quite sufficient division stacks arranged pairs enables limit easily obtained suitable location instructions operands location instructions operands within core store control drum transfer program thus 290 pari 3 1 instructionset processor level variations processor 20 156 number pages operands fig 8 limit imposed cycle time operating speed different divisions core store section 6 1 processors multiprogramming ability several stacks instructions operands separated wherever possible conditions possible calculate limit imposed operating speed cycle time different divisions core store results shown fig 8 stacks arranged pairs instructions read pairs cases instructions operands assumed core store operands assumed selected random operand space instance case two stacks arranged pair successive operand requests equal probability stack alternate stacks limit imposed four stack store never severe com pared limitations example sequence floating point addition orders discussed sec 4 required 16 psec per order ideal distribution instructions operands division eight stacks although reduces limit equiv alent effect overall operating speed division considered justified references kilbt62 broor60 edwad6o kilbt56 mu 60b 61 lonsk56 papiw57 fothj61 hartd68 howadtil 62 63 morrd67 sumnf62 chapter 24 user machine timesharing system1 b w lampson w w lichtenbqm w pirtb summoy paper describes design computer seen machinelanguage programmer timesharing system developed university california berkeley instructions machine executed hardware implemented software user however thinks part machine machine extensive unusual capabilities many might part hardware considerably expensive computer among important features machine arithmetic string manipulation instructions general memory allocation configuration mechanism multiple processes created program facilities provided communication among processes control exceptional conditions inputoutput system capable handling peripheral equipment dorm convenient manner files sym bolic names programs access files belonging number people person protect files unauthorized access others mention made various points techniques implemen tation main emphasis appearance users machine introduction characteristic timesharing system computer seen user programming machine language differs system implemented bright 1964 comfort 1965 forgie 1965 mccullogh et al 1965 schwartz 19641 fact user machine defined combination timesharing hardware running user mode software controls inputoutput deals illegal actions may taken users program provides various services hard ware arranged way calls system form hardware instructions machine lichten berger pirtle 19651 distinction becomes irrelevant user simply programs machine unusual powerful instruction set relieves many prob lems conventional machinelanguage programming lampson 1965 mccarthy et al 19631 pm ieee 54 vol 12 pp 17661774 december 1966 timesharing system developed use members project genie university california berkeley lichtenberger pirtle 19651 user machine number interesting characteristics computer system sds 930 24 bit fixedpoint machine one index register multilevel indirect addressing 14 bit address field 32 thousand words 175 ps memory two independent modules figure 1 shows basic configuration equipment memory interleaved two modules processing drum transfers may occur simultaneously detailed description various hardware modifications computer implications performance overall system given previous paper lichtenberger pirtle 19651 briefly modifications include addition monitor user modes user mode execution class instructions prevented replaced trap system rou tine protection unauthorized access memory subsumed address mapping scheme 16 384 words addressable user program logical addresses 32 768 words actual core memory physical addresses divided 2048word pages set eight sixbit hardware regis ters defines map logical address space real memory speclfying real page correspond users logical pages implicit scheme capability marking users pages unassigned readonly attempt access page improperly result trap memory references user mode mapped monitor mode memory references normally absolute possible however instruction monitor mode even within chain indirect addressing specify use user map furthermore monitor mode top 4096 words mapped two additional registers called monitor map mapping process illustrated fig 2 another sicant hardware modification mechanism going modes machine user mode get monitor mode three circumstances 291 292 part 3 instructionset processor level variations processor magnetic 1 processor ii interface teletypes l memory 175esec i3x io6 words 51105 wdssec 1 general 1 graphic display light pen fig 1 configuration equipment 1 2 3 hardware interrupt occurs trap generated user program outlined instruction particular configuration two bits executed instruction called system pro grammed operator syspop case 3 sixbit operation field used select one 64 locations absolute core current address instruction put absolute location zero subroutine link indirect address bit link word set another bit set marking memory location link word come user mapped memory system routine thus invoked may take parameter word addressed syspop since address field interpreted hardware routine section 6 processors multiprogramming ability address parameter indirectly location zero cause bit marking contents location zero come mer mode user map applied mainder address indirection calls system inadvertent made way monitor mode program gets user mode transferring address mapping specified means among things syspop return user program simply branching indirect location zero discussion perhaps indicated mode changing arrangements clean permit rapid natu ral transfers control user system programs advan tage taken fact create rather grandiose machine user features subject paper basic features machine user berkeley timesharing system working thinks hardware language level disposal machine configuration capability con veniently controlled execution machine instruction se quences simplest configuration similar poq 3 0 4 5 2 6 3 7 4 8 5 9 6 10 7 11 i2 13 la l6k virtual core u15 32k real core 0 0 23 13 j1010o11010110 virtual effective address 24654e joo01001 mapping reglster 5 118 go 003 07m real effective address 44654a readonly bit b fl fig 2 hardware memory map relation virtual real memory typical map b construction real memory address chapter 24 user machine timesharing system 293 standard mediumsized computer configuration machine possesses standard 930 complement arithmetic logic instructions addition set software interpreted monitor executive instructions latter instructions discussed fully following rather complex inputoutput many different kinds perform many frequently used table lookup string processing functions implement floating point operations provide creation complex machine configurations examples instructions available load b x index registers memory store registers indexing indirect addressing avail able almost instructions double word load store also available normal complement fixedpoint arithmetic logic operations skips various arithmetic logic conditions floating point arithmetic inputoutput latter free format equivalent fortran e f format input character teletype write block arbi trary length drum file look string hashcoded table obtain posi tion table create new process start running concurrently present one specified point redefine memory machine include portion also used another program emphasized although many instruc tions software interpreted format identical standard machine instruction format exception one bit specifies system interpreted instruction since system interpretation instructions completely invisible machine user since instructions standard machine instruction format user program make distinction hardware software interpreted instructions possible 192 operation codes legal user machine included category hardware structions would halt machine interfere inputoutput allowed execute software interpreted instructions attempt things forbidden program attempted execution one instructions result ilkgal instruction violation effect illegal instruction violation described later memory configuration memory size organization machine specified appropriate sequence instructions example user may specify machine 6k memory addresses 0 13777 alternatively may specify 6k include addresses 0 3777 14000 17777 34oo0 37777 user may also specify size configuration machines secondary storage considerable extent structure inputoutput system full discussion capa bility deferred later section next paragraphs discuss mechanism users program may specify memory size organization mechanism known process map distinguish hardware memory address mapping uses software mapping register consisting eight 6bit bytes one byte eight 2k blocks addressable 14 bit address field struction bytes either 0 addresses one 63 words table called private memory table pmt user private memory table entry table provides information particular 2k block memory block may either local user may shared block local entry gives information whether currently core drum information important system need concern user block shared pmt entry points entry another table called shared memory table smt entries table describe blocks memory shared several users blocks may con tain invariant programs constants case marked readonly may contain arbitrary data processed programs belonging two different users possible arrangement logical virtual memory process shown fig 3 nature page noted picture virtual memory information also obtained taking corresponding byte map looking pmt entry specified byte figure shows large amount shared memory suggests process might compilation sharing code compiler processes translating programs written source language virtual pages one two might hold tables tem porary storage unique separate compilation note although flexibility map allows block code data appear anywhere virtual memory certainly true program run regardless pages 294 part 3 instructionset processor level variations processor page 5 1 unassigned 6 1 shared bl 3 16 k virtuol memory entry block process privote map memory table fig 3 layout virtual memory typical process particular contains references branch instructions must run virtual pages loaded two instructions provided permit user read modify process map ability read process mapping registers permits user obtain current memory assignment ability write registers permits reassign memory way suits fancy system naturally checks new map established ensure process attempting obtain unauthorized access memory belong users process initiated assigned enough memory contain program data initially loaded stance program constants occupy 3000 words two blocks say blocks 0 1 assigned point first two bytes process mapping register nonzero others zero program runs may address memory outside first 4k user specified machine size larger 4k new block memory assigned makes formerly illegal reference legal way users process may obtain memory fact may easily obtain 16k memory simply ad dressing 16k reading preserving process mapping register setting bytes cleared zero grabbing memory course 16k addressed one time limitation imposed address field machine section 6 processors multiprogramming ability instruction allows process specify maximum amount memory allowed attempts obtain amount memory violation occur memory violation also caused attempts transfer indirect unassigned memory store readonly memory effect violation similar effect illegal instruction violation discussed facilities described entirely sufficient programs need reorganize machines memory solely internal purposes many cases however program wishes obtain access memory blocks created system programs example may package mathematical utility routines system program would like use accommodate requirement instruction establishes relationship name certain process mapping function instruction moves pmt entries blocks addressed specified process mapping function shared memory table generally accessible users correspondence established another instruction allows different user deliver name obtain return associ ated process map instruction necessary make new entries second users pmt various subsystems programs general interest names permanently assigned system user machine thus makes possible number proc esses belonging independent users run memory arbitrary combination blocks local individual process blocks shared several processes blocks per manently available system complex configuration sketched fig 4 process 11 shown detail fig 3 box represents process numbers within rep resent eight map bytes arrows processes show process hierarchy discussed next section note pmts belong users processes discussion apparent user manipulate machine memory configuration perform simple memory overlays change data bases perform complex tasks requiring memory reconfiguration example use common routines greatly facilitated since necessary adjust process map 1 memory references internal external common routine correct 2 memory area routine resides readonly simplest case common routine data base fit 16k memory map initially established remains static throughout execution routine cases chapter 24 user machine timesharing system 295 routine data base fit 16k several common routines concurrently employed may necessary make frequent adjustment map execution multiple processes important feature user machine allows user program current context referred controlling process establish one subsidiary processes minor exceptions discussed subsidiary process status controlling process thus may turn estab lish subsidiary process therefore apparent user machine fact multiprocessing machine original sug gestion gave rise capability made conway conway 19631 recently multics system included multiprocess capability corbato vyssotsky 1965 dennis van horn 1966 saltzer 19661 process logical environment execution program contrasted physical environment hardware processor defmed information quired program run information called state vector create new process given process executes struction arguments specifying state vector new process state vector includes program counter central registers process map new process may memory configuration completely differ ent originating process constraint placed memory specification total memory available multiprocess system limited 128k process mapping mechanism common processes user course 128k facility put system system could control user processes also direct value however many user processes obvious examples inputoutput buffering routines operate independently users main program communicating memory interrupts see following whether operation buff ered large volume output disc teletype requests information progress running program degree flexibility afforded multiple processes far exceeds anything could built inputoutput system fur thermore overhead low additional process requires 15 words core process switching takes 1 ms favorable conditions numerous examples value multiple processes unfortunately complex briefly explained process may create number subsidiary processes independent others equivalent point view originating process figure 4 shows two simple multiprocess structures one two users note process associated pointers controlling process one subsidiary processes process two immediate descendants case processes 12 13 chained together ring thus three pointers ring suffice defme process structure completely pointers course redundant convenient implementation process identified process number returned system created complex structure fig 5 may result creation number subsidiary processes processes fig 5 numbered arbitrarily allow clear description way pointers arranged note user need aware pointers shown clarify manner multiple process mechanism imple mented process may destroy one subsidiary processes execut ing appropriate instruction obvious reasons operation legal process destroyed subsidiary pmt 1 1 m3 2 m4 3 m5 4 smt1 5 smt4 6 smt2 7 m12 8 smt6 9 smt3 10 pmt 2 1 smt1 2 smt5 3 m7 4 m8 5 m9 6 smt2 7 m13 8 smt3 9 m14 io m15 smt 1 m1 2 mi6 3 m2 4 m1o 5 m11 6 m6 fig 4 process memory configuration two users processes numbered user represented process map ping registers memory blocks identified drum addresses written m1 m2 296 part 3 instructionset processor level variations processor section 6 processors multiprogramming ability fig 5 hierarchy processes processes possible find processes subsidiary given one permits process destroy entire tree subprocesses reading tree top de stroying bottom operations creating destroying processes entirely separate starting stopping execution two operations provided process whose execu tion stopped said suspended assure various processes effectively work together common task several means interprocess com munication exist first allows controlling process obtain current status subsidiary processes status information read table execution appropriate system instruction includes current state vector operating status operating status process may 1 running 2 dismissed inputoutput 3 terminated memory violation 4 5 terminated illegal violation terminated process second instruction allows controlling process become dormant one subsidiary processes terminates termina tion occur following four ways 1 2 3 selftermination memory violation illegal instruction violation interactions described previously provide method process attract attention another process pursuing independent course done program interrupt associated process 20bit interrupt mask mask bit set process may certain conditions described following interrupted le transfer fixed address simulated program presumably fixed address location subroutine capable dealing interrupt returning interrupted com putation afterwards mechanism functionally almost identi cal many hardware interrupt systems process may cause interrupt delivering number interrupt appropriate instruction process causing interrupt continues undisturbed nearest process either level one causing interrupt hierarchy processes appro priate interrupt armed interrupted mechanism pro vides flexible way processes interact without wasting time testing flags similar frivolous activities interrupts may caused explicit action processes also occurrence several special conditions occurrence memory violation attempted execution illegal instruction unusual inputoutput condition ter mination subsidiary process intervention user console pushing reserved button may cause unique interrupts previously armed way process may notified conveniently unusual conditions associated processes process console user memory assignment algorithm discussed previously slightly modified presence multiple processes process activated one three options may specified 1 assign new memory process entirely independently controlling process assign new memory process attempt obtain new memory cause memory violation 2 chapter 24 1 user machine timesharing system 297 3 process attempts obtain new memory scan upward process hierarchy topmost process reached time scan process found address causing trap legal propagate memory assigned hierarchy process causing trap option 3 permits process started subset memory later reacquire memory given initially feature important amount memory assigned process influences operating efficiency system thus speed able respond teletypes realtime devices inputoutput system user machine straightforward unconventional set inputoutput instructions primary emphasis design instructions make inputoutput devices interface identically program provide much flexibility common interface possible two advantages result uniformity becomes natural write programs essentially independent environment operate implementation system greatly simplified user former point course important one common example programs written controlled teletype driven instead file let us say drum command exists permits recognizer system command language subsystems driven way device particularly useful repeti tive sequences program assemblies background jobs run absence user output normally goes teletype similarly diverted user files another application uniformity file system demonstrated subsystems notably assembler various compilers subsystem may request user specify wishes program listing placed user may choose anything paper tape drum teletype absence file uniformity subsystem would require separate block code possibility fact however inputoutput instructions used cases inputoutput instructions communicate jiles system turn associates files various physical devices programs part account pecu liarities various actual devices since devices differ widely characteristics behavior flexibility operations available files clearly critical must range single character input output thousands words file opened giving name argument appropriate instruction programs thus refer files symboli cally leaving details physical location organization system rf authorized program may refer files belonging users supplying name user well file name owner file determines authorized access reader may compare file naming mechanism sophisticated one daley neumann 19651 bearing mind fact file names length manipulated strings characters program access files general either sequential random nature devices like keyboarddisplay card reader purely sequential others like disk may either sequentially randomly accessed accordingly two major 10 interfaces deal different qualities interface used conjunction given file depends whether file declared random sequential file two major interfaces broken interfaces pri marily reasons implementation although distinction sequential random files great subinterfaces especially visible user sequential jk three instructions cio character inputoutput wio word inputoutput bio block inputoutput used commu nicate sequential file instruction takes operand ajile number number given program opens file time opening file must specified whether file read written onto whether given device associated file characteroriented word oriented unimportant system takes care necessary charactertoword assembly wordtocharacter disassembly actually three separate fullduplex physical inter faces devices sequential file mechanism generally interfaces invisible programs exist course reasons system efficiency also way devices used interfaces characterbycharacter basically lowspeed character oriented devices used manmachine interaction buffered block 10 mediumspeed 10 applications block 10 directly user core highspeed situations 298 part 3 instructionset processor level variations processor pointed particular relation tween interfaces three instructions cio wio bio interface used given situation function device involved sometimes volume data trans mitted instruction interface may driven instruction three subinterfaces discussion last two straightforward characterbycharacter interface however somewhat different deserves elaboration devices associ ated interface generally necessarily used manmachine interaction consider case person com municating program means keyboarddisplay teletype types keyboard information transmitted computer program may wish make immediate response display screen many cases response consist echo character user feeling typing directly onto screen onto teleprinter inputoutput carried program actually main memory characterbycharacter input interface permits programs choice number echo tables permits programs choice grade service per mitting specify whether given character attention break character thus example program may specify character typed echoed immediately control characters result activation program regardless number characters input buffer alter natively program may specify characters echoed every character break character changing specifi cation program obtain appropriate varying grade service without putting undue load system figure 6 output interrupt routine fig 6 characteroriented interface section 6 processors multiprogramming ability shows components characterbycharacter interface responsibility operation split interrupt called device signals attention routine proc esses users 10 request advantage fullduplex characterbycharacter mode operation considerable characterbycharacter capability means user interact program smallest possible unitthe character furthermore fullduplex capa bility permits among things 1 program substitute characters strings characters echoes received 2 keyboard display used simultaneously example permitting character typed keyboard preempt operation process case typing information output information simple algorithm prevents random admixture characters might otherwise result 3 ready detection transmission errors instructions included enable state input output buffers sensed perhaps cleared discarding un wanted output input course possible program use number authorized physical devices particular includes devices used remote consoles mechanism provided permit output directed given device copied devices output linked similarly input useful communication among users desired numerous situations sequential file structure somewhat similar ordinary magtape file consists sequence logical records arbitrary length number devices card reader teletype file may one logical record full generality available drum files ones commonly used logical record con trasted variable length physical record magtape fixed length record card instructions provided insert delete logical records increase decrease length instructions permit file ﬁpositionedﬂ almost stantaneously specified logical record gives sequen tial file greater flexibility one completely unaddressa ble flexibility possible course file randomaccess device sequential structure main tained pointers implementation discussed follow ing reading sequential file cio wio return certain unusual data configurations encounter end record end file bio terminates transmission either conditions returns address last word transmitted addition certain flag bits set unusual conditions interrupt may caused armed chapter 24 user machine timesharing system 299 implementation sequential file scheme auxiliary storage illustrated fig 7 information written drum 256word physical records locations records kept track 64word index blocks containing pointers data blocks file shown first logical record 256 words long ends second 256word block second logical record fits third 256word block third logical recordin 4th data blockis followed end file file requires 64 index words additional index blocks chained together forward backward thus order access information necessary know location first index block may worthwhile point users share drum since system complete control allocation space drum possibility undesired interaction among users available space new data blocks index blocks kept track bit table illustrated fig 8 figure column represents one 72 physical bands drum allocated storage file information row represents one 64256word sectors around band bit table thus represents one 4608 data blocks available bits set block use cleared block becomes avail able thus new data block required system read physical position drum use position index table search row appearance 0 column 0 found indicates physical track block available way row chosen block immediately accessible scheme two advantages alternative chain unused blocks together easy find block optimum position using algorithm described 1 eor eof fig 7 index blocks pointers data blocks 64 words 72 bits fig 8 bit table allocation space drum 2 drum operations required new block needed old one released may preferable assign new block becomes accessible immediately block last assigned file scheme speed subsequent reading file random la auxiliary storage files also treated extensions core memory rather sequential devices files called random fizes random file differs sequential file logical record structure file information extracted written random file addressing specific word block words may opened like sequen tial file difference need specified output input file four instructions used input output words blocks words random file permit random file look even like core memory instruction enables one currently open random files specified secondury memory file two instructions las load secondary memory sas store secondary memory act like ordinary load store instructions one level indirect addressing see fig 9 ex cept course data random file instead core memory random files implemented like sequential files except end record indicators meaningful although many index blocks used required size random file data blocks actually contain information attached random file new locations accessed new data blocks attached subroutine lea whereas makes little sense associate say card reader random file sequential file associated physi 300 part 3 1 instructionset processor level variations processor main memory secondary memory stax addr addr instruction 16345 16345 1234567 effect 234567a b fig 9 load store form main secondary memory instruc tions b addressing cal device system addition sequential file may associated subroutine file called subroutine le subroutine may thus thought ﬁnonphysicalﬂ device subroutine file defined address subroutine together information indicating whether input output file whether word character oriented input operation subroutine file causes subroutine called returns contents register taken input requested correspondingly output operation causes subroutine called word character output subroutine completely unrestricted kinds processing may input output amount computation may even call preserves old return address recall sequential files system transforms infor mation supplied user format required particu section 6 1 processors multiprogramming ability lar file hence requirement user opening sub routine file must specify whether file character word oriented system thereafter necessary packing unpacking subroutine files logical endproduct desire de couple program environment since arbi trary computations provide buffers desired com plexity assumptions program made environment true state things fact make logically unnecessary provide identical interface inputoutput devices attached system uniformity exist could simulated appropriate subroutine files considerations convenience efficiency course militate arrangement suggests power inherent subroutine file machinery summary user machine described designed flexible founda tion development experimentation manmachine sys tems user given capability establish configura tions multiple processes processes ability communicate conveniently central files peripheral devices given user may course wish use subsystem general system eg compiler debugging routine particular job course using subsystem however may become dissatisfied wish revise even rewrite subsystem features user machine permit activity make easier references brighm comfw65 conwm63 corbf65 daler65 dennj66 forgj65 lampb65 lichw65 mccaj63 mccuj65 saltj66 schwj64 instructionset processor level specialfunction processors part contains descriptions processors interpret general pro gramming languages pcs ps however since interpreter determines operations taken given current instruction next instruction obtained pi0 sec 1 processor controls ms components manages block vector transmission ms mp parray sec 2 processes vectors twodimensional matrices recognizing data fundamental units programs algorithms expressed efficiently terms primitive operators chief advantage ps ability take advantage data structure parallel interpretation thereby increasing processing speed microprogram processor sec 3 designed interpret process data type program effect processor computer within another computer programmed act interpreter language processor sec 4 interprets datatype derived primitives programming language contrast conventional processor interprets language based fundamental hardware implementation primitives difference clearly apparent increased complexity language processors 301 section 1 processors control terminals secondary memories nputoutput processors first three chapters section show evolution ibm data channels io processors 1958 7094 ii present 1800 came 360 processor approach controlling ms components general contrasted specialized one instruction controls b 5000 chap 22 burroughs d825 chap 36 fourth chapter dec 338 shows processor controls cathoderaytube display consoles graphic termi nals first ts sufficient complexity utilize proc essor first crt displays used pc eg whirlwind small pcs adapted task dec 338 one earliest special pdisplays ap pea red example section specialized p message concentration switching computer systems multiple remote inputs still recent enough either main pc handles task via specialized k small pcs committed however telephone industry substantial development bell system electronic switching system ess uses specialized cs control switching routing computer systems expect use specialized processors increase near future ibm 7094 ii ibm 709 member ibm 7017094 ii family one first computers io processor ibm name data channel structure chapter 41 discusses two data channel types early 7607 later 7909 7909 data channel isp k controls given ap pendix 2 3 chap 41 principal difference pc controls pi0 7909 turn controls k turn controls ms pc controls pi0 7607 k k controls ms series discussed part 6 sec 1 page 515 structure system360 part ioutline logical structure io processors selector multiplexor channels system360 evolved ibm 7017094 ii series part 6 sec 3 presents isp pms structures proc essors depending thecomputer model implementations realized microprogrammed processor interpreting shared control program pios pc hardwired pio multiple pios 360 multiplexor channel though logically independent implemented single shared physical processor ibm 1800 pios structure presented chap 33 structure discussed part 5 sec 2 page 396 digital equipment corporation dec 338 display processor dec 338 early pdisplay directly interprets stored program control tdisplay earlier tdisplays con trolled pc whirlwind chap 6 special kdisplay without storedprogram capability generalpurpose pio last method outputs fixed length blocks containing data interpreted tdisplay points vectors characters curved line segments etc control tdisplay first pc k pio finally pdisplay observed evolution myer sutherland 19681 myer sutherland also observe evolution become closed cycle generality pc needed control tdisplay note 338 extensive isp fact pdisplays isp extensive companion pc pdp8 chap 5 display tasks require pc example compiling programs pictures calculating elaborate lightpen tracking figures making coordinate curved lines straightline vector approximation transforma tions communicating system components 303 304 part 4 instructionset processor level specialfunction processors another approach design pdisplay based pmicroprogram shared among many tdisplays rose 19671 yet another alternative yet tried incorporate pi0 pdisplay special mode conventional pc thus p would interpret either conven tional pc instructions pdisplay instructions pdisplay interpreter output pictures graphics 338 utilizes data space efficiently simply data long variablelength strings word vectors instruction requires almost space specify data opera tions addresses data interpreted directly immedi ately instruction rather via instruction addresses another feature allows program efficiently encoded stack mechanism storing subroutine link ages subroutines pdisplays actually programs form part complete picture subroutines actually subpictures although stack mechanism allows recursive picture calls stack used principally save space allow multiple tdisplays use common picture programs problem 338 common multip struc tures intercommunication among ps pc control ling p case pcpi0 structures p338 trap relies interrupt signal pc pc processes tasks pdisplay might process given section 1 processors control terminals secondary memories interrupt system tasks beyond pdisplays capa bility clock built 338 brightness tensity picture determined electronically see mode instructions controlling intensity rate pictures repeated clock would allow time pictures started drawn specified thus intensity would independent picture length 338 requires hardware simpler pc however large amount hardware used control genera tion characters lines lines vectors drawn using dds digital differential analyzer technique perhaps onehalf registers could eliminated 338 p simpler alternative constructed similar computer pdp9 bell telephone laboratories dec using approach making display k elaborate pc interrupt system reduced overhead time would enable pc take specialized program control functions 338 scheme might pass program instruction counter parameter directly pdisplay pc way pc pdisplay would alternatively process part single instruction stream depending task despite problems early pdisplay sophis tication successors appear following chapter 25 dec 338 display computer introduction cdisp1ay dec 338 cdec pdp8 pdisplay connect 18 crt display area 9375 x 9375 in2 pms structure shown fig 1 chap 5 describing pdp8 pc isp given appendix 1 chap 5 c338 although designed stand alone generally used satellite larger c via ldataphone rationale using c based bandwidth storage require ments needed maintain graphical picture displays human manipulating pictures rotation scale change conver sion internal linked data structure picture structure quires short response time requirement places high processing demands larger cs thus cdisp1ay preprocessor larger general cs actual tcrt 16inch crt 93inch square viewing area covered 1024 x 1024 xy points diameter points 0015 inch spot magnetically deflected focused eight tcrts driven together used eaecuted pc start f display executed pc stw display data state statesﬂ 4 control stoteﬂstated stote transitions occur approximately mp cycle control state instructions fig 1 dec 338 instructioninterpretation state diagram independently photomultiplier connected fiberoptic bundle link used light pen photosensitive sensor detect spots light pen allows pdisplay detect whether user ﬁpointed toﬂ displayed spot pc pdisplay access mp total data rate avail able mp one 12bit wordl5 microseconds instruction times pdisplay function point plotting times tcrt03 microsecond next incremental unintensified point approximately 0010 inch away 12 microseconds incremental intensified point 35 microseconds point plotted random position state registers cdisplay given isp description appendix 1 chapter four parts state control registers program flow state picture state position beam console lightpen state mp state instruction interpreter fairly simple best described state diagram fig 1 instructions given tables 1 2 remainder chapter discusses pdisplay instructions pc instructions communicating pdis play principle operation actual picture held stationary repeatedly displaying intensifying particular point line etc number times figure displayed appears stationary flicker depends crt phosphor figure environ mental parameters generally accepted range plotting rate 20 50 plotssecond thus complete picture drawn 50 20 milliseconds assume 30hz plot rate 28000 points plotted vector mode 280 1120 inches depending spacing 1ooo characters dis played 30 milliseconds using character mode light pen used display program required ﬁtrackﬂ pen pens position determined displaying known points pen course detects points present displayed points position therefore program knows location pen parameters interest display vary depending application however general parameters 305 306 part 4 instructionset processor level specialfunction processors skip skip sector count 0 1 scale 14 1 1 group number 0l set unit 0 pen section 1 processors control terminals secondary memories skip pb 0 5 0 count intensity intensity table 1 instruction op code dec 338 controlmode instruction set bits 02 parameters mode conditional skip conditional skip arithmetic compare pb arithmetic compare pb skip flags count set slaves spare 3 4 5 6 7 8 9 10 11 sett scale scale 0l set pen pen set 1 intensity 02 intensity stop clear set scale 1 scale 01 1 set pen 1 pen 1 push clear 1 e 1 enter sector datastate memory field 02 set scale scale 01 set pen pen 1 inhs datamode inh scale pen pushbuttons 05pb 05 test pushbuttons 6 11pb 6 11 test 0 pushbuttons 05 0 lo pushbuttons 6 11 1 0 1 1 set unit 1 1 pen 1 intensity set allow instruction bits specify new value twoword instruction second word contains loworder 12 bits dac jump address 7 skip true false 8 inhibit restoration bits 1 picture 3 display area b c spot size resolution e linearity f shortterm longterm stability phosphor type intensity color function time 4 2 figure plotting generation characteristics data types points lines vectors graphs characters fixed set characters defined set curved line segments etc b plotting time transformation internal representations space encode specify figure b scale change rotation coordinatesystem transformation abilities c ability communicate displayed data structure internal representation picture lightpen graphic input capability chapter 25 1 dec 338 display computer 307 inta inhb escc inh instructions interpretation pdisplay two instructionset types interpreted pdisplay data state instructions specify display information con trol state instructions specify program control informa tion eg jumps modes etc state diagram interpre tation process given fig 1 coordinate x coordinate datastate instructions seven instructions dec calls modes executed pdisplay data state instructions modes really substates data state instructions actually character 1 table 2 dec 338 datamade instruction set character 2 like data interpreted mode data mode instructions interpreted escape instruction returns pdisplay control state control instruction issued select mode simultaneously place display data state blank increment mode mode used draw curves alpha numeric characters small symbols two instructions stored per word instruction cause beam position moved one two three times 0010inch increments one eight directions direction 0 right direction 1 right etc character point increment vector vector continue short vector 6bit character 7bit character graph plot spare esc 6 35 15 2 x 9 36 1 150 1 1200 18 24 375 45 6 35 xvf x coordinate 1 2 2 2 1 1 2 2 2 1 2 2 2 1 1 1 1 intensify turn beam inhibit set value x coordinate e escape enter control state d0 move 1 escape 1 2 3 move 1 2 3 0 set increment x 1 set x increment 8 directions bits 0 5 int 1 cmoov 1 move directione int f delta esc 1 c 1 delta x int esc 1 z int 1 1 delta 2 esc delta x 308 part 4 1 instructionset processor level specialfunction processors vector mode vector mode used draw straightline seg ments twoword instruction causes beam position moved along line represented 11bit delta 11bit delta x vector continue mode mode used draw straight line edge screen similar vector mode causes line extended ﬁedgeﬂ encountered short vector mode short vector mode used draw figures composed short line segments oneword instruction specifies 5bit delta 5bit delta x quantity transformed within display format vector mode operates manner preceding modes move beam counting x position registers counting done 12 microseconds per step intensified move 030 microsecond per step nonintensified move point mode point mode used random point plotting twoword instruction specifies new andor x coordinates placed x position registers graphplot mode used draw curves mathematical functions oneword instruction data x position register time x respectively incremented count one two four eight depending scale factor point graphplot modes operate rate depending upon position new point respect previous point point oneeighth screen away delay beamsettling time 6 microseconds otherwise settling time 35 microseconds character generation option instructions alphanumeric char acters special symbols make character set stored mp increment mode short vector mode characters arbitrarily defined bit 7bit character code instruction used locate word table mp called dispatch table base address table specified starting address registersar05 sar may loaded instructions pc sar represents significant 6 bits 15bit memory address character code represents least significant 6 7 bits seventh sar bit corresponding octal position 100 used bit characters case bit le uppercase lowercase characters may set cleared control character section 1 processors control terminals secondary memories word dispatch table following format bit 0 bit 0 1 bits 11 used perform control function specified particular control instructions bit 0 0 bits 2 11 combined sar specify address character definition program starts address bit 2 common sar bit 2 dispatch word may specified either place places determines mode character displayed bit 1 0 increment mode used plot character used bit 1 1 short vector mode used plot character bit 1 controlstate instructions six controlstate instructions parameter parameter used set values scale lightpen intensity registers mode mode used set datastate mode datamode instruction mode also used stop display conditional skip skip instruction tests state pdisplay pushbuttons miscellaneous instructions include tests additional parameter control display jump push jump subroutine instructions display jump instruction 15 address bits jump may executed location display file within 32kw memory display subroutine instructions pushjump extension jump instruction pop return subroutine pushjump works follows current state display light pen enable data mode scale intensity stored along return address two successive locations first 4096 words memory locations determined pushdown pointer pdp pointer initially set pc instruction normal jump executed return subroutine pop instruction executed address bits function return display previous state sending last words pushdown stack back display stack approach subroutining implemented 338 certain advantages jump subroutine instruction normally used pcs chapter 25 1 dec 338 display computer 309 1 memory space conserved since return address locations required subroutine memory subroutine called number times return main routine since state display saved stack subsequently restored subroutines truly transparent return leave state display program subroutine call subroutines either retain state change state display using one ﬁinhibit restoreﬂ bits available pop instruction program mer elect independently inhibit restoration mode light pen scale intensity information 2 3 4 instructions pc communicating pdisplay instructions pc communicate pdisplay physical con nection sio bus inout transfer instructions pc used initialize read state pdisplay pdisplay state initialization pc instructions set push pointer ac set display address counter ac set push button contents ac set miscellaneous flag status bits ac set character generator sar address pdisplay status pc instructions read push pointer ac read x register ac read register ac read display address counter ac read status words 1 2 3 4 5 ac 60 miscellaneous bits flags modes etc picture debugging modes modes aid programmed pic ture debugging bit set override nonintensify bit datamode instructions bit 1 points vectors plotted whether intensified search enable instruction forces display run particu lar instruction type found instruction type specified search enable instruction 310 part 4 instructionset processor level specialfunction drocessors appendix 1 dec 338 display processor isp description section 1 processors control terminals secondary memories p display state program blow state dacb 14 pdp6li 1 n te rna 1 stop appendix 1 dec 338 display processor isp description partially complete display address counter holds memory address display push pointer stack holding subroutine return addresses c7enotes halt pdisplay instruction instruction external jtop denotes request pc pdisplay halt datastate controljtate two mutually exclusive states lines characters displayed data type interpreted registers switching specific data mode datastate instructions interpreted pdispzay points 7 modes specifuing data types datayfnode register holds controljtate instructions include jwv subroutines using stack controlling pdisplq state datastate control state 7 datastate datajodedm42 sard 5 picture btate x412 y412 verticaldgeflagvef hor izontaledgeil aghef edge terrupte chsz lntensityd2 xdirnens ional 12 ydirnensiondl beam console snd light pen state pushjluttonspbq 11 pushbuttonjii tpbh manual j nterruptm l ightjenfi ndlpf lighlpebenablelpe mp state 0 7 04095 4 1 instruction format instructioniold en teru da taus tate pbdense iqll icd specifies interpretation datajtate instructions starting address register base register dispatch table catting character display subroutines beam position onzy integers range xiy denotes beam within displayable area set beam moues outside display area z plotted character size 0 indicates 6 bit character set 1 indicates 7 bit character set used set increrfent size dataaode instructions incre ments x zsca e brightness displaued points maximum dimension 0f plotting area 9375 2875 375 750 displav point line automatically turned instruction comvletion register tights complemented manually flag set manually striking push button key used interrupt pc becomes one struck stops display interrupts pc whenever light pen seen displayed spot lighlpeenabze one bit enable lightpeqfind flag cause interrupt processor ppimaru memory pdisplay pc individual instructions fields defined instruction type bit field assignments common bits seveml instructions push button control bits chapter 25 dec 338 display computer 311 appendix 1 dec 338 display processor isp description continued pbcleay ib pbdomp 1 ement i6 pbdelectd5 i411 scalehangesc io scale size control bits ca 1 euva 1 ue svo 1 1 ightenhangelpc id light pen test control bits 1 ightypenybitlpb iq i45 instruction interpretation process 7 internaljtop v 7 externa1stop fetch instructionoi c mdacdacl dac c dac 1 next controlstate instructiokdl 2 dac c dac 1 datbstate data mode 0 v oatkmode 2 v 2 w data 2 w instruction data mode 3 oac dac next nstruct ionexecut ion execute instruction set instruction execution process following instruction set definition complete miscellaneous conditional skip instructions include complete character instruction definition instructions microcoded instruct ionexecut ion control instructions parame ter0 1 1 pa rame te ropcode iop 000 parameterintensitychange parameter49 parameter ntens tvd r2 parametek9 1 1 parameteropcode controljtate scalechange scale scalevalue 1 ightpenchange lightpenfind 1 ightpenbi intensitychange intensity parameterintensi ty mode0ll ioil modedpcode io2 001 modes topcode modeb modeslearushuttonflag mode4 modedatapdechange moded modesetdz mode68 modeslearsector mdde model earcoord nate modelo modedpcode controljtate modedtopcode internaljtop c 1 modelearushbuttonflag pushauttonjit c0 modejatamdehange datadode c modedet rnodesleardector xs2 c 0 ys2 0 modelearjoordinate xs12 0 yb12 ebterdatadtate datajtate 1 set parameter instruction fonnat set parameter execution set mode instruction fomt set mode execution 312 part 4 instructionset processor level specialfunction processors section 1 1 processors control terminals secondary memories appendix 1 dec 338 display processor isp description continued pbldli io11 grouv 1 push button test set instruction format grouv 2 defined wsh buttons 6 11 pbj instruction execution push buttons 0 5 prldpcode peld2 100 pblpcode h contro1state pbdense pbselect05 pbo5 pbselect05 skip test dac oac 2 pbclear pbo5 tpb45 pb selectcd5 next pbcomplement pb45 cpb45 pbelect45 jump01011 oicoii j umwp jumbpush old jumpfieldd2 0411 032 010 jumpop controlstate scaledhanqe scale cscalevalue lightenshange lightpelfind iightpenbit dac jumpfieldoil jumppush mpdp l daco2xlpfoscaieodatamodeointensi ty mpdp 23 dac314 pdp pdp 2 popoll i0011 popopcode io2 011 popinhibitmode dopb popinhibitscalepen pop9 popinhibitintensity poplo popopcode h controlstate dac3 l4 mpdp dacod mpdpi popinhibi tintensi ty intensity c mpdp16 1 popi nh b tmode da taj4ode c pdp 1k6 popinhibi tscalechange scale mpdp145 lpf mpdp13 pdp tpdp 2 next scalechange kale c scalevalue liqhtenchanqe lpf lightsenbitl enterdatadnode datadode 1 data instructions point01011 oioii pointintensity point 034 poi nt nh b point 01 poi nt y4 9 point oq 11 point 24 9 pointlqll poi n scape poi ntinh b tx point 13a1 point ii wm stack push subroutine calling instruction format jump push dm erecution stack pop instruction format subroutine return pop execution point data instruction format chapter 25 dec 338 display computer 313 appendix 1 dec 338 display processor isp description continued datkmode 000 datadtate 7 pointinhibitx x e pointx 7 pointinhibity c pointy pointintensify beam c 1 pointescape datastate c 0 vectorintensify vectorc01 vecto rues cape vectorl vectorydyo lo vectoril 1 vectordxold vectorlll 1 vector01 130 1 datamode 010 datadtate c vectordy x c x vectordx vectorintensify beam c 1 vectorescape datastate c 0 vector continuec0 1011 lo ko datamode 011 datastate c si gnaxtend vectordy x x igndxtend vectordx vectorintensify beam e 1 vectorescape datastate c 0 shortvectoro 11 ooll shortvectorintens fy shortvectorcd shortvectorescape shortvectorb shortvectordx shortvectore 11 shortvectordy shortvectorlp datamode 100 datastate x c x signextendshortvectordx signextendshortvectordy shortvectorintensify beam e 1 shortvectorescape datastate e 0 ncremento 9 incrementintensi fy incrementy ncremntdi recti oni ko p ncremntcounti ko icle ic 0 icl ic 1 ic2 ic 2 ic3 ic 3 ncrementc3 5 incremntld datamode 001 datastate increment c iop next plotincrementvector next increment e ibl 1 next plotincremntvector point data execution vector data instruction format vector data execution correct since vector point yx vectordy xt vector plotted vector continue instruction format sme vector vector continue execution correct vector continues plotting ee round short vector instruction format short vector execution increment instruction fonnat 2 incrementinstruction 1 8 directions count 1 escape controlstate count 1 count 2 count 3 increment instruction execution 314 part 4 instructionset processor level specialfunction processors section 1 1 processors control terminals secondary memories appendix 1 dec 338 display processor isp description continued plotincrementvector icle movelgosition contro1state 1 move 1 escape icl movelposition move 1 ic2 movelosition next movelosition move 2 ic3 movelgosition next movelgosition next move 3 movel pos ion movelposition sub process moving beam id 0 x tx scale id x cx scale cy scale id 2 ty scale id 3 ty scale x tx scale id 4 x tx scale id 5 cy scale x cx scale id 6 cy scale id 7 cy scale x x scale increwntdntensify beam 1 8 positions characterdll id 6bit oid5 characterqll 7bi t6 1 character5 1 oatajode 101 datajtate chsz 0 xy tfmswrc60it03m xy tf msarobbi 11 chsz xy tfysarwity character instmction format character instruction execution pzot function see text graph data instruction format graphplotoll ogll grapkp lotescapeo graphpl otxyd graphplotdataosd graphplotzll graphup otq graphup otp datamode 110 datajtate graph data execution graphplotxy x x scale graphplotdata beam 1 graphpioty cy scale x tgraphplotdata beam graphplotescape datastate c 0 end instructionexecution section 2 processors array data two array processors discussed section concep tually outgrowth parallel distributed computer holland 19591 matrixinterpreterbased programs generalpurpose computers nova low cost special processor illiac iv general array proces sor another approach illiac ill mccormick 19631 stores information photographic media optical processing inherently parallel used nova nova proposed nongeneralpurpose machine based belief efficient specialfunction processors built solve particular problems reasonable assume problems nova cyclic memory would perform worse processor randomaccess memory unless opera tions performed arrays extremely simple stricted single system might always work efficiently using variablespeed cyclic memory match operation time form address transformation renaming mechanism access problems might avoided nova represents particularidea effective utilization hardware presented remind us memory considered obsolete may perform nicely restricted appli cation illiac iv computer l slotnick responsible illiac iv computer idea computer number parallel data operators processing elements appeared time ago solo mon computer gregory mcreynolds 19631 tech nology first second generation made solomon impractical build illiac iv designed univer sity illinois contract department defenses advanced research projects agency processing elements constructed thirdgeneration technology although medium largescale integrated circuits used design design ambitious ever undertaken direct indirect effects numerous university illinois monitored contract burroughs corporation paoli pa 315 chapter 26 nova listoriented computer1 joseph e wirsching since advent internallystored program computer us concerned problems involving massive amounts com putation taken oneoperation oneoperand approach large class problems involving massive amounts computation may thought oneoperation many operand nature familiar examples numerical integra tion matrix operations payroll computation article proposes computer called nova designed take advantage oneoperation manyoperand concept nova would use rotating memory instead highcost random access memory reduce number program steps reduce number memory accesses program steps addition shown nova could execute typical problems one operation manyoperand type times comparable modern highspeed random access computers rotating memories used early computers low cost reliability ease fabrication machines replaced machines costly random access memories primarily increase computing speed result decrease access time operands instructions general four instructions must brought memory instruction register pair lists seems great waste one arithmetic operation involved indeed one considers majority computing work consists performance highly repetitive operations merely combinations simple example given attempts made alleviate waste incorporating ﬁinstruction stacksﬂ ﬁrepeatﬂ commands instruction execution units recent computers example 2 consider three lists bs cs wish compute b x c trio two distinct methods accomplished first forming b x c trio numbers list second forming new list consisting b b multiplying c corresponding member new list clearly second method wasteful memory space wasteful programming steps next let us take look memory requirements two examples first instructions kept highspeed random access memory bulk variables need nova approach let us take two simple examples use compare con ventional computing techniques proposed nova kept random access memory must brought one algorithm performed extra transfer may entail instructions perform logistics thus simplicity overall program directly related size example 1 consider two lists bs corre sponding pairs added conventional computer done program adds first first b second second b etc counts operations working part program might consist following instructions fetch add b store h count branch index ldatarnation vol 12 12 pp 4143 december 1966 memory variables bs etc usually stored consecutive memory locations except indexing ordering data exploited nova lists variables kept tracks rotating bulk memory called lists variables streamed arithmetic unit results immediately replaced another track future use process takes maximum ad vantage sequential ordering variables instructions need brought instruction execution unit pair lists rather operand thus instructions need stored random access memory may also stored rotating bulk memory departure requirement random access memory significantly 316 chapter 26 nova listoriented computer 317 reduces cost computer without sacrificing speed problem solution solution network problem going structure nova let us consider significant example shows nova well suited solution differential equations using difference methods rectangular network let fig 1 represent artificial network used model physical process generally speaking method advanc ing variables mesh point k one time step next involves information neighboring mesh points typical hydrodynamics problem require list 10 20 variables physical quantities mesh point traditional computer solution involves listing variables point contiguous fashion regular sequence respect rows columns array total array fit fast memory three adjacent columns rows brought fast memory new column calculated next column sequence brought bulk memory oldest three written bulk memory fashion one proceeds across array process repeated significant physical occurrence happens problem ended nova variables organized separate lists rather mesh point computational standpoint possible since main memory nova may essentially unlimited size least exceeding size largest present network problems one proceeds execute operations 123 1 j fig 1 twodimensional array original lists u0o v0o u0l v0l u02 v0z u1o v10 u1l v1l u1z vk2 ujk ujk vjk v shifted 1 v0o v0l v0z 0k v10 vlj yk vjki vjk v shifted downby2 v0o v0l ﬁ0k1 v0k v1o vja1 vjj2 vjj1 vjk v shifted k ylk vjlk fig 2 lists variables lists variables rather single variables performing single operation mesh points array sequence let us look closely variables possible combinations let uik vjk variables associated array fig 1 variables listed sequentially column fig 2 along lists vcolumn shifted various increments concentration one discovers fig 2 arith metic operation ujk vi simply matter taking two columns exist operating pairs combine ujk nearby neighbor vjkl v column shifted one place time proper neighboring variables found opposite one another entire network certain boundaries array elements proper neighbors nova boundary elements must handled separately way must handled separately conventional machine nova calculations boundaries may temporarily inhibited third input arith metic unit allows calculation result pair operands proceed appropriate third input defined ﬁconditionsﬂ brought bit string arith metic unit concurrently operands bit string may contain number one several bits pair operands 318 pari 4 instructionset processor level specialfunction processors section 2 1 processors array data observation shows possible obtain nearest neighbors easily shifting columns variables respect one another neighbor relationship obtained general operation neighbor kn rows away krn columns away lists offset fn k k k number rows array many problems example payroll inventory records essentially liststructured require offsetting vari ables clearly nova structure well suited solutions problems also structure difficult problem solved proposed computer synchronize movement columns data require offset buffers various types could used solve problem could range way rotating memory devices delay lines core memories former simple direct low cost limited general capabilities hand number small random access buffer memories could used offsetting lists variables facilitating special functions boundary calculations higher equipment cost figure 3 shows block diagram organization nova rotating memory might disc drum would fig 3 block diagram nova computer control results f memory 02 arithmetic circuitry co n dltlons conditions memory fig 4 buffering arithmetic unit composed several hundred tracks storing several thousand words total capacity one two million words track would individual readwrite head heads would organized way attain high wordtransfer rate perhaps high one million words per second mind ideal execution time one addition would time required move two operands disc arith metic unit ie 12 microseconds disc synchronizer would capable simultaneously reading two lists operands writing one list results reading one list writing one list conditional control information addition instructions would read another channel small blocks bit string conditions coming memory used control individual operations pairs operands lists essence bit bits subordinate part indi vidual operations conditions going memory sub sidiary result operation one list upon another bit strings may used later control another list operation want also contain information occurrence overflow underflow presence illegal operand etc figure 4 shows suggested organization arithmetic unit incorporates five sets alternating buffers two sets lists operands coming memory one set lists results going memory two sets ﬁconditionsﬂ condi tional control information coming going memory chapter 26 nova listoriented computer 319 buffer buffers equivalent length number words track rotating memory loading unloading buffers rotat ing memory dependent timing rotating memory whereas loading unloading buffers arithmetic unit guided solely rate arithmetic performed may also possible take advantage streaming nature operands designing ﬁassemblyline arithmetic unit one pair operands could process time kind unit may possible execute additions rate equal wordtransfer rate rotating memory however multiplication division two lists may require several revolu tions memory timing diagram fig 5 shows several typical instructions carried certain amount look ahead required ample time since instruc tions prepared execution average rate less one per revolution rotating memory detailed cost estimate made simple prototype nova quick estimate would 50000 head pertrack disc 50000 arithmetic control section making total 100000 buffering scheme one shown fig 4 cost would considerably higher would offset increased versatility revolutions rotating memory 1121 314 15 16 conclusions previous paragraphs demonstrated nova capable handling network problems significantly lower cost contemporary computers comparable speed availability machine nova would stimulate fig 5 timing diagram buffers rotating memory arithmetic unit dotted line shows movement data device solid line shows movement interest oneoperation manyoperand approach compu tation doubt would uncover many problems could applied nova makes possible easily establish neighbor relationships mesh points away nearest neighbors may possible develop new differencing techniques solution coupled sets differential equations may increase accuracy shorten time required solution memory arithmetic units needed nova commercially available new technology would required fabricate prototype model view potential advantages machine seems clear construction model would justify minimal development costs chapter 27 illiac iv computer1 george h barnes richard brown maso kato david j kuck daniel l slotnick richard stokes summary structure illiac iv parallelarray computer con taining 256 processing elements described special features include multiarray processing multiprecision arithmetic fast datarouting interconnections individual processing elements execute 4 x lo6 instruc tions per second yield effective rate lo9 operations per second array computer structure lookahead machine lam page parallel processing speed thinfilm memory index terms introduction study number wellformulated computationally massive problems limited computing power currently available proposed computers involve manipulations large matrices eg linear programming others solution sets partial differential equations sizable grids eg weather models others require extremely fast data correlation techniques phased array signal processing substantive progress areas requires computing speeds several orders magn tude greater conventional computers time signal propagation speeds represent serious barrier increasing speed strictly sequential computers thus recent years variety techniques introduced overlap functions required sequential processing eg multiphased memories program lookahead pipeline arith metic units incremental speed gains achieved considerable cost hardware complexity accompanying problems machine checkout reliability use explicit parallelism operation rather lapping subfunctions offers possibility speeds crease linearly number gates consequently explored several designs slotnick et al 1962 unger 1958 holland 1959 murtha 19661 solomon computer slotnick et al 19621 introduced large degree overt parallelism structure four principal features 1 large array arithmetic units controlled single ieee trans c17 vol 8 pp 746757 august 1968 control unit single instruction stream sequenced processing many data streams memory addresses data common data processing broadcast central control amount local control individual processing element level obtained permitting element enable disable execution common instructions according local tests processing elements array nearestneighbor con nections provide moderate coupling data exchange studies original solomon computer indicated parallel approach feasible applicable variety important computational areas advent lsi cir cuitry least mediumscale versions gate times order 2 5 ns suggested solomontype array potentially lo9 word operations per second could realized addition memory technology advanced sufficiently indicate lo6 words memory 200 50011s cycle times could produced acceptable cost illiac iv phase design study latter part 1966 resulted design discussed paper machine fabricated defense space special systems division burroughs corporation paoli pa scheduled installation early 1970 summary illiac iv illiac iv main structure consists 256 processing elements arranged four reconfigurable solomontype arrays 64 processors individual processors 240ns add time 40011s multiply time 64bit operands processor requires approximately lo4 ecl gates provided 2048 words 240ns cycle time thinfilm memory instruction addressing control illiac iv array possesses common control unit decodes instructions generates control signals 320 chapter 27 illiac iv computer 321 processing elements array eliminates cost complexity decoding timing circuits element addition index register address adder provided processing element final operand address element determined follows b c base address specified instruction b contents central index register control unit ci contents local index register processing ele ment independence operand addressing effective handling rows columns matrices multidimen sional data structures kuck 19681 mode control data conditional operations although goal illiac iv structure able control processing number data streams single instruction stream sometimes necessary exclude data streams process differently accomplished providing processor enable flipflop whose value controls instruction execution processor level enable bit part test result register processor holds results tests conditional local data thus illiac iv data conditional jumps conventional computers accomplished processor tests enable disable local execution subsequent commands instruction stream routing processing element illiac iv data routing connections 4 neighbors processors 1 1 8 8 end connection end around single array processor 63 connects processors 0 62 7 55 interprocessor data transmissions arbitrary distance ac complished sequence routings within single instruction 64processor array maximum number routing steps required 7 average overall possible distances 4 actual programs routing distance 1 common distances greater 2 rare common operand broadcasting constants operands used common processors fetched stored locally central control broadcast processors conjunction instruction using several advantages 1 reduces memory used storage program constants 2 permits overlap common operand fetches operations processor partitioning many computations require full 64bit precision processors make efficient use hardware speed computations processor may partitioned either two 32bit eight 8bit subprocessors yield 51232bit 2048 bit subprocessors entire illiac iv set subprocessors completely independent share common index register 64bit data routing paths 32bit subprocessors separate enableddisabled modes indexing data routing 8bit subprocessors array partitioning 256 elements illiac iv grouped four separate subarrays 64 processors subarray control unit capable independent processing subarrays may dynamically united form two arrays 128 processors one array 256 processors following advantages obtained 1 programs moderately dimensioned vector matrix variables efficiently matched array size failure subarray preclude continued proc essing others 2 paper summarizes structure entire illiac iv system programming techniques data structures illiac iv covered paper kuck 1968 illiac iv structure organization illiac iv system indicated fig 1 individual processing elements pes grouped four arrays containing 64 elements control unit cu four arrays may connected together program control permit multiprocessing singleprocessing operation system program resides generalpurpose computer burroughs b 6500 supervises program loading array configuration changes 10 operations internal illiac iv system external world provide backup memory illiac iv arrays large parallelaccess disk system 10 bits lo9 bit per second access rate 40ms maximum latency directly coupled arrays also provision realtime data connections directly illiac iv arrays 322 part 4 1 instructionset processor level specialfunction processors parallel disk access section 2 processors array data general purpose computer 06500 real time link 4 peripherals computer net fig 1 illiac iv system organization array organization internal structure array indicated fig 2 64 processing elements array arranged string controlled control unit cu receives instruc tion string generates appropriate control signals address parameters instructions transmits indi vidual processing elements execution addition cu broadcast via common data bus operands common use eg constant full word length 64 bits communication exists processing elements exchange information organized rout ing words along string array direct routing connections exist nearest neighbors also processing elements 8 units away routing intermediate distances generated via se quences routes 1 1 8 8 end connections string circular broken connected ends arrays system organized one multiarray configurations processing elements array execute course instruction unison control cu local control provided mode bit processing element enables disables execution current instruction control unit able sense mode bits processing ele ments control thereby monitor state operation multiarra configurations permit optimal matching array size problem struc ture four arrays may united three different configura tions shown fig 3 enlarge arrays end connections pe strings decoupled attached ends arrays form strings 128 256 processors multiarray configurations cus receive instruction string data centrally accessed control units execute instructions independently however intercu synchronization occurring instructions data control information must cross array boundaries simplifies speeds struction execution multiarray configurations multiplicity array configurations introduces complexities memory ad dressing discussed later section control unit array control unit cu following five functions 1 2 control decode instruction streams generate control pulses transmitted processing elements instruction execution generate broadcast components memory addresses common processors manipulate broadcast data words common calculations processors 3 4 routing network common data bus memory address common operand1 ___ ___ 1l 1 pe61 ___ peo pe 1 r __ __2ijt control unit bus unstruction common operands fig 2 array structure chapter 27 illiac iv computer 323 f pe 0 631 127 9 pe pe 0 63 127 191 255 foui wadrant arrays pe 0 63 127 1 single olmmiant arrays fig 3 multiarray configurations 5 receive process trap signals arising arithmetic faults processors internal 10 operations b 6500 structure control unit shown fig 4 principal components cu two fastaccess buffers 64 words one associatively addressed holds current pending instructions pla local data buffer ldb four 64bit accumulator registers car central communi cation within cu hold address indexing information active data logical manipulation broadcasting cu arithmetic unit culog performs addition subtraction boolean operations complex data manipulations rele gated pes specify control array configurations three 4bit configuration control registers whose use described another section instruction processing instructions 32 bits length belong one two classes cu instructions generate operations local cu eg indexing jumps etc pe instructions decoded cu transmitted via control pulses processing elements instructions flow array memory upon demand blocks 8 words 16 instructions struction buffer control advances individual instructions extracted instruction buffer sent advanced instruction station advast decodes executes instructions local cu case pe instructions advast constructs necessary address data operands stacks result queue finq await transmission pes pe instructions taken bottom stack ha1 instruction station finst controls broadcast address data holds pe instruction execu tion period use pe instruction queue permits overlap cu pe instruction executions amount overlap depends course distribution cu pe instructions overlap strategies careful attention instruction sequence programmer compiler result consider able speedup program execution instruction buffer holds maximum 128 instructions sufficient hold inner loop many programs loops initial loading instructions fetched buffer minimal delay variety strategies instruction buffer loading ex amined following straightforward approach taken instruction counter halfway block 8 instruction associ4tlve buffer local buffer ai gpy seouencer control signals common 0414 bus 110 rewest mow fif pes pes fromim pes fig 4 controlunit block diagram 324 part 4 instructionset processor level specialfunction drocessors section 2 processors array data words 16 instructions fetch next block initiated possibility pending jumps different blocks ignored next block found already resident buffer action taken else fetch next block array memory initiated arrival requested block instruction buffer cyclically filled oldest block assumed least required block buffer overwritten jump instruc tions initiate procedures fetch new instruction block memory requires delay approximately three memory cycles cover signal trans mission times array memory control unit execution straight line program delay overlapped execution 8 instructions remaining current block multiplearray configuration instructions fetched array memory specified program counter broadcast simultaneously participating control units instruction processing thereafter identical singlearray operation except synchronization control units necessary whenever information form either data control signals must cross array boundaries cu synchronization must forced fetches new instruction blocks upon data routing operations conditional program transfers configuration changing instructions exceptions cus several arrays run independently one another simplifies control multiplearray operation furthermore permits 10 transactions separate array memories without steal ing memory cycles nonparticipating memories memory addressing data instructions stored combined memories array however cu access entire memory pe directly reference 2048word pem memory appears twodimensional array cu access sequential along rows pe access column multiarray configurations width rows increased multiples 64 resulting variablestructure addressing problem solved generating fixedform 20bit address cu shown fig 5 lower 6 bits identify pe column within given array next 2 bits indicate array number remain ing higherorder bits give row value row address bits actually transmitted pe memories configuration dependent gated shown addresses used pes local operands contain three components fixed address contained instruction cu row artov column single array address bits 12 pes fig 5 memory address structure index value added one cu accumulators local pe index value added pe prior transmission memory cu data operations control unit fetch either individual words blocks 8 words array memory local data buffer addi tion fetch 1 bit selected 8bit mode register processing element form 64bit word read cu accumulator cu program counter pcr configura tion registers also directly addressable cu data manipulations boolean performed selected car result returned car data broadcast processing elements inserted finq along accompanying instruction transmitted pes appro priate time configuration control variety array configurations illiac iv necessary specify control subarrays conjoined designate instruction data addressing purpose cu three configuration control registers cfc 4bit length bit corresponds one four subarrays cfc registers may set b 6500 cu instruction cfco cu specifies array configuration participating means 1 appropriate bits cfco cfcl specifies instruction addressing used within array united configuration thus possible instruc tion stream derived subset united arrays cfc2 specifies cu data addressing form manner similar cfc 1 control instruction addressing chapter 27 illiac iv computer 325 addressing indicated cfcl cfc2 must consistent actual configuration designated cfco else configuration interrupt triggered trap processing external demands arrays preprocessed b 6500 system computer interrupt system control units relatively straightforward interrupts provided handle b 6500 control signals variety cu array faults undefined instructions instruction parity error improper con figuration control instruction etc arithmetic overflow flow processing elements detected produces trap strategy response interrupt effective fork singlearray configuration cu saves status word automatically independently cus may previously configured hardware implementation consists base interrupt address register biar dedicated pointer array storage status information transferred upon receipt interrupt contents program counter status information contents car0 stored block pointed biar addifion car 0 set contain block address used biar subsequent register saving may programmed interrupt returns accomplished special instruction reloads previous status word car 0 clears interrupt interrupts enabled mask word special regis ter interrupt state general unique specific trigger trap interrupt processing subsequent interrupts responded although presence flagged interrupt state word high degree overlap control unit precludes immediate response interrupt instruction generates arithmetic fault processing element alleviate possible program control force non overlapped instruction execution permitting access definite fault information processing element pe processing element shown fig 6 executes data com putations local indexing operand fetches contains following elements 1 four 64bit registers b r hold operands results serves accumulator b operand register r multiplicand data routing register general storage register addermultiplier msg pat cpa logic unit log barrel switch bsw arithmetic boolean shifting functions respectively 16bit index register rgx adder ada memory address modification control 8bit mode register rgm hold results tests pe enabledisable state information described earlier pes may partitioned subproc essors word lengths 64 2 x 32 8 x 8 bits figure 7 shows data representations available exponents biased rela tive base 2 table 1 indicates arithmetic logical opera tions available three operand precisions pe mode control two bits mode register rgm control enabling disabling instructions one active 32bit precision mode controls instruction execution second operand two bits rgm set whenever arithmetic fault overflow underflow occurs pe fault bits pes continuously monitored cu detect fault condi tion initiate cu trap data paths pe 64bit wide routing path 4 neighbors kl 8 minimize physical distances involved routing pes grouped 8 cabinet puc pattern shown fig 8 routing distance 58 occurs interior puc routing distance 1 requires 2 intercabinet distances cu data instruction fetches require blocks 8 words accessed parallel 1 word per puc cu buffer cub 512bit wide distributed among pucs 1 word per table 1 pe data operations operation time per element operation 64 bit 2 x 32 bit 8 x 8 bit 200 ns 240 ns 80 ns x 400 ns 400 ns 2200 ns 3040 ns boolean 80 ns shift 80240 nst 160 ns single lengthdouble length 326 part 4 instructionset processor level specialfunction processors section 2 processors array data news drivers receivers r register rgr 1 control unit mir cdb 1 1 drivers mode receivers rgm register jl register rga leading detector 1 address mar registers kmemory 1 fig 6 processingelement block diagram chapter 27 illiac iv computer 327 e 15 f481 64 bit 81 32 bit 82 b3 b4 b5 b6 b7 cui cuz cu3 16 48 0 bit cu4 sign exponent f mantissa memory rewest peml pemz pem fig 7 illiac iv data representation pem4 fig 8 electrical connectivity routing b physical layout fig 9 10 data path 328 part 4 1 instructionset processor level specialfunction processors section 2 1 processors array data cabinet data transmitted cu cub 512line bus disk online 10 data transmitted 1024line bus switched among arrays within array parallel connection made selected 16 64 pes 2 per puc maximum data rate one 10 transaction per microsecond lo9 bits per second 10 path 1024 lines expandable 4096 lines required processing element memo pem individual memory attached processing element thinfilm dro linear select memory cycle time 240 ns access time 120 ns capacity 2048 64bit words memory independently accessible attached pe cu 10 connections diskifile subsystem computing speed memory illiac iv arrays quire substantial secondary storage program data files well backup memory programs whose data sets exceed fast memory capacity diskfile subsystem consists six bur roughs model iia storage units capacity 161 x los bits maximum latency 40 ms system dual half capacity 5 x 1ox bits independent electronics capable supporting transfer rate 500 megabits per second data path disk subsystems becomes 1024 bits wide interface array figure 9 shows organization diskfile system b 6500 control computer b 6500 computer assigned following functions 1 2 3 executive control execution array programs control multiplearray configuration operations supervision internal 10 processes disk arrays etc external 10 processing supervision processing supervision files disk file sub system independent data processing including compilation illiac iv programs 4 5 6 control array operations single interrupt line 16bit data path ways b 6500 control units addition b 6500 control data gpcioc disk test pemdisk test pem test cu test pe test 0 tested partially tested zzl tested fig 10 system diagnostic sequence path 10 controller ioc supervises disk also direct connections array memories reliability maintenance illiac iv progress computer components vacuum tubes semi conductors several generations improved meantime betweenfailures computers tens hours several thou sand hours using larger scale integration tedfold increase chapter 27 1 illiac iv computer 329 number gates per system possible comparable reliability virtue highdensity integration 50 100gate package design threemilliongate system contemplated reliability major part system 256 processing elements 256 memory units expected range lo5 hours per element 2 x lo3 hours per memory unit organization illiac iv collection identical units simplifies maintenance problems processing ele ments memories part power supplies designed pluggable replaceable reduce system time improve system availability remaining problems 1 location faulty subsys tem 2 location faulty package subsystem location faulty subsystem assumes b 6500 faultfree since determined using standard b 6500 maintenance routines steps follow shown fig 10 b 6500 tests control units cu turn test pes pems tested disk channel capability functional partitioning subsystems simplifies diag nostic procedure considerably references hollj59 kuckd68 murtj66 slotd62 unges58 330 part 4 instructionset processor level specialfunction processors section 2 1 processors array data appendix 1 al classified list cu instructions ai 1 data transmission alit bin binx bout boutx indexed block store clc clear car copy dupi dupo exchl add literal 24 bit car block fetch cu memory indexed pe index block fetch block store cu memory copy car car quadrant duplicate inner half cu memory ad dress contents halves car duplicate outer half cu memory ad dress contents halves car exchange contents car cu mem ow address contents ldl lit load loadx orac slit stl store storex tcc w tcw a12 skip test ctsb 4 instructions 4 instructions load car cu memory address con tents load car 64bit literal following instruction load cu memory contents pe memory address found car load cu memory contents pe memory address found car indexed pe index cars array place car load car 24bit literal store car cu memory store car pe memory store car pe memory indexed pe index transmit car counterclockwise cus array transmit car clockwise cus array skip nth bit car tis present skip 1 f present skip 0 pres ent together bits cus array testing absent together bits gus array testing ctsbt ctsbta ctsbf ctsbfa skip car equal cu memory ad dress contents letters f meaning ctsb eqlt eqlta eqlf eqlfa 4 instructions 4 instructions less j 4 instructions ones 4 instructions onex 4 instructions skip 4 instructions skip 8 instructions skip index portion car bits 40 63 equal bits 40 63 cu memory address contents letters f meaning ctsb eqlxt eqlxta eqlxf eqlxfa skip index part car bits 40 63 greater bits 40 63 cu memory address contents letters f meaning ctsb grtrt grtrta grtrf grtrfa skip index part car bits 40 63 less bits 40 63 cu memory address contents letters f meaning ctsb lesst lessta lessf lessfa skip car equal 1s letters f meaning ctsb onest onesta onesf onesfa skip bits 40 63 car equal 1s letters f meaning ctsb onext onexta onexf onexfa skip tf flipflop previously set letters f meaning ctsb skipt skipta skipf skipfa skip unconditionally skip index portion car bits 40 63 less limit portion bits 1 15 letters f meaning ctsb present index portion car cremented increment portion car bits 16 39 test progress present incre menting takes place txlt txlti txlta txltai txlf txlfi tklfa txlfai skip index portion car bits 40 63 equal limit portion car bits 1 15 see ctsb meaning f see txl meaning chapter 27 1 illiac iv computer 331 8 instructions 8 instructions zer 1 4 instructions 4 a13 al4 zerx 1 instructions transfer control txet txeti txeta txetia txef txefi txefa txefia skip index portion car bits 40 63 greater limit portion car bits 1 15 see ctsb meaning f see txl meaning 1 txgt txgti txgta txgtai txgf txgfi txgfa txgfai skip car 0s see ctsb meaning f zert zerta zerf zerfa skip index portion car bits 40 63 0s see ctsb meaning f zerxt zerxta zerxf zerxfa exec exchl halt jump load loadx stl route rte a15 arithmetic alit cadd csub incrxc a16 logical cand ccb cexor execute instruction found bits 32 63 car exchange contents car contents cu memory address halt illiac iv jump address found instruction load cu memory address contents contents pe memory address found car load cu memory address contents contents pe memory address found car indexed pe index store car cu memory route routing distance found address field car indexable register con nectivity found skip field add bit literal car add contents cu memory address car subtract contents cu memory address car increment index word car cu memory car complement bit car exclusive cu memory car clc cor crb crotl crotr csb cshl cshr lead0 clear car cu memory car reset bit car rotate car left rotate car right set bit car shift car left shift car right detect leading one car quad rants array detect leading zero car quad rants array cars array place car leadz orac a2 classified list pe instructions a21 data tramisdon lda ldb ldr lds ldx ldco ldcl ldc2 ldc3 lex ones sta stb stc str sts stx swapa swap swapx load register load b register load r register load register load x register load car 0 pe register load car 1 pe register load car 2 pe register load car 3 pe register load exponent register load ones register store register store b register store c register store r register store register store x register interchange inner outer contents register interchange contents register b register interchange outer operand register inner operand b a22 index operations set comparison x register op erand presence l means set x less operand presence e means set x equal operand presence g means set x greater operand z present increment x performing test absent increment x 332 part 4 instructionset processor level specialfunction processors section 2 1 processors array data 6 instructions jx i7 11 6 instructions xi xi0 a23 mode setting eqb grb lsb chws 3 instructions 3 instructions 3 instructions liz 3 instructions 3 instructions j z 0 15 instructions l ix2 ixl ixli ixe ixei ixg ixgi set j comparison x register op erand see meaning l e g jxl jxli jxe jxei jxg jxgi increment pe index x register bits 48 63 operand increment pe index bits 48 63 operand plus one comparisons test b equality bytewise test b register greater register bytewise test b register less register bytewise change word size set 1 register less operand l means test logical means test arithmetic means test mantissa ill ial iml set 1 register equal operand see meaning l ile iae ime set 1 register greater operand see meaning l ilg iag img set 1 register equal zeros ilz iaz imz set 1 register equal ones ilo iao imo set j conditions specified set instructions immediately 6 instructions 6 instructions 3 instructions 3 instructions sete seteo setf setfo setg seth set1 setj setco setc 1 setc2 setc3 iba jsn a24 arithmetic adb sbb add sub jll jal jml jle jae jme jlg jag jmg jlz jaz jmz jlo jao jmo set 1 comparison x register op erand see section a22 meaning l e g ixl ixli ixe ixei ixg ixgi set j comparison x register op erand see section a22 meaning l e g 1 jxl jxli jxe jxei jxg jxgi set 1 comparison register op erand see section a22 meaning l e g isl ise isg set j comparison register op erand see section a22 meaning l e g jsl jse jsg set sign bit register set j sign bit register set e bit logical function bits set el bit similarly set f bit similarly set f1 bit similarly set g bit similarly set h bit similarly set 1 bit similarly set j bit similarly set pth bit car 0 similarly set pth bit car 1 similarly set pth bit car 2 similarly set pth bit car 3 similarly set 1 nth bit register bit num ber found address field set j nth bit register bit num ber found address field add bytewise subtract operand register bytewise add register operand 64bit operands subtract operand register 64 bit quantities add operand register r n specify possible variants arith metic instruction meaning letter present mnemonic r round result n normalize result mantissa special treatment signs chapter 27 illiac iv computer 333 16 instructions adm adms adnm adnms adn adns adrm adrms adrm adrnms adrn adrns adr adrs ad ads adex add exponent dvr n divide operand see ad instruction meaning r n 16 instructions dvm dvms dvnm dvnms dvn dvns dvrm dvrms dvrnm dvrns dvrn dvrns dvr dvrs dv dvs extend precision floating point add extend precision floating point sub tract lex load exponent register mlr n multiply operand see ad instruction meaning r n mlm mlms mlnm mlnms mln mlns mlrm mlrms mlrnm mlrnms mlrn mlrns mlr mlrs ml mls ead esb 16 instructions san set register negative sap set register positive sbex subtract exponent operand expo nent register sbr n subtract operand register see ad instruction meaning r n sbm sbms sbnm sbnms sbn sbns sbrm sbrms sbrnm sbrnms sbrn sbrns sbr sb sbs 32bit mode perform multiply leave outer result register inner result b register results ex tended 64bit format 16 instructions norm normalize register mult a25 logical register operand left register righthand set operand meaning variants present use true n use complement z use zeros 0 use ones hand set letters specifies variant 16 instructions cba chsa eor 16 instructions lex 16 instructions rba rtal rtaml rtamr rtar san sap sba shabl shabr shal shaml shar shamr andn andz ando nand nandn nandz nando zand zandn zandz zando oand oandn oandz oando complement bit register change sign register exclusive register operand eor eorn eorz eoro neor neorn neorz neoro zeor zeorn zeorz zeoro oeor oeorn oeorz oeoro load exponent register register operand orn orz oro norn norz noro zor zorn zorz zoro oor oorn oorz ooro reset bit register zero rotate register left rotate mantissa register left rotate mantissa register right rotate register right set register negative set register positive set bit register one shift b registers doublelength left shift b registers doublelength right shift register left shift register mantissa left shift register right shift register mantissa right section 3 processors defined microprogram processors defined microprogram recently come existence although wilkes suggested idea 1951 discussion chap 3 page 71 suggests reasons controversial idea taken long adopted microprogramming design control circuits electronic computer chapter 28 extension earlier paper wilkes includes example microprogrammed processor page 337 earlier paper best way design automatic computing machine wilkes 1951a1 essential ideas microprogramming first outlined observation instruction set isp looked program interpreted basis micro programming idea isp acknowledgment view processor program little say chapter historical yet timely well written microprogramming like wilkes ideas present many computers chines designed formal ruse used make design seem difficult well foundedcertainly arbitrary kampe truthfully admits making decisions somewhat arbitrary fashion sd2 microprogram structure unlike ibm sys tem 360 models pmicroprogram similar external pc defines main question design whether cheaper single hard wired pc rather computer within computer packard bell 440 boutwell hoskinson 19631 example betterknown pc whose internal p resembles sd2 authors book feel internal external ps similar may better single pwhich suits needs gain speed still define powerful functions mp could made conventional mp small fast mp hewlettpackard hp 9100a computing calculator hp 9100a chap 20 discussed part 3 sec 4 page 235 design generalpurpose microprogram controlled computer elementary structure sd2 computer chap 29 described kampe casual highly communicative fashion engineers tend somewhat formal stuffy describing microprogrammed implementation euler ibm system 360mode1 30 microprogrammed processor chap 32 also discussed language processor part 4 sec 4 page 348 334 chapter 28 microprogramming design control circuits electronic digital computer1 v wilkes j b stringer 1 introduction experience shown sections electronic digital computer easiest maintain simple logical structure structure readily borne mind maintenance engineer looking fault makes possible use faultlocating programmes test equipment without use elaborate test gear control section electronic computers greatest degree complexity generally arises particularly machine comprehensive order code designed make simple fast operation general different order code special equipment must provided complicated function order complex equipment past fear complicating unduly control circuits machines prevented designers electronic machines providing facilities orders floatingpoint operations although experience relay machines interpretive subroutines shown valuable orders paper describes method designing control circuits machine wholly logical enables alterations additions order code made without ad hoc altera tions circuits outline method given one us wilkes 19511 conference automatic calculat ing machines university manchester july 1951 operation called single machine order broken sequence elementary operations example shifting number accumulator one place right may involve first transfer number auxiliary shifting register secondly transfer number back accumulator along oblique path elementary operations referred microoperations basic machine operations addition subtraction multiplicatiotc thought made microprogramme micro proc cambridge phil soc pt 2 vol 49 pp 230238 april 1953 operations microoperation called microorder process writing microprogramme machine order similar writing programme whole calculation terms machine orders method applicable necessary machine contain suitable permanent rapidaccess storage device microprogramme helda diode matrix proposed case machine discussed example belowand means provided executing microorders one also necessary provision made conditional microorders play role microprogramming similar played conditional orders ordinary programming since feature machine designed specially particular set machine orders configura tion diodes matrix corresponding configuration whatever equivalent device used difficulty making changes order code machine experience shows desirable fact design machine first place carried completely without firm decision details order codebeing taken long care taken provide accommodation greatest number microorders likely required would even possible number interchangeable matrices providing different order codes user could choose one suited particular requirements 2 system described relation parallel machine arithmetical unit designed along conventional lines contain set registers adder together switch ing system enables microoperations various machine orders performed microoperations simple transfers number one register another without shifting number one place left description proposed system 335 336 part 4 instructionset processor level specialfunction processors right others also involve use adder particular microoperation performed applying pulses simultaneously appropriate gates switching system certain cases may possible two microopera tions take place time convenient regard control system consisting two parts register needed hold address next order due executed another hold current order executed rate part time means counting number steps shifting operation multiplication must also provided one method meeting requirements provide group registers adder together switching system enables transfers num bers without addition made part control system called control register unit case operations need performed numbers standing control register unit execution order like operations performed arithmetical unit regarded made sequence microoperations performed application pulses appropriate gates part control system concerned control sequence microorders required carry machine order operation gates required execu tion microorder called microcontrol unit consists decoding tree two rectifier matrices two regis ters additional control register unit connected indicated fig 1 shows pulses used operate gates arithmetical unit control register unit generated series control pulses pulse generator applied input decoding tree pulse routed one output lines tree according number standing register output lines pass rectifier matrix outputs matrix pulses operate various gates associated microoperations thus one input line matrix corresponds one microorder address microorder number must placed register cause control pulse routed corre sponding line output lines tree also pass second matrix b outputs connected register 11 matrix wired address microorder performed next time address microorder placed register 11 next control pulse applied input tree connexion established register i1 register address microorder due executed next transferred register way de coding tree prepared route next incoming control pulse section 3 processors defined microprogram matrix b c_____ 7 r1 contro pulses arithmetical unit control condltiona registers etc flipflop fig 1 microcontrol unit correct output line thus application pulses alternately input tree gate connecting registers i1 causes predetermined sequence microorders executed necessary means whereby course micro programme made conditional whether given digit one registers arithmetical unit control register unit 1 0 means shown x fig 1 twoway switch controlled special flipflop called condi tional flipflop inserted matrix matrix b conditional flipflop set earlier microorder digit one registers two separate addresses wired matrix b one passes register thus becomes address next microorder determined setting conditional flipflop conditional microorders play part construction microprogrammes conditional orders play construction ordinary programmes apart obvious uses micro programmes operations multiplication division enable repetitive loops microorders used desired two branchings may inserted connexions matrix matrix b one four alternative addresses next microorder may selected according settings two conditional flipflops another possibility chapter 28 1 microprogramming design control circuits electronic digital computer 337 make output decoding tree branch enters matrix nature microoperation per formed depends setting conditional flipflop microprogramme wired matrices contains sec tions performing operations required order basic order code machine initiate operation necessary control microprogramme sent correct entry point done placing function digits order least significant part register 11 digits register made zero microprogramme constructed number passes register control microprogramme sent correct entry point switching system arithmetical unit may either designed permit large variety microoperations per formed may restricted allow small number operations machine comprehensive order code much said flexible switching system since enable economy made number microorders needed microprogramme similar remark applies connexion degree flexi bility provided designing switching system control register unit specification machine allows number registers used arithmetical control sections construction two sections may identical except far number digits concerned new machine construction mathematical labora tory cambridge registers constructed basic units containing five registers addersubtractor together associated switching system hoped possible use identical units arithmetical unit control register unit 3 etample example given show way micro programme drawn machine singleaddress order code covering usual operations supposed arithmetical unit contains following registers multiplicand register b accumulator least significant half c accumulator significant half shift register registers control register unit follows e register connected access circuits store address storage location access required placed sequence control register contains address next order due f executed g register used counting assumed drawing microprogramme addersubtractor arithmetical unit one input permanently connected register similar addersub tractor control register unit one input permanently connected register g convenience assumed switching systems case comprehensive enough provide microoperation required supposed arithmetical unit provided 20 digits numbers 0 1 18 could introduced one registers adder control register unit two conditional flipflops used microoperations including involving access store supposed take amount time reference made point r54 table 1 gives order code machine table 2 microprogramme line table 2 refers one microorder first column gives address microorder second column specifies microoperations called arithmetical unit machine third column specifies micro table 1 notation acc accumulator accl significant half accumulator accz least significant half accumulator cx contents x x register storage location n storage location n order effect order n n v n n cacc cn acc cacc cn acc cacczcn acc cn 2 0 cacc1 n 0 acc w ti cn acc u n cacc n r n l n cacc acc cacc znl acc g n n 0 n cacc 0 transfer control n cacc 2 0 ignore ie proceed serially read next character input mechanism send cn output mechanism 338 part 4 1 instructionset processor level specialfunction processors section 3 1 processors defined microprogram table 2 notation b c stand various registers arithmetical control register units see 03 text c indicates switching circuits connect output register c input register da c indicates output register con nected one input adding unit output permanently connected input output adder register c numerical symbol n quotes eg stands source whose output number n units least significant digit ari thmeticul unit control register unit conditional flipfeop next microorder set use 0 1 0 1 2 3 4 a5 s6 h7 v8 t9 u 10 r 11 l 12 g 13 14 0 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 c c store b store c store c store b c input store store output dstore c store c b rt c c r c l b b l 0 b b c 0 c b b r c r c da c btod b r c r c da c f g e gl f store g g e e decoder etog e g e g gl e gl e 18 e e g gl e 1 2 3 4 16 17 0 27 25 0 19 22 18 0 0 0 0 0 20 21 11 23 24 12 26 0 28 29 30 31 28 28 34 35 36 0 0 1 0 0 32 33 33 37 right shift switching circuits arithmetic unit arranged least significant digit register c placed significant place register b right shift microoperations significant digit register c sign digit repeated thus making correction negative numbers left shift switching circuits similarly arranged pass significant digit register b least significant place register cduring left shift micro operations chapter 28 microprogramming design control circuits electronic digital computer 339 operations called control register unit fourth col umn shows conditional flipflop set digit used set example 1c means flipflop number 1 set sign digit number register c 2g means flipflop number 2 set least significant digit number register g case uncon ditional microorders columns 5 7 blank column 6 contains address next microorder executed case conditional microorders column 5 shows flipflop used operate conditional switch columns 6 7 give alternative addresses control sent conditional flipflop contains 0 1 respectively microorders 0 4 concerned extraction orders store serve bring transfer order store register e cause five significant digits order placed register i1 result control transferred one microorders 5 15 corresponds distinct order machine order code way sequence microorders needed perform particular operation called begun way various operations performed followed table 2 section dealing multipli cation assumed numbers lie range 1 x 1 negative numbers represented machine complements respect 2 noted process drawing microprogramme similar draw ing ordinary programme automatic computing chine problems involved much alike 4 timing microoperations assumption microoperations take length time perform likely borne practice particular parallel machine may possible design adder carry propagation time sufficiently short enable addition performed substantially length time taken simple transfer neces sary therefore arrange waveform generator feeding decoding tree suitably stimulated pulse one outputs matrix supply somewhat longer pulse normally required operations may take many times long perform ordinary microorder example access store particularly delay store used operation input output devices machine sequence operations microprogramme must therefore interrupted one way prevent pulses waveform generator reaching decoding tree waiting period method although quite feasible appears involve kind complication present system designed avoid attractive system make machine wait conditional microorder transfers control back unless associated conditional flipflop set setting flipflop takes place operation com pleted control goes next microorder se quence machine thus condition dynamic stop waiting operation completed system advantage complication introduced units sup plying waveforms decoding tree control equipment required similar already provided purposes 5 discussion seen equipment needed execute compli cated order machine order code form required simple one namely outlets decoding tree diodes matrices quite complicated orders fore built machine without difficulty particular arithmetical operations numbers expressed floating binary form similar operations microprogrammed found involve large numbers micro orders example microprogramme providing float ingpoint operations addition subtraction multiplication needs 70 microorders switching system arith metical unit must course designed operations view decoding tree matrices parallel machine 40 digits arithmetical unit provision 256 microorders would amount 15 total equip ment machine appears machine well provided builtin facilities considerable complexity number microorders needed complicated micro programme sometimes reduced making use might called microsubroutines example two num bers added together floating binary machine shifting one usually necessary addition take place making microorders shifting opera tion serve also multiplication called considerable saving effected four registers bare minimum needed arithmetical unit order enable basic arithmetical operations performed extension refinement facilities provided required may necessary increase number registers 340 part 4 1 instructionset processor level specialfunction processors example four registers sufficient enable succession products accumulated without transfer intermediate results store since accumulator must clear beginning multiplication addition one register enables accumulation products provided micro programme register associated outlet store also enables waiting time storage access eliminated microprogramme arranged call number store soon known number required continue necessary microoperations finally proceeding use number dynamic stop would occur number required use another way saving time arrange case orders permit next order extracted store operation currently performed completed minimum number registers required control register unit machine simplest mode operation three extra registers provided facilities similar provided blines machine manchester university could included microprogramme section 3 1 processors defined microprogram 6 discussion far reference parallel chines technique described paper adapted type machine however possible design serial machine along lines parallel computer asynchronous arithmetical unit every gate requires one kind waveform operate timing waveform critical serial machine hand different gates require different waveforms gate may require different waveforms different times wave forms must critically timed complications may handled including microcontrol unit third matrix c selecting appropriate waveform microorder main waveform routed decoding tree matrix opens gate fed waveform selected matrix c enables waveform correct duration applied selected gate arithmetical control sections chine microprogramming applied serial machines references wilkm5la boute63 flynm67 greej64 66 mercr57 patz67 rosir69 tucks67 wilkm58b 69 webeh67 chapter 29 design generalpurpose microprogramcontrolled computer elementary structure1 thomas w kampe summary paper presents design parallel digital computer utilizing 20psec core memory diode storage microprogram unit machine intended online controller organized ease maintenance word length 19 bits provides 31 orders referring memory loca tions fourteen bits used addressing 12 base address one index control one indirect addressing 32nd order permits address bits decoded generate special functions require address logic machine resistortransistor arithmetic unit bus structure permits many variants order structure order make logical decisions ﬁgeneralpurposeﬂ logic unit incorporated microcoder much freedom area arithmetic unit introduction paper discusses logical design binary parallel real time computer aspects packaging circuitry bear directly topic considered since specifications job computer perform enough fix design logical designer faced undetermined system one main functions analyze system natural environment ie malfunctions operator errors etc supply remainder side conditions fix design discussion exposition directed toward design philosophy led machine built order accomplish shall consider functional require ments analysis terms state art basic design decisions finally description computer stands ire trans ec9 vol 2 pp 208213 june 1960 functional requirements design computer known variety reasons sd2 undertaken supply computer capable mod erately fast arithmetic perhaps five decimal places accu racy 3000 words storage furthermore com puter must reside hostile environment small house 0ﬂ 85c temperature withstand severe shocks maintained men two weeks training system volume limitation 40 cubic feet within space must reside control computer memory power supplies complete maintenance facilities sufficient inputoutput equipment handle 20 shaft position outputs 30 inputs numerous switch settings 20 display relay signals final specification blow 15 months available start preliminary design delivery operating instrument debugged program design analysis maintenance requirement evidently major problem order achieve simplicity required two design criteria necessary first computer readily understood implied usual clever logical tricks intensive time sharing control arithmetic undesirable second builtin maintenance facilities kept sim ple machine must designed mind since temperature reliability important extremely conservative approach taken respect component performance schedule requirements machine could designed released pieces needed since control system usually troublesome part computer design simple control needed 341 342 part 4 instructionset processor level specialfunction processors volume available together schedule required logical design natural packaging properties sense break natural way logical packages reason able size minimum interpackage communication design decisions need 2000 operations per second poses serious access problem serial memory unless one resorts several simul taneously operating control units neither small simple hence random access memory seemed advisable mag netic core memories 85c problem built provided memory cycle time short memory chosen 4096 words core storage 20psec cycle time requirement training man two weeks maintain machine argues simplestructured parallel machine providing much use made asynchronous transfer variety simple maintenance methods particularly bus structure adopted also asynchronous semiasynchronous parallel machines require average performance set components particular component central limit theorem statistics come aid reliability ap proach finally adopted simplicity design understanding aided use microprogram control system maintenance made rather simple two provisions maintenance con sole first manner going micro program stepbystep basis tests little dynamics often locate totally defective parts helps factory checkout immeasurably second means taking microprogram unit substituting set switches permits maintenance man exercise specific registers memory powerful tool almost free microprogram control finally rather pragmatically microprogramming permits ﬁlast minuteﬂ changes machine operation without seri ous hardware modifications approach chosen regardless control used various times process executing orders decisions must made occasionally single bit often two occasionally two one excludes order decoding functions zero detection require use two bits point logical designer faced rather sticky decision whether design specific set decision logic cheap build section 3 1 processors defined microprogram sometimes messy use microcontrolled logic generating scheme case latter alternative taken unit called several obscure reasons alteration unit designed amounted threeaddress onebit unit generate boolean function two binary variables transmit value another variable special set logic needed detecting zeros rather wild nature inputs seemed desirable include trapping mode logic made adjunct alteration unit circuitry chosen resistortransistor logic yields either sheffer stroke logic one prefers high low true logic pnp npn transistors case com bination high true logic pnp transistors logical operation sheffer stroke temperature reliability requirements maximum frequency available 250kc square wave gave cycle time 4 pec available asynchronous transfer sequence logic index register seemed advisable amount data processing thus additions needed indexing arith metic counter advance seemed undesirable one parallel adder adder accessible registers chosen another argument bus structure multiplicity problems handled simul taneously one index register really enough rather add another register indirect addressing chosen point one needs 12 bits address one index tagging one specify whether address direct direct 14 bits operand selection thirtytwo orders tight minimum minimum word length 19 bits since consistent five decimal place accuracy tenta tively chosen decided however design structure basically suited length word shifting necessary multiply divide required two registers yet shift registers asynchronous operation complex hence decided put shift facility data transfer bus providing complementing subtraction could generated decided use twocomplement arithmetic first simplicity multiplydivide logic second avoids whole negative zero question precise number microsteps needed determined trial microprogram machine designed 512 microsteps although 384 used eight bits chapter 29 1 design generalpurpose microprogramcontrolled computer elementary structure 343 output distributor register called j one flipflop alteration unit thus allowing fixed sequence onebit micropro grammed choice incidentally genesis name ﬁalteration unitﬂ j arithmetic unit c sd2 computer figure 1 block diagram computer pres ently blockbyblock description computer two boxes left added facilitate input output output buffer holds 20 words outputs values 48msec cycle thus providing nearly continuous outputs output distributor selection system allows programmer transmit contents accumulator onto one eight channels control external devices ﬁinputsﬂ line represents 32 channels read accumu lator numbers 8 32 purely arbitrary upper limit 32 microcode convenience alteration unit addition decision making duties several functions five bit counter used microsubroutines set value chosen number arithmetic unit alteration unit sense goes zeros ones addition flipflops con buffer order 1 trap signal fig 1 computer block diagram memory elsetere p bus fig 2 arithmetic flow trolling initial carry adder end carry shifting mem ory read write control unit figure 2 block diagram arithmetic unit information may put onto b bus register outside sources inputs constants microprogram unit thence shift unit finally bus bus may sent places output distributor microprogram register etc arithmetic register data addressing memory arithmetic unit private channels leaving bus free memory operation memory buffer address register part arithmetic unit figure 3 expanded view unit capital letters stand registers small letters logical entities registers b c e simply storage registers used accumu lator bline counter extension least significant arithmetic register distributor memory buffer often used working storage registers f g inputs adder logic logic algebraic sum f g e rather weird logic e f g used generating extract order f yields fg fg used ﬁexclusiveﬂ generation c carry logic g constant emitter microprogram control h set gates used input number moves b one five operations may performed uiz normal shift left one bit shift right one bit complement shift left 5 bits last used automatic fill connection microprogram unit control example add number registers three microprogram steps would needed first transfer g f finally 12 psec would required 344 part 4 instructionset processor level specialfunction processors n al memory 0 memory fig 3 arithmetic unit detail figure 4 diagram microprogram unit eightbit j register augmented flipflop alteration unit decoded 512 steps students microprogramming recognize wilkes model pure form wilkes stringer 19531 ﬁnextﬂ value microprogram register may chosen one three ways first value may controlled microprogram second five bits bus corresponding order portion word may entered three bits set zero manner order decoding accomplished third eight bits j register may filled bus practice order shifted five bits left pre senting eight bits address get j register manner one may generate ﬁno addressﬂ commands principle programmer may start microstep amuses practice limited number yield noaddress orders steps used parts add subtract order procure etc author doubt however section 3 1 processors defined microprogram someone find useful reason popping middle divide command feature chine however pathological exploited programmer actual decoding nine bits accomplished partly logic partly current switching clock pulse diode matrix used convert microsteps control signals 15 micro operations may called single step including selection next microorder stepping microregister ploy used reduce number diodes instead specifying next step micro coder specifies bits j wishes reverse instead minimum latency coding earlier days microcoder sd2 must minimum diode coding roughly anal ogous asking fast efficient computer program containing minimum 1s author well others spent endless hours trying devise computer program microcoding results one may note passing man wrote micro code tomo hayata several years specialized advanced programming problems wilkes viewsl logical design future done programmers seem verified limited microarithmetic available micro coding highest order must since microstep 4 psec time simple orders eg extract processes order procure indexing indirect addressing operand procure exe cution compressed time two memory cycles le 40 psec indirect reference adds another memory cycle private communication aug 17 1959 fig 4 microprogram unit chapter 29 design generalpurpose microprogramcontrolled computer elementary structure 345 input gates zero detect storage flipflops output e flipflops time multiply divide shift ultra simple structure begin expensive time temperature requirement imposed clock frequency could doubled materially improving perform ance machine multicycle orders figure 5 block diagram alteration unit consists gates permit entry conditions within computer outside world flipflops used working storage flipflops including make conclusions known sundry fivebit tally register circuit detect zero bus trap logic many 20 input gates 9 storage flipflops 10 output flipflops exclusive 1 register change contents one two ways viz counting one accepting entry bus may transmit intelligence two ways viz b bus notifying input gate system anyone care counted past zero zero detector signals truth statement identically zero practice checks lower digits sign related existence number 1 twocomplement system systems answer negative zero ones complement logic trap logic follows one output signals alteration unit signals whether system receiving trap signals trap logic makes note callers system accepting signals transmits whether signals received resets memory zero timing trap signal ever lost trap logic logic unit lines going logic unit actually two busses logic source may read either bus logic unit four control wires microprogram unit specifying 16 boolean functions two busses put output bus value routed appropriate logic destination output flipflops inputs logic unit outputs go various control points machine three major points 1 establishing whether memory cycle readrestore erasewrite 2 setting initial carry adder 3 determining value shall shift vacant spot left right shift initial carry used simply adding one value since logic two complement one comple ment one transmitted bus initial carry general one subtraction zero addition microprogram details figure 6 gives circuit details microprogram decode system nine flipflops used broken two groups one four five flipflops decoded respectively 16 32 wires group one one wire goes nega tive clock signal 2 pec width applied emitters first set 16 gates passed selected gating transistor collector transistor routed emitter set 32 transistors one pass current thus clock signal routed one 16 x 32 x 512 lines diodes selected line cause signal routed appropriate gates arithmetic alteration unit appropriate placement diodes microstep operate variety gates number limited current available microcontrol wires return j register microcoder may control selection next microstep register designed actual change state inhibited clock goes negative output decoding trees may go 16 bases one transistor 16 signal emitter thus one must driven engineering point view control computer elaborate timing system microprogram unit thus programmable timing generator gating transistordiode de coding system one many ways achieve wilkes observedl diode system one fig 5 alteration unit im v wilkes private communication aug 17 1959 346 part 4 instructionset processor level specialfunction processors 4 select n selected v section 3 1 processors defined microprogram fig 6 details microdecode system acute packaging problem coworkers led consider use switchcore decoding wilkes et al 1958al eachusl coworkers evolved yet another switch core system depend coincident current switch ing order code since order code small problem design microprogrammed machine gott sei danke little need dwell several comments design interest however unable structure get multiplication five microsteps per iteration divide six thus costing respectively 20 24 psec per bit dealt moreover division required precalculations overflow detect dr joseph eachus minneapolishoneywell private conversation sep tember 1959 postcalculation obtaining rounded quotient correct mainder boosted time asynchronous nature transfer possible read register simultaneously hence shifting one register requires two steps 8 psec per bit doublelength shifting requires 16 psec painful short words four doublelength orders microprogrammed add subtract clear add store take total 60 psec execute rich collection branch orders included branch un conditionally branch negative branch zero self explanatory branch b tally loop order decreases b one branches go negative br1 br2 br3 br4 sense toggle branch toggle set turned program branches sense toggles actually storage flipflops t1 t2 t3 t4 alteration unit may set orders t1 also used overflow mark chapter 29 design generalpurpose microprogramcontrolled computer elementary structure 347 machine ﬁdynamicﬂ idle halted either externally order fact observed microprogram alteration unit whereupon microprogram goes tight loop continuously asking ﬁcan go go go ﬂ two forms halting provided ﬁhalt displayﬂ registers presented halt console lights left unaltered manual halt equivalent halt display addressed order bit positions one five sent microprogram unit order procure micro program examines bits zero six indirect addressing index modification nonaddress order recognized binary equivalent 31 order bits microprogram unit causes order word shift left 5 bits 8 high bits ﬁaddressﬂ field enter j register conclusion paper intended argument favor general acceptance sd2 structure ideal like computers sd2 stateoftheart device intended meet needs problems hand also impor tantly meet side conditions use vague analogy computer specification like partial differential equation logical designer must choose boundary conditions solve problem least approximate solution todays emphasis system speed performance serious mental gearshifting designers part required order design simple machine goes grain instinct experience posteriori sd2 could made even simpler particularly respect several peripheral areas discussed paper several conclusions drawn however bus structure easy fabricate maintain proven milsmac breadboard sd2 highly flexible structure permitting wide variation order code change arithmetic unit time components cascaded point one absurd situation fastswitching relatively slow computer designer busstructured machine would well consider alternatives multiple busses accumulators etc permit parallelism speed important use specialpurpose logic unit alteration unit sd2 gives freedom design possible specialpurpose logic time uses parts slow handling multiple variable problems requires great deal control input appears weapon opportunity use microprogramming much general logic unit flexibility speed design unquestionable also uses parts specialpurpose control real substitute specialpurpose design use generalized elements computer design justified side conditions never basic specification simplicity speed design major items use seems indicated wilkes presented paper best way design computer launched microprogramming notions author would like comment ease reliability design criteria absolutely correct references kamptgo wilkm53a wilkm58a section 4 processors based programming language programminglanguagebased processors described chap 3 page 73 three examples presented sec tion two languages fortran euler algebraic languages operating conventional data types whereas iplvi like conventional machine language operating unconventional data types ie list structures peculiar fea ture iplvi conception data program well program data multiprogramming organization led command structure complex information processing iplvi processor chap 30 discussed part 3 sec 5 outgrowth ipl series programming languages newell shaw simon paper seriously treats language merits casting language hardware processor iplvi never implemented hardware partial iplv processor cdc 3600 built argonne national laboratory hardware processor iplvi third generation would undoubtedly exist interpreter microprogrammed processor system design fortran machine paper chap 31 presents way map software pro gram hardware machines passes modes corre spond activities one would see compiling loading executing fortran program bcd format used arithmetic symbol table simply organized therefore searched serious approach actual implementation machine might follow lines euler chap 32 microprogrammed implementation euler ibm system 360imodel 30 clearly written paper describes processor imple ment algollike language wirth weber 19661 earlier processor proposed directly execute algol anderson 19611 implemented using model 30 ibm system360 pmicroprogrammed include paper describes model 30 euler planguage operates like conventional compiler operating system description presents clearly process compiling execution microprogramming aspects model 30 typical ibm system360 models ibm approach pmicroprogrammed significantly different kampes sd2 chap 29 360 microprogram instruc tion encoded long word 60 100 bits depending model number microcoded operations selected parallel sd2 uses short word one operation encoded single instruction 348 chapter 30 command structure complex information processing1 1 c shaw newell h simon 0 ellis generalpurpose digital computer virtue large ca pacity generalpurpose nature opened possibility research nature complex mechanisms per se chal lenge obvious humans carry information processing complexity truly baffling given urge understand either humans alternatively kinds mecha nisms might accomplish tasks computer turned basic research tool varieties complex information processing understood synthesized mechanisms created perform processes last years seen number attempts synthesis complex processes included programs discover proofs theorems newell et al 1956 1957b1 programs synthesize music brooks et al 1957b programs play chess bernstein et al 1958 kister et al 19571 programs simulate reasoning particular humans newell et al 19581 feasi bility synthesizing complex processes hinges feasibility writing programs complexity needed specify processes computer hence limit imposed limit complexity human programmer handle measure complexity absolute depends programming language uses powerful language greater complexity programs write authors work sought increase upper limit com plexity processes specified developing series lan guages called information processing languages ipls duce significantly demands made upon programmer communication computer thus ipls represent series attempts construct sufficiently powerful languages permit programming kinds complex processes previ ously mentioned ipls designed far realized interpretively current computers newell shaw 1957al alternatively course language viewed set specifications generalpurpose computer ipl implemented far expeditiously computer designed handle interpretation computer designed quite different com mand structure mismatch ipls designed current computers appreciable 150machine cycles needed one feels take 2 3 machine cycles become apparent difficulty would removed ﬁcompilingﬂ instead ﬁinterpretingﬂ resurrect set wellworn distinctions operations mismatched current computers must go execution program hence compiled purpose paper consider ipl computer computer constructed machine language information processing language called language iplvi sixth series ipls designed version realized interpretively resulted considering hardware requirements light programming experience previous languages limitations must placed investigation paper concerned central computer command structure form machine operations general arrangements central hardware neglect completely inputoutput secondary storage systems mean unimportant present simple problems problem secondary storage difficult enough current computing systems exceedingly difficult ipl systems since systems initial memory organized neat blocklike packages ease shipment secondary store case one would place order ipl computer described without experience results entirely predictable ipls sufficiently differ ent current computer languages utility evaluated much programming moreover since ipls designed specify large complicated programs utility linguistic devices incorporated ascer tained simple examples one caution needed provide proper setting proc wjcc pp 119128 1958 349 350 part 4 1 instructionset processor level specialfunction processors paper computing world still concerned essentially numerical processes either problems numerical nonnumerical problems appropriately arithmetized kinds problems authors concerned essentially nonnumerical tried cope without resort arithmetic models hence ipls designed view carrying arithmetic great efficiency fundamental goals devices basic aim construct powerful programming language class problems concerned given amount kind output desired computer reduction size complexity specification program written order secure output desired goal reduce programming effort reducing computing effort required produce desired output specification programming feasibility must take precedence computing economics since yet known write program enable computer teach play chess premature ask whether would take computer one hour one hundred hours make move meant apology support contention seeking write programs large complicated tasks overriding initial concerns must attain enough flexibility abbreviation automation underlying computing proc esses make programming feasible concerns power programming language rather efficiency system executes program next section straightforward description ipl computer begun put details proper setting remainder section devoted basic devices iplvi uses achieve measure power flexibility devices include organization memory list structure provision breakouts identity data program twostage interpretation invariance program execution provision responsibility assignments centralized signalling test results list structure fundamental characteristic feature ipls organize memory list structures whose arrangement independent actual physical geometry memory cells undergo continual change computation proceeds computing systems topology memory character section 4 processors based programming language istics hardware program determine memory cells regarded ﬁnext toﬂ given cell plays fundamental role organization information processing obviously true serial memories like tape equally true random access memories random access memories topo logical structure derived possibility performing arithmetic operations memory addresses make use numerical relations among addresses thus cell address 1435 next cell 1436 specific sense second reached first adding one number counter standard computers use made static topology based memory addresses facilitate programming computation index registers relative addressing schemes example make use program arithmetic depend efficacy upon orderly matching arrangement information memory topology addressing system memory organized list structure relation information storage topology reversed topol ogy memory continually modified adapt changing needs organization memory content arithmetic operations memory addresses permitted topology built single asymmetric modifiable ordinal relation pairs memory cells called adjacency system contains processes make use adjacency relations searching memory processes change relations inex pensively course processing list structure established computer memory associating word memory address determines word adjacent far operations computer concerned memory space additional address associated word given adjacency relation changed quickly word memory changed paid price however many basic features ipls obtained almost without cost unlimited hierarchies subroutines recursive definition processes vari able numbers operands processes unlimited complexity data structure capable created modified extent execution time breakouts languages require grammarfixed structural features interpreted grammar imposes constraints said said simply language however constraints created fixed grammatical format alleviated cost intro ducing additional stage processing devices allow one chapter 30 command structure complex information processing 351 ﬁbreak outﬂ format use general modes specification format permits devices breakouts ex change processing time flexibility several devices achieve iplvi associated part format illustrative example 1plvi singleaddress format without breakout devices format would permit informa tion process operate single operand input would permit operand process specified giving address limitations removed first using special communication list store operands second allowing address operand refer either operand process determine operand latter device allows broad freedom method specifying operand illustrates another important facet flexibility problem breakouts great importance ducing burden planning imposed programmer certainly possible principle anticipate need particular operands particular stages processing pro vide operands way addresses known programmer appropriate times usual way machine coding done however plans obtained without cost must created programmer indeed writing complex programs creation plan computation difficult part job constitutes task ﬁprogrammingﬂ sometimes distinguished routine ﬁcodingﬂ thus devices exchange computing time reduction amount planning required programmer provide significant increases flexibility power language identity data programs current computers data considered ﬁinertﬂ symbols operated upon program ﬁstructureﬂ data initially developed programmers head encoded implicitly programs work data structure embodied conventions determine bits processes decode etc alternative approach make data ﬁactiveﬂ words computer instruction format ﬁdataﬂ programs data obtained executing programs advantages alternative obvious full range methods specification available programs also available data list data example may speci fied list processes determine data since data desired ﬁon commandﬂ processing programs approach leads computer although still serial control contains given moment large number parallel active programs frozen midst operation waiting called upon produce next operation piece data identity data program attained proc essing programs require operation information structure data programs information receive data twostage interpretation identify operand iplvi instruction designating operation operates address part instruction pro duce actual operand thus depending designating operation specified address part may operand may provide address operand may stand less direct relation operand designating operation may even delegate actual specification operand another desig nating operation invariance program execution order carry generalized recursions necessary provide storage indefinite amounts variable informa tion necessary operation routines 1plvi variable information stored externally associated routine routine remains unmodified execution name routine appear definition routine without causing difficulty execution time responsibility assignments automatic handling processes erasing list searching list requires scheme keeping track part list processed part example erasing program containing local sub routine appears within program care must taken erase subroutine accomplished system assigning responsibility parts list general responsibility code iplvi handles matters without explicit attention programmer except situations issue responsibility central problem centralized signalling test results structure language simplified conditional processes set switch symbolize output instead pro ducing immediate conditional transfer control specialized processes defined transfer control basis switch setting symbolizing retaining conditional 352 part 4 instructionset processor level specialfunction processors information actual transfer postponed convenient point processing flexibility obtained device proves especially useful dealing transmission conditional information subroutines routines call upon general organization machine machine described profitably viewed ﬁcontrol computerﬂ consists single control unit access large randomaccess memory memory contain lo5 words less lo4 words available primary memory probably frequent occasions transfer information primary secondary storage make system profitable operation computer entirely nonarithmetic arithmetic unit since arithmetic processes used basis control standard computers unit inessential although would highly desirable computer access one given arithmetic tasks computer perfectly capable proving theorems logic playing chess without arithmetic adjunct memory memory consists cells containing words fixed length word divided two parts symbol link entire memory organized list structure following way link address link word address word b b adjacent link word simple list address next word list symbol part word may also contain address may address first word another list indi cated earlier entire topology memory determined links addresses located symbol parts words links permit creation simple lists symbols links symbol parts together creation branching list structures topology memory modified changing addresses links symbol parts thereby changing adjacency relations among words modification link addresses handled directly various list processes without attention programmer hence memory viewed consisting symbol occurrences connected together mechanisms struc ture whose character need specified basic unit organization list set words linked together particular order means link parts section 4 1 processors based programming language way previously explained address first word sequence name list special terminating symbol whose link irrelevant last word every list simple list illustrated fig 1 name l contains two symbols symbols list may designate names lists symbols special format names lists designate names manner described thus list may list lists sublists may list lists example list structure shown fig 2 name list structure name main list l l contains two sublists l l plus item information l name list l turn consists item plus another sublist l l contains information broken sublists lists terminates word holds symbol available space list list uses certain number cells memory cells uses unimportant long right linkages set executing programs continually create new lists destroy old ones two requirements arise creating list cells memory must found otherwise occupied available new list conversely list destroyed longer needed system cells become avail able uses something must done gain access available cells needed device used accomplish two logistic functions available space list cells available linked together single long list whenever cells needed taken front available space list whenever cells made available inserted front available space list behind fixed register holds link first available space operations taking cells avail able space list returning cells available space list volve case changes addresses pair links s2 fig 1 simple list chapter 30 command structure complex information processing 353 communication list available space list cia list ccla list list camporator memory fig 2 list structure organization central unit figure 3 shows special registers machine main information transfer paths four addressable registers accomplish fixed functions shown part main memory would fast access registers lo l l2 l3 communication list lo system allows introduction unlimited numbers processes variable numbers inputs outputs communication inputs outputs among processes centralized communication list known name lo subroutines find inputs list subroutines put outputs list available space list l cells currently used available space list cells obtained needed returned longer used list current instruction addresses cia l given moment working sequentially program whole hierarchy instructions process interpreta tion whose interpretation completed include instruction currently interpreted routine instruction belongs superroutine routine belongs cia list list addresses hierarchy routines first symbol list gives address instruction currently interpreted second symbol gives address current instruction next higher routine etc system proves preferable keep track current instruction interpreted rather next one list current cia lists l control sequence complicated computer existence numerous programs become active called upon whose processing may interspersed among processes hence single cia list suffice must list program completely executed therefore necessary also list gives names cia lists active list l besides special addressable registers three nonaddress able registers needed handle transfers information two r r full word length transfer information memory register r receives input memory r transmits output memory com parator provides information tests takes input comparison symbols r r pair registers also performs secondary function regenerating words memory basic ﬁread operation memory assumed destructive nondestructive ﬁreadﬂ merely shunts word received memory e r back means ﬁwriteﬂ operation memory cell register holds single address controls references memory specifies memory address ﬁreadﬂ ﬁwriteﬂ operation performed references four addressable registers lo l made either directly control unit memory cells referred finally computer single bit register used encode retain test results fig 3 machine information transfer paths 354 part 4 1 instructionset processor level specialfunction processors environment inputoutput secondary storage highspeed arithmetic could handled machine indicated machine manipulates symbols construct complex structures search tell two symbol occurrences identical processes sufficient play chess prove theorems tasks symbols manipulates ﬁcoded simply form set arbitrary distinguishable entities like large alphabet computer manipulate things outside hardware provided make symbols refer outside objects symbols refer operations objects could highspeed arithmetic example symbols names words memory encoded numbers usual computer fashion others names arithmetic opera tions scheme words would ipl language would format either fixed floatingpoint binary decimal might occupy physical memory used control computer thus ipl language would deal numbers one remove names much manner programmer deals numbers current computer similar approach used manipulating printers input devices etc word interpretation words ipl format shown fig 4 word divided two major parts symbol part bcde link f observed programmer never deals explicitly link although frequently represented explicitly show manipulations accomplished since symbol appear many words symbol occurrence symbol word discussed symbol occurrence consists operation b designation location word b operation code c designation code address field e responsibility code f link next word fig 4 ipl word format section 4 processors based programming language operation c address responsibility code e opera tion b takes operand single symbol occurrence called operand determined applying designation operation c address thus process determined word carried two stages firststage operation designation operation determines operand becomes input secondstage operation responsibility bit single bit e essential piece auxiliary information address symbol may address another list structure responsibility code symbol occurrence indicates whether occurrence ﬁresponsibleﬂ structure designated address occurs one word one indicate responsibility main function responsibility code provide way searching branching list structure every part structure sooner later reached part reached twice need definite assignment responsibility various parts structure seen considering process erasing list suppose list sublist appears twice appear anywhere else memory list erased sublist must erased lost forever space occupies however sublist erased occur rence name encountered list imperative erased second encounter since words used sublist would returned avail able space list prior second encounter chaos could result erasing responsibility code would indicate responsibility erasing one one two occur rences name sublist detailed consideration systems responsibility inappro priate paper believed adequate system constructed single bit although system handle merging lists also requires responsibility bit link f responsibility code essentially automatic programmer need worry except cases explicitly seeking modify structure interpretation cycle routine list words list instructions name address first word used list interpretation program proceeds according simple cycle instruc tion fetched control unit designation operation decoded executed placing location address chapter 30 1 command structure complex information processing 355 register fig 3 operation b decoded performed cycle repeated using f fetch next instruc tion operation codes simple interpretation cycle previously described provides none powerful linguistic features outlined beginning paper hierarchies subroutines data programs breakouts etc features obtained particular b c operations modify sequence control opera tion codes explained following headings designation code sequencecontrolling operations save delete operations communication list operations signal operations list operations operations designation code designation operation c operates address desig nate symbol occurrence serve input operand operation b designation operation places address designated symbol address register designation codes proposed based usefulness coding ipls shown appendix 1 first four c 0 1 2 3 allow four degrees directness reference usable programmer knows advance symbol located illustrate definition consider instruction parts b e e collec tively called address part instruction may address another instruction address part may address etc code c 1 means symbol whose address symbol case designating operation puts address address register code c 2 means hence operation puts address s3 address register code c 3 puts address s4 address register finally c 0 designates actual symbol hence means b operate therefore operation places u1 address register remaining two designation operations c 4 5 intro duce another kind flexibility allow programmer delegate designation parts program c1 4 task designating delegated symbol word u2 case found applying designation operation c2 word address word u2 operation kind permits programmer unaware way data arranged structurally memory notice operation permits indefinite number stages delegation since c 4 delegation designation operation e word last designation operation c 5 provides dele gation breakout c 5 interpreted process determines program whatsoever initial instruction written specify program executed designated interpretation continue reverting original cycle applying b designated necessary provide convention communicating result process interpreter convention used leave location l standard communication cell sequencecontrolling operations appendix 2 lists 35 b operations first 12 ones affect sequence control accomplish 5 quite different functions executing process b 1 lo executing variable instructions b 2 transferring control within routine b 3 4 5 transferring control among parallel program struc tures b 0 6 7 8 9 finally stopping computer routine list instructions name address first word list execute routine name le name becomes previous section designated applied operation b 1 ﬁexecute sﬂ interpreter must keep track location instruction executed current routine return location completing execution instruction general subroutine lists end word containing b 10 terminates list returns control higher routine subroutine completed occurred symbol really symbol b 10 figure 5 provides simple illustration relations routines subroutines course executing routine l ie instructions constitute list l struction 10 l encountered interpreted ﬁexecute lﬂ course executing l instruction encountered interpreted ﬁexecute lﬂ assuming l contains subroutines instructions executed order terminate instruction reached 10 b part instruction returns control instruction follows l lz0 final word l reached operation code instruction following l b part b 10 terminal word routine used interpretation c b 11 10 b part returns control ll0 continues 356 part 4 1 instructionset processor level specialfunction processors l10 fig 5 simple subroutine hierarchy parts irrelevant standard subroutine linkage sequence control centralized operation code b 2 ﬁinterpret sﬂ delegates inter pretation word effect instruction containing b 2 exactly instruction contained instead symbol designated c parts one think instruction b 2 variable whose value thus routine altered modifying symbol occur rence without modification whatsoever words belong ing routine three operations b 3 4 5 standard transfer operations first unconditional transfer two others transfer conditionally signal bit mentioned earlier binary conditional processes set signal either ﬁonﬂ ﬁoffﬂ order describe operations b 0 6 7 8 9 concept program structure must defined program structure rou tine together subroutines designation processes structure corresponds single although perhaps com plex process computer capable holding given time number independent program structures interrupt one processes time time order execute one others structures coordinate parallel operations h 0 6 7 8 9 used transfer control perhaps conditionally one currently active new one previously active one sense com puter described may viewed serial control parallel program machine execution particular routine program structure used example operation b 6 transfer control independent program structure determined call b section 4 processors based programming language machine begin execute b encounters ﬁstop interpretationﬂ operation b 0 b control returned program structure previously active ﬁstop interpretationﬂ operation unlike ordinary ter mination b 10 mark end program structure b later point execution control may transferred b case execution latter program resumed point interrupted earlier ﬁstop interpretationﬂ command operation ac complishes second transfer control b h 7 ﬁcontinue parallel program sﬂ thus b 0 really ﬁinterruptﬂ operation returns control previous structure leaves structure interrupts condition continue later point large numbers independent program struc tures ﬁopen businessﬂ single control passing one determining access proc essing facilities gradually executing operations b 8 9 simply allow interruption conditional test switch notice passage control one structure another entirely decentralized depends upon occurrence appropriate b operations program structure control control transferred parallel program structure either two outcomes possible either ﬁstop interpretationﬂ instruction reached structure control transferred execution structure completed termination reached either case control returned program structure previously together informa tion whether returned interruption termina tion thus b 0 turns signal bit returns control b 10 topmost routine structure turns signal operation b 11 simply halts processing continues location halted upon receipt external signal ﬁgoﬂ save delete operations two operations b 12 13 sufficiently fundamental warrant extended treatment example consider word l contains symbol location symbol link lloo 11 link l indicates next word holds termination operation b 10 ﬁsaveﬂ operation b 12 chapter 30 command structure complex information processing 357 provides copy way later recalled even meantime symbol lloo changed ﬁsaveﬂ operation performed l result location symhol link lloo 11 lzoo lpoo i1 new cell happened l obtained ﬁsaveﬂ operation available space list l copy put symbol l changed without losing irretrievably suppose different symbol copied example 12 l location symbol link lloo i2 l2oo lpoo 11 although replaced l recovered performing ﬁdeleteﬂ operation b 13 ﬁdeleteﬂ operation explained instructive show happens ﬁsaveﬂ operation l1 interated executed make copy therefore location symbol link lloo ip l300 l3oo 12 loo lzo 11 notice cell l copy symbol retained affected second ﬁsaveﬂ operation top cell list new cell available space list involved transaction saving process performed matter long list trails l thus save operation applied many times desired constant processing time ﬁdeleteﬂ operation b 13 applied symbol l illustrated operation puts symbol link second word list l first cell l puts l back available space list following result location symbol link loo 12 lzoo lzoo 11 result exact situation obtained last ﬁsaveﬂ performed description ﬁdeleteﬂ operation point changes makes ﬁpushdownﬂ list case l considered operation however ﬁdelete sﬂ also erases structures symbol ii examples responsible copy symbol made eg operation initially replaced l copy assigned responsibility symbol e 0 set copy thus additional erasing would required particular ﬁdeleteﬂ operation illustrated hand moved lloo respon sible structure could reached name list example second ﬁdeleteﬂ operation putting back l would also erase list put cells back available space list thus ﬁdeleteﬂ also equivalent ﬁeraseﬂ list structure communication list operations describing process list subprocesses question inputs outputs processes entirely bypassed since subroutine arbitrary variable number operands input provides routine uses arbitrary number outputs scheme communication required among routines communication list l accom plishes function ipl inputs outputs routine symbols required real restriction since symbol name list structure whatever routine take inputs first symbols l list routine three inputs first three symbols l inputs routine must remove inputs l terminating b 10 permit use communication list subsequent routines finally routine leaves outputs head list lo b operations 14 19 used communication l one common feature whenever put symbol l save symbol already push symbols already ﬁstackedﬂ lo likewise whenever symbol moved l memory symbol l ﬁpops upﬂ become top one precise 358 part 4 instructionset processor level specialfunction processors responsibility bit travels symbol moved hence example b 16 17 unlike ﬁdeleteﬂ operation erase structure responsible four operations b 14 15 16 17 main inout operations lo two options provided depending whether programmer wishes retain memory b 14 16 destroy h 15 17 move operation 15 significance i6 17 responsibility bit moves symbol symbol previously location recalled operation b 18 special input aid breakout designation operation c 5 recall latter operation quires place location symbol determines lo operation 18 allows process accomplish operation b 19 provides means creating structures takes cell example l available space puts name symbol 00 l location designated symbol symbol previously location pushed saved signal operations ten 6 operations primarily involved setting manipu lating signal bit observe test equality b 20 21 identity symbols since nothing system provides natural ordering symbols inequality tests like impossible e means symbol lo neces sary able detect responsibility bit b 22 since occasions explicit structure lists important information designate finally although signal bit single switch necessary two symbols one corresponding ﬁsignal onﬂ ﬁsignal offﬂ b 26 27 information signal retained later use b 28 29 sense signal arbitrary general ﬁoffﬂ used mean process ﬁfailedﬂ ﬁdid findﬂ like thus operations h 6 7 failure find ﬁstop interpreta tionﬂ operation sets signal ﬁoff ﬂ likewise end list symbolized setting signal ﬁoffﬂ list operations ﬁsaveﬂ ﬁdeleteﬂ operations used manipulate lists besides several others needed three opera tions 6 30 31 32 allow search list structures paraphrased ﬁget referentﬂ ﬁturn sublistﬂ ﬁget next word listﬂ common replace known symbol unknown symbol section 4 1 processors based programming language unknown symbol need exist symbol referred may contain b 10 operation means end list reached consequently signal always set ﬁonﬂ symbol found ﬁoffﬂ symbol found one virtues common signal apparent point since programmer knows symbol exists simply ignore signal instruction formats provide additional addresses conditional transfers would force programmer attend condition even meant leaving blank space program illustrate search operations work fig 6 shows list lists l known cell l cell l contains reference list structure programmer know list l referenced wants find last symbol last list structure first step 30 1 l replaces reference name list l searches end list l series opera tions 32 replaces one location list next one fact loop required since length list unknown hence ﬁfind next wordﬂ opera tion must transfer basis signal back operation end list hasnt reached net result end list reached location last word list l rests l since example wants go end sublist last word main list next performs 31 1 lloo operation replaces location last word name last list l search sublist repeated end reached point location last symbol last list l desired sequence code follows location symbol link operations b 33 34 allow inserting symbols list either symbol designated lists system oneway although always way finding symbol follows designated symbol way finding symbol precedes designated symbol ﬁinsert beforeﬂ operation violate rule operations chapter 30 1 command structure complex information processing 359 direct designation operations figure 7 shows information flows c 2 operation typical first four designation operations flows follow simple fixed interpretation sequence assume instruction 2 l inside control unit contents l brought r input register transferred r output register back l part r contains location location transferred r address register execute subroutine b 1 ﬁexecute sﬂ interpreted address register already contains location brought first stage interpretation cycle l current instruction address list cia holds address instruction containing ﬁexecuteﬂ order ﬁsaveﬂ operation performed l transferred l ends operation result interpreter interpret first instruction next sublist proceed usual fashion upon reaching terminate operation b 10 delete operation performed e thus bringing back original instruction address subroutine executed interpretation cycle resumed proceed original list thus two operations save delete perform basic work keeping track subroutine linkage parallel programs single program structure routine sub routines subroutines etc requires cia list order keep track sequence control order number independent program structures cia list required l fixed register holds name current cia fig 6 example finding last item last sublist 33 34 cell obtained available space list inserted word holding designated symbol identical first step ﬁsaveﬂ operation ﬁinsert beforeﬂ operation b 33 designated symbol copied new cell 1l moved previous location ﬁinsert afterﬂ b 34 designated symbol left unchanged moved new cell cases moved longer remains head communication list operations completes account basic complement operations ipl computer form sufficient set operations handle wide range nonnumerical problems arith metic efficiently one would either add another set bs covering standard arithmetic operations deal operations externally via breakout operation b formally defined would move frill symbol special register hardware interpretation relative external machines adders printers tapes etc set operations described reading writing various parts word b c e f although may possible automatize last completely operations rarely occnr seemed best ignore well inputoutput operations interest simple presenta tion interpretation section describe general terms machine interpre tation required carry operation codes prescribed enough space exhaustive therefore selected examples discussed lioo fig 7 information transfers c 2 operation 360 part 4 1 instructionset processor level specialfunction processors 81lloo lioori list name cia list program structure reactivated completion interruption current program structure second item l list etc therefore l list appropriately called current cia list ﬁsaveﬂ ﬁdeleteﬂ operations used manipulate l analogously use l previously described appendix 3 gives complete schematic representation interpretation cycle still necessary represent selected b operations lmtl data programs section list operations search list described data passive processing program dictated steps taken covering list consider similar situation shown fig 8 working cell l contains name list l l data program program wants process data l3 sequence symbols program knows l obtain first symbol data 61 l ﬁexecute parallel program whose name lﬂ result create cia list l put name l fire program sort processing occur indicated blank words l presumably something determining data although might bookkeeping ls experi ence data file eventually l reached contains 0 1 operation stops interpretation returns con trol original processing program first symbol data defined ll8 processing program designate 4l since sequence c 4 prefixes l l pass along interpretation ultimately becomes il processing program proceed data remains 8illoo lu3olgt l section 4 1 processors based programming language completely oblivious processing structure involved determining first symbol data simi larly although shown processing program able get second symbol data time simply ﬁcontinue parallel program llﬂ b 7 one virtue use data programs solution offers ﬁinterpolated lists working chess program example one various lists men pawns pieces pieces move one square rooks queens etc one would like list men already exists list pieces list pawns would desirable compose lists single long list without losing identity either short lists since still used separately words form list whose elements two lists list lists searched looks like single long list necessary condition successfully one afford make program uses list lists know structure operation ﬁexecute sﬂ b 1 precisely opera tion needed accomplish task data program says ﬁturn aside go sublist sﬂ since opera tion b 0 ﬁdataﬂ simply ﬁpunctuationﬂ describes structure data list allows appropriate symbols designated figure 9 shows data list kind described authors taken liberty writing names chessmen stretch code follows shows use data program ﬁtable look upﬂ operation table arbitrary arguments symbol value etc used represent arguments find value corresponding argument example put communication cell 14 0 data program executed 6 0 j control lies table tests argument symbol communication lists le sets signal accordingly program stops interpreting b 8 word holding value arguments case would stop designating l entry found course control would return inquiring program signal locution symbol link lloo fig 8 example data program chapter 30 command structure complex information processing 361 l jo lzoo h 1oloo oo queen oo krook fig 9 application data program chess conclusions purpose paper outline command structure complex information processing following concepts used series interpretive languages called ipls ulti mate test command structure complex problems allows one solve would solved coding language available least two different factors operate keep problems solved computers difficulty specification effort required processing primary features command structure aimed specification problem authors tried specify language requirements complex coding see hardware organization allowed mechanization features delegation indirect refer encing breakout imply good deal interpretation machine instruction similarly parallel program structure requires additional processing set cia lists data symbol designated delegated interpreting several words exacts toll machine time one solely concerned machine efficiency one would require programmer plan arrange program direct uniform processes would suffice considering size current computers continued rate growth toward megaword memories microsecond operations believed limitation already lies programmer limited capacity conceive plan complicated programs authors certainly know true efforts program theorem proving programs chess playing programs ipl languages equivalent flexibility also power necessary tool considering amount interpretation fact interpretation uses operations available programmer eg save delete operations one think alternative ways realize ipl computer one extreme interpretive routines current computers method authors using costless hardware expensive computing time one could also add special opera tions standard repertoire facilitate interpretive version language probably much fruitful addition small amount fast storage speed interpreter finally one could wire programs operations get even speed clear arrangement direct wired program need inter preter use whole capability operation code references shawj58 berna58 broof57b kistj57 newea56 57a 57b 58 appendix 1 c nature operation b c e 0 1 2 3 4 5 appendix 2 b operations c operations designating operations symbol address symbol address address symbol address address address symbol address designating instruction deter mines address name process determines b nature operation sequencecontrol operations 0 1 execute process named 2 interpret instruction 3 transfer control location 4 transfer control location signal 5 transfer control location signal 6 execute parallel program turn signal stops 7 continue parallel program turn signal stops 8 stop interpreting signal 9 stop interpreting signal stop interpreting return previous program structure 10 terminate 11 halt proceed go save delete operations 12 save 13 delete everything responsible 362 part 4 instructionset processor level specialfunction processors section 4 processors based programming language communication list operations 14 15 16 17 18 19 copy communication list saving il move communication list saving 1l move location saving move il location destroying copy location communication list saving il create new symbol location saving signalling operations 20 21 22 23 24 25 26 27 28 29 turn signal turn signal delete il turn signal responsible turn signal turn signal invert signal copy signal location copy signal location saving set signal according set signal according delete appendix 3 interpretation cycle 1 fetch current instruction according current instruc tion address cia current cia list 2 decode execute c operation c 3 replace part word address reduce c c 2 continue c 2 replace part word address reduce c c 1 continue c 1 put address register go step 3 c 0 put cia address register go step 3 c 4 replace c c parts word address go step 2 c 5 mark cia ﬁincompleteﬂ save set new cia go step 1 3 decode execute b operation b operations affect interpretation cycle follow b 0 turn signal delete cia go step 4 b 1 save cia set new cia part go step 1 b 2 replace b c go step 2 b 3 replace cia part go step 1 b 10 delete cia list operations 30 31 32 replace symbol designated turn signal symbol doesnt exist b lo leave turn signal replace symbol turn signal symbol doesnt exist leave turn signal replace location next symbol turn signal replaced ﬁ0 4 f part sﬂ next symbol exist leave turn signal cia ﬁpops upﬂ turn signal delete cia go step 4 ﬁpopped upﬂ cia marked ﬁincompleteﬂ fetch cur rent instruction move address register go step 3 otherwise go step 4 33 34 insert 1l move symbol communication list insert il move symbol communication list 4 replace cia f part current instruction go step 1 chapter 31 system design fortran machine theodore r bashkow azru susson arnold kronfeld summary system design given computer capable direct execution fortran language source statements allowed types statements fortran go computed go arith metic read print arithmetic continue pause dimension end statements two subscripts allowed variables format statement needed programmers source program converted slightly modified form loaded placed program area lower memory original variable names statement numbers retained symbol table upper memory also serves data storage area execution program fortran statement read interpreted basic circuit speeds since machine hardware interpreter statements machine corresponds therefore ﬁonepass loadandgoﬂ compiler except course translation different machine language estimated control circuitry machine require order 10000 diodes 100 flipflops include arithmetic circuitry tern digital computer system digital machine design direct ion fortran fortran computer system fortran lan machine hardware interpreter introduction algebraic languages particular fortran country enormous impact utilization computers scientific engineering computation designed large part overcome annoyance lengthy learning time laborious attention detail needed use basic machine language annoyances overcome providing language closer english form freer ﬁbookkeepingﬂ details usual machine languages providing machine language program called compiler translator convert source program written user object program execut able computer thus original drawbacks overcome discrepancy external language user internal language machine leads least two others compilation run machine ieee trans ec16 vol 4 pp 485499 august 1967 language translation accomplished waste time money user since must pay time though gets problem answers secondly user specified logical flow arithmetic details solution source language however machine ﬁhangs upﬂ attempts debug program finds displayed machine console machine language large machines gets equivalently esoteric printout symbolic form machine language overcome difficulties one could use interpretive translator source language instead historical deficiencies interpreters loss memory space loss speed execution caused solution shunned another solution also possibledesign machine executes algebraic language directly ﬁmachine languageﬂ approach based recognition allowable syntax associated semantics language statements firmly specified matter choice whether write compiler write interpreter build interpreter hardware software choice almost overwhelmingly write compiler since choice hardware interpreter machine made fact hardly explored great extent study made order see choice leads system competitive usual software system understood machine constructed however design2 sufficiently complete construction seems feasible languagedesign philosophy since machine language algebraic one seemed reasonable choose simple subset commonly used one fortran eliminates necessity inventing still another language allows attention focused machine design fact subset chosen quite close known ﬁpreliminary fortran ibm 1620ﬂ complete enough quite useful include 2see ha1 technical report contract af 196282798 363 364 part 4 1 instructionset processor level specialfunction processors innovations subroutines etc addition usual ﬁbuilt inﬂ subroutines sin x cos x etc included clusion would require additional effort hardware imple mentation appear worth expending time fortran statement types accepted machine machine language table follows stutement comment ab go n value arithmetic expression b stored memory location referenced variable name may two subscripts program control transferred statement numbered n go nl n2 nm program control transferred one statements numbered nl n2 n depending value time statement executed pause program control transferred statement numbered nl algebraic expression e negative num bered n2 e zero numbered n3 e positive program execution halted restarted console switch n ml m2 m3 statements following one program including statement num bered n executed repeatedly first execution equal ml cremented value m3 succeeding execution continues greater m2 time pro gram control transferred either statement following n statement required sequencing rules nests m3 given stood 1 contl nue end statement effect ﬁno operationﬂ instruction conventional machines program control goes next statement program unless continue last statement range case normal sequencing takes place statement generates control signal start execution program familiarity fortran language assumed section 4 1 processors based programming language read list statements cause data read print list printed respectively accordance specified list variables may subscripted however ﬁimplied doﬂ feature implemented format control available machine therefore statement number need given statement effect reserv ing memory space subscripted variables g u stands variable name followed parentheses enclosing one two constants dimension u u distinction made machine fixed integer floating point real variables may names length starting alphabetic character fixed point constants may specified program data combination one four numeric characters preceded sign however converted internal decimal floating point number restrictions ﬁmixed modeﬂ expressions statement numbers must unsigned fixed point constants converted since affect program control arithmetic processing floating point comtants specified form mantissa one four numeric symbols preceded decimal point sign followed character e single positive negative digit representing power ten usual scientific notation constraints number size format made simplify certain circuits could easily relaxed desired restriction twosubscript maximum subscripted variables similarly motivated internally numerical data require three bit words fig 1 first two words contain fourdigit mantissa packed two per word 4bit code digit decimal point assumed exist left significant digit significant two bits third word zero third bit 0 mantissa positive 1 negative similarly fourth bit 0 1 exponent respectively positive negative single exponent digit occupies least significant four bits word characters occupy full 8bit word two significant 1s numeric characters symbols variable eg ﬁ2ﬂ abzx also occupy full word type statement numbers simply packed 2 digits per word always occupy 2 full words proceeding description overall charac chapter 31 system design fortran machine 365 05739 e4 three consecutive words memory mantissa word11011 1011 1011 ill11 word 2 0 10 11 11 11 10 10 11 word 3 0 0 0 1 0 1 1 1 0 1 0 used exponent exponent sign number sign fig 1 data format memory teristics machine loads executes language speci fied may well indicate two basic design goals 1 card deck tape containing hollerith bcd version english language form source program deck tape required time execute program program loaded memory execution started look ﬁinto machineﬂ reveal infor mation form entered thus program executing x b one find ﬁxﬂ ﬁﬂ ﬁaﬂ ﬁ ﬂ ﬁrﬂ least bcd form 2 second goal compromised somewhat far internal representation program concerned interest execution speed however compromises kept minimum addition mechanisms one take looks ﬁinto machineﬂ conceal com promises memory organization machine effect hardware version ﬁonepass loadandgoﬂ compiler operates two modes load mode fortran statements read analyzed quired stored memory last statement stored execution mode entered program execution begins first executable statement read input output device machine design flexowriter model spd programs assumed punched onto paper tape one statement per line followed ﬁcarriage returnﬂ gen erates paper tape symbol separate statements tape read memory blanks automatically ﬁsqueezed outﬂ memory around machine designed 4096 word 8bitperword randomaccess core mem0ryl treated control circuits though consisted three distinct regions 1 inputoutput io buffer one statement time loaded sequentially memory locations 099 sixbit paper tape codes first converted internal often different sixbit memory codes stored six least significant positions bit words carriage return symbol encoded special ﬁendofstatementﬂ symbol repre sented paper ﬁﬂ symbol read tape also automatically stopped symbol table area memory locations 4095 sequentially downward memory hold programmers names variables statement numbers etc well ﬁpointersﬂ machine addresses plus empty execution locations data program area memory locations 100 sequentially ward hold fortran program slightly modified form 2 3 operating modes load mode circuits control input fortran statements place certain information symbol table area modified form fortran statements program area mode necessary searches variable names take place machine addresses assigned ad dresses replace portions variable names statement appears program area similar processing replaces programmerassigned statement number references program area various internal ﬁpointersﬂ control go statements modification done statement execution execute mode proceed high speed short fortran statement program area modified extent variable names replaced actual data addresses statement number references replaced actual addresses statement locations program area translation done statement analyzed load mode might noted ﬁonepass nature translation given statement analyzed certain 5ps cycle time ee co model 781 366 part 4 instructionset processor level specialfunction processors pointers correspond indirect addresses figure 2 shows sketch overall system control tables 2 7 show extent original statements altered loading program program punched paper tape loaded memory energizing tape read circuit reads state ment tape including endofstatement symbol 10 buffer read circuit deenergized least significant 6 bits word buffer hold internal bcd representation symbol scan circuit fig 3 picks symbol state ment left right symbol decoded reacts follows 1 first symbol digit control turned statement number load circuit circuit shifts statement number digit digit register shr maximum allowable length statement number 4 digits statement numbers carried internally form ie programmers statement number 13 carried 2 words 0013 search made symbol table area one three possibilities exists statement number found symbol table 10 buffer execute 7 input program output read print section 4 1 processors based programming language put symbol table followed value current program location statement number also putinto program area starting location program counter incremented appropriately le 2 since two 8bit words used statement number found symbol table previously referred go current value program counter placed two memory locations following statement number left blank statement number previously processed state ment number put program area program counter incremented statement number found symbol table previously referred statement description deferred statement loading described since circuits behav ior meaningful context b c 2 statement number processed fashion first symbol statement digit statement number assigned scan circuit con tinues pick symbol left right able classify statement type turns control appropriate loading circuit indicated fig 3 loading circuits put statements pro gram area replacing variable names statement number references program addresses pointers also replace reserved names go continue single 8bit code token unique variable name pro gram however also stored symbol table using 8bit code symbol nonsubscripted variables three words following name reserved data associated name program executed sub scripted variable names found dimension statements must precede use variables program case many locations following name reserved computed dimension statement name symbol table preceded special symbol indicate subscripted variable addition first two subscript values dimension statement also stored immediately following name number needed program execution constructing proper element array specified subscripted variab1el address pointer next available location symbol table also stored speed symbol table searching fig 2 fortran computer system chapter 31 system design fortran machine 367 print process print j process pause process pause continue process continue papertope control program switch process end statement process dimension process p arithmetic l fig 3 load processing sequence control process process go computed go process computed go ﬁon ckt hd process data location replaces symbols variable name program area except first symbol must alphabetic retained program area indicator indeed variable special symbols etc simply stored sequentially program area bit bcd form appear original statement statement numbers go statements similarly replaced address symbol table holds address program area statement number note indirect address statement statement numbers statements dealt somewhat differently explained later variable names statement number references appear many times program searches symbol table controlled two special circuits variable match unit vmu statement match unit smu circuits indicate either name statement number already symbol table thus first appearance variable name statement number reference statement number causes put symbol table subsequent references merely utilize previously assigned data program addresses therefore name statement number stored symbol table exception noted general programmers statement altered described fashion however ease execution computed go index parameter name ie ﬁiﬂ go nl n2 nm changed position following parenthesis position preceding parenthesis statement requires complex loading algo rithm basically idea place statement essentially unchanged program area extract 368 pari 4 instructionset processor level specialfunction drocessors range statement number specifies last statement range put symbol table preceded special symbol designating referenced followed program area address corre sponding statement statement program area original statement number replaced special symbol internal address determined follows see table 6 one nest dos internal address program area address x token next preceding statement easily found symbol table search range statement number since entry symbol table corresponding every statement thus nest three deep ending statement number 100 example three entries ﬁdo nest orderﬂ number 0100 fol lowed corresponding statement program area address first nest dos specifying particular range statement number internal address program address next statement outside range le address control go nest satisfied b outside address found statement number load circuit time last statement range appears 10 buffer loading circuit first detects matching statement number symbol table preceded extracts saves program area address first last nest simply address one statement number put program area always addition program area address h token last nest also put program area immediately following addition special flipflop lsff set loading circuit statement type allowed last statement range tests lsff loaded statement program area current contents program counter address next statement outside range used internal address first nest noted range statement number together program area location also appear symbol table without preceding necessary possible even legal cases go refer also method used design circuits implement section 4 processors based programming language functions case english language description function sequential circuit state diagram constructed circuit synthesized state diagram using established methods state diagrams arithmetic statement loading circuits variable match unit used loading shown appendix hardware implementation state diagram variable match unit also described executing program end statement signaling end source program encountered scan unit machine leaves load mode executes automatic reset enters execution mode reset forces address 100 program counter pressing console start button causes statement execution begin first executable statement always found memory address 100 separate statement execution circuit statement type addition statement number proc essing circuit reacts digit first symbol statement circuits initial state execution begins one one leave initial state first symbol statement read memory responding circuit retains control executes statement end statement symbol read memory returns initial state first symbol next statement indicated program counter read causes circuit leave initial state etc thus first symbol statement acts like ﬁoperation codeﬂ portion conventional computer instruc tion word first symbol must since load circuitry causes one 8bit tokens various statement types digit statement number alphabetic character variable left ﬁﬂ symbol arithmetic statement tokens represented paper shown table 1 table 1 statement type token go n go nl n2 nm e nl nz n3 pause n ml m2 m3 continue read print go comgoto pa us e continue read prlnt chapter 31 1 system design fortran machine 369 possible however execution circuitry leave initial state either reading reading token immediately following former causes initial ization latter causes indexing testing described later action execution circuits briefly given statement number processing first symbol statement digit circuit energized four digits packed two memory words circuit returns initial state remainder statement executed eight digits packed four memory words last four digits address last nest saved register ssar lsff turned circuit returns initial state remainder statement executed remainder statement go statement execution circuitry control executes statement tests lsff program counter contents placed ssar contents lsff reset circuit returns initial state case ssar holds program address h token innermost read indexing testing take place lsff circuit returns initial state go n goto token energizes circuit fourdigit address packed two memory words immediately following token extracted contents address put program counter circuit returns initial state exump2el go 15 table 2 go nl nq nm comgoto token energizes circuit initial alpha betic symbol immediately following token read discarded fourdigit address immediately following extracted contents address current value put register decremented one 1 result zero fourdigit address following left parenthesis extracted contents address put program counter circuit returns initial state examples written though statement statements first program table 2 symbol table program area address contents address contents 4095 00 machine form 0100 0102 0103 4094 15statement 15 0101 0250 0251 goto 40 address address 93 statement 15 00 statement 15 15 program result nonzero fourdigit address following left parenthesis read discarded register decre mented one result zero fourdigit address following next comma treated 1 result nonzero fourdigit address following next comma read discarded register decre mented one steps 3 4 repeated register zero right parenthesis read register nonzero error condition found indicated exumple go 5 10 lso italy2 table 3 n2 n3 token energizes circuit left parenthesis immedi ately following token read control given temporarily arithmetic statement execution circuit latter circuit forced state would ready evaluate expression right equal sign arith metic statement special ff ifff also set 1 expression e statement read evaluated final right parenthesis statement read since arith metic statement circuit allowed read initial left parenthesis would normally go error condition circumstances ﬁunbalanced parentheses however sensing ifff set 1 resets ifff places value expression e evaluated accumulator returns initial state reenergizes statement circuit ac cumulator equipped sense contents energizes one 370 part 4 instructionset processor level specialfunction processors section 4 processors based programming language table 3 exampze ifa b 10 20 202 table 4 symbol table program area address contents address contents 4095 4094 4093 4092 409 1 4090 4089 4088 4087 4086 4085 4084 4083 4082 408 1 4080 4079 4078 4077 4076 1 l 00 representation 05 statement 5 02 50 00 10 03 address 50 statement 10 01 50 05 address 53 1 statement 150 0100 0101 0102 0103 0102 0103 0104 0105 0106 0107 0108 0109 0110 0111 0112 0250 0251 comgoto 40 address 90 data italy 40 address address 85of statement 5 40 address address 81 statement 10 40 address address 77of statement 150 00 05 0350 00 0351 10 0553 01 0554 50 three signal lines depending whether number zero positive negative circuit senses lines reacts follows 1 accumulator signal negative next fourdigit address n extracted contents address put program counter circuit returns initial state accumulator signal zero next fourdigit address skipped fourdigit address following next coininas nz treated 1 accumulator signal positive next 2 fourdigit addresses intervening comma skipped fourdigit address following next comma n3 treated 1 2 3 pa use pause token energizes circuit end statement symbol read discarded execution circuits forced state 0 automatic reading memory ceases start signal initiated console switch required return circuits state 0 initiate memory reading location specified current contents program counter example pause table 5 n m2 m3 n m2 circuit energized ie caused leave initial state either token h token action different two cases described separately table 4 symbol table program area address contents address contents 4095 4094 4093 4092 409 1 4090 4089 4088 4087 4086 4085 4084 4083 4082 4081 4080 b 00 10 03 address 50 statement 10 00 20 0100 0101 0102 0103 0104 0105 0106 0107 0108 0109 01 10 0111 0112 01 13 0114 0115 01 16 0117 0118 40 94 b 40 90 40 address address 81 statement 20 40 address address 81 statement 20 0350 00 0351 10 0441 00 0442 20 chapter 31 1 system design fortran machine 371 table 5 symbol table program area address contents applicable 0100 pause 0101 1 circuit energized token h token fourdigit address immediately following read discarded initial alphabetic symbol read discarded fourdigit address immediately following extracted saved register called sar symbol read discarded initial value statement either purely numeric may name variable purely numeric load circuitry placed internal machine representation number therefore number simply read stored symbol table starting address given sar register name variable initial alphabetic symbol read discarded fourdigit address following extracted contents address treated either event given value ml required remainder statement including sym bol read discarded circuit returns initial state h 2 circuit energized x token fourdigit address immediately following extracted saved ssar initial alphabetic symbol read dis carded fourdigit address immediately following put sar contents address placed accumulator current value symbol symbols including next comma read discarded final value m2 may numeric name variable numeric value placed numeric register shr h name variable initial symbol read discarded contents fourdigit address following extracted placed numeric register shr next symbol read comma specified specified comma either following purely numeric value added contents accumulator contents following fourdigit address added c symbol contents accumulator incrementedby one either event current value incremented either m3 one contents accumulator put symbol table starting address given sar final value saved shr subtracted accumulator accumulator signal positive value must greater final value m2 therefore address ssar placed program counter circuit returns initial state address ssar either address h token preceding nest address next statement outside nest depending statement executed accumulator signal positive value less equal m2 circuit returns initial state thus next statement statement executed example see table 6 dimension b20 io 5 5 j n 5 bk js 1 100 l continue continue token energizes circuit 1 symbol read lsff circuit returns initial state lsff turned contents ssar place contents program counter circuit returns initial state thus statement either labeled last statement range execution effect program example assumes usual case last statement range example table 7 5 1 150 5 continue read list print list read token energizes circuit energizes flexowriter read circuits data paper tape read io buffer endof statement symbol stored data must punched one four decimal digits fixed point numbers one four decimal digits preceded decimal point floating point numbers latter may also followed 372 part 4 instructionset processor level specialfunction processors section 4 1 processors based programming language table 6 symbol table program area symbol table program area address contents address contents _______ address contents address contents 4095 4094 4093 4092 409 1 4090 4089 3488 3487 3486 3485 3484 3483 3482 348 1 3480 3479 3478 3477 3476 3475 3474 3473 3472 3471 3470 3469 3468 b 34 1 next free symbol 88 1 table address machine form constant 20 00 machine form 05 j statement 5 l 00 05 01 address 2nd 21 nest j 0100 0101 0102 0103 0104 0105 0106 0107 0108 0109 01 10 0111 01 12 01 13 01 14 0115 01 16 0117 0118 01 19 0120 0121 0122 0123 0124 0125 0126 0127 0128 0129 0130 h 01 address statement 57 1 following nest 34 address data 81 00 01 04 01 00 04 l 34 77 h 01 address preceding 01 nest j 34 68 w 34 64 3467 3466 3465 3464 3463 3462 346 1 3460 3459 3458 3457 3456 3455 3454 3453 3452 345 1 3450 0131 0132 n 0133 0134 0135 0136 0137 0138 0139 0140 00 0141 05 0142 0143 0144 0145 0146 0147 0148 0149 0150 0151 0152 0153 0154 0155 0156 0157 34 60 00 05 01 address last 21 1 nest 34 52 b 40 91 1 34 81 j 34 68 letter e single positive negative digit indicating power ten numbers must separated comma distin guish since format information available read circuits squeeze outﬂ blanks first set digits starting beginning io buffer memory address 0 read 24bit register size three bit memory words required data numerical registers set zero initially first character minus sign bit mantissa sign position x set one internal form data representation described earlier section languagedesign philosophy plus sign action required since zero mantissa sign position indicates positive mantissa action depends next character 1 next character numeric sign given first character numeric must fixed information 10 buffer 6bit code two significant bits 0 code numeric character q placing information 24bit register easier stand consider 16bit mantissa register hold four decimal digits 8bit sign exponent register x hold 2 bits sign information exponent digit point constant four bits numeric information gated least significant four positions register next character numeric shifted left four posi tions character also gated least significant chapter 31 1 system design fortran machine 373 table 7 symbol table program area address contents address contents 4095 0100 4094 00 0101 h 4093 05 0102 01 4092 01 0103 22 4091 01 0104 4090 0105 40 4089 0106 89 4088 0107 4087 0108 00 4086 00 0109 01 4085 05 0110 04 4084 01 0111 4083 16 0112 01 0113 50 0114 04 0115 0116 00 0117 05 0118 01 address 0119 01 statement 01 20 continue 0121 0122 position continues comma read nu meric code four gated least significant four positions x since arithmetic unit assumes decimal point left data action insures fixed point number properly interpreted next character sign one decimal point must floating point number case following digits stored indicated three shifts always taken whether four digits stored required insure proper interpretation number comma follows series digits action taken e follows digit following placed least significant 4 positions x minus sign found following e setting exponent sign position x precedes action comma read 2 first piece data placed x alphabetic character following read token read dis carded next 4 digits used address significant two digits stored decre mented appropriately store remainder data remaining data 1o buffer stored one one sequence addresses given remainder read list subscripted variable list requires additional arithmetic operations compute correct address current index values original dimension information stored symbol table operations given later arithmetic statement description token io buffer reached next char acter read list read character also token circuit returns initial state however flexowriter energized read data 10 buffer processing proceeds reading read statement returns circuit initial state print statement circuit operates almost exactly inverse fashion described detail list variables used sequence extract data proper memory locations place x registers contents regis ters put sequentially 10 buffer together 6bit codes decimal point plus minus signs commas e symbol appropriate places data thus output floating point form token read flexowriter print circuits energized circuit returns initial state example read b ci print b ci appearance symbol table program area apparent previous examples since would add little description circuit action omitted ab arithmetic statement execution unit energized 8bit alphabetic character code first character variable name represented ﬁaﬂ discarded either following fourdigit data address saved data address subscripted variable computed saved register reading discarding symbol circuit executes expression h accordance given sequence arithmetic operator symbols used control arithmetic unit partial results time execution stored 10 buffer area course otherwise unused 374 part 4 instructionset processor level specialfunction processors arithmetic statement execution storage areas partial results called di di specifies ﬁlevelﬂ computation taking place equal zero left paren thesis encountered increases current value 1 exception occurs left parenthesis immediately follows symbol case level remains zero also necessary store control information relates par tial results two control values required every level count left parentheses level stored number zi incremented incompleted arithmetic operations still quired current level indicated giving indicator value 1 2 3 also needed indicators distinguish clarify significance control values analysis made following ex pression contains unneeded legitimate sets parentheses b cd ef g 1 circuit reads saves address reads discards puts circuit level 0 first two left parentheses cause set 2 value b stored plus sign followed left parenthesis cause indicator set 1 indicate condition ﬁb ﬂ since might cases find ﬁb ﬂ set zero indicate plus sign left parenthesis also causes incremented one since one level also set 1 value c stored division symbol followed left parenthesis causes set 2 indicate condition ﬁcﬂ since might find ﬁcﬂ cases left parenthesis also causes incremented 2 next left parenthesis increments 1 2 value stored value e put respec tively multiplication symbol followed left paren thesis causes set 3 indicate condition ﬁd e ﬂ set zero indicate plus multiplication symbols respectively left parenthesis f causes incremented 3 z set 1 value f placed d3 arithmetic statement circuit always puts final value computed level arithmetic unit regis ter sr whenever zi 0 clearly zi must decremented one right parenthesis basic circuit operation level described earlier report see page 363 footnote 2 2 set 1 indicate division 3 4 section 4 processors based programming language therefore first right parenthesis f causes 1 equal zero condition causes value stored placed sr value decremented 2 tz 3 0 causes computation sr stored dzo next two paren theses f caiise equal zero therefore result placed sr value decremented 1 since equal 2 equal 1 computation dsr made stored final parenthesis f causes 1 equal zero therefore result goes sr decremented zero since one zero computation sr made result stored g causes computation g made stored final two parentheses cause 1 zero therefore value placed sr another right parenthesis found would cause error condition indicated 3 symbol causes contents sr stored previously saved memory address subscripted variable addresses computed easily initial dimension statement information saved sym bol table current value subscripts assume first data location array a1 j stored location abase 1 dimension statement read dimension a5 10 computation abase 5 j 1 gives correct data address nonzero value j true complete data word stored per memory word machine expression slightly complicated machine partial result locations actually 3 words long course accommodate data additional word used store control information 4 bits used ti remaining 4 bits zi count counter therefore actually incremented decre mented 7 instead one thus level 14 since 10 buffer 100 words long li count great 15 adequate since allows 210 left parentheses much longer 10 buffer length since appearance symbol table program area would add little discussion example omitted conclusion illustrated detail machine direct trans lation simple algebraic language possible would therefore chapter 31 system design fortran machine 375 seem investigation made economic position solution viskvis software compiler solution unfor tunately present authors sufficiently versed compiler construction make comparison actual construction machine independent unit probably reasonable except particular circum stances small oneshot scientific problems form bulk computing however adjunct larger general purpose machine may well serve need hardware inter preter widely used higher level languages result fairly complete design control circuits machine estimated 10000 diodes 100 flipflops would needed alone including arithmetic circuits design techniques used simple straightforward rather expensive designs probably consid ered use integrated circuitry references andej61 basht64 international business machines corporation general information manual fortran form f28807401 december 1961 ibm 1620 fortran preliminary specifications form j2r42002 april 1060 appendix variable match unit vmu fig 4 symbol table end load mode contain variable names used program together empty locations reserved data associated names pro gram area end load mode program variable names modified first letter retained followed symbol table address data associated name since variable name may appear many times program search required loading see name already exists symbol table search symbol table st consists comparing name variable name statement loaded statements loaded appropriate circuit fig 3 10 buffer program area memory fore variable name statement exists physically io buffer function vmu make search ener gized ﬁcalledﬂ loading circuits dimension computed go read print arithmetic statements variable names appear output action vmu symbols used appendix described table 8 set either ok aok eol flipflops flipflops respectively indicate st either holds variable question result previous loading variable subscripted previously loaded dimension statement loading circuit endoflist eol token found indicating absence variable st state diagram circuit shown fig 4 triggered start vmu signal state 0 circuit goes state 1 next clock pulse sends state 2 starts search st going 1 2 10 counter cio contents saved register scio since name may scanned symbol table counter stc initialized 4095 since st scanned sequentially downward character variable name 10 buffer found corresponding position name st character said matched vmu proceeds state 2 state 3 first character name scan matches otherwise state changes 2 8 match signal given match match signals generated result comparing contents st location undergoing scan contents reside memory buffer register mbr contents register comp character 10 buffer first character put comp calling circuit thereafter vmu picks 34 transition clo stc counters incremented decremented respectively vmu oscillates states 3 4 long matching continues comparison process termi nate either arithmetic operator read 10 buffer sending circuit state 6 state 3 st contents cause match signal respect contents comp unit causing transition state 4 5 state 6 digit next read st corresponding position appearance operator 10 buffer clearly names okff set 1 transition 6 0 macle hand another alphameric character st corresponds operator 10 buffer names transition 6 5 made state 5 circuit reads end nonmatching name st digit end name causes transition 57 stc stepped 3 data locations next st entry cio reini 376 part 4 1 instructionset processor level specialfunction processors section 4 processors based programming language stc read st dset okff read stc c vmu olset eolff match syt stc c read stc read stc stcl save stcm stcl savestcm scio cio read 110 read io fig 4 variable match unit tialized start name sought first character name read placed comp circuit goes 2 stated earlier first character 10 buffer match contents st state becomes 8 mismatch caused eol token st eolff set 1 state 0 reached mismatch due present st location stc decremented 5 steps 2 fourdigit numbers stored circuit returns 2 try match next st entry mismatch caused digit statement number information chapter 31 1 system design fortran machine 377 table 8 cio cp comp sar save sclo sh r sr ssar stc sd x eol match counter input output buffer 4 bcd numeric char acter 4 bits counts set given num ber program counter execution points state ment executed loading points loca tion program loaded 4 bcd numeric characters counts set given value comparator register 8 bits loading holds char acter matched character memory execution saves input symbol drives execution circuits acts second rank memory buffer register save address register 4 bcd numerics counts dur ing loading holds address last nest execution auxiliary counter 2 bcd 8 bits total auxiliary register bit set independently others 4 bcd numeric register holds temporarily value cio special shift register 4 bcd character shifted left 1 bcd character 4 bits time 24bit register used accumulator arithmetic unit bits 18 916 1724 gated independently special save register 4 bcd numeric used auxiliary register loading execution symbol table counter 4 bcd character counts 8 bits mbr decoded single alphabetic character a2 8 bits mbr decoded digit 09 bits 14 represent bcd value digit bits mbr decoded one following operators 8bit character precedes subscripted variable name symbol table 8bit character precedes statement number last statement nest symbol table 8bit character follows token program area 8 bits mbr decoded 2 bcd digits 4 bits 8bit character placed current end symbol table signal generated content mer identical content comp requires decrement stc 4 get next entry unmatched alphabetic character st reason mismatch variable read end state 12 done state 5 st symbol could caused mismatch array symbol symbol sends vmu state 9 match occur subscripted variable name thus match causes transition 9 13 states 13 14 correspond state 3 4 simple variable matching proceeds reading arithmetic operator 10 buffer causes transi tion 16 corresponding digit st causes aokff set circuit returns 0 time decre ments stc necessary order stc hold address first constant given dimension state ment caused st entry transition 16 15 corre sponds 6 5 transition st name longer 10 buffer name state 15 rest name stepped however next two words st hold address next st entry therefore saved put stc transition 15177 otherwise corresponds transition 57 single variable however match state 9 circuit steps rest name st state 10 initializes stc next st entry transition 101112 note vmu returns 0 state setting either eol ok aok flipflops stc holds precisely address needed action eol needs replaced starting stc address new variable name case ok aok stc address one placed program since holds data address simple variables address required indexing constant subscripted variables calling circuit used vmu received one 3 signals vmu certain statements signals used detect syntax errors none calling circuit takes whatever action necessary variable name scanned arithmetic statement loading circuit fig 5 arithmetic statement consists string alphameric symbols ss grouped form variable names numeric symbols grouped form constants arithmetic operator sym bols separate arithmetic statement loading circuit calls vmu circuit find variable names described puts new name st required 378 part 4 1 instructionset processor level specialfunction processors section 4 processors based programming language start vmu 3 arith stat v w prog 9 cpssar start read 8 lsff1 res lsff shift shr shr fig 5 arithmetic statement loading adjust shr puts data address program 8bit bcd forms operator symbols simply put program constants put program conversion machine form state diagram circuit shown fig 5 scan circuit signal arith stat sends circuit 0 1 2 scan circuit saved address beginning statement register scio used initialize cio statement read beginning first symbol arithmetic statement must variable digit takes circuit state 3 symbol put program prog vmu initialized started one vmu signals possible valid simply forces circuit state 5 35 transition circuit loads appropriate address pro gram name matched matched existing name circuit first goes state 4 puts name symbol table going state 5 state 5 loading accomplished variable names separated operators loaded program cycle state 5 prog note convention repre sents operator symbol explicitly specified another exit 5 variable names cause transition state 3 output action state 2 floating point constants loaded via states 595 decimal point indicates floating point constant takes circuit state 7 note minus sign preceding constant simply operator processed state 5 shr cleared preparation storing follow ing digits state 7 e received digits fraction shr left adjusted adjust shr less four placed program area exponent sign found transition 8 9 exponent digit together exponent sign bit stored program area chapter 31 1 system design fortran machine 379 9 5 transition fixed point constants handled state 6 important difference digits left adjusted shr 04 put program exponent since decimal point assumed precede first data word see fig 1 takes circuit initial state statement happens last nest statement number load circuit set lsff 1 also put st address word following symbol first nest ssar register since program counter cp holds correct exit address statement placed address given ssar transition state 0 transition signal start read also sent paper tape reader order put next statement 10 buffer hardware implementation vmu state diagram function mentioned paper plus auxiliary ones initially represented state diagram form state diagram loading arithmetic statement fig 5 variable match unit vmu fig 4 describe method used realize circuit perform function defined given state diagram sd example use vmu information needed present sd operations righthand side ﬁ sd output operations required per formed order implement operations must specify actual register gating signals memory read write signals arithmetic unit signals etc required call various signals microsteps output operation therefore realize sd given function must implement microsteps corresponding output operations begin listing state diagram output opera tions corresponding microsteps example state 2 fig 4 match signal present supposed increment cio counter read 10 buffer consequently microsteps required tcio signal causes cio incremented one cio mar signal causes cio gated read signal initiates memory read cycle change state signal causes vmu go state memory address register 2 state 3 therefore execution microsteps order would implement 23 transition fig 4 microsteps vmu listed end appendix largest number microsteps transition one state another 8 occurs transition state 8 state 2 maximum number microsteps determined control cycle counter constructed count high maximum since case number 8 need 3 flipflops realize addition ﬁone hot lineﬂ decoder needed count one one line decoder ﬁoneﬂ output also needed state diagram counter realizes ﬁskeletonﬂ state diagram skeletal counter tells us state change given present input signal symbol thus skeletal counter ﬁknowsﬂ circuit state 2 match signal present change state 3 upon receipt change state signal real ization skeletal counter described bashkow 19641 use outputs skeletal counter indicate us state outputs decoder control cycle counter input lines sv match match connect shown fig 6 gate figure 3 inputs except requiring input line information one input comes input set match etc second input comes state diagram skeletal counter indicates unique state state dia gram finally third comes control cycle counter output gate line indicating unique micro step ands feed gates actually energize given microstep example output lead ﬁreadﬂ gate connected ﬁreadﬂ terminal memory assume control cycle counts sequence 1 2 etc lead numbered 1 go first microstep sequence one numbered 2 go second etc therefore see following microsteps executed order listed states 0 1 2 5 fig 4 circuit causes execution shown fig 6 state 0 state 1 state 2 start vmu change state cio scio 0100 0000 1001 0101 stc stc mar read change state match increase cio cio mar read 380 part 4 instructionset processor level specialfunction processors section 4 processors based programming language ld match ma1 states 0 1 2 variable __ 4 17 clock reset 0 e start vmu change st cioscio 010000001000101stc stc mar pi fig 6 state diagram implementation chapter 31 1 system design fortran machine 381 change state change state decrease stc stc mar read change state state 5 decrease stc decrease stc decrease stc scio cio cio mar read change state state 2 match state 5 state 0 fig 4 start vmu signal takes state 1 accomplished top fig 6 microstep needed change state state 1 fig 4 next clock pulse reaching state 1 causes transition state 2 case need save cio contents register scio cio scio set stc 4095 4095 stc shown bcd form get contents address symbol table counter readstc latter implemented two microsteps stc mar followed read command core memory transition 1 2 fig 4 accomplished next 5 gates shown fig 6 next gates shown accom plish transition state 2 3 match next accomplishes transition 2 8 match case nothing need done finally lowest two groups gates implement required microsteps circuit changes state 5 7 4bit digit code sensed causes circuit remain state 5 decrementing stc 8bit variable code read chapter 32 microprogrammed implementation euler ibm system360 model 301 helmut weber summary experimental processing system algorithmic language euler implemented microprogramming ibm system360 model 30 using second readonly storage unit system consists microprogrammed compiler microprogrammed string language terpreter 10 control program written 360 machine language system described results given terms microprogram main storage space required compiler interpreter performance obtained role microprogramming stressed opens new dimension processing interpretive code structure content higher level language matched appropriate interpretive language executed efficiently microprograms existing computer hardware introduction programs written procedureoriented language usually processed two steps first translated equivalent form efficiently interpretable translated text interpreted ﬁexecutedﬂ interpretation mechanism translation process datainvariant flowinvariant operation consists two partsan analytical part analyzes higher level language text generative part builds string instructions directly inter preted machine analytical part translator depends higher level language generative part depends set instructions interpretable machine historically one set instructions could interpreted effi ciently machine ﬁmachine languageﬂ figure 1 outlines scheme processors ibm system360 family microprogrammed machines ﬁ360 machine lan guageﬂ interpreted wiredin logic interpretive microprogram stored control storage turn inter preted wiredin logic therefore certain sense 360 language ﬁmachine languageﬂ processors efficiently interpretable language processors cvmm acm vol 10 9 pp 549558 september 1867 system360 family compatible true ﬁmachine lan guageﬂ processors microprogram language language lower level ﬁ360 languageﬂ contains elementary operations machine operators elements data flow storage operands conceivable compile program written higher level language microprogram language string string would undoubtedly contain substrings occur sequence could call substrings procedures move main string replacing occurrence procedure call symbol followed parameter designator pointing particular procedure object program takes appearance sequence call statements final step eliminate call symbols furnish interpreting mechanism interprets remaining se quence ﬁprocedure designatorsﬂ process described result definition string language development microprogrammed interpreta tion system interpret texts string language situation similar system360 case string language corresponds 360 language programs written higher level language compiled string language text stored main storage string language interpreter corresponds microprogram fig 1 processing programs written higher level languages via trans lation machine language i82 chapter 32 microprogrammed implementation euler ibm system360 model 30 383 interprets 360 language texts consists recognizing part read next consecutive string element branch appropriate action routine action routines execute particular procedure called string element essential difference situation 360 case string language reflects features particular higher level language well features particular hardware better general purpose 360 language gained defining string language provid ing microprogrammed interpreter method definition described seen elements string language correspond directly elements higher level language simplifying datainvariant flowinvariant transformations performed elements string language also welladapted microprogram struc ture machine therefore compiling process see fig 2 minimum generation necessary produce string language text compiler shorter runs faster important aspect object code execution also faster string language interpreter case 2 coded take care necessary operations concise form whereas case 1 necessary compile whole sequence machine language instructions elementary operation higher level language examples compilation 360 code add operation cobol two numbers different scaling factors compilation machine instructions table lookup search operations etc cases string language interpreter fig 2 execute function much faster machine language interpreter fig 1 execute equivalent sequence machine language instructions therefore object code execution faster scheme 2 object code performance much demand object storage space economy string language interpreter also written string language tightly packed input doto ovtput doto intermediate analyrir higherlevel intermediate text itcrprcter fig 2 processing programs written higher level languages via trans lation interpretive language possible translated program compact possible take less storage space eqnivalent machine language program scheme fig 1 ideas applied experimental microprogram sys tem higher level language euler wirth weber 1966a 1966133 described problem areas approach indicated ideas future development offered special considerations euler higher level language euler wirth weber 1966a 1966bl dynamic language means programs written many things done object code execution time done compile time languages euler also contains basic functions compara ble basic counterparts machine languages machines compile machine code dynamic properties special functions would require rather lengthy sequences machine language instructions would consume considerable object code space require high object code execution time therefore language like euler interpretation string language level interpreter dynamic features special functions included microcode yield much higher object code economy object code performance compilation machine language interpretation chine language three examples euler given 1 dynamic type handling variable euler constants varying type assigned dynamically example 3 c 4515 c true quantities assigned variable types integer real logical procedure therefore euler quantity carry type indicator along operator operating variable perform dynamic type test adding operator instance b test dynamically whether operands type number integer real type testing done string language interpreter minimum time whereas would require extra instructions program compiled 360 machine language 2 recursive procedures dynamic storage allocation euler procedures called recursively eg f c formal n n 0 1 else n fn 1 384 part 4 1 instructionset processor level specialfunction processors storage allocated dynamically eg new n n 4 begin new list n order cope problems euler execution system uses run time stack operation accompanied stack pointer manipulations microprogram accom plished minimum time general even without extra time overlapped operation proper whereas extra instructions would required program com piled 3 list processing euler includes list processing system lists general tree structure eg c 3 4 5 6 7 true list operators provided like tail cat subscripting b ca3 c b cat c tail c string language interpreter handles list operations directly efficiently special microprograms program would compiled 360 machine language sequence instructions would required list operation euler system ibm system360 model 30 experimental processing system euler language written demonstrate validity ideas system running ibm basic operating system con sists three parts 1 translator written model 30 microcode trans lator onepass syntaxdriven compiler translates euler source language programs reverse polish string form interpreter written model 30 microcodel interprets string language programs 110 control program written 360 machine language2 iocp links translator interpreter oper ating system handles 110 requests translator interpreter 2 3 stored second readonly storage compatibility ros model 30 360 microprograms stored first readonly storage 360 ros model 30 section 4 processors based programming language system experimental system features euler includedonly general principles demonstrated restrictions 1 real numbers included integers recog nized interpreter microprograms operators divide integer divide remainder exponentiation coded type symbol included garbage collector provided therefore system comes error stop list processing program used available storage space 32k bytes 2 3 4 also reasons simplicity system written 64k system36o model 30 storage areas tables compiled programs stacks free space assigned fixed ad dresses string language source programs translated defined closely possible interpretive language used definition euler wirth weber 1966a 1966b question whether ideal directly interpretable lan guage corresponding euler source language given model 30 hardware left open also attempt made define string language becomes relocatable use time sharing conversational processing mode three storage areas used execution system 1 program area 2 stack 3 variable area program area translated program string language consists sequence onebyte symbols operators begin end c go etc symbols trailer bytes associ ated instance symbol number three trailer bytes 24bit absolute value integer constant symbol reference two trailer bytes one containing block number bn second one ordinal number chapter 32 microprogrammed implementation euler ism system360 model 30 385 operators else two trailer bytes containing 16bit absolute program address eg 11 operators trailer bytes label listbuilding operator stack execution time stack consists sequence 32bit words contains block procedure marks control proc essing blocks procedures temporary values various types first 4bit digit word stack always type indicator format words given fig 3 variable area variable area area 32k bytes long 32bit words used storage values assigned variables lists also auxiliary words procedure descriptors see type procedure fig 3 format entries exactly format stack entries see fig 3 exception mark never occur variable area microprogramming ibm system360 model 30 fagg et al 19641 microprograms sequences microprogram words micro program word composed 60 bits contains various fields control basic functions ibm system360 model 30 cpu basic functions storage control control type procedure iowa type undefined u value magnitude hexadecimal 169 type logical value true 1 13 upmflj false 0 type lahel mp block ahich label defined na 1wiit absolute drogram address mark pninter points stack location mark 5 dp ic j type reference mp mark poiiiter poinis stack irwation mark tilnck ahirh variahle defined lot location nf nnrd variahle area rontains value assigned trr variable mp mark printer pint stack lncarion mark hlnck prrjcediire prredure defined link pointer tr anrd variahle area contains additional infnrmatirn hn hlock niimher rf tlnrk procedure procedure defined pa 16hit program arldresq string code procedure starts length numher elenicrit list 163 ioc stored coiifecutive storage locations 16bir lucatinn ff first liit element variable area lists mark mark coiisistl 3 rrords stack hililt time block procedure entered static link static link mark embracing block hn hlrrck numher dynamic link dynamic link mark emhracing block procedure return address hit program address return upon normal exit procedure ifor procedure marks field 0 hlock marks last stack word iti mark list descriptor see type list variable list hlork mark actual parameter list procedure mark fig 3 format words stack variable area 386 part 4 1 instructionset processor level specialfunction processors section 4 processors based programming language 2 bus carry fig 4 simplified data flow ibm system360 model 30 data flow registers arithmeticlogicunit alu micro program sequencing branching control status bitsetting control microprogram words stored card capacitor readonly storage ccros fetching one niicroprogram word executing takes 750 nsec basic machine cycle figure 4 shows simplified form data flow ibm system360 ibm 2030 cpu consists core storage 65536 8bit bytes local storage accessible microprogrammer explicitly 360 language pro grammer 16bit storage address register n set 10 bit data registers j r arithmeticlogicunit alu con necting 8bit wide buses z b nbus temporary registers e switches gates figure 5 shows important fields microprogram word 47 bits shown fields contain various parity bits special control bits field interpretation given fig 5 microprogram words second readonly storage unit compatibility ros machine equipped 1620 compatibility feature meaning microprogram word fields explained connection fig 6 shows symbolic representation microprogram word together example appears microprogram documentation sheet fields microprogram word grouped five categories 1 2 3 alu control fields ca cf cb cg cv cd cc storage control fields cm cu microprogram sequencing branching fields cn ch cl status bit setting field cs 4 5 constant field ck chapter 32 microprogrammed implementation euler ibm system360 model 30 387 0000 000 1 0010 001 1 0100 0101 0110 01 11 1000 1001 1010 101 1 ___ __ ____________ _______ 0 1 nooccsi ls x l 1 l l llss ro store 3f x 2 x h h x hts4 thr zcs4zs si gi uvmn 4 r0rovec ots4oss 5 x rzvalid dr ltmn xl t150vec 1s l alu corry rl x 6 xh csovec 0so tc r 7 r x xor iso r2 g7 8 osz 52 53 l ansnzs2 s6 57 xb 146 0 wrlte ms r 0 c n ijmn x k 3 54 55 g x3a h 0s6 fig 5 ibm system360 model 30 microprogram word detailed explanation provided text field inter pretation given microprogram words compatibility ros machine equipped 1620 compati bility feature fields marked contain designators explained order confuse basic principles 1100 alu control fields line designated alu fig 6 alu statement appear specify asource bsource possibly asource modifier bsource modifier operator destination possibly carryin control carryout control ca asource field controls one 10 8bit data registers connected transient aregister therefore ainput alu cb bsource field controls whether r l dregister ckfield connected transient bregister therefore binput alu k cb 3 speci fied field 4bit constant field ck doubled ie four bits used high digit low digit aregister alu input straightcross switch highlow gate function controlled cffield depending value field input gated alu 0 low l high digit h admitted cf 3 gates eight bits straight whereas codes cf 5 6 7 cross two digits byte admitting low xl high digit xh digits x bregister alu input highlow gate truecomplement control highlow gate controlled cgfield manner highlow gate ainput truecomplement control operated cvfield admits true byte alu inverted byte controls sixcorrect mechanism decimal addition operator carry controls given ccfield field specifies binary addition without carry handling addi x6x7 ros addr constant alu storage status setting branching sequence coord coord format symbolic representation 01 1101 rfkhdc write hz 54 lzs5 g4g5 c4 c4 cd example fig 6 symbolic representation system360 model 30 micro program word 388 part 4 instructionset processor level specialfunction processors tion injection 1 1 instance simulate subtraction connection binput inverter addition saving carry bit 3 register osave c lsave c addition using old carry stored bit 3 register saving new carry bit csave c codes specify logical operations xor cdfield specifies register result alu operation gated one 10 data registers speci fied z means alu output gated nowhere lost storage control fields line designated ﬁstorageﬂ figure 6 storage statement appear specify whether microcycle ready cycle write cycle store cycle nostorage access cycle storage address supplied cmfield whether storage access main storage local storage cufield note full storage cycle 15 psec corresponds two readonly storage cycles 750 nsec codes cm 3 4 5 specify read cycles addresses supplied register pairs uv lt respectively read cycle reads one byte data core storage storage data register r write cycle regenerates data storage data regis ter r address supplied last read cycle store cycle acts exactly write cycle except inhibits read cycle immediately preceding insertion data byte storage rregister cufield specifies whether storage access main storage ms local storage 256 bytes explicitly ad dressable 360 language programmer microprogram sequencing brunching microprogram word stored unique address ros 13bit ros address register w3 w7 x0 x7 holds address word executed symbolic representation microprogram fig 6 ros address given hexadecimal upper right corner last two bits address repeated binary upper margin execution microprogram step next sequential word executed instead address next word executed derived follows high five hits w remain unless changed special command microword explained socalled module switching next six bits xo x5 supplied cnfield written hexadecimal symbolic representation fig 6 low two bits set according conditions specified ch cl fields x6 set according condition specified ch section 4 processors based programming language instance ch 8 bit r2 transferred x6 ch 6 x6 set one last alu operation carry occurred set zero carry occurred x7 controlled cl instance cl 0 x7 set zero x7 5 x7 set one digits r valid decimal digits le ro r3 5 9 r4 r7 5 9 x7 set zero either digit r valid decimal digit le ro r3 9 r4 r7 9 microprogram sequencing scheme allows fourway branch execution microprogram word status bit setting csfield allows unconditional condi tional setting certain status bits specified combined register instance cs 3 s4 set one result alu operation performed microprogram cycle shows zero high digit le zo z1 22 23 0 s4 set zero otherwise time s5 set one result alu operation shows zero low digit le 24 z5 z6 27 0 s5 set zero otherwise cs 9 s2 set one result alu operation zero ie least one bits zo z7 equal 1 result alu operation zero s2 changed constuntfield 4bit ckfield used various purposes one instance explained alu statement supply constant bsource alu operation examples explained addressing specific scratchpad local storage locations module switching replacement high part w ros address control certain special functions symbolic representation microprograms microprograms symbolically represented network boxes fig 6 representing microword connected nets indicating pos sible branching ways figure 7 gives example microprogram explained next section exist programming systems aid development microprograms contain symbolic translators translate contents box according fig 6 contents actual fields microprogram word according fig 5 drawing program generates documen tation fig 7 drawn program systems usually also contain programs simulation generation actual ros cards string language interpreter euler string language interpreter euler entirely written model 30 microcode consists microprogram steps read next sequential symbol program string chapter 32 microprogrammed implementation euler ibm system1360 model 30 389 fig 7 microprogram operators function branch symbol group micropro gram routines perform necessary operations program byte read routines also take care dynamic type testing stack pointer manipulations routines equiva lent routines described definition string lan guage euler wirth weber 1966a 1966b figure 7 shows example microprogram interpret program string symbols internal representation x52 x50 x53 operators test highest entry stack value type logical logical operators euler work fortran sense algol sense evaluation first operand result determined false true second operand evalu ated skipped operator finds value false branch occurs program address given two x mi represents hexadecimal number composed digits n n 0 9 f trailer bytes finds value true deletes value stack proceeds next symbol pro gram string evaluate second operand similarly operator finds value true branch occurs program address given two trailer bytes finds value false deletes value stack proceeds next symbol program string operator conditional branch code deletes logical value stack value false branch taken program address given two trailer bytes value true next symbol program string executed pointer symbol program string instruction counter located functionally associated pair registers j model 30 pointer leftmost byte highest entry stack stack pointer located two registers u v model 30 following individual steps microprogram explained detail 390 part 4 instructionset processor level specialfunction processors section 4 1 processors based programming language location location address figure description address figure description 1161 11 17 1171 11 5d 11c4 c1 instruction counter ij addresses main stor age addressed byte main storage read storage data register r instruction counter updated adding 1 register j possible carry saved added 1 operator read main storage r also transferred aluto register g fourway branch occurs two highest bits ro r1 oper ator operators 52 53 50 branch goes ros word 1171 whereas operators cause branch 1170 1172 1173 indicated three lines continued complete updating instruction counter carry 1161 added first byte highest entry stack addressed uv read r fur ther fourway branch operator made g2 g3 operators branch goes 115d high order byte highest stack entry read storage r contains type entry high digit type logical contains value true 1 false 0 second digit byte tested adding xdo observing result ignoring carry s4 set 1 type 3 logical otherwise 0 s5 set 1 low digit byte 0 value false s5 set 0 low digit byte 1 value true another four way branch occurs bits g4 g5 operator operator 50or 51 occur 52 53then branch 11c4 occurs next byte read program string high byte twobyte program ad dress trailing operator instruction counter updated adding 1 j saving possible carry another fourway branch occurs bit g6 operator value stack entry operator g6 1 value false s5 l branching llcb occurs operator g6 0 value true s5 branching llc8 occurs operator g6 0 value false s5 l branching c2 c3 c4 l4 11cb g5 llc3 j6 j7 11 1e llc3 j6 l7 111f llce n8 n9 1144 llc8 j5 llc9 n5 11ca 45 11c9 occurs operator g6 1 value true s5 0 branching 11ca occurs word executed operators value false type test made type logical s4 0 branch llcl occurs type correct microprogram proceeds fetching trailing program address two bytes store new instruction counter ij done operator g7 0 word following two words llc3 11 1e operator g7 1 done word words 11c3 11 1f two bytes trailing operators stored new instruction counter ij operation completed microprogram branches back 1161 read next operator two bytes trailing operator stored new instruction counter ij carrysaving bit s3 forced zero stackpointer decremented four operator means complement add effect deletes highest entry stack observe two words entered lllf operator value false microprogram go 1145 cause forced s3 zero l l l f operation completed microprogram branches back 1161 read next operator word executed operator value true similarly llcb typetest taken types logical branch llcl occurs type correct microprogram proceeds fetching trailing program address two bytes store new instruction counter ij words llc3 111e word executed operator value false typetest made type correct trailing program ad dress skipped ij updated 1 twice 11c4 11c9 possible carries j handled 11cf 1145 stackpointer decre mented four llce 1144 word executed operators value true typetest made type correct trailing chapter 32 microprogrammed implementation euler ibm system360 model 30 391 location address figure description address skipped ij updated 1 twice llc4 llca possible carries j handled llcf 1145 stackpointer decre mented four llce 1144 11c1 g6l6n6 words executed typetest occurs error code 01 set l branch occurs error routine drawn 11 11cd seen fig 7 execution times microprograms including readout operator icycle following 6 pet 8 microprogram steps 6 psec 8 microprogram steps 6 psec value true 8 microprogram steps 75 pec value false 10 microprogram steps order compare hypothetical euler system system360 language let us assume compiler produces inline code probably give highest performance although wasteful respect storage space reasonable sequence might cli 0 stack logfalse andfalse cli 0 stack logtrue bne typeerr sh stack 4 timing true yo psec false 32 psec comparison seems indicate microprogram terpreter order magnitude faster equivalent program 360 language however comparison yield high factor functions euler simple system360 language counterparts instance listoperators begin end procedurecalloperator overhead dynamic testing stackpointer manipulation heavy example logical operations functions system360 language counterparts slower overhead relatively lighter instance arithmetic operations especially real numbers microprogrammed interprete still faster system 360 language program factor 10 cases carries occur ij uv updating disregarded timing purposes total ros space requirement string language terpreter coded routines 1000 microwords routines real number 500 microwords estimated divide exponentiation etc 400 microwords estimated garbage collector 600 microwords estimated handling 2500 microwords euler compiler translator translate euler source language verse polish string language onepass syntaxdriven compiler syntax language precedence functions f g terminal nonterminal symbols stored table form model 30 main storage also main storage space reserved translation tables character delimiters word delimiters compile time stack name table course compiled code areas fixed storage locations experimental nature system microprogram consists following parts routine reads next input character input buffer translate 1byte internal format delimiter collect name buffer part identifier convert hexadecimal part numeric constant collect number buffer ﬁprescanﬂ requires 100 microwords soon input unit collected delimiter identifier number main parsing loop entered makes use precedence tables syntax table main stor age syntactic analyzer loop requires 100 micro words parsing loop identifies syntactic unit reduced calls appropriate generation routine performs essentially functions described semantic interpretation rules euler definition micro program space required programs amounts approximately 250 ros words syntactic error detected system signals error try continue compilation process though procedure totally inadequate practically useful system deemed sufficient prove essential point minimum error analysis linkage 360 microprograms iocp approximately 60 micro words required 392 part 4 instructionset processor level specialfunction processors total compiler microprogram space therefore approxi mately 500 ros words total main storage space required approximately 1200 bytes speed compiler limited speed card reader system 1000 cardsminute excellent per formance three main reasons 1 euler simple prece dence language language extremely easy compile 2 functions compiler mainly table lookup bit bytetesting type microprogramming extremely wellsuited kinds operations 3 since target language string code example 360 machine language generative part compiler relatively short difficult assess individual contributions three main reasons high compiler performance therefore possible stage make statement whether nature language euler fact compiler microprogrammed dominant factor development microprogram since higher level language express microprogram procedures compiler compile microcode micropro grams written symbolic language explained fig 6 actually process hand translation algorithms euler definition symbolic microprogram language microprograms translated actual microcode simulated put system360 model 30 means general microprogram development system outlook general discussion hoped development experimental system euler shows help microprogramming create systems higher level languages special applications section 4 processors based programming language utilize existing computer hardware much higher degree conventional programming systems among thoughts raised scheme following investigation determine ideal directly interpretable languages correspond higher level languages although several attempts made define string languages interpretive systems stance wirth weber 1966a 1966bi mel bourne pugmire 1965 authors knowledge work published attacks question general theoretically founded manner proliferation interpretive languages develop ment microprogrammed interpreters justified better tools developed reduce cost microprogramming necessary able ex press microprogramming concepts also machine design concepts higher level language form develop compilers translate microprograms higher level language form actual microcode also good microprogram simulation debugging tools called whole relationship programming micropro gramming machine design viewed common denominator tradeoffs made ultimate goal reached effec tively solve users problem green 1966 offers thinking direction state art progress complete understanding relationships tradeoffs references webeh67 faggp64 greej66 hainl65 melba65 wirtnbba 66b tran specifications operating procedures ibm1401 ibm systems ref lib 22414552 part 5 pms level part presents pms structure dimension computer space sections arranged order increasing organizational structure complexity sections follows 1 pc 1 pc multiple pio multiprocessing n pc parallel processing n pc computers networks networks computers chap 37 lehman defines terms multiprogramming multiprocessing parallel processing 393 section 1 computers one central processor computers one pc pios control ms either two ways first pc contains k ms second separate k controls data transmission pc initializes k latter case k like p instruction received pc instead fetched auto matically k processing concurrency difficult achieve structure first discussed part 2 sec 1 page 90 sds 9109300 series sds 9109300 series presented chap 42 dis cussed part 6 sec 2 page 542 inputoutput interrupt system especially interesting whirlwind computer whirlwind chap 6 controls data transmissions ms mp using pc thus arithmetic inputoutput 395 section 2 computers one central processor multiple input output processors computer structures discussed section manu factured mainly ibm reason bias toward ibm fairly elaborate specialized structures pios computers manufacturers pios tend also general multiprocessing capability1 would place sec 3 dec pdp8 pdp8 presented chap 5 338 pdisplay ap pears chap 25 discussions given part 2 sec 1 part 4 sec 1 respectively section reader look methods transmitting data ms mp three methods used pi0 pdisplay used control tdisplays chap 25 pc directly transmits word buffer k lowdatarate devices k may request data using program interrupt k transmits data directly mp ibm 1800 chapter 33 describes 1pc9pio ibm 1800 computer five pi0 types depending components control although classify pios barely processors since instruction counter restricted behavior unless data channel ﬁdata chainingﬂ capability effect jump instruction processor ibm 7094 ii ibm 7094 ii computer discussed part 6 sec 1 page 515 description appears chap 41 earlier 709 first computer use independent pios univac chap 8 extensive k data transmission con current processing whereas 701 704 required pc control data word transmitted pios 7094 ii might looked overreaction overdesign inspired 701704 example cdc3600 casale 19623 sds sigma 7 mendelson england 19661 structure system360 part ioutline logical structure structure 360 presented part 6 sec 3 dis cussion alternative implementation 360 authors book using multiprocessors given page 585 chapter 43 gives overview isp chap 44 presents implementations various 360 models implementa tions physical processors give multiple logical processors using microprogramming interesting ibm rather conserv ative regard providing structures convenient multi programming multiprocessing design appears com plex attempt outside research environment engineering design stretch computer stretch also known model 7030 univac larc eckert et al 19591 perhaps first computers principal design goal maximizing numerical computing power stretch aptly named influence technology ibm organization initiated atomic energy commission los alamos designed interpret largescale scientific programs nuclear engineer ing like number highrisk major developmental efforts computer field stretch outstandingly successful computer system few5 10 built cost substantially exceeding contract price performance modestly better art time production however common similar efforts substantial positive effect state art stretch case particular 218microsecond mp core technology developed stretch transferred 7090 fact major contribution stretch modestly better 7090 design goal per formance 100 times ibm 704 computer described high level chap 34 buchholzs book project stretch buchholz 19621 outstanding text computer struc tures description stretch read computer designers computers built maximize numerical computing power also include besides univac larc lawrence radia 396 section 2 1 computers one central processor multiple inputoutput processors 397 tion laboratory livermore control data 6600 chap 39 ibm system360 models 91 85 stretch derives power 1 compound complex isp instructions 2 pms structure mp218 pswpc025 1 psw pios satisfactory switch ps mp 3 many datatypes 4 parallelism within pc involving concurrent interpre tation instruction stream using ﬂinstruction lookahead mechanism last internal pc parallelism novel stretch possibly earliest computer make use ﬁmaximumﬂ power cs listed also uses version instruction lookahead ﬁmaximumﬂ systems faced obtain computing power goes beyond basic logic memory technology available time system designed conclusion reached cases move toward internal paral lelism stretch instruction lookahead mechanism fetches next several instructions partially interprets future instruction mechanism elaborate compared straightforward instruction stack cdc 6600 chap 39 page 489 stretch lookahead complexity stems par tially interpreting instructions may later un done stretch uses basic mpcore 16384 w 64 8 parity bw tc218 ps sixteen mps connected ps via smemory bus time multiplexed 8 parity bits used give singleerror correction doubleerror detection substantial amount error protection compared standard design practice memory incor porated ibm 7090 became operational even stretch delivered thus often case large development efforts byproducts important main product single welldesigned physical pio called ex change consisting several logical pios ability state logical pios accessible mp useful important design seems better data channels ibm 7097094 series almost prototype ibm system360 pios stretch word length 64 bits operations following datatypes binary integers decimal integers address integers variablelength integers boolean vectors single double floating point length thevariable integer speci fied parameters instruction noisymode floatingpoint data provide method introducing roundoff error least significant bit program control thus problem run conventional noisy modes results com pared instruction either 32 64 bits isp processor state instruction counter dou blelength accumulator 15 index registers 6 registers 100 miscellaneous bits computing power obtained instruction set complex instructions hence instruction almost every possible operation though inverse subtract inverse divide instructions lacking however ﬁmultiply addﬂ instruction stretch complete set 16 operators boolean vec tors compound instructions formed sequence sim pler instructions also increase power instructions specify array element accessed operation element calculation get next element single instruction notice several instructions oriented toward operations arrays ie matrices type numericalanalysis tasks system built multiprogramming done stretch codd et al 19591 undoubtedly influence within ibm stretch pair bounds registers relocate protect single program interrupt scheme stretch brooks 1957al better existing ibm computers though described chap 34 importance stretch lies byproducts inspired influence ibm encouraging concern hardware project management elaborate isp complex im plementation stretch may worth effort especially one compares computer later larger elegant cdc 6600 however interesting note stretch used central component early spe cialized multiprocessor system called ibm harvest herwitz pomerene 19601 provides extremely powerful data processing capabilities pilot nbs multicomputer system national bureau standards pilot computer chap 35 first described 1959 time multiple computer criteria classify multipleprocessor computer shown pms structure fig 1 however 398 part 5 1 pms level section 2 1 computers one central processor multiple inputoutput processors mpl psw 60 w 16 bw pcsecondary computertconsole pcprimary computertconsole piothird computer mshagnetic tape treader fig 1 national bureau standards pilot computer pms diagram unlike present multiprocessors several identical proces sors pilot processor different pilot good example early attempt use multi processors successors look little like one best analytical discussions computer leiner et al 19571 machine attempt resolve contro versy shortword edsac 17 bits long word institute advanced studies computers 40 bits providing processor memory ie computers problem first computer substantial mp computers processors could concerned first computer third computer introduced proc ess devices msmagnetic tape used plugboard program memory idea independent processor ibm 7094 computer cdc 6600 inputoutput processing used though doubtful pilot inspired de signs capacitordiode store novel daring tech nology two threeaddress computers used pri mary secondary computers secondary computer 16bit words useful memory limited essentially used address calculations book keeping operation threeaddress computer could easily keep small processor busy chapter 33 ibm 1800 introduction thirdgeneration computer constructed hybridcircuit technology semiconductors bonded ceramic substrates known slt solid logic technology core primary memory 1800 designed process control realtime applica tions nearly identical ibm 1130 designed smallscale generalpurpose scientific calculation appli cations two cs perform computation bound problems 1130 1800 program compatible ﬁuniversalﬂ ibm system360 series though introduced time however 1800 uses terminals secondary memories similar identical system360 organized standard ibm system360 8bit byte thus common information media provide link two hence 1800 sometimes connected system360 preprocessor relative performance ibm 1130 1800 ibm system360 seen page 586 1800 better costperformance ratio system360 model 40 performance model 30 refer ibm 1800 although much applies ibm 1130 1800s interface facilities include large number ts connect different physical processes multiple priority interrupt facility fast response multiple pios transfer information high data rates complete instruction set realtime nonarithmetic processing include 1800 typical 16bit realtime process control computer isp straightforward ibm computers book perhaps nicest several different pios implementations unusual carefully studied important aspects 1800 include pms structure links realtime processes eg analog processes straightforward pc isp appendix 1 chapter specialized pios realtime ts pc implementation pi0 implementation chapter written expose explain aspects2 comparing 1800 whirlwind evolutionary pro gression seen isps similar better lakhoigh refer data channels pios limited isp pio fact might better called ks material chapter ha5 abstracted jbm 1800 functional characteristics manual technology 1800 shows increase capability 1800 pc mediumsized state isp six registers including three index registers implementation elegant single register array adder would provide basis straightforward pc implementation 1800 features facilitate higher information processing rates compared whirlwind major change whirlwind 1800 machines brought decreasing cost registers primary memory 1800 ks independent memory usually 1 2 words characters concurrent operation almost ms via ks possible contrast whirlwind single shared register pc one device operate time lower hardware costs allow multiple pios 1800 pios represent unusual approach information processing period pios process standard disk magnetic tape card reader conventional pios analog process signals novel interesting latter pios unusual part 1800 allow independent pro grams pi0 trivial processing tasks alarmcondition monitoring independent pc however pios limited example difficult transmit receive data block ms mp using pio without surrounding data block pi0 control words thereby transmitting control words interrupt system typical second thirdgeneration computers comparable sds 900 series chap 42 later computers interrupt conditions used determine fixed address processor interrupts generally many conditions 100 1000 discrete levels 8 20 1800 depends program polling within discrete interrupt level level unique fixed address principal isp design problem addressing 65536 word mp thus 16bit number generated within pc address regard 1800 behaves like 12bit machines address 212 4096 word memory modes methods 1800 uses addressing reasonable noted relatively difficult write programs modify example instruction store status changed execution 399 400 part 5 1 pms level section 2 computers one central processor multiple inputoutput processors peculiar feature 1800 storage protection see page 408 feature provide program relocation capability addition protection pms structure simplified picture ibm 1800 structure given fig 1 without piodata channels kdevice adapters ms k connects pcs bus spc k ks attach pios directly pc information transferred mp k via pi0 rates 05 megawordis 8 megabitsis ibm configurator fig 2 gives restrictions possible structures together minute l details presented alternative pms structure fig 1 configurator intended show permissible structures show logical physical structure pms diagram fig 3 alternatively shows physicallogical hardware structure performance parameters lt noted pms diagram information computer component configurator fig 2 would require slightly de tails space central processorprimary memory ibm 1800 fixedwordlength binary computer 4 8 16 32kword memories 16 1 1 bits memory cycle time 2 4 microseconds 18 bits 1 bit used parity check p bit 1 bit used storage protection bit pc instruction set operates 16bit 32bit words indirect addressing three index registers used address modifica tion pc 24level interrupt system three interval timers console pc interrupt forced branch jump normal program sequence based upon external internal pc conditions devices conditions cause interrupts hardwired fixed priority levels interrupt request honored level request higher level serviced level requested masked examples interrupt condi tions 1 external process condition requires attention detected ibm name processorcontroller pc processor 1 process io controller pnlog input points data procejsing io fig 1 ibm 1800 data acquisition control system courtesy international business machines corporation chapter 33 1 ibm 1800 401 mws mpx r digital inputs fig 2 ibm 1800 dataacquisition controlsystem configurator courtesy international business machines corporation 402 part 5 pms level section 2 computers one central processor multiple inputoutput processors chapter 33 1 ibm 1800 403 analog inputs 404 part 5 pms level section 2 computers one central processor multiple inputoutput processors tconsole k tl typewriter t24 page printer t5 typewriter st t68 paqe printer mpl pc k tincrementa1 point plot k tpaper tape reader 1punch pi04 k tcard reader1 punch pi0 k sms magnetic tape pi0 3 pi0 k ystem360 interface pio6s ms removable skpak kl3sskt ir diqital input 1 w c contacts llogic voltage 3 k46skt iqi tal event pulse 1 1 input counters c 116 8bilr 16 b digital contact inputs inter upt 16 b ks kl 4skt 4 digital output contactllogic voltage ulse 16 b piosslk skt 10113 14 analoq b output p 07 tsk l 11024 analog input voltage current lo1 20 150100 200j500 mv15 v110 vi 20ma p io8 k l l z mpcore 214 pw 4096 32768 w 2pc1801 11802 1 2 winstruction technology hybrid mps 6 w 1 address 16 parity protect bw instruct ion 1965 31n bus bus 4maximum 9 pi0 per c piodigita1 input data channel piodigita1 analog output data channel pioanal0g input data channel optional pi0 control analog channelstructure qreatly simplified kadc analog input 9 12 15 bw rate 9 24 kws fig 3 ibm 1800 pms diagram simplified chapter 33 ibm 1800 405 2 3 interval timer counted previously set time interval magnetictape drive completed data transfer previ ously requested ready another request operator initiated interrupt pc console device typewriter printed character ready receive next one 4 5 primarymemory communication data transmission terminals secondary mentory two methods used transmit data mp ms mp first lowspeed devices controlled directly program character word data transmitted pc onto means execute ioxio instruc tion pc program device synchronization accomplished using interrupt mechanism devices operating direct program control include typewriter printer plotter paper tape reader punch analogtodigital converters contact sense voltagelevel sense pulse counters etc second method transferring data via piodata channe1s pi0 program started xi0 instruction pc transfer data words proceeds control specified pio completely asynchronous parallel pc program operation pi0 gains mp access independent pc pc operation suspended one mp cycle mp cycle data taken placed core storage pi0 via internal pc control registers soon pi0 satisfied normally takes one cycle pc proceeds logical state pc instructionset processor changed pios access mp method access referred ﬁcycle stealingﬂ devices ms operating pi0 control include magnetic tapes disks line printer card reader punch link ibm system360 devices operate pc pi0 control depending characteristics configuration eg analog input analog output digital input digital output process zo controls transducers analog inputs analoginput equipment includes analogtodigital converters multiplexors amplifiers signal conditioning equip ment handle various analoginput signals data input rates 20000 16bit samples per second program selecta ble resolution external synchronization 1024 via relay 256 via highspeed solid state multiplexed analog input channels connected single k analogtodigital con verter confignrator fig 2 shows allowable inputs digital inputs digital input provides 384 process terrupts 1024 bits contact sense digital input parallel register input 128 bits event input counters 1 8 16bit counting registers analog outputs 128 analog outputs provided digital outputs digital outputs provide 2048 bits pulse output contacts registers zo processors data channels piodata channels give ms ability communicate directly mp example input unit requires primary memory cycle store data collected pi0 communi cates directly mp stores data pios run even pc waiting pios two registers word count used count number words transferred block device mp memory channel address points next word transferred block channel address also used select next instruc tion program next block transfer task two basic types pios used nonchaining chaining pios provide ability transfer either single block nonchaining multiple blocks chaining directly mp inde pendent pc central processor registers physical processor figure 4 shows relationship registers pc together instructionset processor registers acces sible program shown registers accessible console description functions register given storuge address register sar pc references mp selected accessed 16bit register pi0 references mp use channel address register car active pio instruction register 16bit counter register holds address next instruction storuge buffer register b 16bit register used buffering word transfers mp descriptive name undoubtedly concocted one ibms marketing departments 406 part 5 pms level section 2 1 computers one central processor multiple inputloutput processors console core storage r e sing c timers 1 u operotion 1 monitor 4 w 0 b 5ps 1 1 connected bus input dev ces connected output devices bus control registers regis ers accesslb instruct sc 6 overflow carry processor allows processor registers reed written fig 4 ibm 1800 pc data flow courtesy international business machines corporation arithmetic factor register 0 16bit register used hold one operand arithmetic logical operations accumu lator provides factor accumulator 16bit register contains results arithmetic operation loaded stored core storage shifted right left otherwise manipulated specific arithmetic logical instructions accumulator extension q register 16bit loworder extension accumulator used multiply divide shifting doubleprecision arithmetic shift control counter sc 6bit counter used primarily control shift operations accumulator temporury u u register used store temporarily instruction operation requires facilities op register op 5bit register used hold operation code portion instruction index registers three l6bit registers used effective address calculations chapter 33 ibm 1800 407 op code overjlow carry indicators two indicator bits associated accumulator overflow carry overflow indicator turned add subtract divide instruction indicates result larger represented accu mulator overflow indicator also turned load status instruction overflow changed except testing indicator loadstatus storestatus instruction carry indicator provides information carry borrow highorder position accumula tor occurred carry indicator used add subtract shiftleft loadstatus storestatus compare instructions f displacement inbus 18bit bus linkl used carry information k pc generally 16 18 bits used although transfers magnetic tape made three 6bit characters outbus 18bit bus used carry information pc k instructionset processor operation pc program viewpoint follows isp registers declared previous section fig 4 isp registers 18bit q xr l 2 31 1bit overflow carry ssp description 1800 appears appendix 1 chapter incomplete following respects memory protect bit checking described illegal undefined struction action described double word data must aligned even odd address word boundaries else fault occurs io instruction interrupt operation given instruction formats two basic instructionword formats used one word fig 5 two word fig 6 bits within instruction words used following manner op operation code 5 bits define instruc tion fig 5 ibm 1800 onewordinstruction format courtesy inter national business machines corporation i5 8910 15 0 1 fig 6 ibm 1800 twowordinstruction format courtesy inter national business machines corporation f format bit 0 indicates singleword instruc tion 1 twoword instruction tag 2 bits specify three index registers used address modification shift count displacement 8 bits usually added instruction register index register speci fied oneword instructions modified address defined effective address ea 00 displacement added struction register ea disp displacement twos complement form nega tive sign bit 8 bit position 8 automatically extended higherordered bits 0 7 displacement used ea generation indirect addressing bit used twowordinstruction format 0 addressing direct 1 addressing indirect one level indirect addressing permitted load index modify index skip instruc tions exceptions shown isp descrip tion branch bit used specify branch skip condition bsc instruction interpreted branch bosc used interrupt routine conditions 6 bits select indicators interrogated bsc bsi instruction bit assignments conditions cond 10 0 condl1 0 condl2 0 cond 13 condl4 carry 0 cond 15 overflow 0 16 bits usually specify core storage address disp sa bo cond 15 0 eoen address 408 part 5 pms level fo direct addressing direct addressing f 1 1a 0 section 2 1 computers one central processor multiple inputoutput processors f 1 1a 1 indirect adressing 00 01 10 11 ea disps ea xr1 disp ea c xr2 disp ea xr3 disp ea address ea address xr1 ea address xr2 ea c address xr3 ea c caddress ea caddress xrl ea caddress xr2 ea caddress xr3 twoword instruction address modified contents index register used indirect address ia bit effectiveaddress generation effective address ea devel oped shown table 1 instruction set divided five classes shown table 2 storuge protection storageprotection facility protects contents specified individual locations mp change due erroneous storing information execution program status location identified ﬁread onlyﬂ ﬁreadwriteﬂ condition storage protect bit storestatus instruction used write clear storage protect bits execution instruction control write storage protect bits switch console attempt program write readonly protected location results storageprotect violation causes internal interrupt highest priority interrupt instruction interpretation process simplified pc dataflow block diagram fig 4 shows instruc tions data entering leaving memory via b register additional bits pc hold p bits mp input devices send data instructions b register via 18bit inbus output devices receive data b register via 18bit outbus eighteen bits transferred pc kmag netic tape storedprogram instruction selected various parts op code format bit etc directed control registers via b register outbus control registers decode interpret instruction instruction executed except pi0 operations instructions data memory addressed storage address register sar sar obtains memory address register register table 2 instruction set class znstnrction indirect addressing mmmnic load store arithmetic shift branch io load accumulator double load store accumulator double store load index store index load status store status add double add subtract double subtract multiply divide exclusive shift left instructions shift left logical shift left logical aqt shift left count aqt shift left count shift right instructions shift right logical shift right arithmetically aqt rotate right aq branch store branch skip condition modify index skip wait compare double compare execute 10 yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes yes ld ldd sto std ldx stx lds sts ad sd eor sla slt lc slca sra srt rte bsi bsc bosc dx wait cmp dc xi0 letters parentheses indicate registers involved shift operations see section individual instruction mdx ldx chapter 33 1 ibm 1800 409 contents register developed one following means depending pc operation 1 2 register incremented instruction effective address instruction developed accumulator register transferred sar contents accumulator saved auxiliary u register effectiveaddress computation instruction branch contents sar transferred register following examples illustrate data flow instruction interpretation process load accumulator ld instruction oneword load instruction instruction cycle register transfers u register register transfers sar register incremented sar addresses memory location containing instruc tion memory location transfers b register outbus control registers store various parts instruction op code format tag displacement stored register b displacement register added register tag 00 register transfers register tag 00 specified xr transfers register execute cycle 9 10 11 sar addresses data word 12 13 register transfers sar effective address u register transfers register data word transfers b register b register loads register via register twoword load instruction direct addressing instruction cycle 1 1 2 register transfers u register register transfers sar register incremented 3 sar addresses memory location containing instruc tion first word memory location transfers b register outbus control registers store various parts instruction op code format tag tag 00 specified xr transfers register 4 5 6 instruction cycle 2 7 8 9 10 11 register transfers sar register incremented sar addresses second word instruction second word instruction address read b register address b register stored register b tag 00 register transfers register tag 00 register added register register contains contents xr execute cycle 12 13 14 15 16 register transfers sar effective address u register transfers register sar addresses memory effective address data word data word transfers b register b register loads register register centralprocessor communication controls direct program controz controls pc direct programmed control 10 devices basis singleword characteratatime transfers xi0 instruc tion executed one data word character transferred mp k xi0 instruction specifies 10 control command iocc function control sense read write controlled device command either directly device pio possible program sequence execute xi0 instruction device busy responding previous xi0 instruction device busy indicator signals whether device accept data control information incorrect program sequence timing may cause undetected errors ibm name adapter device adapter 410 part 5 pms level section 2 1 computers one central processor multiple inputoutput processors possible device operating synchronously program request data word transfer program sequence ready service request devices poten tial ﬁprogram checkﬂ indicator signal data lost pc kept device execute zo instruction xzo instruction used programmed 10 operations initialize pio may either one two words length specified f bit twoword instruction address either direct indirect address specified ia bit proper operation effective address must even ad dress effective address used select twoword 10 control command iocc storage iocc specifies 10 operation 10 device core storage address format twoword iocc follows explanation assigned fields area iocc104 area field specifies unique segment 10 may single device 1442 card readpunch 1443 printer etc group several units magnetictape drives serial 10 units contact sense units etc area 00000 used address system devices console interrupt mask register function iocc157 primary 10 functions speci fied 3bit function code iocc 000 001 010 011 100 removes 10 device online status places ﬁfreeﬂ mode write transfers single word storage 10 unit address storage location provided address field 10 control command read transfers single word 10 unit storage address storage location provided address field 10 control command sense interrupt level directs selected 10 device make status available accumulator interrupt level status word ilsw control causes selected device interpret address andor modifier iocc specific control action examples feed card load interrupt mask register 101 110 111 initialize write initiates write operation device unit subsequently make data transfers storage via pc initialize read initiates read operation device unit subsequently make data transfers storage via data channel sense device reads selected device status word accu mulator device status word dsw process interrupt status word pisw sensed instruction area 00000 specified console status interval timer status may brought accu mulator specified unit address code modifier field current contents accumulator destroyed execution sense interrupt level sense device initialize read initialize write read write modijier iocc1815 bit field provides additional detail either function area example area spe cifies disk function specifies control 100 particular modifier code specifies direction seek opera tion case modifier serves extend function however area specifies group 10 devices function specifies write ool particular unit address specified modifier address locco 015 meaning prescribed 16bit field dependent upon function specified 10 control command function initialize write 101 initialize read 110 address specifies starting address table storage 10 block contents table data words control information function control 100 example area speci fies 1443 printer address may specify specific control action function sense 011 ill address field ignored instead increment time equivalent memory cycle taken selected 10 device inter rupt level places status word accumulator chapter 33 1 ibm 1800 411 4 function write 001 read 010 address speci fies storage location data word xi0 execution interpretation process 1 ea xi0 developed accumulator routed storage address register sar locate iocc ea bit position 15 sar forced select ea 1 iocc area function modifier found area function modifier routed b register outbus control device speci fied area bit position 15 sar turned allow address portion iocc word transferred mp location specified effective address ea b register function initialize read initialize write control address part iocc routed b register outbus address part initialize readwrite iocc goes channel address register car pio function read write address routed b register regis ter sar sar addresses memory location data transmitted 2 3 4 5 interval timers three timers provided supply realtime information program corestorage locations 0004 timer 0005 timer b 0006 timer c timer incremented ac cording associated permanent time base hardwired 0125 0250 05 1 2 4 8 16 32 64 128 milliseconds timers started stopped program control count reaches zero interrupt requested level assigned timers interrupt interrupt feature provides automatic branch normal program sequence based upon external condition maximum 24 external interrupt levels groups available arranged order priority twelve external interrupt levels standard interrupt level unique corestorage address assigned several devices may connected single inter rupt level program polling used differentiate possible signals causing interrupt interrupt level status word ilsw used identify specific condition causing interrupt level request service internal interrupt one following error conditions occur internal interrupt pc invalid op code mp parity error even number bits storageprotect violation channel address register check error internal interrupt takes priority external interrupts masked mask register exists masking unmasking inter rupt levels interrupt level masked initiate request service unmasked device status word dsu dsw indicators usually fall three general categories 1 2 3 routine status conditions error exception interrupt conditions normal data servicerequired interrupts process interrupt status word indicators pisw pew indi cators physically located pc turned events external computer eg contact closures voltage shifts io processors1 pc initializes pi0 xi0 instruction pi0 priority extent 10 device ready send receive data word pc stopped word transfers core storage pc data conditions undisturbed except memory locations receive data input device 10 devices operated concurrently must separate pios xi0 instruction pi0 specifies 10 control com mand iocc function initialize read initialize write however even though device operates pio xi0 instructions pc used sense device status control registers channel address register channel address register car 16bit register used store mp address next word addressed pio pi0 car pi0 associated car selected assigned 10 device selected area code modifier iocc word car incremented 1 transfer contents cab ibm name data channel dc 412 part 5 pms level section 2 1 computers one central processor multiple inputoutput processors channel address buffer common channel address buffer cab used channel address registers address mp cycle steal request occurs car requesting pi0 transferred channel address buffer channeladdressregister check bit channel address register car checking provided ensure first word addressed selected car first word correct data table thus check determines pc program set pi0 program correct1yl car check made devices address iocc word transferred selected car bit bybit comparison made contents selected car contents b register corresponding bits equal car check error occurred car check error terminates pi0 task initiates internal inter rupt word count register word count register provided pio word count register loaded contents wordcount portion data table 215 register decremented time data word transferred data table scan control register scan control register provided pi0 chaining ability scan control register bits stored first word first data table bit positions 0 1 second word bit positions 0 second data table subsequent data tables chain scan control register controls 10 device pi0 operation end data table follows single scan data table stop interrupt single scan data table stop interrupt continuous scan data table different data table interrupt end table continuous scan data table different data table interrupt io processor program operation sequence steps pi0 program given memory map format program shown fig 7 1 pc issues xi0 instruction references iocc word initializes pio area code modifier iocc select 10 device function specifies type operation initialize read initialize write etc 2 completely arbitrary program fault check since processors volved 3 address portion iocc word stored car selected data channel 10 device car check made selected car b register b 4 5 cycle steal requested pio car transfers cab cab addresses core storage first word data table car incremented 1 first word data table contains scan control bits bit positions 0 1 b word count bit position 2 15 transferred respective registers 10 device end first cycle steal another cyclesteal request pi0 occurs car incremented step 5 transfers next higher address cab cab addresses core storage car incremented first data word transferred 10 device via b register data channel word count reg ister 10 device decremented 1 end second cyclesteal cycle 6 7 8 steps 7 8 continue cyclesteal basis occur 10 device requests data transfers car incremented data transfer wcr decremented sequence continues last data word data table transferred last word transfer sensed wcr reach ing zero indicator device device chaining ability demands data transfer made device reinitialized another xi0 instruc tion chaining steps second subsequent data tables see steps 1 8 9 contents word following last data word first data table transferred car word must contain address next data table 10 next cycle requested car transferred cab address core storage contents first word next data table transferred b register word must contain address 10 b car check performed car incremented next cycle steal requested car transferred cab cab addresses mp scancontrol bits wordcount bits transferred second word 1 11 chapter 33 ibm 1800 413 0 15 0 15 x10 instruction sc word count word count 22 sc continuous interrupt 1001 first data word word count 54 ingle scan 1002 1022 11 last data word 2002 11 first data word c 1 2055 last data word b ond stop interrupt fig 7 ibm 1800 datachannel tables chaining memory maps first data table b second data table courtesy international business machines corporation data table respective registers car incre mented 1 data transferred 10 device cycle steal basis via b register data channel cab addresses core storage transfer data word b register time cab addresses core storage car incremented 1 next cyclesteal request occurs car transferred cab wordcount reg ister decremented word transferred last data character transferred word count decremented zero operation continue speci fied scan control register see section scancontrol register 12 13 special data channels four pi0 types special functions 1 analog input block data transfers comparisons analog inputs limits 2 digital inputoutput 3 analog output 4 digital output analoginput datu channels memory maps fig 8a b illus trate command formats interpreted analog data chan nel programs list limit values placed table fig sa analog input compared limits operation sequence read specific addressed analog voltage called multiplex point mpx compare input voltage limits stored table following analog address limit word contains high low value bits 07 815 respec lthe ibm multiplexor allows multiple inputs read tana1og digital converter sequentially 414 pari 5 pms level io section 2 1 computers one central processor multiple inputoutput processors address first mpx point location j iiiiiiii l1i11 di1iiiili limit word 11 address 6 limit word jliii iiiiiiii llncl iiiiiiii_ 00 address c 11 address limit word io address e jp etc l limit word follows k perform comparison word contains address mpx address 47 limits used second mpx point comparison performed third mpx point fourth mpx point comparison performed fifth mpx point 31 i9 used 31 23 ilnt wr 3012 location 2999 1 word count 12 1 starting toble addrerrbo15 3000 multiplex address 1 3001 1 value 1 3011 value 11 locaticm 301 5 car check word 3015 1 3016 word count 25 3017 1 multiplex address 1 3018 1 3041 value 35 value 12 3043 al 1nitiolize read b location 3201 3202 3203 3204 3321 loccrim 3402 3403 3434 3521 3522 sicrtins iocc 35 24 word contains address lvord count adc dolue 47 adc flue 82 adc value 14 adc volue 47 adc value 82 adc value 141 1 starting table addr 3201 starling table addr iocc 1 ai in1 rd ii fig 8 ibm 1800 datachannel analoginput instruction format memory maps multiplexor address table limit words comparisons b data table chained sequential control c multiplexor address table random addressing analogtodigital converter storage tables random addressing used second data channel chapter 33 ibm 1800 415 word count 1 control initial digital input group address 1 scan word count n 1 control output address data 2 data 1 data rn zrol word count 2m digital input group address1 data 2 data rn b data n c scan control word count 2n initial output address 1 data 1 output address data2 output addresses datag fig 9 ibm 1800 datachannel digital analogoutput instruction formats memory maps digital input sequential b digital input random addressing c digital analog output sequential digital analog put random addressing courtesy international business machines corporation tively analoginput value lies outside limit range initiate interrupt figure 8h describes second use data channel pi0 accepts sequence analog inputs packs table following address initiation instruction analog inputs ts either fixed selected cyclic fashion multiplexor two pios used concurrently one pi0 controls input series analoginput addresses fig 8c second pi0 packs corresponding analog values second table fig 84 digitalinput data channels digital parameters events read mp control digitalinput data channel memory map fig 9a shows control format selecting inputting block sequence external data memory map fig 9h illustrates general ability address inputs random read succeeding mp locations digital analogoutput data channels memory maps fig 3c show program format used digital analog output data channels channels output selected data points 416 part 5 pms level section 2 1 computers one central processor multiple inputoutput processors external analog digital ks pi0 similar digital input data channel conclusions tried show typical thirdgeneration computer used process control many facilities 1800 possesses general pios rather special designed monitor control process independent pc although pios powerful providing parallel data transmission use like multiprocessing systems nontrivial pc isp fairly straightforward one write program using ap preciate simplicity chapter 33 ibm 1800 417 appendix 1 ibm 1800 isp description pc state ao15 qo15 1015 xr 1 3 10 l5 ov c r mu state mo ffffl 61p 0 l5 pc console state check stop switch uspb switch spv indicator instruction format instructioni01015 opd4 ion4 shopo7 opoi 0589 f io5 t41 ioib7 d15 io15 dsgna 15 signgxtenddc8mq 15 a015 i11015 ia old bo cold cond45 olol5 effectiv address calculation process zo15 0a f dsgn oa 7 f dsgn xrt 1 0 f ia 0 f 0 f ia mn1 0 f f ia xrtll iaa xrt z015 f dsgn f 7 ia f ia mia appendix ibm 1800 isp description accwnulator accumulator frtension mutiplier auotient double instruetior location counter index registers 0iierfloii indicator carru indi ea denotes running comutcr length mp parity protect bits pc stops storage protect wiolation occurs write storage protect elits enables writing bits arord storage protect violation indicator set 1 memory reference made orotected iuord operation code shift ooeration code count format specifies 1 2 word instruction tag index register specification disnlacement short address afldress irrirect aciiress bit branch bit coniytions test effective address 1 word relative 7 word relatioe indexed 2 word direct 2 iiord direct indexei 2 iord inirect 2 word indirect indexed effective address index register ivstructions 418 part 5 1 pms level section 2 computers one central processor multiple inputoutput processors appendix 1 ibm 1800 isp description continued zdin15 z15 z process locating econd operand double length z15 iz xid15 7 f idsgn index increment f 7 ia f ia mal s05 shift count cazcuzatcnn 0 d1015 0 xrtlol5 tnstruction interaretotion process runinstructionoll mli next fetch f 61 f tl 2 next 1 2 uord instruction instructionuexecution execute instructicrr yet anﬂ tnstruction fzerutior pr0cess instructiondxecution load arithmetic lo ldd op ildol aoq tmzomzd double load sto op 11010 4 mz store accmlotor std op iloll mzomzd taoq double store ad op 10010 ovcoa mz sd op iooil ovcoloa aoq mzcclzd double subtract op 11000 mzl load accm lator op ioooo ovcd mz op ioooi ovcoaoq ana mzlomzd add double add subtract op 10100 3 aoq x mz muztipzy op iolol ovq taoq mz mod mz divide iogica instruct ion op ll100 mz op illol v mz logical eor op illlo mz loycal ezclusiiie logical compare cmp op 10110 mz1 compare mczl 1 1 2 dcm op loll1 aw mzlpzdl 1 double comnare aq mzlmzdl 2 shifts sla shop ooolococoo shift left lopical x 2 logical c agi x 2 logical 1 c ai slt shop 000106o10 shift douhle lpft lopial sra shop ooollcoo 2 shist right logical srt shop ooollolo ana 2 shift right 0 rte shop 0001 ioool 1 aoq 2 slca shop 00010od101 shift 7eft cv4 court p logical rotate rotate right 0 chapter 33 ibm 1800 419 appendix 1 ibm 1800 isp description continued 0 ax 2 c ai f 0 normaiizea cxrtl019 normal izeexponenta xrc t189 0 1 slc shop ooolcnll 7 0 v ao 0 paq paq x 2 c casl 0 bq tnorrnaiizeanq coxrt normal izeexponenta lox op 01100 0 tz 0 xrtl tz stx op 01101 0 mz 0 mzi txrtl sts op oolol f bo mzbc condl5 bo 8 id c oooocbcoov coov 00 los io ooiomcoomoooooomm c iolllu bsc op 01001 i9 ov iollp skipcondition f tz skipcondition 7 f kid ov c 0 ekibcondition ov d15 v ic dl4 v al5 d13 v 0 dl2 v ao dl v ao dl bosc op olool skipcondition 7 f 1 interrupt 7 skipcondition f z interrupt dl 9 ov bsi op oiooo 1 tz mz f d15 ov 0 skipjondition tz pzl 1 mdx op 01110 f 0 f dsgn 0 f mal tmal dsgn msumo v m1010 msumo msurno15 mtal dsgn 0 txrtl txrtl xi xsurno v tla xsurnqo 1 1 xsurndl15 xrt dsgn wait 3000 shift left count load index instruction counter store index instruction countei store status load status branch skip condition overflow carry accumulator even accumulator greater zero accumulator negative accumulator zero branch interrupts branch store instruction regie modify index skip local branch result zero sign change result zero sign change 420 part 5 1 pms level appendix 1 ibm 1800 isp description continued section 2 computers one central processor multiple inputoutput processors io control instruction xi0 op ooool execute io defined loccoll emzlomzdl next executeloinst ruct ion end instructiondzecution io instruction format io addresso15 ioccc0l address io data io device area94 ioccciio4 io device name 10 function57 loccl357 io modifier825 locclc815 device function details device mode line io function 0 device mode write io function device mode read io function 2 device mode sense interrupt level io function 3 device mode control io function 4 device mode initialize write io function 5 device mode initialize read io function 6 device mode sense io function 7 chapter 34 engineering design stretch co pu terl erich bloch summary stretch computer advanced scientific computer variable facilities floatingpoint fixedpoint variablefieldlength arithmetic datahandling facilities performance goal 100 x 704 speed achieved highspeed circuits multiplexing simultaneousoperation technique instruction datafetching well overlap within execution units massive overlap multiplexing results complicated recovery routines lookahead instruction units units described detail arithmetic units significant algorithms used floatingpoint arithmetic flexible set circuits using currentswitching technique overridinglevel facility described well packaging circuits printed cards frame gate concept also shown performance figures hardware count illustrate size complexity performance system introduction stretch computer dunwell 19561 project started order achieve two orders magnitude improvement perform ance existing 704 although computer like 704 aimed scientific problems reactor design hydro dynamics problems partial differential equation etc instruc tion set organization handle ease dataprocessing problems normally associated commercial applications processing alphanumeric fields sorting decimal arithmetic order achieve stated goal performance factors go computer design must contribute towards performance goal includes instruction set buchholz 19581 internal system organization data instruction word length auxiliary features statusmonitoring devices circuits packaging component technology one give hundredfold increase speed combining interacting contributing factors performance obtained proc ejcc pp 4859 1959 paper reviews engineering design stretch system primary concentration central computer main contributor performance new techniques devices instructions pushed limit set present technology therefore analysis convey best prob lems encountered solutions employed stretch system early system design appeared evident sixfold improvement memory performance tenfold improvement basic circuit speed 704 best one could achieve meet proposed performance criteria system organized way took advantage every possible overlap systems function multiplexing major portion system processing operations simultaneously anticipa tion occurrences wherever possible system capable making assumptions based probability certain events might occur means provided retrace steps assumption proved wrong simultaneity multiplexing operations reflects stretch system levels overall systems organiza tion cycle specific instructions following descrip tion discussed detail one considers stretch system fig 1 overall point view becomes apparent major parts system operate simultaneously 2psec 16384word core memories selfcontained clocks addressing circuits data registers checking circuits memories interleaved first two memories addresses distrib uted modulo 2 four interleaved modulo 4 modulo2interleaved memories used primarily instruction storage since highperformance instruc tions halfword formats used average rate ob taining instructions one per z psec similarly 05psec 42 1 422 part 5 pms level section 2 computers one central processor multiple inputoutput processors instruction memories mod 2 interleaved operand memories mod 4 interleaved 2p sec core 2p sec core zp sec core 2p sec core 2p sec core 2p sec core gi gig gi gi i1 11 memory bus 1 memory bus central computer 1 io exchange disk synch unit 1 disk 1 1 console 11 reader control adapter adapter fpt 4 x lo6 words 5 tape tape tape adapter adapter adapter 729 ix tape fig 1 stretch system transfer information memories memory bus permits new addresses information pass bus every 200 mpsec linked memories computer exchange initial instruction computer coordinates starting 10 equipment checking errorcorrection information arrangement information memory words fetching storing information memory functions executed without use computer meantime continue data processing computation central computer processes executes stored program simultaneity multiplexing functions reached ultimate h simultaneouslyoperating inputoutput units b c c dataword rate achieved use four modulo4 organized memories addressing memories discussing computer organization general features must mentioned completeness word length fj4 bits plus eight bits parity checks errorcorrection codes memory capacity addressing possible 256000 words randomly addressed storage positions external memory except 32 first addresses positions consist internal registers accumulators time clocks index registers instructions singleaddress instructions exception number special codes imply second address explicitly instruction set fig 2 generalized contains full set single doubleprecision floatingpoint arith metic full set variablefieldlength integer arith metic binary decimal also generalized set index modification branching set well set chapter 34 1 engineering design stretch computer 423 10 instructions told 765 different types instructions used system instruction format fig 3 makes use half full words half words accommodate indexing floating point instructions optimum performance two sets instructions use rigid format fullword formats used variablefieldlength instructions notice latter specifies operand field address leftmost bit length field byte1 size well starting point offset implied operand byte generic term denote number bits operated accumulator halves word independently indexable general monitoring device used important status triggers called interrupt brooks 19571 system system monitors flipflops reflect internal mal functions result significance exponent range mantissa zero overflow underflow program errors illegal instruction protected memory area inputoutput conditions unit ready etc status flipflops cause break normal progression stored program fixup purposes status automatically interrogated e unit variablefieldlength instruction times computer vocabulary modifier examples instruction category number instr class variable field length arithmetic binary decimal signed add memory unsigned load store sign negative sign divide 280 32 3lndec radix conversion logic connects 48 16 logic statement floating point arithmetic normalized unnormaliz e sign opposite sign negative sign noisy mode add single 8 double loadistore mpysingle 8 double div remainder interchange divide cumulative mpy square root 24 0 indexing arithmetic direct medl ate progressive 43 branches unconditional indexing dicator bit ﬁb set 0 leave bit invert bit store inst ctr 68 transmitswap i10 instruction 24 total 735 fig 2 instruction set 424 pari 5 pms level yte 8 byte 7 byte 6 byte 5 byte 4 byte 3 byte 2 byte 1 section 2 computers one central processor multiple inputoutput processors ecc pty data formats index word ecc parity count refill value lual inb expone nty point data word adr isin count word mantissa fraction 1 ecc parity refill 4 tll 11 par address di r ect index j op flag 0 i8 25 28 46 63 71 instruction formats address 1 opol point i1 0 18 28 31 binary decimal fig 3 data wordand instruction word formats organization stretch two instruction words four operands fetched simultaneously addition execution instruction done parallel simultaneously described fetching functions units computer loosely coupled together one controlled clock system turn synchro nized master oscillator multiplexing units computer results large number registers adders since stretch computer one considers internal organization majority corn puters produced last eight years 704 case point organization looks shown fig 4a sequential flow instructions computer due processing execution next instruction called memory compare fig 4b showing chapter 34 engineering design stretch computer 425 timesharing major computer organs longer possible computer 3000 register positions 450 adder positions despite multiplexing simultaneous operation suc cessive instructions result appears sequential stepbystep internal operation utilized made design interlocks quite complex data flow data flow computer shown fig 5 comparable pipeline steady state namely filled large output rate matter length true startup execution instructions fast bears relation stages must progress data word 1 instruction instruction fetch instruction data word instruction execution 4 instructions 4 data words instruction instruction updating execution 70 4 stretch fig 4 comparison stretch 704 organization 426 part 5 1 pms level r 2 word section 2 computers one central processor multiple inputloutput processors 2word fr exchange exchange instr word bufffr operand buffer instr word buffer indexing unit operand buffer operand buffer e operand buffer lookahead checker bus v i1 pitransfer bus 11 operand 171 register accumulator 1 ab interrupt 1 system ar ith metlc 1 check 11 arith checker inbus fi serial arith unit fig 5 stretch computerunits data flow memory bus communication link mem ories one side exchanges computer monitors requests storage fetches memory sets priority scheme since 10 units hold requests exchange get highest priority followed computer computer instructionfetch mechanism priority operandfetch mechanism told memory bus gets requests assigns priority eight differ ent channels since memory accessed multiple sources accessed complete cycle busy condition exist memory bus tests busy conditions delays requesting unit memory ready inter rogated data fetches return address remembered requesting unit receives information becomes available accomplish time information quested receiving data register reserved status requests stores fetches processed 200 mpsec rate time busy priority conditions exist return word requesting unit 16 psec direct function memory readout time instruction unit blaauw 19591 computer instruction set small memory index word storage arithmetic unit operation many six instructions various stages execution instruction unit fetches instruction words mem chapter 34 engineering design stretch computer 427 ory steps instruction counter performs indexing instructions initiation data fetches preliminary decoding class instruction recognizes instruc tions executes indexing instructions branches conditional unconditional instruction unit executes case conditional branches makes assumption branch successful assumption availability two fullword buffer registers keep flow instruction computer continuous therefore rate instructions entering instruction unit practical purposes independent memory cycle since high speed instructions halfword formats used four one time buffer storage soon instruction unit starts processing instruction moved buffer thus making room next memory word access fig 6 incidentally halfword instructions fullword instructions intermixed within word therefore latter cross word boundary permits maximum packing instructions memory also serves facility automatic program assemblers compilers adder path index registers transfer bus lookahead complete instruction unit system fig 6 noted index registers part instructionunit data path therefore permitting fast access long transmission lines index word 16 index words available programmer index registers consisting multiaperture cores oper memory bus lookahead load lines checker bus v memory address bus j fig 6 instruction unit 428 part 5 pms level section 2 computers one central prbcessor multiple inputloutput processors ated nondestructive fashion since representative pro gram index word used nine ten times without modi fying permits fast operation conditions additional time applied modification involved processing instruction unit updated dexed instruction enters level lookahead fig 5 besides instruction necessary information associated instruction counter value certain tag information also stored level operand already requested instruction unit enter level directly checked error corrected awaiting transfer arithmetic units execu tion interlocked counter mechanism lookahead keeps four levels step preventing outofsequence execution structions even information succeeding one available previous instruction started preaccessing operands lookahead instruc tions instruction unit leads sometimes embarrassing positions fixup routine must provided consider program n store accumulator n 1 loadr n2 addm assume instruction n lookahead waiting execution n 2 enters lookahead reference made since data stored position subject change store instruction lookahead must recognize ﬁforwardﬂ result instruction n received level n 2 stored another example case instruction unit assumed conditional branch would executed instruction stored lookahead recognized branch successful modifications addressable registers made instruction unit meantime must restored lookahead case acts recovery memory information similar condition exists interrupts occur due arithmetic results lookahead data stored pertaining registers modified erroneously meantime restoring recovery routines described break instruc tion unit processing interrupting temporarily flow instruc tion indexing arithmetic units described later slaves look ahead receiving operands instruction codes also startexecution signal conversely arithmetic units signal lookahead termination operation case ﬁto memoryﬂ operations place lookahead result word transfer proper memory position arithmetic units design arithmetic units established along lines similar design lookahead instruction unit every attempt made speed execution arithmetic opera tions multiplexing techniques overlapping algo rithm mathematically permissible arithmetic units consisting serial unit parallel unit use arithmetic registers namely double length accumulator consisting 128 bits doublelength operand register cd consisting 128 bits reason use arithmetic registers fact time shift floatingpoint variablefieldlength operation vice uersa made program therefore result obtained floatingpoint operation serve starting operand variablefieldlength operation chief reason double length registers definition maximum field length 64 bits field start bit position therefore cross word boundary executions floatingpoint mantissa operations varia blefieldlength binary multiply divide operations per formed parallel unit whereas floatingpoint exponent operation variablefieldlength binary decimal add type operations executed serial unit squareroot operation binarytodecimal conversion algorithm executed unison units salient features two units described serial arithmetic unit brooks et al 19591 fig 7 serial arithmetic consists switch matrix extract 16 con secutive bits ab cd 16 bits aligned way loworder bit field specified struction right end field wraparound circuit feeds carrypropagate adder case logicalcon nect instructions logic unit adder output true complement unit binarytodecimal correction unit used subtract decimal operations inverse process ex tracting used insert processed byte back register without disturbing neighboring positions notice one clock cycle information extracted arithmetic per formed result inserted back registers addition arithmetic information checked parity checks switch matrices duplication comparison arith metic procedure duplicate unit chapter 34 1 engineering design stretch computer 429 wrap around 8 16 fr lookahead 1 1 wrap around 8 16 kcumulators 8 bit true com p pass around 8 bits ti operand registers truekomp 8 bit 8 bits pass around trueicomp 1 decimal correct write 1616 1 write matrix fig 7 serial arithmetic unit parallel arithmetic unit parallel arithmetic unit fig 8 designed execute floatingpoint operations maximum efficiency since single doubleprecision arithmetic performed shifter adder exist doublelength format 96 bits insures almost performance single doubleprecision arithmetic adder carrypropaga tion type lookahead 4 bits time reduce delay normally results ripplecarry adder carry lookahead results delay time 150 mpec 96bit binarynumber additions additions subtractions made ones com plement form automatic endaround carry shifter capable shifting 4 positions right 6 positions left shifter arrangement takes care majority shifting operations encountered normal operation higherorder shifts required suc cessive operation set parallel unit register shifter expedite execution multiply instruction 12 bits 430 part 5 pms level section 2 computers one central processor multiple inputoutput processors 3 bits 3 bits 3 bits unit register i7 carry propagate adder 100 bits shifter iii adder 1 3 bits csa 2 1 s2 c1 c2 j 1 csa 3 1 sum reg carry reg fig 8 floatingpoint arithmetic unit multiplier handled within one cycle accom plished breaking 12 bits groups three bits action right left consists decoding group three bits observing lowestorder bit next higher group decision made multiple multiplicand one must add partial product since even multiples multiplicand available subtraction addition multiples result following example elaborate point mcd means multiplicand groups n4 n3 11 2 nl multiplier 12 bit group xxo 011 110 101 n 010 octal value 3 6 5 2 two addition5 multiples permitted 4 x mci 6 x mcd 6 x mcd 2 x mcd 1 x mcd 1 x mcd instead subtracting 1 x mcd n 1 subtract 8 x mcd n 2 x mcd 8 x mcd 6 x mcii 4 x mcd 6 x imcd 8 x mcd resulting decoding 4x mcd 2x mcd 6 x mcd 6 x mcd four multiple multiplicand groups partial product previous cycle fed carrysave adders form chapter 34 engineering design stretch computer 431 sum awbwc carry c ab ac bc four adders two parallel followed two series fig 8 output carrysave adder 4 results doublerank partial product product sum product carry cycle fed carrysave adder 2 last cycle carrypropagate adder accumulation carries since propagation carries required four cycles multiple multiplicands added operation fast main contributor fast multiplytime stretch divide scheme robertson 19581 similarity multiply scheme multiples divisor used namely 32 x divisor 34 x divisor 1 x divisor plus shifting strings ones zeros results generation required 48 quotient bits within thirteen machine cycles machines using nonrestoring divide method require 48 cycles 48 quotient bits following example explains technique scheme depends use normalized divisors dividend dd 101000000000000 divisor dr 1100011 2s comp dr dr 0011101 34 dr 100101001 using skip ouer 10 101000000000000 dividend 1 101 101 step 1 0011101 add dr remainder negative 1st quotient hit 0 shift one position leading 1 indicates next quotient bit must 1 qq2 01 011010000 remainder step 2 1100011 add dr 100101 11 overflow remainder positive q 1 leading zero indicates q4 0 1011100 remainder step 3 0011101 add dr 1llj001 negative remainder qn 0 leading 1s indicate qbq7q8 i11 number quotient bits per cycle cycle 1 01 2 cycle 2 10 2 cycle 3 0111 4 b problem uith hotli skip ozjer 10 34 32 complement 101000000000000 11011010000 step 1 0011101 qiq2 01 100101001 11 11 1 1001 step 2 add 34 dr table lookup indicates qrq4qsq6q7q8 100111 quotient bits generated per cycle cycle 1 01 2 cycle 2 100111 6 general method results generation 37 quotient bits per subtraction mantissa operations multiply divide performed parallel unit serial arithmetic unit executes exponent arithmetic case overlap simultaneity operation used special advantage checking operation computer checked entirety correction codes employed data transfers memory inputoutput units involved particular information sent memory correction code associated checked accuracy way memory single error indicated correction made error recorded via maintenance output device within machine arithmetic operations checked either parity duplica tion ﬁcasting threeﬂ process checks overlapped execution next instruction hardware count figure 9 shows percentage transistors used various sections machine becomes obvious parallel unit instruction unit use highest percent age transistors case parallel unit due extensive circuits multiply additional hardware achieve speed divide scheme instruction unit controls consume majority transistors high multiplexed operation encountered performance performance comparisons fig 10 show increase speed achieved especially floatingpoint operations 432 part 5 1 pms level 10500 section 2 1 computers one central processor multiple inputoutput processors 60 2 unit 17900 8600 io 000 10000 8700 32700 3000 24500 6000 169100 memory controls 156 1 112 59 1 io 5 1 12 1 21 212 12 145 1 35 12 1000 18 instruction unit data path controls lookahead data path controls arlth registers serial arith unit data path controls floating pt unit data path controls ___ ch eckl ng interrupt system total double cards 4025 single cards 18747 power 21 kw transistors 1 total 1 frames 17700 19500 2 312 fig 9 component count 704 noted large number prob lems particular increase arithmetic speeds almost proportional performance increase problem whole since instruction executiontimes overlapped great extent preparation fetching instructions simulation stretch programs 704 proved performance 100 x 704 speed meshtype calculations higher performance figures achieved double tripleprecision calculations required chapter 34 engineering design stretch computer 433 circuits reviewed systems organization stretch interest discuss briefly components circuits packag ing techniques used implement design basic component used stretch highspeed drift transistor exists npn pnp version transistor frequency cutoff approximately 100 mc highspeed operation must kept saturation times explains pnp npn version used mainly avoid problem level translation would required due potential difference base col lector difference 6 volts optimum point device figure 11 shows basic circuit configuration consists current source represented 30 volt supply resistor r functional operation circuits consists two possible 0 per 1 floating point exponent range mantissa bits floating add floating mpy floating div loadistore 2 binary variable field length arith bit range 16 add lo adstor e bit mpy field divide 3 decimal ar ith meti c digit range 5 digits load store 4 miscellaneous error cor r ectlo n check ng word size ibm 70 4 _ 128 22 27 84 psec 204 psec 216 psec 24 psec 36 bits ibm 705 1 mem capacity 119 psec 799 psec 4828 psec 204 psec yes stretch 2 2048 22 48 1 psec 18psec 7 opsec o6psec 1 64 20psec io psec 150 psec 1 21 35 psec 400 psec 6 50 psec 32 psec yes yes 64 bits fig 10 comparison stretch 7051704 operation times 434 part 5 1 pms level section 2 computers one central processor multiple inputoutput processors truth table circuit diagram ii il hi output 52v 56v 6v input 5v min max 4v ref ov ref signal v 0 ltag es 64v ilulll765v circuit response delay x 20mpsec output fig 11 current switching circuits chapter 34 engineering design stretch computer 435 op symbol truth tables 6 circuit circuit 30 outputs inputs ab8x z22ze minmax signal voltages ref gnd x input 60v ym 64 65 outputs output delay 20mpsec input circuit response fig 12 thirdlevel circuit 436 part 5 pms level section 2 computers one central processor multiple inputoutput processors circuit truth tables circuit diagram min max signal voltages eli 442il 634 6v 6v i121 6v 6v 1 35 6v ref gn ref gnd beg chain 35 end chain 4 fig 13 emitterfollower circuit chapter 34 engineering design stretch computer 437 paths represented transistor c path chosen current depends condition existing base point positive respect ground 04 volts particular transistor cut making emitter transistor c positive respect base therefore making c conducting current supplied current source 6 flow transistor c load output 6 positive 04 volts respect 6 volt reference indicates equivalent function impressed time negative respect 6 volt power supply 04 volt representing therefore inverse function impressed conversely negative respect ground reference transistor conducting one keeping emitter c negative respect base current flows transistor making positive respect 6 negative respect 6 output reflects function impressed whereas additional transistor paralleled becomes obvious bases b positive output represents inverse function positive negative none bases b positive negative positive words function obtained output principle reflected circuits essen tially principle current switching current steering logical functions pnp circuits therefore two outputs circuit block available function inverse function dual circuit exists npn transistors input levels 6 volts output levels ground circuit give function thorough investigation systems design showed circuits described far versatile enough used throughout system however enough special cases resulting many data buses registers throughout machine could use distributor function overriding function caused design circuit permitted great savings space transistors adding third voltage level figure 12 shows pnp version thirdlevel circuit fig 14 circuit package 438 part 5 pms level section 2 computers one central processor multiple inputloutput processors transistor x eliminated transistors b conjunction reference transistor c would work normally current switching circuit case circuit transistor x added stipulation level x negative lowest possible level b becomes apparent x negative current flow branch circuit preference branch regardless inputs b therefore output negative provided input x negative output ill inverse input x however x positive status b determine function 5 implicitly demonstrates overriding function input x similarly npn version shown results function c input x negative positive output regardless status b x positive minimum maximum signal swings shown fig 12 speed circuits described far depends number inputs number circuits driven load response circuit anywhere 12 25 mpsec per logical step 18 20 mpsec average number inputs allowable per circuit eight number driven circuits three additional circuits needed drive three bases current switching circuits communicate long lines termination networks must added avoid reflections improve performance computer certain critical places emitterfollower logic used shown fig 13 circuits gain less one number stages require use current switching circuits level setters gain devices circuits available groundlevel 6level input change 6level circuit groundlevel circuit obtained applying ap propriate power supply levels due variations inputs driven loads circuits must designed load vary wide range resulted instability offset feedback capacitor c shown circuit functions needed computer implemented use aforementioned circuits including flipflop opera tion obtained tying pnp current switch block npn current switch block together proper feedback circuit package using smaller two printed circuit boards shown fig 14 called single card contains circuits mentioned printed wiring onesided besides components transistors rail added permits shorting addition certain loads depending use circuits rail effect reducing different types circuit boards machine twentyfour different boards used two types reflect approximately 70 total single card population due large number registers adders shifters used computer seems reasonable functional packages could employed economically wide usage results highdensity package also shown fig 14 called packaging circuits described last paragraph packaged two ways fig 15 back panel chapter 34 1 engineering design stretch computer 439 double card 4 times capacity single card wiring sides board furthermore components doublestacked rail used effect circuit variations due different applications eighteen double card types used system approximately 4000 double cards used housing 60 transistors rest transistors approximately 18000 single cards cards single double assembled gates two gates assembled frame figure 15 shows gate backpanel wiring using wirewraps figs 16 17 frame construction closed open version achieve high performance special emphasis must placed keeping noise low level required use plane fig 17 frame extended overlies whole back panel intercircuit wiring laid addition powersupply distribution system must low impedance extraneous noise induce circuit malfunction reason bus system consist ing laminated copper sheets used distribute power row card sockets wiring rules single conductor wire used maximum 24ﬁ twisted pair maximum 36ﬂ unterminated coax maximum 60ﬂ terminated coax maxirniim 100 feet whole backpanel construction application single wire twisted pair coax calculated computer program minimize noise circuit node two gates frame sliding pair power supply mounted sliding portion connecting wires frames coax arrayed layers formed drape references blaag59 broof57a 59 ruchw58 dunws56 robej58 rlosrlio bnchw57 62 rroof6o cockj59 codde5iy 62 fig 16 frame closed chapter 35 pilot nbs multicomputer system1 l leiner w notz j l smith weinberger summary pilot new nbs system possesses powerful external control capabilities versatile internal processing capabilities contains three independently operating computers primary secondary computers utilize 16 basic types instructions thus providing simple code structure many variations formats possible wide variety computing dataprocessing informa tionretrieval operations performed instructions secondary computer specially adapted performing socalled ﬁred tapeﬂ operations secondary primary computers acting cooperatively carry special complex sorting search operations third computer system called format controller specially adapted performing editing inspecting format modifying opera tions system equipped transfer information concurrently along several inputoutput trunks though two planned near future using two trunks possible maintain two continuous streams data simultaneously flowing two external units internal memory without interrupting dataprocessing program system operate wide variety inputoutput devices digital analog either proximate remotely located external control capabilities system enable machine supervise wide family external devices unscheduled basis interrupt redirect overall program automatically order assist manage national bureau standards nbs new largescale digital system designed carrying wide range experimental investigations special importance government system utilized investigating new stringent applications general types 1 dataprocessing applications system used performing accounting informationretrieval operations management purposes 2 mathematical applications system used performing mathematical calculations scientific purposes including scientific datareduction 3 control applica tions system used performing realtime control simulation operations conjunction analog computer facilities conjunction instrument instal lations remotely located necessary 4 network applications poc ejcc 7175 1958 system used conjunction digital computer facilities forming interconnected communication network machines work together collabora tively largescale problems beyond reach single machine system designed varied uses ranging automatic search interpretation patent office records realtime scheduling control commercial aircraft traffic system characterized variety features ordinarily associated single installation namely high computation rate highly flexible control facilities communicating outside world wide repertoire internal processing formats system contains three independently programmed computers specially adapted performing certain classes operations frequently occur largescale dataprocessing applications computers intercommunicate way permits three work together concurrently common problem system thus provides working model integrated multicomputer network system organization exclusive datastorage peripheral equipment central processing control units overall system contain ap proximately 7000 vacuum tubes 165000 solidstate diodes basic component units modified version one megacycle package used nbs dyseac turn evolved hardware used nbs electronic automatic computer seac result effective logical design faster memory however new nbs system run 100 times faster seac programs involving fixedpoint operations programs involving floatingpoint nipulations advantage exceeds 1000 arithmetic speed new system derives large part connecting novel type parallel adder diodecapacitor memory capable providing one random access per microsecond system contains seven major blocks indicated fig 1 namely 1 primary computer lower center 440 chapter 35 1 pilot nbs multicomputer system 441 inputoutput control c format inputoutput conk1rrent controller trunks tr4nsfers table 1 arithmetic operation times including 4 random access times last memory secondary storage high speed internal memory high speed internal memw 68817 words concurrent 16bit words de14 60 storage locations transfers 32768 total addressible stmage words total time microseconds vi v address d4t4 0 2 62 3 a0 progrim 8 dat4 second4ry operation v minimum average maximum 1 fixedpoint addition subtraction comparison fixedpoint multiplication 31 2240 fixedpoint division 73 7274 floatingpoint addition subtractiont 20 1921 floatingpoint multiplication 37 2846 shift 4 bits 75 69 8 manual data 4nd displays oﬁs control sign4ls 4 figure 2 primary storage upper center 3 second ary computer secondary storage right 4 inputoutput control upper left 5 external storage units upper far left 6 external inputoutput units readers printers displays lower far left 7 lower left external control containing special features facilitate communication people devices world outside system remotely located necessary interchanges information system outside world take place time 1 arithmetic program program arithmetic 8 control unit fsucessing unit twoaddress binary processing unit control unit binary decimal threeaddress fixed floating loﬂ system 16811 direct instructions explicit next points fulla halfwjrns sekxt 4nd mntrdl sign4s instruction i6 varieties 4 16types 16 basic types completely impromptu basis instigation either system external world acting jointly primary computer highspeed generalpurpose com puter contains arithmetic unit program control unit considerable versatility computer carry variety high precision arithmetic logical processing operations either binary decimal code wide variety word lengths formats partner computer secondary computer spe cializes shortword operations usually manipulations address numbers ﬁredtapeﬂ information supplies auto matically needed primary program third computer system called format controller see inputoutput con trol fig l specially designed carrying editing inspecting formatmodifying operations data flowing internal memory via peripheral external units system three computers external units system share access privileges common highspeed internal memory linked inputoutput external storage units via independent trunks effecting datatransfers transfers data take place external units memory units computers concurrently without interrupt ing progress computational program flexibility format controller incoming data accepted nbs pilot electronic dataprocesser fig 1 overall block diagram pilot 442 part 5 pms level section 2 1 computers one central processor multiple inputoutput processors wide variety external devices wide variety formats format respective lefthand righthand halves double operand processed simultaneously single instruc tion time two independent halfword results written back corresponding halves fulllength result location functions major units specific functions major units described briefly follows primary computer arithmetic processing unit using 64bit number word algebraic sign unit carries 7 different types arithmetical operations 5 types choice branch operations 2 types logical patternprocessing operations see table 2 arithmetical operations performed 16 possible formats example arithmetic performed using either pure binary binarycoded decimal number code fixedpoint floatingpoint notation fixedpoint operations also carried special halfword format two independ ently addressable halfwords stored single fullword storage location two halfwords processed either separately independent words concurrently duplex format duplex table 2 types internal operations program control unit program control unit interprets regulates sequencing instructions program operates 68bit binarycoded 3address instruction word see table 3 instruction word contains three 16bit codes specify addresses two operands alpha beta usually address result operation gamma main memory memory location next instruction word specified 16bit address number contained one 16 possi ble base registers 4bit code instruction word ddigits specifies one base registers contains desired word whenever register used nextinstruction address source contents automatically increased unity choice instruc tions used program branching time time may cause new alternative address number inserted one base registers register used source address number next instruction primary computer name abbreoiation secondary computer name abbreviation arithmetic operations add augment subtract multiply divide squareroot shift nonnumerical processing operations transplant segment shift generate boolean functions choice operations compare algebraic compare modulus compare equality check scale compare boolean functions ad ag sb mp dv sh sq clear add hold add store positive transfer increase decrease logical multiply compare zero compare righthand bit compare lefthand bit compare negative check primary proceed check primary wait regulate primary computer replace primary instruction secondary take input primary tl gb ca cm ce cs cb ca ha sp tr de im cz cr ci cn cp rp ri si cw control operations transfer storage units ts regulate secondary computer rs leiner notz smith weinbergerpilot chapter 35 1 pilot nbs multicomputer system 443 table 3 contents primary instruction word digits numbered 1 68 6865 6461 6057 5653 5249 4845 4441 4037 3633 3229 2825 2421 2017 1613 129 85 41 tags address alpha address beta address gamma next code mon instn operation break point ooo b c param basic e digits digits digits digits eter type digits addresses alpha beta gamma written instruction word subject automatic modification desired writing 1digit specified bit position addresses called relative addresses three addresses 3 instruction word contains 4bit code group called b cdigits respectively base register identification number 0 15 may written done address number computer actually refers equal sum modulo 216 address number stored designated base register plus addressmodification constant indicated remaining 12 bits 16bit address segment instruction word primay storage units fast access memory budget limitations initial installation system contain relatively small section internal memory diodecapacitor type diodecapacitor memory originally developed nbs 1953 fast ie capable providing one random access per micro second disadvantage relatively high cost per word storage type memory available modules 256 words subdivided follows numerical information algebraic signs tags parity check digits total word length 64 bits 4 bits 4 bits 72 bits overall system designed accommodate 32768 internallyaccessible fullwords may held storage units access times ranging 1 microsecond psec 32 psec thus minimum fast access memory backed much larger slower magneticcore memory intermemory trunsfer trunk provision made transferring blocks information various internal storage units system concurrently computation size block transferred may range single word entire contents memory addresses information transferred specified single programmed intermemory transfer instruction automatic interlocks pro vided insure future references program may make memory positions involved intermemory transfer operation automatically made data shifted new locations secondary computer arithmetic processing unit secondary computer highspeed independently programmable generalpurpose com puter operates conjunction primary computer perform 16 distinct types operations using 16bit words operations include 6 arithmeticprocessing operations 4 choice operations 1 nonnumerical processing operation 5 operations transfer digital information controlsignals tween primary secondary computers see table 2 operation times secondary computer average 2 psec computers operate concurrently transfer infor mation back forth one principal functions secondary computer carry socalled ﬁredtapeﬂ operations 1 counting iterations 2 syste matically modifying addresses operands instructions referred primary program 3 monitoring primary program 4 various special tasks use special subroutines secondary computer computers acting cooperatively made carry wide variety complex operations without unduly complicating writing primary computer programs examples operations 1 special types sorting 2 logarithmic search 3 routines involving crossreferencing items selected according attached code 4 error analyses 5 operations involving small numerical fields 444 pari 5 1 pms level section 2 computers one central processor multiple inputoutput processors secondary storage unit associated secondary computer secondary storage unit consists 60 storage locations containing 16bit words sixteen locations used base registers primary computer may selected primary computer according b c ddigits primary instruction word contents registers selected primary computer way automatically added address numbers specified primary computer instruction word secondary storage unit also capable addressed directly primary computer fifteen 4word blocks secondary storage identified 15 special primary address numbers addressable registers associated secondary storage hold address numbers current next instruction words primary program program control unit secondary computer program operates 2address instruction system addresses referring words secondary storage unit including base registers see table 4 time time primary instruction program may order insertion new instruction secondary instruction register may order transfer data either direction primary storage units secondary storage unit secondary computer program may also cause data transferred secondary storage unit primary instruction register also cause information trans ferred primary instruction register location main memory using facilities secondary computer inspect instruction word primary program selected primary store acting upon specifications written secondary program cause primary instruction either executed written replaced new instruction word memory location determined secondary types discrimination effected secondary depend upon result primary operation overflow jump etc features facilitate use interpretive programming methods table 4 contents secondary instruction word digits numbered 1 16 16 13 12 7 61 operation code 015 address ﬁgﬂ address ﬁhﬂ inputoutput control concurrent inputoutput trunks concurrent inputoutput trunks function controlling transfer information either direction internal memory external storage units inputoutput transfers initiated single internally programmed instruction carried trunk units aid automatic interlocks similar used intermemory transfer trunk preventing interfer ence progress computing program size block data transferred may range single word entire contents memory may directed addresses using two trunks possible maintain two continuous streams data simultaneously flowing internal memory two external storage units without interrupting progress computations format controller data passing internal storage system via inputoutput trunks subject concurrent processing format controller format con troller independent internallyprogrammed dataprocessing unit specially designed carrying generalpurpose editing inspecting formatmodifying operations incoming going data programs format controller stored removable plugboards primary computer program able direct format controller select whichever particular format program may appropriate among small library format programs contained boards currently attached machine among typical kinds programs format controller carry 1 searching magnetic tapes words bearing identifying addresses coded labels specified internal program selective input output data selected tape locations 2 insertion incoming data internal storage units system address locations specified incoming data 3 conversion rearrangement data stored external units formats compatible formats used internal units eg binarydecimal character conversion adjustment wordlength modules etc external storage external storage initial installation system consist mainly magnetic tape units flexibility format controller possible supplement tape units later wide variety types external units without making significant changes existing equipment chapter 35 pilot nbs multicomputer system 445 inputoutput units system designed operate wide variety input output devices digital analog input readers printers flexowriter units papertape read ers punches available initial installation punched card input readers highspeed printers along auxiliary controls may attached format controller manner indicated preceding paragraph displays two types displays provided 1 pilotlight display data control information various registers flipflops throughout system order aid rapid diagnosis equipment malfunctions programming faults 2 picturetube display realtime data stored internal memory system kinematic diagram type display important performing dynamic simulation operations require visual presentation simulated data real time human operators external control manualmonitor control term ﬁmanualmonitorﬂ coined nbs several years ago describe certain types control operations initiated either manually machine operator machine conditions specified means external switch settings former referred manual operation latter called monitor operation machine must monitor internal program determine precisely operation performed type operation performed well conditions performed specified means external switch settings feature provides convenient communication dataprocessor operator allows operator monitor progress program automatically insert new data instructions withdraw intermediate results con veniently without need advance preparation special pro grams particularly useful debugging programs checking equipment malfunctions monitor operations performed machine whenever conditions specified external switch settings occur course program eg every time program refers new instruction time program refers instruction special monitor breakpoint symbol edigits attached time arithmetic overflow occurs etc pairing particular type manualmonitor operation selected set conditions variety special composite operations performed remote controls manualmonitor operations specified initiated external devices well human operators since external switch settings control dc voltages external devices even remote machine distance via ordinary electrical transmission lines exercise supervisory control internal program machine makes possible harness together two remotely located dataprocessing machines work together cooperatively common task member interconnected network separate data processors free time initiate dispatch special control orders partners system consequence supervisory control common task may shared among various members system may passed back forth one machine need arises references leina57 59 section 3 computers multiprocessing parallel processing computers section probably general book although general pms model computer chap 3 page 65 characterizes computers struc ture lehman chap 37 closely fits model burroughs computers presented multiple pcs however ks used control device ks rather piosperhaps wise choice d825a multiplecomputer system command control burroughs d825 computer discussed together stack processors part 3 sec 5 page 257 chapter 36 emphasizes pms structure operating system charac teristics necessary multiprocessor system b 8500 successor d825 however successor b 8501 designed pios design b 5ooo system computer chap 22 discussed together stack processors part 3 sec 5 page 257 survey problems preliminary results concerning parallel processing parallel processors chapter 37 lehman provides good introduction concepts multiprogramming multiprocessing parallel processing specific multiprocessor computer struc ture postulated provide parallel processing processing ability structure analyzed instruction level significant paper ibm scientist ibm particularly advanced use multiple arithmetic processor computers 446 chapter 36 d825a ult plecorn puter system command controll james p anderson samuel hoffman joseph shifman robert 1 williams introduction d825 modular data processing system result burroughs study initiated several years ago data processing requirements command control systems d825 developed operation military environment initial system constructed naval research laboratory designation angyk3v completed tested paper reviews design criteria analysis design rationale led system structure d825 implementation operation system also described particular interest role developed operating system program coordinating system components functional requirements command control data processing ﬁcommand control systemﬂ meant system capacity monitor direct aspects operation large man machine complex term applied exclusively certain military complexes could well applied fully integrated air traffic control system even operation large industrial complex operation com mand control systems characterized enormous quan tity diverse interrelated tasksgenerally arising real timewhich best performed automatic dataprocessing equipment effectively controlled fully integrated central data processing facility data processing functions alluded typical data processing plus special func tions associated servicing displays responding manual insertion consoles data dealing communica tions facilities design implications functions considered aoailability criteria primary requirement dataproc essing facility else availability requirement essentially function hardware reliability maintainability afips proc fjcc vol 22 pp 8696 1962 user simply percentage available online opera tion time given time period every system designer must trade costs designing reliability incurred unavailability application costs unavailability high presented command control requirement hardware reliability greater commercial systems downtime complete system preventive maintenance permitted depending upon application greater lesser portion complete system must always available primary system functions system must available time data processing facility may also called upon except critical times take part exercising evaluating operation parts system fact actual simulation system functions exercises simula tions system must maintain although perhaps partially temporarily degraded reallife realtime capability must able return quickly full operation implication profound significance system design requirement system always available must system elements unsupported alternates perform ing functions critical failure points could compro mise primary system functions adaptability criteria another requirement equally difficult achieve computer system must able analyze demands made upon given time determine analysis attention emphasis given individual tasks problem mix presented working configuration system must completely adaptable accommodate diverse problem mixes moreover must respond quickly important changes might indicated external alarms results internal computations exceed ing certain thresholds example changes hard ware configuration resulting failure system compo nent intentional removal system system 447 448 part 5 1 pms level section 3 1 computers multiprocessing parallel processing must ability dynamically automatically structured working configuration responsive problemmix environment expansibility criteria requirement expansibility unique command control desirable feature application data processing equipment however need expansibility acute command control dependence much efficacy system upon ability meet changing requirements brought rapidly changing technology warfare must possi ble incorporate new functions way little transitional downtime results hardware area expansion possible without incurring costs providing capability needed time ability system grow meet demands apply conventionally expansible areas memory 10 computational devices well programming criteria expansion dataprocessing facility require reprogramming old functions programs new functions easily incorporated overall system achieve capability programs must written manner independent system configuration problem mix even interchangeable sites performing like tasks different geographic locales finally large volume routines must written command control system possible many different people different locations different areas responsibility write portions programs programs subse quently linked together suitable operating system concomitant latter requirement configurationindependent programs desirability orienting system design operation toward use highlevel pro cedureoriented language language features usual algorithmic languages scientific computations also include provisions maintaining large files data sets may fact illstructured also desirable language reflect special nature application especially true language used direct storage retrieval data design rationale dataprocessing facility three requirements availability adaptability expansi bility motivating considerations developing d825 design arriving final systems design several existing proposed schemes organization data processing systems evaluated light requirements listed many conclusions regarding schemes use computers command control reached inde pendently recent study conducted department defense institute defense analysis kroger et al 19611 singlecomputer system obvious system scheme least acceptable command control singlecom puter system scheme fails meet availability require ment simply failure partcomputer memory 10 controldisables entire system system given serious consideration replicated singlecomputer systems system organization well known time considerations active involves duplication triplication etc singlecomputer systems obtain availability greater processing rates approach appears initially attractive inasmuch programs application may split among two independent singlecomputer systems using many systems needed perform required computation even availability requirement seems satisfied since redundant system may kept idle reserve backup main function closer examination however perceived system many disadvantages command control appli cations besides requiring considerable human effort coordinate operation systems considerable waste available machine time replicated single computers found ineffective highly interrelated way data programs frequently used command control appli cations steps necessary redundant backup system take main function need arise would prove cumbersome particularly timecritical ap plication constant monitoring events required partially shared memory schemes seen replicated computer scheme modified use partially shared memory important new capabilities would arise partially shared memory take several forms provides principally shared storage storage privately allotted individual computers shared storage may kindtapes discs corebut frequently core system providing direct path communication computers goes long way toward satisfying requirements listed chapter 36 d825a multiplecomputer system command control 449 one advantage found memory private computer data protection advantage van ishes necessary exchange data computers computer failure occur contents private memory computer would lost system many tasks command control application require access data example would desirable permit privately stored data made available fully shared memory private memory considerable time would lost transferring data also clear certain amount utilization efficiency lost since private memory may unused another computer may require memory directly available may forced transfer blocks data back bulk storage make way necessary storage might added passing private 10 complements considered questions decreased overall availability decreased efficiency arise mustersluve schemes another aspect partially shared memory system control number systems employ masterslave scheme achieve control technique wherein one computer designated master computer coordi nates work done others master computer might different character others pilot system developed national bureau standards leiner et al 19571 may basic design differing prescribed role thompson ram0 wooldridge trw400 anfsq27 porter 19601 scheme recognize importance multicomputer systems problem coordi nating processing effort master computer effective means accomplishing coordination however several difficulties design loss master com puter would whole system command control availability requirement could consequently met weakness countered providing ability master control function automatically switched another processor still remains inherent inefficiency example workload master computer becomes large master becomes system bottleneck resulting inefficient use system elements hand workload fails keep master busy waste computing power results conclusion reached master established needed done design d825 totally modular scheme result analyses certain implications became clear availability requirement dictated decentralization computing functionthat multi plicity computing units however nature problem required data freely communicable among several computers decided therefore memory system would completely shared processors point view availability efficiency also seen unde sirable associate 10 particular computer 10 control therefore also decoupled computers furthermore system several computers totally shared memory decoupled 10 seemed perfect structure satis fying adaptability requirements command control structure resulted flexibility control fine match dynamic highly variable processing requirements encountered major problem remaining realize computational potential represented system course coordinating many system elements behave given time like system specifically designed handle set tasks faced time limitations previously available equipment operating system program always identified equipment running pro gram however proposed design entire memory directly accessible computer modules operat ing system could therefore decoupled specific com puter operation system could coordinated processor complement run operating system need arose became clear master computer actually become program stored totally shared memory transformation also seen offer enhanced program ming flexibility point need identical computer modules established equality responsibility among com puting units allowed computer perform master running operating system led finally design specification identical computer modules freely interconnected set identical memory modules set identical 10 control modules latter turn freely inter connected highly variable diverse 10 device comple ment clear complete modularity system ele ments effective solution problem expansibility inasmuch expansion could accomplished simply adding modules identical existing complement also clear important advantages economies resulting manufacture maintenance spare parts provisioning iden tical modules also accrue system perhaps important result totally modular organization redun 450 part 5 pms level section 3 1 computers multiprocessing parallel processing dancy required complement module type greater reliability easily achieved incorporating little one additional module type system furthermore additional module type need idle system may looked upon operating active spares thus design structure based upon complete modularity set two items remained weld various functional modules coordinated systema device electronically interconnect modules operating system program effect master computer coordinate activities modules fully integrated system operation d825 two tasks carried switching interlock automatic operating scheduling program aosp respectively figure 1 shows various functional modules interconnected via interlock matrixlike fashion system implementation important design implementation d825 studies toward practical realization switching interlock aosp computer memory 10 control modules permitted conventional solutions incor porate unusual features many 10 devices selected existing equipment exception latter theses elements discussed briefly summary d825 characteristics specifications included end paper switching interlock determined completely shared memory system would adequate necessary find way permit access memory processor fact permit sharing memory module two processors 10 control modules function distributed physically modules d825 system designated aggregate switching interlock effects electronically many brief interconnections information transferred among computer memory 10 control modules addition electronic switching function switching interlock ability detect resolve conflicts occur two computer modules attempt access memory module switching interlock consists functionally crosspoint switch matrix effects actual switching bus intercon nections bus allocator resolves time conflicts resulting simultaneous requests access bus system module conflicting requests queued according priority assigned requestors priorities pre emptive appearance higher priority request cause service request service lower priority request already queue analyses queueing probabilities shown queues longer one extremely unlikely priority scheduling function performed bus allo cator essentially set logical matrices conflict matrix detects presence conflicts requests interconnection priority matrix resolves priority request logical product states conflict priority matrices determines state queue matrix turn governs setting crosspoint switch unless requested module busy aosp operating system program aosp operating system program stored totally shared memory therefore available computer program run needed exert control system aosp includes executive routine operating system operating system calling additional routines required con figuration aosp thus permits variation application application sequence quantity available routines disposition aosp storage aosp operates effectively two levels one system control task processing system control function embodies necessary call system programs associated data location 10 complement ready programs execution finding allocating space memory initiating proc essing system control function well task processing function consists elaborate bookkeeping pro grams run programs active occupy memory space 10 commands executed 10 commands waiting external data blocks received decoded activation appropriate programs handle external data would inappropriate discuss myriad details aosp idea scope however obtained following list major functions 1 configuration determination 2 memory allocation 3 scheduling 4 5 reporting logging program readying endofjob cleanup chapter 36 d825a multiplecomputer system command control 451 fig 1 system organization burroughs d825 modular data processing system 452 part 5 pms level section 3 computers multiprocessing parallel processing 6 diagnostics confidence checking 7 external interrupt processing task processing function aosp execute program 10 requests order centralize scheduling problems protect system possibility data destruction illstructured conflicting programs aosp response interrupts aosp function depends heavily upon comprehensive set interrupts incorporated d825 interrupt conditions transmitted computer modules system computer module respond interrupt conditions however make possible dis tribute responsibility various interrupt conditions system local computer module interrupt mask register controls setting individual bits interrupt register occurrence interrupt causes one system computer modules leave program running branch suitable aosp entry entering control mode branches control mode differs normal mode operation locks response lowpriority interrupts although recording enables execution additional instructions reserved aosp use setting interrupt mask register memory protection registers transmitting 10 instruction 10 control module responding interrupt aosp transfers control appropriate routine handling condition designated interrupt interrupt condition satisfied control returned original object program interrupts caused normal operating conditions include 1 2 3 realtime clock overflow 4 array data absent 5 computertocomputer interrupts 6 16 different types external requests completion 10 operation control mode entry normal mode halt interrupts related abnormalities either program equipment include 1 2 arithmetic overflow 3 illegal instruction attempt program write bounds 4 inability access memory internal parity error parity error 10 operation causes termination operation suitable indication aosp 5 primary power failure 6 7 automatic restart primary power failure 10 termination normal completion reasons including interrupts listed evident word comment order arraydataabsent interrupt initiated reference made data present memory since array references ak made relative base location first element array necessary obtain address index value k base array fetched hardware sensing presence bit either allows operation continue initiates arraydataabsent interrupt way keeping track data use interacting programs simplified may storage allocation problem primary power failure interrupt highest priority always preemptive interrupt causes computer 10 control modules terminate operations store volatile information either memory modules magnetic thinfilm registers latter integral elements computer modules interrupt protects system transient power failure initiated primary power source voltage drops predetermined limit automatic restart primary power failure interrupt provided previous state system recon structed description external interrupt handled might clarify general interrupt procedure upon presence external interrupt computer assigned respon sibility handle interrupts automatically stores contents registers program counter necessary subsequently reconstitute state enters control mode goes standard hardwaredetermined location branch external request routine located routine responsibility determining external request line requires servicing consulting table external devices teletype buffers console keyboards displays etc associated interrupt lines computer constructs transmits input instruction requesting device initial message computer makes entry table 10 complete program program handles 10 complete interrupts activate appropriate responding routine message chapter 36 d825a multiplecomputer system command control 453 read check made occurrence additional external requests finally computer restores saved register contents returns normal mode interrupted program aosp control 10 activity mentioned control 10 activity also within province aosp records kept condition availability 10 device locations files within computer system whether magnetic tape drum disc file card represented external inputs also recorded request input file name evaluated device associated name readily available action initiated reason request must deferred placed program queue await conditions permit initiation typical conditions would cause deferral 10 operation include 1 2 3 available 10 control module channel device file located presently use file exist system latter case typically message would typed supervisory printer asking missing file 10 complete interrupt signals completion 10 operation along interrupt 10 result descriptor deposited aosp table status relayed descriptor indicates whether operation successful successful went wrong parity error tape break card jams etc indicated aosp may initiate appropriate action operation successful waiting 10 operations proceed initiated aosp control program scheduling scheduling d825 relies upon job table maintained aosp entry identified name priority precedence requirements equipment requirements priority may dynamic depending upon time external requests programs function many variable conditions time aosp called upon select program run whether result completion program interrupt condition job table evaluated realtime system situations occur wherein system program run machine time available uses time could used auxiliary functions confidence routines aosp provides capability program segmentation discretion programmer control macros embedded program code inform aosp parallel processing two computers possible given point addition programmer must specify branches indicated manner join following parallel processing computer module computer modules d825 system identical generalpurpose arithmetic control units deter mining internal structure computer modules two con siderations uppermost first programs data arbitrarily relocatable simplify storage allocation func tion aosp secondly programs would modified execution latter consideration necessary mini mize amount work required preempt program since would saved reinstate interrupted pro gram later time would data program register contents computer module running program time dumped d825 computer modules employ variablelength struction format made quarterword syllables zero one two threeaddress syllables required associated basic command syllable implicitly addressed accumulator stack used conjunction arithmetic unit indexing addresses command provided well arbitrarily deep indirect addressing data computer module includes 128position thinfilm mem ory used stack also many registers machine program base register data base register index registers limit registers like instruction complement d825 includes usual fixedpoint floatingpoint logical partialfield commands found reasonably large scientific data processor memory module memory modules consist independent units storing 4096 words 48 bits unit individ ual power supply necessary electronics control reading writing transmission data size memory modules established compromise module size small enough minimize conflicts wherein two computer 10 modules attempt access mem ory module size large enough keep cost duplicated power supplies addressing logic within bounds might noted larger modular processor system tradeoffs might indicate memory modules 8192 words would suitable modules larger thisof 16384 32768 words examplewould make construction relatively small equipment complements meeting requirements set forth quite 454 pari 5 pms level section 3 computers multiprocessing parallel processing difficult cost smaller units memory offset lessening catastrophe event failure module io control module 10 control module executes 10 opera tions defined initiated computer module action keeping system objectives 10 control modules assigned particular computer module rather treated much way memory modules automatic resolution conflicting attempted accesses via switching interlock function 10 operation initiated proceeds independently completion 10 action initiated execution transmit 10 instruction one computer modules delivers 10 descriptor word addressed memory location inactive 10 control module 10 descriptor instruction 10 control module selects device determines direc tion data flow address first word number words transferred interposed 10 control modules physical external devices another crossbar switch designated 10 exchange automatic exchange similar function switching interlock permits twoway data flow 10 control module 10 device system enhances flexibility system providing many possible external data transfer paths 10 control modules equipment complements d825 system assembled expanded selection appropriate modules combination one four computer modules one 16 memory modules table 1 specifications d825 modular data processing system computer module computer module type word length index registers computer module magnetic thinfilm registers computer module realtime clock computer module binary add binary multiply floatingpoint add floatingpoint multiply logical memory type memory capacity 10 exchanges per system 10 control modules 10 devices access 10 devices transfer rate per 10 exchange 10 device complement 4 maximum complement digital binary parallel solidstate 48 bits including sign 8 characters 6 bits plus parity 15 128 words 16 bits per word 033psec readwrite cycle time 10 msec resolution 167 psec average 360 eec average 70 psec average 340 psec average 033 psec homogeneous modular randomaccess linearselect ferritecore 65536 words 16 modules maximum 4096 words 1 2 10 per exchange maximum 64 per exchange maximum 10 devices available every 10 control module exchange 2000000 characters per second standard 10 types including 67 kc mag netic tapes magnetic drums discs card paper tape punches readers char acter line printers communications display equipment one ten 10 control modules one two 10 exchanges one 64 10 devices per 10 exchange combination selected operating system status consoles magnetic tape transports magnetic drums magnetic disc files card punches readers paper tape perforators readers supervisory printers highspeed line printers selected data converters special realtime clocks intersystem data links figure 2 photograph hardware com pleted d825 system equipment complement system includes two computer modules four memory modules two per cabinet two 10 control modules two per cabinet one status display console two magnetic tape units two magnetic drums fig 2 typical d825 equipment array chapter 36 d825a multiplecomputer system command control 455 card reader card punch supervisory printer electro static line printer d825 characteristics summarized table 1 summary conclusion belief authors modular systems sense discussed natural solution problem obtaining greater computational capacitymore natural simply build larger faster machines specifically organiza tional structure d825 shown suitable basis data processing facility command control although investigation leading toward structure proceeded attack upon number diverse problems become evident requirements peculiar area application effect aspects single characteristic might called structural freedom furthermore clear unique characteristic structure realizedintegrated opera tion freely intercommunicating totally modular elements provides means achieving structural freedom example one requirement specified minimum data processing capability always available conditions system degradation due failure mainte nance equipment remaining line sufficient perform primary system functions d825 module failure results reduction online equipment configuration permits normal operation continue perhaps reduced rate individual modules designed highly reliable main tainable system availability derived solely source necessarily case conventional systems modular configuration permits operation effect active spares eliminating need total redundancy second requirement working configuration system given moment instantly reconstructable new forms suited dynamically unpredictably changing work load d825 communication routes public modules functionally decoupled assignments scheduled dynamically assignment patterns totally fluid system interrupts priorities controlled aosp switching interlock permits instant adaptation work load without destruction interrupted programs requirement expansibility calls simply adaptation greater time scale since d825 modules functionally decoupled modules types may added system simply plugging switching interlock 10 ex change expansion functional areas may pursued far beyond possible conventional systems clear however d825 system would fallen far short goals set hardware considered aosp much part d825 system structure actual hardware concept ﬁfloatingﬂ aosp force molds constituent modules equipment complement system important notion effect beyond implementation d825 one interesting byproduct design effort d825 fact change perspective become abundantly clear computers rim programs programs control computers references andej62 krogm61 leina57 portreio thomrh3 chapter 37 survey problems preliminary results concerning parallel processing parallel processors1 lehman summay introduction discusses significance trend des parallel processing systems paper describes results obtained date project aims develop evaluate unified hardwaresoftware parallel processing computing system techniques use normal circumstances units operational could assigned specific activity within overall control program result multiplicity units multiprocessing systems failure one would degrade immobilize system since supervisor program could reassign activities configure failed unit system subsequently recognized 1 ultiprogramm ing multiprocessing parallel processing brief review literature partial listing given bibliography reveals active growing interest multiprogramming multiprocessing parallel processing three terms distinguish three modes usage also serve indicate certain historical development attempt trace history detail must rely bibliography credit contributions industrial university research development organizations emergence autonomous inputoutput devices first sug gested gill 19581 timesharing processing periph eral units computing system among several jobs thus surplus capability could applied processing leading job batch processing load stage compu tation could usefully applied successor jobs work load particular computation held 10 activity single main processor could used compu tation necessary decisiontaking scheduling allocation procedures vested supervisor program within userjobs embedded resultant mode operation termed multiprogrumming use computers online control situations applications giving rise evermore stringent reliability availability specifications resulted construction systems including two central processing units leiner et al 1959 bright 1964 desmonde 1964 mccullough et al 19651 proc ieee vol 54 12 pp 18891901 december 1966 systems advantages single processor system general environment processor system multiprogramming capability well finally following ideas first exploited gamma 60 computer dreyfus 19581 come realization multiinstruction counter systems speed computation par ticularly large problems may partitioned sections substantially independent one another may therefore executed concurrentlythat parallel several units multiprocessing system utilized process parallel independent sections job exploit macroparallelism lehman 19651 job distinguished microparallelism lehman 19651 relative independence individual machine instructions exploited lookahead machines mode operation termed purullel processing pli ibm os360 pli language specifica tion form c286571 p 741 execution program string termed tusk note parallel processing may normally include multiprocessing activity 2 approach parallel processing system design previous section indicated prime impetus development parallel processing systems arose potential high performance reliability systems may operate pools resources organized symmetrical classes property promises high auuilubility also possess great reserve power applied single problem appropriate degree parallelism yield high 456 chapter 37 survey problems preliminary results concerning parallel processing parallel processors 457 performance fast turn around time surplus resources applied jobs system potentially efficient displaying peakload averaging effect hence high utilization hardware corbato vyssotsky 19651 concept sharing parallel processing systems related cost reduction however limited hardware perhaps even significant common use datasets maintained system library file even concurrent access execution high speed store may represent considerable economy storage space processing time 10 internal memory hierarchy transfers corbato vyssotsky 19651 facilitates sharing ideas experience results cross fertilization among users prospect long term point view represents perhaps significant potential large libraryoriented multiprocessing systems finally brief summary basic advantages parallel processing systems refer intrinsic modularity may yield expandable system effect expansion user improved performance adequate performance parallel processing systems ever predicated appropriately low level overhead allo cation scheduling supervisory strategies particular must simplified related procedures minimized comprise small proportion total activity system system design must based performance objectives permit user specify time period tolerance within requires expects receive results cost obtained general entire system must yield minimum throughput time large job adequate response time terminal requests conversational mode guaranteed throughput time realtime tasks minimum cost processing batchprocessed small job needs require development executive supervisory system integrated hard ware single unified computing system finally tech niques algorithms classical computation problem analy sis programming must modified new intrinsically parallel procedures developed full advantage gained exploitation parallel systems studies date represent small fraction ground covered effective parallel processing systems come however abundantly clear systems yield potential design ap proached broad unified front ranging problem differentiate intuitively executive supervisory activities former whose costs chargeable individual user directly whereas latter absorbed system running costs analysis usage techniques executive strategies operating systems logic design technology therefore present concepts results areas obtained preliminary investigation design use parallel processing systems 3 language 31 analysis high level language requirements parallel processing received considerable attention literature may refer particular paper conway 1963 discussed concepts fork join quit recent review dennis van horn 1966 recognizing programming languages possess capa bilities express structure computational algorithm schlaeppi 19 proposed augmentations plilike lan guages portray macroparallelism numerical algorithms turn reflected proposals machine language implementation examples discuss split terminate assemble test set wait interlock resume storetest branch external execute instructions describe basic functional elements machine instructions actual realization composed suggested practical programming experience parallelism high level languages 32 split provides basic taskgenerating capability indicates addition continuing execution present instruction string normal fashion new task set tasks may initi ated execution starting specified address set addresses potential tasks queued await pickup appro priate processing unit terminate causes cessation activity task terminat ing unit volition access appropriate queue obtain next task alternatively may execute executive allocationtask determine number taskqueues accessed next according current urgency status work system assemble permits merging several tasks first n 1 tasks nway parallel set belonging single job reaching assemble instruction terminate nth task however proceed execute program string constitutes continuation n tasks machine level instructions tasking 458 part 5 1 pms level section 3 computers multiprocessing parallel processing test set wait provides interlock facility thus number tasks operating common data set may required filter certain sections program data one time may achieved instruction related s360 test set instruction falkoff et al 19641 causing task finding specified location already set go wait state system efficiency requires processors idle waiting task generally returned queue processor released work hewme directs processor processors waiting result test specified location proceed generally specified waiting tasks returned queue reactivated await spontaneous availability appropri ate processor test branch storage location permits communication tween parallel tasks based tests analogous register tests uniprocessors associated contents storage loca tions desirable since processor registers private processor inaccessible outside external execute special case general interaction facility discussed section 4 permits related tasks influ ence one another achieved application instructions already discussed however efficient provide new facility akin interrupt concept applying interaction function task may cause specified tasks execute instruction specified location comple tion present instruction thus example number processors searching particular item partitioned list caused abandon search item located one processors searching items otherwise busy redirected 4 interaction 41 interaction concept extension task interaction concept introduced preceding section fundamental efficient parallel processing particular example cited interaction form external execute instruction forms part computational procedure fact many situations arise processing intertask communication may detached problem processing carried concurrently autonomous units thereby increasing system utilization therefore propose associate active unit system autonomous interaction controller groups controllers linked special bus provides facilities whereby one unit may given time act command signal source units potential recipients thus systemizing interunit communication making concurrent activity increase system utilization remove maze intercon necting cables succeeding subsections describe func tions controllers fulfill briefly one hardware proposal realization 42 interaction activities presentday systems already exist activities type classified interaction thus example systems6o find cpu channel halt io facility channel interruptions processors timer interruptions extending concept differentiate among three classes interaction problem interaction relate logical dependencies tasks generally require waits forced branches terminations search termination previously discussed example type interaction data instruction sequence interlocks executive interaction activity concerned primarily allocation system resources consider example problem processing interrupts parallel processing system usually need interrupt computing activity may await spontaneous availability unit terminate natural lxeakp0intl interrupt become critical applied specific physical unit instead interruption steered unit virtue work processing may classed interruptable selection latter may obtained ahead time maintained interaction system basis relative urgency tasks another example executive interaction concerns constant provision queue status information active units besides simplifying scheduling activity may prevent units access ing empty queues reducing storage executive interfer ence similarly units caused access previously empty queue entry made obviating continuous testing queue status possible parallel processing system since tasks smaller jobs since many processors furthermore units operate anonymously picking task unit records task identity internal register identity table associated work queue processors therefore know tasks processors matched time since matter chance determination would require extensive wasteful table search chapter 37 survey problems preliminary results concerning parallel processing parallel processors 459 interaction system also supports activities associated accounting recording general system supervision system interaction system interaction provides controls interlocks operation maintenance physical system includes example interchange information active units validity storage map entries storage protection control queue interlocks checks counts unit availability initiation routine emergency diagnostic maintenance activity isolation malfunctioning units summary preceding paragraphs indicated many applications interaction controller common property practicality used identify poten tial interaction activities autonomous rela tive main computational stream execution require access storage 43 interaction controller 431 basic system hardware architecture intended give full description interaction controller present paper shall however outline basic structure indicate mode operation list proposed interaction instructions termed directiues first step introduce fig 1 diagrammatic descrip tion overall representative hardware system consists central processors pi local storage lsi 10 processors sci storage modules si requestorstorage queue qi communication system functionally equivalent crossbar switch iln 10 area including bulkstore files channels ch devices device control units cu interconnection networks indicated less detailed fashion 432 lnteraction controllers interaction controllers ic associated central 10 processors communicate special bus similarly localized interaction systems may provide facility certain classes 10 units devices interact amongst economically feasible interaction controller must simple figure 2 illustrates structure includes two hundred fifty bits storage half organized registers remainder used status bits appear controllerprocessor interface control obtained readonly store whose capacity depends size directive repertoire interaction directive analogous processor instruction number interaction functions required implement controller connection tenbit wide interaction bus means gates interaction occurring one one controller command bus figure 3 illustrates sequence events required implement inter action controller required associated processor initiate activity await availability bus indicated zero state attempt seize control transmitting unique identifying fouroutofeight code one controller attempt seize bus time conflict resolution procedure initiated based simultaneous transmission requesting controllers second two byte identifying code byte consists one ones followed zeros simple comparison controller trans fig 1 representative system hardware configuration 460 part 5 pms level section 3 computers multiprocessing parallel processing ___ task ident seizure code registers ___ status bits processor channel interface job ident 7v interlock id reg f interaction bus fig 2 interaction controller mitted signals state bus identifies controller ones byte since found match comparisons enables seize bus switch command state remaining controllers remain listening state controller command bus transmits signals select recipients directives follow controllers ignore communications next selection signal appears 44 interaction directives signal designating interaction function required proc essor transmitted across processorcontroller interface result execution processor instruction processor generally continue execution sequence unless required pass second interaction func tion previously issued function completed upon receipt interaction command successful seizure bus described command controller may initiate interaction required a7 bus free seize bus conflict l ernit order question fig 3 interaction sequence execution interaction transmitting sequence one directives selected units basic set directives listed table 1 compare directives frequently used seize bus select subset controllers receipt subsequent directives remaining units ignore direc tives alerted attention signal free bus provides release permits waiting controllers attempt seize bus receive provides transmittal data control lers example transmission machine instruction se lected set controllers followed directive interact thus sequence could realize basic interaction function external execute however considered fundamental efficient exploi tation parallel processing system include table 1 send compare compare received set status bits interact external execute attention free bus chapter 37 1 survey problems preliminary results concerning parallel processing parallel processors 461 explicit directive status bits may set reset appropri ate directives provide data status various systems queues interruptability given processors wait status 5 storage communication fact interest large parallel processing systems creasing rapidly technology enters integrated mono lithic era coincidence systems fact practical general purpose application miniaturization reaches stage large amount hardware required assembled compact fashion need apparent one considers communication highspeed store various classes processors may collectively termed requestors already presently available systems transmission delay storage requestors order magnitude storage cycle time cycle times still decreasing formulation hardware model fig 1 led imme diate conclusion feasibility interconnection large numbers units first established many possible systems considered preliminary studies concluded crossbar switch appropriate system early study view regular structure simplicity basic modularity particularly monolithic crossbar modules visualized possible interconnect provide networks required dimensions alternatively additionally interconnections modules provide highly available multilevel trunking systems addition switch proper crossbar network requires selection control mechanism moreover appropriate locate queues store one group conflicting requests within switching area switch complex fig 4 designed system configuration including twenty four requestors thirtytwo memory modules thirtytwo data plus four parity bit words sixteen plus two parity bit addresses result design study shows size com plexity switch excessive large scale system simplest form using standard highperformance logical devices fanin four fanout ten fourway capability use leads worst case delay seven logical levels control queue decision circuits two levels direction switch switch uses two three times many circuits central processor model 75 system36o represents consid erable amount hardware still order magnitude less hardware found units switch intercon necting moreover regular structure simple repetitive logic suggest ultimate economical realization using monolithic circuit techniques 6 usage 61 executive system basic properties outlined sec 2 give parallel processing systems potential overcome many ills shortcom ings presently beset computer systems maximum effec tiveness system must library fileoriented ever exploited efficiently overhead resulting executive control supervisory activity strangle system particularly gains sharing resources peak averaging effect must exceed additional head due resource allocation procedures conflict resolutions processing activity arising concurrent operation many units thus unified integrated design approach required software hardware operating system processing units lose separate identities merge one end storage 1 1 storage cycle select reql sconneri switching sec decoders decoder scanners request signal 181 tors n inputs ccept signal decision section crossbor switch signal fig 4 centralized crossbar switch 462 part 5 pms level section 3 computers multiprocessing parallel processing overall complex allocation scheduling procedures example basic critical arithmetic operations equally significant successful exploitation parallel processing potential problems data management man machine interactions generally problem preparation usage system restrict present discussion brief comments programming techniques task generation development algorithms possessing macroparallelism particular indicate multiinstructioncounter systems profitably applied solution large problems whose computing requirements tax speed capability storage largest computer patience users fol lowing section evaluate proposals quoting per formance measurements obtained executing simulator 62 programmed task generation study usage parallel processing systems rapid solution large realtime problems involves two aspects one hand must consider development algorithms dis playing appropriate form macroparallelism hand programming techniques must developed efficient exploitation terms problem machineoriented instructions discussed sec 4 appropriate discuss programmed task generation first simplicity consider job segment requires n executions procedure procedure include modification index registers changes distinguish individual tasks assume completion n tasks new proce dure j initiated moreover processing power available time n executions initiated n completed assume independent procedure k belonging job may initiated simplest case k terminate instruction releases processor makes available process work determined workqueue complex azo bo co st n b 5 1 go suppress split nth task initiated aal 2 p go split less p proces sors allocated split st bb1 b n go fin n itasks started proceed k call procedure ccl c n go n itasks completed proceed j call j procedure fin call k procedure execution split terminate instructions involves executive overheads instructions used indiscrim inately within system maximum p processors available job pointless partition job one time p tasks however undesirable guarantee user p processors even one processor execute program simple task generation scheme makes many entries task queue potentially concur rent parts algorithm example loop containing split instruction inefficient number much larger number processors happen available technique also leads large queues alternative termed onion peeling us puts instruction sequence containing split head procedure ends execution procedure terminate restricts queue length job segment one otherwise inefficient previous method modilfied onion peeling scheme mop restricts split terminate overhead one morel number processors actually applied segment also ensures processing completed quickly efficiently possible number processors become available job segment thus execution processors freed n tasks executed sequentially one split terminate hand number processors used execution procedure speeded accordingly maximum number p processors may applied job may limited number processors system available executive edict basic scheme illustrated program first expressions following zeroing counters ensures unnecessary splits queued quite accurate simple mop algorithm presented explicitly interlock split seqnence therefore possi bility unnecessary taskcalls may queued execution split generate nth task probability however small degradation arising interlock could significant algorithm form given appears economical chapter 37 1 survey problems preliminary results concerning parallel processing parallel processors 463 63 macroparallelism commonly used numerical algorithms data processing procedures computer programs generally sequential nature reason largely historical consequence fact mechanisms human mechanical electronic used developing executing procedures incapable significant parallel activity perhaps simultane ous coordinated use many humans advent parallel processing systems thus calls modification accepted techniques expose inherent parallelism resultant pro cedures must adapted make parallel tasks magnitude overhead involved generation becomes insignificant ultimate benefit parallel execu tion obtained going back problems selves must analyzed anew algorithms must devel oped make possible exploit parallel executing capa bility introducing mathematical program model parallelism ultimately reflects parallelism physical system phenomena studied need return fundamentals situation somewhat analogous early days electronic computing attempts commercial ap plication largely frustrated realized wide spread application required development new techniques rather adaptation mechanization existing proce dures present time however direct activity problem analysis concentrated mainly adaptation existing numerical techniques parallel processing problems basic macroparallelism selfevident include example linear algebra solution elliptic partial differential equations areas extent nature parallelism previously led proposals vector processing systems solomon slotnick et al 1962 gregory mcreynolds 19631 vamp senzig smith 19651 areas parallelism selfevident hut vector processors prove less effective algorithms model distinct physical activities file processing monte carlo techniques significant problems investigated schlaeppi 19 possible establish existence parallel tasks length tasking overheads could expected negligible classes problems studied terms extension existing algorithms development new ones particular refer extraction polynomial roots shedler lehman 19661 solution equations shedler 19661 solution linear differential equations niever gelt 19641 miranker liniger 19671 various studies directly related present project mathe matical nature best knowledge attempt yet made develop efficient parallel computer programs thus numerical methods beginning emerge enable exploitation macroparallelism solution timelimited problems appears significant reductions may obtained throughput times much work remains done reprogramming problems 7 simulation 71 experience simulation principal function design tool focus attention features require investigation explanation many results qualitative quantitative obtained simulation experiments may also obtained analytically however insight understanding gained design simulation experiments analysis results draws attention specific details difficulties undeniable value simulation development design therefore quite different system evaluation meaningful performance figures may obtained work load well defined simulation design tool 72 executing simulator present study simulation seen fulfilling number additional functions particular made available usable working model parallel processing system would give potential users incentive undertake actual programming gain limited operational experience executing simulator also required investigation commonly regarded immediate question parallel processing extent performance degradation due storageaccess interference executive queueaccess interference executing simulator operational use discussed next section note parenthetically limitation type simulator speed evaluation total system performance length time particularly using computer much slower simulated system gross nonexecuting sim ulation reasonable katz 19661 system presently modeled executing simulator cludes processors switch storage modules fig 1 storage modules accessed fully interleaved address 464 part 5 pms level section 3 computers multiprocessing parallel processing structure though clear realization interleaving partial sustain high availability decrease storage interference independent jobs individual processors system36olike structure blaauw brooks 19641 execute augmented subset s36o machine lan guage nonstandard instructions added repertoire clude functions discussed section 4 local store lsi used also instruction buffer however included model interference results quoted next section simulator configuration parameterized example numbers storage modules processors instruction execution times storage cycles nature statistics gathered printed may selected run program modular system features measure ment facilities may expanded modified required 73 simulator experiments 731 kernels simulation experiments fist concentrated investigation storage interference arising execution typical kernels numerical analysis results indicated limited condition experiments storage moduletoprocessor ratio two interference would degrade performance less twenty percent dropping five percent storage moduletoprocessor ratio eight addition local processor store use instruction buffer effectively eliminated interference expected indicating substantially due instructionfetch interference results considered generated conditions restrictive permit generalization particular set referred concurrent executions single loop thus recent experiments included many runs matrixmultiply subroutine solution electrical net work problem using appropriately modified version jacobi variant gaussseidel solution set linear alge braic equations 732 matrix multiplication matrix multiply program written two versions classical sequential program ex cluding special instructions provided standard measurement parallelism overhead interference could based second parallel program used onion peeling rather mop algorithm described sec 72 product matrix partitioned rows computation comprising one task experiments performed square matrices dimensions thirtynine forty one sixteen processors sixteen sixtyfour storage modules two sizes matrices used isolate effect commensurate periodicities array mapping address structure store demonstratively significant influence results instruction execution times frequently executed instructions used experiment given table 2 times exclude instruction fetch time one instruction fetch since overlapped unless storage conflict occurs request must queued arithmetic operations may also include data fetch rx instructions case store access time required absence internal instruction buffer processors executing program string interfere continuously instruction fetches minimize effect loops short relative width interleaving profitable unwind loops repetition resultant string stretches far possible across interleaved store program unwound way note however fact better rosenfeld 19651 repeat loop appropriately modified several times across interleaved store directing successive processors successive hut unconnected loops decrease interference much twenty percent previous case results simulation given table 3 plotted figs 5 6 note running time col 4 defined interval start first processor first task completion last processor finish final task since onion peel technique used splitting interval order 70 storage cycles start suc cessive tasks also initial interval 87 memory cycles first processor initializes program finally finish processors staggered particular sixteen processor case eight processors assigned two tasks rows succession eight three tasks former processors table 2 instruction execution time storage cycles fixed point addition 04 floating point addition 05 floating point multiplication 1 floating point division 20 split 250 terminate 250 new task fetch part terminate 250 chapter 37 survey problems preliminary results concerning parallel processing parallel processors 465 3 400k 5 300k g 200k rn 100k table 3 results matrix multiply simulation parallel processor progrom program 8 uniprocessor 40x40 401 40 n 64 16 tosks x 40tasks 1 2 3 4 5 6 7 8 9 10 11 total storage interference exec storage storage matrix run proc intel storage utilization proc mods dim time time time accesses notes 1 1 2 4 8 16 16 16 16 64 64 64 64 64 64 32 16 64 40 40 40 40 40 40 40 40 39 427 429 216 109 56 35 38 47 33 427 429 432 436 445 46 1 507 639 428 102 021 177 579 144 303 759 207 261 2 na 005 na 04 033 13 039 33 068 7 076 177 088 482 064 65 nv 459k 460k 460k 460k 460k 460k 460k 460k 427k 169 sequential program 168 interference 33 instruction data fetches 66 130 250 454 721 269 note times thousands storage cycles nanot applicable nvnot available acc x proc storage utilization roc time x mods col 9 x col col 5 x col 2 course terminate considerably earlier latter thus indicated corresponding entry column four particu lar mode partitioning optimum shortest execution time obtained system efficiency point view however actual operation jobs tasks system consequence since processor idling actually occur new tasks perhaps arising quite different jobs initiated according scheduling strategy whenever processor becomes spontaneously available fig 5 execution time matrix multiply time 4ox40x40x 40 n 64 420ki e 30k total delay due storage interference lnp 10k 5 number processors fig 6 total processor time interference matrix multiply modules addition run time define total processor time col 5 represents sum total time individual processors active program therefore reflection total processor running cost storage interference cols 6 7 measures total time processors inactive due attempts initiate simultaneous accesses storage module occurs also single processor applied repre sents conflict data fetch attempt overlap circuit initiate instruction fetch module 466 part 5 pms level section 3 1 computers multiprocessing parallel processing storage kilocycles ii 400 350 2 300 16 storage modules inner loop size 2 eountlons 3 eouations 4 equations id li 5 eouations ii 40 30 20 fig 7 total processor throughput times electrical network analysis16 storage modules executive interference col 8 represents processor holdups due simultaneous attempts two processors access system workqueues interferences course repre sentative whole class effects lead performance degradation parallel processing systems table 3 interference related number interleaved storage modules number processors actual system course complex function number storage modules degree address interleaving relationship active jobs degree program data sharing total system utilization storage optimizing design numbers processors storage mod ules addressing scheme must fixed subject constraints related cost total storage capacity capacity available storage modules degree availability desired ex pected nature work load processor utilization storage alone significant since critical factor 10 storage activity present degree storage utilization required get program data highspeed store output results include utilization figures executions table 3 aid analysis system behavior evaluation purposes 733 electrical network analysis problem problem represents solution set simultaneous linear equations described sparse coefficient matrix technique used solution executing simulator essentially comprises relaxation procedure extensive runs made using specific thirtysix node network yielding twentysix equations four terms equation wealth results obtained present representative sets indicate general trends related characteristics performance parallel processing system available space permit however detailed analysis present paper permit discussion equally interesting results obtained concerning speed convergence particular storage kilocycles 32 storage modules 600 550 inner loop size 2 equations e 3 equations 4 eouations _x 5 ewations 8 350 300 w z 3 e p number processors fig 8 total processor throughput times electrical network analysis32 storage modules chapter 37 survey problems preliminary results concerning parallel processing parallel processors 467 storage kilocycles 64 f 500 550l n 250 8 200 100 64 storage modules inner loop size f 2 ewations 3 equations 4 equations 5 eouations 2 3 4 5 6 7 8 9 1011 1213141516 number processors fig 9 total processor throughput times electrical network analysis storage modules effects must understood within framework numerical analysis relaxation solutions figures 78 9 present basic performance data put time total processor time total one hundred fortyfour cases variables number processors system 12 cases size inner loop represented number currents 2 5 evaluated loop number interleaved storage modules 16 32 64 curves clearly indicate reduction throughput time obtained use parallel processing consequent increase processor cost due interferences various sorts resultant effect diminishing returns actual increase throughput time many processors chase equa tions generally get seriously ﬁinto others wayﬂ smaller inner loops interference processors low total processor times vary somewhat erratically causes related relaxation pattern rate convergence case fact appears strong circumstantial evidence ad hoc procedure guarantee sequential evaluation equations improves per formance point however requires study figure 10 reproduces results previous three figures case fiveequation inner loop table 4 lists results percentage time using one processor compares reciprocal number processors figure 11 indicates storage interference parallel processing overheads function number processors storage modularity parameter inner loop comprising storage kilocycles 5 equations 260 loop w 240 220 9 200 0 180 160 e 140 n 120 100 0 16 storage modules 32 storage modules 64 storage modules 601 40 501 20 number processors fig 10 total processor throughput times electrical network analysis number storage modules parameter 468 part 5 1 pms level section 3 computers multiprocessing parallel processing table 4 using one processor five equation inner loop run time resistor network system relative run time relatiae time 100 number 16 storage 32 storage 64 storage processors modules modules modules processors 1 2 4 6 7 8 9 10 11 12 14 16 100 528 295 224 209 192 178 176 168 175 173 177 100 512 279 203 179 168 152 145 139 139 132 137 100 512 271 195 171 158 142 137 129 130 117 117 100 500 250 167 143 125 111 100 91 83 72 63 evaluation five currents storage interference previously defined parallel processing overhead represents percentage excess total number storage cycles required execution excluding storage interference cycles one processor used relative number cycles quired oneprocessor execution 2345678910111213141516 number processors fig 11 storage executive interference 20 3 io 0 f i2345678910111213141516 number processors fig 12 storage utilization cost performance factors actual counts execution show general sixtyseven percent store access instruction fetches program thirtythree percent data fetches thus incorporation substantial instruction buffer processor clearly reduces interference order magnitude since four ways storage interference occur onea data fetch conflicting data fetchremains inner loop moreover measurements refer processor arithmetic speeds table 2 order magni tude memory cycle time implies somewhat powerful processor thus every sense interference figures worst case results performance curves relate support view storage interference serious obstacle parallel processing four contours drawn curves represent lines constant storage moduletoprocessor ratio slope slightly upward due statistical marbles boxes rosenfeld 19651 effect previously referred figure 12 presents two sets data based fiveequation line loop upper family curves relates storage utilization reservations made end sec 732 reference significance utilization figures also apply second family curves represents first attempt estimating relative quality processing function costperformance chapter 37 1 survey problems preliminary results concerning parallel processing parallel processors 469 factor factor intuitive environmentsensitive de pending relative concern speed costs various sorts present data chosen display function throughput time x total processor time k constant throughput time measure speed computation total processor time measure cost k 8 conclusion i11 paper presented thoughts parallel process ing particular chosen survey topic including extensive bibliography results work area discussion brief intention convey picture potential parallel processing systems offer future development computing key successful exploitation lies new unified scientific approach entire problem design usage computing systems development large integrated sys tems raises many problems doubt eco nomic solutions found development comprise significant part computer system architectural design effort next years ultimate evaluation parallel processing system within working environment depends actual operating experience turn requires existence system interest users usable systems become available concept parallel processing integrated systems accurately evaluated references blaagm brigh64 conwm63 corbf65 dennj66 desmw64 dreyp58 falka64 gills58 gregj63 katzj66 lehmm65 leina5q mccuj65 miraw67 nievj64 rosej65 schlii shedggba b slotd62 smitr64 pli language specification formc286571 bibliography 411em63 amdac62 andej63 65 rdeb66 baldf62 biaa664 brigifi4 buchw62 bussb63 codde62 comfw65 conwm63 corbf62 65 crita6 dalerb5 dennj65 66 desmw64 dijke65 dreypjx ernsh63 estrgw 63 ewinr64 falka64 forgj65 franj57 gills58 61ase65 gregj63 hellh61 66 katzj66 kinsh64 knutd66 lehmm6xa 6311 65 leina59 lourn59 marcm63 mccaj62 mccnj65 meadr63 millw63 miraw67 nievj64 ossaj65 pennj62 rosej65 schlh seehrb3 senzdb5 shedc66a 6611 slotd62 smitr64 squij63 strac59 vyssv65 wirtn66 ibm os360 plz language specijication form c 286571 proc ifip1062 ﬁsymposium multiprogrammingﬂ 1963 section 4 network computers computer networks rw400 cdc 6600 actually computer networks definition computer chap 2 page 17 yet restrictions quantity location compo nents structures still consider com puters hand two computers separated physically yet connected constitute computer network computer networks appear future important understand basis rw400a new polymorphic data system chapter 38 presents rw400 also called anfsq27 later version ramowooldridge rw40 originally de signed 1959 diagram page 478 gives indication relationship names components pms structure fig 1 configuration details least six rw400s built military command control applica tions although number computers type existence little machines worth ability rw40 isp given appendix 1 chap 38 good example processor twoaddress instruction set isp index registers small state consisting accumulator limited extended accumu lator b program counter p 6 state bits pc limited ability address directly 1024word mp isp undoubtedly sufficient solving kinds problems encountered computer compares favorably whirlwind ibm 1800 rw40 introduced multiple parts reliability roth man 19591 multiple cs mppc mppio provided redundancy capacity however scentra1 ex change provides communication among cs may redundant parts multiplecomputer concept viewed forerunner present computer networks central switching element telephone ex change longer time span rw400 may significant pioneer however whole system exception small mps nicely designed problem low speed ttypewriter displays handled well trans ferring data mppc msdrum concurrent independent p activity similar solutions common managing activity using local particular ts local cs structure compared cdc 6600 chap 39 network examples chap 40 cdc 6400 6500 6600 6416 7600 cdc 6600 development began 1960 using highspeed transistors discrete components second generation first 6600 delivered september 1964 subsequent compatible successors included 6400 april 1966 implemented conventional pca single shared arith metic function unit instead 10 ds 6500 october 1967 uses two 6400 pcs 6416 1966 peripheral control processors first 7600 nearly compatible delivered 1969 dual processor 6700 consisting two 6600 pcs introduced october 1969 subsequent modifications series 1969 included extension 20 peripheral control processors 24 channels cdc also marketed 6400 smaller number peripheral control processors eg 64157 7 reducing maximum pcp number 7 also reduced overall purchase cost approximately 56000 per processor computer organization technology construction described chap 39 isp descriptions pc pc peripheral control processorspcp given ap pendices 1 2 chap 39 obtain high logic speeds components placed close together logic cards use cordwoodtype construction logic directcoupled transistor logic 5 nanoseconds propagation time clock 25 nano seconds fundamental minor cycle 100 nanoseconds major cycle 1000 nanoseconds also memory cycle time since component density high 500000 transistors 6600 logic cooled conduction plate freon circulating series interesting many aspects remained fastest operational computer many years large 470 section 4 1 network computers computer networks 471 mppc mp pi0 kms drum 0 17 rns 1 i6 sw 8192 w 1 kti ines cards paper tape kt mas ter con e 7 peripheral buffer drum w 1 display ruffer drum 8l9 w pc2 addressinstruction wps 34 technoloqytransistor descendantsrw400 anfsq 27 wpcore1 10 usw 1024 w 262 parity bw kperiphera1 buffer kdisp1ay ruffer fig 1 rw40 polymorphic pms diagram component count almost implies exist opera pms structure tional entity thus tribute organization project leaderdesigner seymour cray large number exist sufficiently high data bandwidths within system remains balanced job mixes uncommon feature large cs high performance msdisks tdisplays avoid bottlenecks pcs isp nice variation generalregisters processor allows efficient encoding programs pc nicely multi programmed switched job job quickly computer ten smaller cs control main pc allow spend time useful billable work rather administration independent multiple data operators 6600 increase speed least 2y2 times 6400 shared finally realizes 10 cs unique interesting efficient manner many com puter systems claim half many innovations simplified pms structure c6400 6600 given fig 2 see cio 1lo access central computer cc primary memory mp figure 2 shows cc fig 2 cdc 6600 pms diagram simplified 472 part 5 pms level section 4 network computers computer networks consider 6600 fundamentally network cio actually generalpurpose 12bit c easily serve specialized pi0 function cc mp cc ms cio course powerful cio complex inputoutput tasks handled without cc intervention tasks include datatype conversion error recovery etc ks connected cio also less complex figure 2 information thortons fig 1 block diagram chap 39 detailed pms diagram c6400 6416 6500 6600 given fig 3 interesting structural aspects seen diagram four configurations 6400 6600 included considering pertinent parts structure 6416 large pc 6400 sin gle straightforward pc 6500 two pcs 6600 single powerful pc 6600 pc 10 ds several parts single instruction stream interpreted paral lel 6600 pc also considerable mbuffer hold instruc tions pc need wait mp fetches implementation 10 cios seen pms diagram fig 3 one physical processor used timeshared basis 01 ps new logical p processed physical p 10 mps phased new access occurs 01 ps 10 mps always busy thus irate 10 x 12 bps 120 megabitss process shifting new pc state position 01 ps likened barrel cdc diagram process shown fig 4 ts ks ms given although mentioned following units rather unique k management 64 telegraph lines connected cio msdisk four simultaneous access ports 168 megacharls data transfer rate capacity 168 megachar msmagnetic tape k 14 allow simultaneous transfers 4 ms display monitoring systems operation ks cs mss con ventional tcard reader punch line printer etc isp isp description pc given appendix 1 chap 39 pc clean straightforward scientificcalculation oriented isp consider variation general register structure pc state three sets general registers use explained chap 39 ap pendix 1 structure assumes program consists several read accesses large arrays large number operations accessed elements followed occasional write accesses store results would agree valid assumption scientific programs eg look tran arithmetic statement probably valid programs well cc provisions multiprogramming form protection relocation address mapping given isp description mp msextended core storage ecs appendix 2 chap 39 isp description pcp appendix 2 includes figure shows instruction de coding execution well 6600 pcp early cdc 160 pcp 18bit register process addresses large cc one interesting aspect 6600 question lack communication among components isp pro gramming level pc stops way explicitly informing components interprocessor interrupts io device interrupt pio pios communicate one another except polling state switching pc however elegant since pi0 request pc stop job store mps resume new task one instruction tsave trestore 2 ps operating system cios functions data transmission peripheral device large cc via cios mp data trans formation conversions complete task management includ ing initiation termination error handling manage ment pc cios perform manner cattached support processor n360 asp chap 40 page 506 operatingsystem software managed single fixed cio remaining nine cios free io tasks arise system cios assign particular tasks carry tasks free take tasks operatingsystem software resides mppc cc accessible cios includes 1 variables determine state particular job eg data pointers msdisk ecs running time list jobs etc 2 programs cios parts operating system used cio sponsible system management b io management programs programs get task management program ms cios use section 4 1 network computers computer networks 473 mbarre1 working io w 51 bw 01 psw mpoy spc3 bo9stms 112 tdead start console kll vsw i2 bw v 41 fixedjrksttbl 2 crt display mp4 031s6 lt key board read pyramid buffer 12 bw mworkinq 12345 12 bw 2 pw 77 s4 k i6 msms 015 1 cb l234 toextended core coupler j c9 mpcore 10 psw 4096 w 12 bw zstime multiplex psw 12 bw 3pcperipheral control processor 09 time multiplexl p5w 1 addressinstruction 12 bw mpscprogram counter accumulator 1 2 wlinstruction 4mpcore 1 psw 4096 w 5 x 12 bw stime multiplex 01 psw 60 bw msextended core storageecs 32 psw 125952 8 w 8 x 60 parity bw 7see chapter 39 operation present cdc 6500 ccentra1in cdc 6416 cdc h500 cdc 6400 kscoreboard separate ds mlnstruction stack pc6600 15 30 binstruction techno1ogytransistor 1964 data sibvwsfd dshift dboo1ean di 2 lncrement branch dadd 03 ps olong add d12 multiply 1 ps ddivide 29 ips f 1 ip flop 16 wsswi tchboard worki ng fig 3 cdc 6400 6416 6500 6600 pms diagram 474 part 5 1 pms level i2 3 4 5 6 7 io ii 12 section 4 network computers computer networks 0 i2 3 4 5 6 central memory 60 71011121314 10 memories 4096 words 12bit ttl 1121 1 l 1121 1 real time 121 external ewipment fig 4 cdc 6600 peripheral control processors courtesy control data corporation section 4 network computers computer networks 475 yps flip flop 275 nsw dlong add increment pop count dboolean 11 16 w 60 bw k mworkinq instruction shift c 12 w 60 bw 1 1 interpreter dnormalize instruction stack dfloatinq add flip flod 275 nsw dfloatinq multiply float nq divide typical system one might expect find following assignment pcps 1 operatingsystem execution including scheduling management cc cios display job status data tdisplay 2 3 msdisk transfer management 4 5 l 13 tocsatellite 6 msmagnetic tape 7 t64 teletypes 8 9 free 10 free tprinters card reader card punch free used msdisk msmagnetic tape cdc 7600 cdc 7600 system upward compatible member cdc 6000 series although main pc 7600 compati ble main pc 6600 instructions added controlling io section communicating large core memorieslcm small core memoryscm expected compute average rate four six times c6600 pms structure fig 5 substantially different 6600 c7600 peripheral processing unitippu unlike cl6600 peripheral control processors loose coupling main c ppus control main c transferring words scm via kinput output section 15 cppus 8 inputoutput chan nels channels run concurrently provide link cppu peripheral mss ts ppus located physical space pc ms07 mp031s3tfjc5 tmbuffer core core transfers1 ti basic ncdc 7600 fig 5 cdc 7600 computer pms diagram 476 part 5 1 pms level 7600 pc interrupted clock ppus trap condition within pc breakpoint address bpa set within pc program reaching bpa trap initiated interruption scheme contrast 6600 could interrupted trapped 7600 interrupt may reaction lack intercom munication 6600 conclusions although 6600 somewhat behind announced delivery schedule represented significant drain financial resources cdc clear successful product section 4 1 network computers computer networks instances large computers carried completion either financial technical reasons 6600 seems first large computer achieve marks success interested 6600 held ﬁworlds largest computerﬂ title long computernetwork examples chap 40 present examples seven computer networks dearth computer networks papers computer networks chapter takes examples papers knowl edge several existing proposed networks chapter 38 rw400a new polymorphic data system1 r e porter summary rw400 data system based upon modularly constructed independently operating flexibly connected components logically evolved snccessor conventional computer designs provides means information processing requirements met equipment capable producing timely results cost commensurate problem economic value system obsolescence minimized expandahility numbers types processing modules real time reliability assured component duplication minimum cost advanced design techniques employed systems manufacture manmachine commu nication facilities program controlled maximum flexibility parallel processing parallel information handling modules increase systems speed adaptability handling complex computing workloads polymorphic design truly represents extension mans intellect electronics rw400 data system new design concept devel oped meet increasing demand information processing equipment adaptability realtime reliability power cope continuouslychanging information handling require ments polymorphic system including variety function allyindependent modules interconnectable programcontrolled electronic switching center many pairs modules may independently connected disconnected connected microseconds need meet continuously varying processing requirements system assume whatever configuration needed handle problems moment hence best characterized term ﬁpolymorphicﬂhaving many shapes rapid programcontrolled switching many pairs func tionallyindependent modules permits nondisruptive system ex pandability operating reliability simultaneous multiproblem processing capability manmachine intercommunication feasibility partially found computers conven tional design computer users forced heretofore match problems computer limitations problem changes posed serious reorien tation reprogramming difficulties changes one computer datumnution vol 6 1 pp 814 januaryfehruary 1960 another model due growth applications often resulted large expenditures time money maintenance malfunction conventional computer entire processing capacity shut real time processing reliability maintained aroundtheclock basis conventional chine must process problems serially serious limitation partially alleviated timesharing computingele mentdoubling designs high costperhour conventional computer operation rules direct manmachine intercommuni cation emergency situations radicallynew polymorphic design concept rw400 data system evolved ramowooldridge engineers pro vide practical solution information processing problems inadequately handled conventional computer designs rw400 powerful new tool field intellectronicsthe extension mans intellect electronics system description rw400 data system contains optional number variety functionallyindependent modules communicate via central electronic switching exchange module designed within practical economic functional limits maximize system adaptability wide range problem types sizes new design embodies latest proven electronic design techniques assuring high processing speeds high equipment reliability rw400s modularity assures reliable roundthe clock processing information controllable computing ca pacity degradation module maintenance malfunction practical manmachine intercommunication achieved rw400 system use programcontrolled information display interrogation consoles figure 1 shows overall system design modules various types communicate central exchange switching center computing buffering modules provide control system modules selfcontrolled make possible completely independent processing two problems one computer modules may designated master computer 477 478 part 5 pms level section 4 network computers computer networks display controlling computing buffering 4 switching center auxiliary storage input output fig 1 rw400 data system role initiates monitors actions entire system alertinterrupt network provided allow coordinated system action therefore system applied given information processing problems may change short range microsecond basis thus providing programming selforganizing aspect system addition system may change years applications change efficient eco nomical complement equipment applied problem times rw400 system built around expandable central exchange cx number primary modules may attached computer modules cm selfinstructed buffer modules bm magnetic tape modules tm magnetic drum modules dm peripheral buffer modules pb console communication display buffer modules db many modules put together system entirely function system application addition primary system modules punched card punched tape high speed printing control console devices available handle nominal system putoutput requirements additional manmachine communica tion devices interrogation display control consoles may included system problem requirements dictate tape adapter ta module available provide compatibility magnetic tape computers information generated flexowriter inquiry recording stations may directly ceived system via peripheral buffer module latter module also buffers receipt twx punched tape infor mation way particular rw400 data system functions depends number type module included may initially composed minimum number variety modules needed small problem initial part large yettobedefined problem system would work much like conventional computer would probably include buffer module thus parallel data handling capability found conventional design comparable price initial system installation may augmented timely addition modules chapter 38 1 rw400a new polymorphic data system 479 buffer module bm capability control acquisi tion dissemination information independently buffer provides computer module parallel data handling capability without complicating problem processing program conventional intermixture arithmetic housekeeping structions information previously generated processing program may appropriately disposed within system processing continues data needed subsequent time processing may retrieved system storage advance need processing progresses simultaneity oper ations materially increases overall processing speed also increases practical utility less costly types ternal system storage magnetic tape computer cm buffer bm modules acting controlling capacity may initiate connection information storage handling module part processing program two work profitably unison pair modules thus interconnected neither affect affected modules logical interlocks prevent unwanted cross talk among modules intermodule communication system lets con trolling modules signal status alert modules need communicate decision module receiving alert signal permit interruption proceed optional module optional interrupt feature needed make oftendiscussed seldomused program interrupt capability useful practical programs may thus permit interruptions convenient points processing sequence modules may assigned program control work together problem proportion needs soon modules function complete given problem module may released reassignment task system thus selfcontrolled match processing capacity prob lem time necessary job full system capacity may brought bear upon large problem needed capacity may apportioned among number smaller problems simultaneous processing program compilation program checkout module maintenance etc needed maximum system effort preceding system description apparent equipment expanded modest initial installation powerful comprehensive information processing cen ter requirements warrant specific descriptions prin cipal system modules follow give reader better feel system might perform information processing work functional modules key appreciative understanding power rw400 lies knowledge intermodule connection appropriate describe central exchange cx unit first follow descriptions various modules central exchange central exchange performs vital function intercon necting pair modules whenever requested either computer buffer module since internal programmed control possible within computer buffer module one interconnected pair modules must either computer buffer time connection may made broken 65 microseconds exchange basic capacity connect 16 computer buffer modules 64 auxili ary function modules nothing sacred number 16 since possible extend cx modules interconnection matrix design modification need arises cx expandable programcontrolled electronic switching center capable connecting disconnecting available pair modules roughly time one computer instruction execu tion figure 2 illustrates permissible module interconnections within central exchange every intersection illustration represents possible connection modules ﬁxedﬂ intersections indicate typical connections force point time control logic cx modules connection table prevents one interconnection horizontal controlling vertical con trolled data path representation diagram connec tion requested central exchange one quired modules already carrying previous assignment requesting module programmed sense condition wait connection made without interference waiting undesirable requesting module go business check back later see desired connec tion made implication course knowing kind system dealing programmer requests connections advance need whenever possible provision masterslave control included via assignment matrix established within cx module computer module previously assigned master status provision necessary preclude inadvertent connection requests unchecked programs malfunctioning control modules affecting sets modules simultaneously processing another problem connection requests therefore essentially filtered assign ment interconnection validity matrix prior acted 480 part 5 pms level section 4 1 network computers computer networks tm fig 2 central exchange connection matrix upon central exchange computer module manually assigned master status one permitted cause interconnection pair modules include computer module see fig 3 computer module cm selfsufficient general purpose twoaddress parallel word fixed point random access computer internal magnetic core memory capacity 1024 words computer word consists 26 information bits 2 parity bits parity bit associated 13bit half word transferred parallel via central exchange system modules instruction repertoire cm consists 38 primary instructions whose various modes effectively result 300 different oper ations 39 available cm400 instructions 24 may classi fied ﬁarithmeticﬂ 10 ﬁprogram controlﬂ ﬁsequence determiningﬂ instructions five additional instructions may classified ﬁexternalﬂ ﬁinputoutputﬂ instructions three 24 arithmetic instructions fit symmetric scheme classification wherein seven basic operations three distinct modes seven basic operations areadd subtract absolute subtract multiply divide square root insert three modes arereplace hold store let capital letter ﬁgﬂ identify first operand ﬁhﬂ identify second operand ﬁﬂ signify arbitrary operation sym bol ﬁﬂ indicate replace ﬁaﬂ word accumulator three modes may characterized replace h g h hold h g store g h three remaining arithmetic operations add accumulate wherein contents h g added accumulator chapter 38 1 rw400a new polymorphic data system 481 multiply accumulate wherein contents h multiplied g added transmit contents g stored h ten program control instructions store store double length accumulator load accumulator insert mask register stop link jump compare jump tally jump test jump multipurpose shift five external instructions cause data transmitted received device external com puter command multipurpose nature hence equiv alent several conventional external instructions commands arecommand output data input conditional data input data output character transfer comprehensive discussion variation commands pertinent article suffice say commands available carrying wide variety intermodule data communication interrupt capability computer module logical generalization ﬁtrappingﬂ feature found several conven tional computers permits automatic interruption pro gram option program computer module receives ﬁalertﬂ condition requiring attention arisen used warn program error type occurred minimize unproductive computer waiting time another module completes task eliminate many programmed status test instructions provide convenient means sub jecting one computer module control another program control interruptions within cm400 accomplished sense register register may filled interrupt j control logic 1 l op address address instruction register input lines b magnetic core storage central exchange rjtl output lines txchange rfgistfr c l control panel interrupt sensing accumulator register accumulator extension alert conditions fig 3 cm400 computer module 482 part 5 pms level section 4 1 network computers computer networks rw400 analysis console mask means insert instruction bit bit correspond ence exists register interrupt register interrupt register alert lines connected test jump instruction used examine coincidence registers alert signal bit position corre sponding one register mask alert received computer execution instruction control transferred memory location ﬁ0ﬂ end instruction sense bit corresponding alert ﬁoneﬂ b master sense bit ﬁoneﬂ c struction ﬁinsert master sense bit reg ister may programmed permit interrupt take place according interrupt mask inhibit interrupt program conveniently cope instructions executed time interrupt condition occurs completed interruption allowed take place figure 3 schematically illustrates computer modules pri mary registers interconnecting information paths typical twoaddress addition subtraction times ap proximately 35 microseconds including memory access time mul tiplication takes 80 microseconds division square root 130 170 microseconds respectively attempting draw comparison cm deluxe conventional computer reader bear mind trade offs features versus cost parallel processing versus sequential processing independent information handling versus program complicating ﬁhousekeepingﬂ real time system reli ability versus periodic inoperability valid comparison rw400 data system conventional computer applied task contribution rw400 system made buffer modules better assessed reader following description considered buffer module buffer module consists two independent logical buffer units 1024 words random access magnetic core storage number internal registers used performing functions selfcontrolling mode buffer module may con nected computer module buffers core storage accessible computer extension computers storage buffer may also serve intermediary device computer another module tape drum minimize time conventionally lost data transfers buffer capable recognizing executing certain instructions stored memory therefore left perform data han dling functions computer modules otherwise occupied buffer module may connected computer module buffer 1024 word storage used indirectly addressed extension computers working storage ad dress 1023 ones appears operand field computer instruction executed computer signalled operand refers cell buffer storage computer uses number buffer read register r case instructions buffer write register w effective address designated operand field instruction ex tended addressing may used either first second operand field instruction operand fields extended addressing used one operand field effective address designated field number register r ﬁ1ﬂ automatically added contents r register instruction executed extended addressing used operand fields instruction effective address first operand number register r effective address second operand one number register r ﬁ2ﬂ automatically added contents register r execution type instruction r w register may preset desired initial condition means computers command output instruction commands executed computer must stored within computer chapter 38 1 rw400a new polymorphic data system 483 modules storage may buffer cells addressed computer execution time extended addressing buffer register indexing may used materially simplify repetitive data acquisition operations primary function buffer module however auxiliary computer storage unit drum tape modules aptly serve function rw400 system buffer module capable operating autonomously controlling modules tape modules drum modules peripheral buffers display buffers printers plotters capability en ables buffer modules system perform routine tape searching data transferral tasks thereby freeing computer modules computing ﬁselfinstructionﬂ mode buffer executes internally stored program much fashion computer memory buffer module therefore occupied control programs well blocks data holding transmission units buffer used acquire information relatively slower auxiliary storage communication modules computer proceeds high speed blocks information retrieved advance computer need buffer may rapidly transferred computers storage operated upon stand buffer via indirect addressing capability computer another feature buffer switching capability buffer module composed two buffer units tied together unit function switching feature permits employment two units together alternating mode operation continuous information transfer tape computer example may accomplished without stopping tape unit switching struction executed simultaneously units buffer module causes whatever devices connected first unit connected second vice versa functional controlling modules module interconnection concept discussed conven tional auxiliary storage modules available system may described round processing capability system tape modules tape module consists altered ampex fr300 tape transport plus necessary power supplies control circuitry effect information reading writing control one inch mylar tape used information written 16 channelstwo clock channels remaining 14 channels consist 13 informa tion bits plus parity information reading recording rate 15000 computer words per second data may recorded tape variable blocks maximum 1024 words per block size storage available hold data sending receiving module block preceded block identi fication permits selective tape information searching buffer module single blocks imbedded tape file blocks overwritten twostack head permits automatic verification block written readback parity errors automatically detected writing process thus drop areas may determined data still available computer buffer recording elsewhere description rw400s tape handling capability would complete without mentioning tape adapter ta module selfcontained unit capable performing reading writing magnetic tapes format acceptable ibm 704 709 systems ta consists ampex fr300 halfinch digital tape transport including dual gap head servo control system reading writing control circuits module housing blower power supply rw400 buffer module 484 part 5 pms level section 4 network computers computer networks drum module drum module dm contains magnetic drum storage capacity 8192 words may connected either computer buffer module central exchange average access time first word position drum 8y2 milliseconds successive words transmitted rate 60000 computer words per second drum module conventionally used intermediate item storage device minimize tape handling time special system communication modules external data manmachine communication rw400 data system handled via drum buffer modules wide variety asynchronously operated equipment speed matched program controlled features designed special system communication modules peripheral buffer pb provides inputoutput buffers communication computer buffer modules rela tively slow speed external devices flexowriters plotters punched tape handlers teletype lines keyboard operated equipment peripheral buffer stores information four pairs bands operate alternately circulating registers band contains eight input eight output buffers total 32 input buffers 32 output buffers peripheral buffer module buffer drum band sector 64 computer words long conventionally one input one output buffer sector connected external device flexowriter permit twoway communication external device rw400 system display buffer display buffer db acts recirculating storage cathode ray tube display units display console information displayed sent db band associated particular display tube via central exchange display buffer sends status information back system modules upon request information displayed tube controlled bit pattern sent display buffer display pattern regener ated 30 times per second minimize image fading flicker preceding explanation display buffer little meaning reader unfamiliar features display console console therefore described detail following paragraphs display consoles display consoles give problem ﬁanalystﬂ ﬁmonitorﬂ visual picture status results information handled rw400 system addition actual cathode ray tube numerical indicator signal lamp typewriter infor mation outputs several types keyboard activated system control parameter entry facilities provided console total manmachine communication facility represented console designed primarily function computer control programs initiated analyst via console set display control keys generate messages recorded peripheral buffer sector later interpretation display generation computer program set process step keys provided analyst initiate prepro grammed system processing variations associated process step keys overlay ﬁprogram card permits assignment variety meanings set process step keys insertion overlay analyst gives unique label process step key automatically cues controlling computer assign corresponding set programs key message data entry keyboard provided console analyst enter control parameters asked via display devices joystick lever affords console operator means con trolling position cross hair markers cathode ray display tubes associated joystick control keys may used send message controlling computer speci fying coordinates cross hairs control programs may written example act upon information reorient display respect area selected cross hair position light gun also provided means selecting point cathode ray tube displays gun emits small beam light beam centered given point cathode ray display tube pressing trigger results automatic generation message peripheral buffer specifying address display buffer containing coordinates selected point set status error lights contained display console provide console operator overall knowledge system thus minimize conflicting control requests intermodule interference example peripheral buffer may ready accept console key message certain previously requested control actions completed status lights indicate condition console operator may act accordingly printer module printer module pr basically 160 column 900 line per minute anelex type printer receives information either computer buffer module via central exchange indi chapter 38 1 rw400a new polymorphic data system 485 vidual characters printed represented 6bit code transmitted four computer word zero suppression line completion information block end codes included format control plugboard provided flexibility columnar data arrangement paper feed controlled means loop 7channel punched paper tape control printing operation arranged connected control module may send line headings one set memory locations stop sending information going different part memory proceed send data new set memory locations complete line print punched card modules rw400 data system may equipped high speed punched card reading module cr ibm card punch cr communicates computer buffer modules via central exchange capable reading 80 column punched cards rate 2500 cards per minute card punch connected system peripheral buffer module pb since relatively low speed device emphasis placed directly connected punched card equipment since sources large volumes punched cards usually convert data magnetic tape form may rapidly handled using tape adapter module ta references roths59 westc6o 486 part 5 pms level section 4 1 network computers computer networks appendix 1 rw 40 isp description appendix rw40 i5p description descriotion include innutoutput instructions interrupts nnri communication iiith comuters processors description taken preliminaru yanual 1nformation rci40 vo doubt hanged final machines pc state k26 b26 abol261 ab piol ov sr201 parity error program error run mp state m11022261 c console state cjk8 controloanel tes fxternal state io computers taperead external jddressealo eo io23 146 1 ondl9 io se 1 ect 0 1 lojatal3 instruction format instructioniq6l fopdl iq621 giol iqoll j6l g61 h101 iiol operand calculation process gq61 gi next g 17778 iexternaljddress externaljddress gq61 4 0 0 0 g 1777 mqlq6l g 1777 mexternaladdressiq61 hq61 hi next h 1777 texternaladdress externaladdress h26b h 0 0 ok 1777 idh261 g 1777 hexternaladdress26 arithmetic register extension arithmetic repister double proaram counter overflow arithmetic shifts sense register transfer comuters undefined command incorrect seouence io commands mp repistern n 7087 tnnccessihle conditional im switches communication indicator tune search flag register associated e address another module extra memow accessed fxternal address register interrunt conditions pc 1 8 io devices selected io device drrta function od code bits first address test selection parameter second acdress first onerani second operand chapter 38 1 rw400a new polymorphic data system 487 irstmclion interpretaicq ycjcs runinstruction mp p p 1 next etch 1nstructionexecution etecu c trstructior set nn tnsiructior kecuipr nroepss instruct ionexecu ion transmit atitmetic ills complemencl replace add hold add store add replace subtract hold subtract store subtract replace absolute subtract hold absolute subtract store absolute subtract replace multiply hold multiply store multiply redlace divide hold divide store divide replace square root hold square root store square root accumulate add accumulate multioly op 27 h g op 0 ova h g next h op ova th g op 2 dva g next h op 3 ova ih g next h op 4 ova h g op 5 flva g next h op 6 absh absg next h op 7 absh absg op io absa absg next h op 11 ar h x g next h op 12 a6 1 h x c op 13 ab x g next h op 14 hrg ovi h g ae hg next h op 15 h z g 0 h g ab thg 16 c jnv 1 ag ae ag next h op 17 sqrthg next h op 20 sqrthg op 21 sqrtag next h op 25 ovoa h c op 26 iflvoa h x g 488 part 5 pms level section 4 network computers computer networks g107 0 gio isond 7 gio 177777 h 96 sr 7 g8 177777777 g 10welectolodata 7 sb gq cjs igc 177777777 next gq test p h test condition selected bit pc io bits test j 0 0 j 32 aj j 33 ov ov 0 j 34 parity error parity error 0 j 35 controlpanel test controlpaneltest 0 j 36 taperead taperead 0 j 37 programgrror programerror 0 link jump op 32 g 0 p h g4ol p g 0 p h tally jump op 33 g 70 p ch g 0 g gi g 1 p h g 0 g g 1 compare jump op 37 g p h load op 34 oogoh insert op 35 oogoh v 7 bgoh store ab op 36 g 8 h g 0 h 0 8 b end instructionexecutior chapter 39 parallel operation control data 66001 james e thornton history summer 1960 control data began project culminated october 1964 delivery first 6600 com puter 1960 apparent brute force circuit perform ance parallel operation two main approaches critical system control operations separate processors central processor operates central memory relocating register file protection program central memory peridheral control processors advanced computer paper presents considerations parallel operations 6600 important fortunate event coincided beginning 6600 project appearance highspeed silicon transistor survived early difficulties become basis nice jump circuit performance system organization computing system envisioned project called 6600 paid special attention two kinds use large large problem highspeed floating point central processor access large central memory obvious obvious important 6600 system idea isolation central arithmetic peripheral activity general line reasoning idea multiplicity peripheral processors formed fig 1 ten peripheral processors access central memory one side peripheral channels executive control system always one peripheral proces sors others operating assigned peripheral control tasks ten processors access twelve inputoutput chan nels may ﬁchange handsﬂ monitor channel activity perform related jobs processors access central memory may pursue independent transfers memory ten peripheral processors contains memory program buffer areas thereby isolating protecting afips proc fjcc pt 2 vol 26 pp 3340 1964 scientific problem time sharing smaller problems peripheral control processors housed one chassis main frame processor contains 4096 memory words 12 bits length 12 24bit instruction formats provide direct indirect relative addressing instructions provide logical addition subtraction shift conditional branching instructions also provide single word block transfers twelve peripheral channels single word block transfers central memory central memory words 60 bits length assembled five consecutive pe ripheral words processor instructions interrupt central processor monitor central program address get much processing power reasonable economy space timesharing design adopted fig 2 design contains register ﬁbarrelﬂ around moving dynamic information ten processors things program address accumulator contents pieces information totalling 52 bits shifted around barrel complete trip around requires one major cycle one thousand nanoseconds ﬁslotﬂ barrel contains adders assembly networks distribution network interconnections perform one step periph eral instruction time perform step words time slot one minor cycle one hundred nanoseconds ten processors therefore allowed one minor cycle every ten perform one steps peripheral instruction may require one steps depending kind instruction effect single arithmetic single distribution assembly network made appear ten memories kept truly independent incidentally memory readwrite cycle time equal one complete trip around barrel one thousand nanoseconds 489 490 part 5 1 pms level 4096 word core memory peripheral processor control section 4 network computers computer networks 4096 word 4096 word 4056 word corememory core memory core memory periph eral per1 ph eral peripheral processor processor processor control control control c 4096 word core memory peripheral processor control core memory ukl central memory 4096 word corememory peripheral n 6600 central memory 4 processor 6600 central processor control pheripheral control processor core memory core memory control processor control processor 4096 word core memory peripheral processor control 4096 word peripheral processor control fig 1 control data 6600 processor processor registers memori es 1 cc processor timeshared processor registers instruction memori es control l central memory 60 write pyramid central memory 60 2 3 4 5 6 7 1011 12 1314 external equipment fig 2 6600 peripheral control processors chapter 39 parallel operation control data 6600 491 inputoutput channels bidirectional 12bit paths one 12bit word may move one direction every major cycle 1000 nanoseconds channel therefore maximum burst rate 120 million bits per second possible using ten peripheral processors sustained rate 50 million bits per second maintained practical operating system channel may service several peripheral devices may interface systems satellite computers peripheral control processors access central memory assembly network disassembly network since five peripheral memory references required make one central memory word natural assembly network five levels used allows five references ﬁnestedﬂ network major cycle central memory organized independent banks ability transfer central words every minor cycle peripheral processors therefore introduce 2 interference central memory address control peripheral control processors 12 input output channels upper boundary lower boundary single real time clock continuously running available peripheral processors central processor 6600 central processor may considered highspeed arithmetic unit system fig 3 program operands results held central memory connection peripheral processors except memory except two single controls exchange jump starts interrupts central processor peripheral processor central program address monitored peripheral processor key description 6600 central processor see later discussion ﬁparallel functionﬂ means number arithmetic functions may performed concurrently end ten functional units within central central processor 24 operating fig 3 block diagram 6600 492 part 5 pms level section 4 1 network computers computer networks processor two increment units floating add unit fixed add unit shift unit two multiply units divide unit boolean unit branch unit general way units three address unit example floating add unit obtains two 60bit operands central registers produces 60bit result returned register information units held central registers twentyfour eight considered index registers 18 bits length one always contains zero eight considered address registers 18 bits length serve address five read central memory trunks two store central memory trunks eight considered floating point regis ters 60 bits length central registers access central memory central program sense whole central processor hidden behind central memory peripheral processors ten functional units hidden behind central registers central memory consequence considerable instruction efficiency obtained interesting form concurrency feasible practical fact small number bits give meaningful definition function makes possible develop forms operand unit reservations needed general scheme concurrent arithmetic instructions organized two formats 15bit format 30bit format may mixed instruction word fig 4 example 15bit instruction may call add f rn h operation code 60 bits 0 result reg 8 4 151 operand reg 8 2nd c _j rand reg 8 fig 4 fifteenbit instruction format designated f octal digits registers designated k octal digits result going register desig nated octal digit example addresses threeaddress floating add unit three bits length address referring one eight floating point registers 30bit format follows form substitutes k octal digit bit constant k serves one input oper ands two formats provide highly efficient control concurrent operations background consider essential difference general purpose device special device high speeds required desiper special device generally improve traditional general purpose device introducing form concurrency example activities housekeeping nature may performed separate main sequence operations separate hardware total time complete job optimized main sequence excludes housekeeping two categories operate concurrently would course attractive provide general purpose device generalized scheme kind thing organization 6600 central processor provides kind scheme multiplicity functional units operand registers simple highly efficient address ing system generalized queue reservation scheme practi cal called scoreboard scoreboard maintains running file central register functional unit three operand trunks unit typically scoreboard file made two three fourbit quantities identifying nature register unit usage new instruction brought conditions instant issuance set scoreboard snapshot taken speak pertinent conditions waiting required execution instruction begun immediately control unit waiting required example input operand may yet available central registers scoreboard controls delay released allows unit begin execution important activity accomplished scoreboard functional unit necessarily limit later instructions brought issued manner possible issue series instructions related functional units left free specific register ib assigned one result two restrictions issuing unit free double result several independent chains instructions may proceed concurrently instructions may issue every minor cycle chapter 39 parallel operation control data 6600 493 absence two restraints instruction executions com parison range three minor cycles fixed add 10 minor cycles floating multiply 29 minor cycles floating divide provide relatively continuous source instructions one buffer register 60 bits located bottom instruction stack capable holding 32 instructions fig 5 instruction words memory enter bottom register stack pushing old instruction words straight line programs bottom two registers use bottom refilled quickly memory conflicts allow programs branch back instruction upper stack registers refills allowed branch thereby holding program loop completely stack result memory access memory conflicts longer involved considerable speed increase five memory trunks provided memory central processor five floating point registers fig 6 one address register assigned trunk therefore floating point register instruction calling address register result implicitly initiates memory reference trunk structions handled scoreboard therefore tend overlap memory access arithmetic example new memory word loaded floating point register brought memory may enter register previous uses register completed central registers therefore provide data ten functional units receive unit results storage maintained unit central memory organized 32 banks 4096 words con secutive addresses call different bank therefore adjacent addresses one bank reality separated 32 addresses may issued every 100 nanoseconds typical central memory information transfer rate 250 million bits per second mentioned functional units hidden behind registers although units might appear increase hard ware duplication pleasant fact emerges design unit may trimmed perform function without regard others speed increases simplified design example special functional unit design floating multiply accomplishes coefficient multiplication nine minor cycles plus one minor cycle put away result total 10 minor cycles 1000 nanoseconds multiply uses layers carry save adders grouped two halves half concurrently forms partial product two partial products finally merge long carries propagate although fairly large complex circuits resulting device sufficiently smaller originally planned allow two multiply units included final design instruction stack 8 60417 words buffer register central memory 4 fig 5 6600 instruction stack operation 494 part 5 pms level section 4 1 network computers computer networks operands 60blt 8 words fig 6 central processor operating registers sum characteristics central processor remem ber broadbrush description ﬁconcurrent operationﬂ words program operating within central processor utilizes available concurrency program need written particular way although centainly optimiza tion done specific method accomplishing concurrency involves issuing many instructions possible handling conflicts execution essen tial requirements scheme include 1 many functional units 2 units three address properties 3 many transient registers many trunks units 4 simple efficient instruction set construction circuits 6600 computing system use alltransistor logic fig 7 silicon transistor operates saturation switched ﬁonﬂ averages five nanoseconds stage delay logic circuits constructed cordwood plugin module 2y2 inches 21 inches 08 inch average 50 transistors contained modules memory circuits constructed plugin module six inches six inches 2 inches fig 8 memory module contains coincident current memory 4096 12bit words readwrite drive circuits bit drive circuits plus address trans lation contained module one module used peripheral processor five modules make one bank central memory logic modules memory modules held upright hinged chassis x shaped cabinet fig 9 interconnections modules chassis made twisted pair transmission chapter 39 parallel operation control data 6600 495 fig 7 6600 printed circuit module lines interconnections hetween chassis made coaxial cables maintenance operation accomplished pro grammed display console fig 10 one consoles may included system desired dead start facilities bring fig 8 6600 memory module fig 9 6600 main frame section fig 10 6600 display console 496 part 5 pms level section 4 1 network computers computer networks ten peripheral processors condition allows infor mation enter chosen peripheral device loads normally bring operating system provides highly sophisticated capability multiple users maintenance 6600 computer taken advantage certain technology advances particularly logic organization advances appear quite successful control data exploring advances technology upward within compatible structure identical technology downward also within compatible structure references allarm clayb64 chapter 39 parallel operation control data 6600 497 appendix 1 central processor isp description cdc 6400 6500 6600 appendix coc 6400 6500 6600 central processor isp description pc state p170 x07590 ao7il7 0 boll70 0 e 717 run em4 7 address gutofrangernode emi 2 operandgutaf rangeurnode em13 lndef ini teaperandurnode em14 description incomplete tha alarm condition occurs mode one mp state mp 7777778 169o ms 0 2015232 169 0 rai 7 fli 70 raecsb936 fleck59 36 addressaut df range memoru mannina process program counter main arithmetic registers xl15 implicitly loaded x671 implicitly stored mp al5 loaded mp a67 zoaded index registers b registers general arithvetic registers used 1 interpreting instructions program control exit mode bits modes alarm allow conditions trap pc mpra trapping occurs main core memory 218 w 256 kwj ecsextended core storage program transfer data reference relocation address register map logical mp field length bounds register limits programs reference relocation register ms extended core storage field length ecs bit denoting state memory mapping invalid mp ms physical mp access range mp program executed ms process maps relocates logical program location mp msinto physical mp ms mpx x fl impx ral logical mp x 5 fl run addressyoutdfurange 1 msx x flecs msxl raecsi logical ms x 2 flecs run addressoutofrange 1 ezchange juq storage allocation map locotion n within wp following mp array reserved pc state stored switched another job peripheral control processor enacts operation exchange instruction imp mp mp mp mp n53 0 mpn1530 raoallobil mp n253 0 floa2ob2 mp n353 0 emoa 3ob3 mpn4 raecsoa4ob4 mpn5 flecsoa5ob5 mp n635 0 6ob 61 mpn7135 0 a7lob 71 hpnlo ni781 xo7 poa 0300000008 8 498 part 5 1 pms level section 4 network computers computer networks instruction format instructionq90 frndo instructionq924 frni 8 fmoi iqo instructionq321 jqo instructionq0lb kq instructionl715 jkdo jok k170 instruct ionl70 longinstruction fm log v 50 fm 53 v 60 fm 63 v 70 fm 73 shortjnstruction long instruction although 30 bits instructions 15 bits see operation code function extended op code specifies register extension op code specifies register specifies register shift constant 16 bits 18 bit address size constant 30 bit instruction instruction interpretation process 15 bit instruction instruction interpretation process 15 bit short 30 bit long instruction fetched mppq x 15 f 15 1p x 19 p 3 2 1 0 bit instruction stored across word boundaries 2 mp locations 30 pointer 15 bit quarter word instruction pl4 run instructionq915 mppp x 15 14p x 15r next fetch p tp next p 0 iongjnstruction run p 0 longinstruction instructionl40 tmppip x 15 14p x 15 p tp next instructionexecution next execute p 0 p 3 p tp instruction set instruction execution process fd tppjalir oeeurs z 61 2 store made moaill description describe addressbutofrange ease ilhzc treated like null operation etches stores betueen mp xi occur loading storing registers alii 10 c 61 fetch nstructionexecution set sa sa j k fm 50 ai caj k next fetchdtore sa j k fm 51 ai 1 tbj k next fetchdtore sa xj 11 fm 52 ai txjl170 k next fetchstore sa xj bk fm 53 ai 1 xjd7n bk next fetchstore sa j bk fm 54 ai taj bk next fetchstore sa bkl fm 55 ai taj bk next fetchdtore sai bj bk frn 56 tbj bk next fetchstore sai bj bk fm 57 ai tbjj ek next fetchjtore fetchstore 0 6 xil tmpaill 2 6 mphi c xi operations b x set b vsbi sbi aj k frn 60 3 e jl k process get operand x store operand x uhen written chapter 39 parallel operation control data 6600 499 sbi bj k fm 61 4 bil bjl k sbi xj k fm 62 f bil txj117b k sbi xj bk fm 63 bi xjl7lb bkl sbi aj bk fm 64 bil ajl bckl sbi aj ek fm 65 bcil ajl bckl sbi bj bk fm 66 bil bjl blkl sbi bj bk fm 67 bcil bjl bkl set xilsxi sxi aj k fm 70 4 x 11 signextendaj sxi bj k fm 71 f x 11 signextendbj sxi xj k fm 72 f x il signextendxj sxi xj bk fm 73 f x il signextendxj sxi aj bk fm 74 x il signextendaj sxi aj bk fm 75 x il signgxtendaj sxi bj bk fm 76 x c signxtendbj sxi bj bk fm 77 x csignxtendbj miscellaneous program controz psi fm 0 run 0 fm 46 dunp unconditiowl program stop operation pass jp bi k frn 02 p sy k p 3 jump jwnp xj conditions zr xj k fmi 030 xj 0 p tk p 3 nz xj k fmi 031 xjl 0 p ck p 3 pl xj k fmi 032 f xcj z 0 f p k p t3 pig xj k frni 033 xj 0 p k p t3 ir xj k fmi 034 zero non zero pius 011 position negutiue range constant tests yjm54e 3777 xjl948 40no p k p 3 xj k fmi 035 xjl69483777 v xcj169484000 p k p 3i indefinite form constant tests df xj k fmi 036 xlj16948hl777 v xcji89486000 p k p 3 id xj k fmi 037 xcjlb948hl777 v xj18948x6000 p k p t3 jwnp b 1 b lj comparison eq bi bj k frn 04 bi bj p tk p c3 equal ne bi bj k fm 05 bj1 rp k p 3 equaz ge bi bj k frn 06 bil 2 bjl p k p 3 greater qua2 lt bi bj k fm 07 bcil bcj1 p k p 3 less rj k frni 010 return jump subroutine call mkibp 04rnoo mooooo next p tk 1 p 3 rec bj k fmi 011 peading recl writing weci mp extended core storage subjeced bounds checks mp mapping read extended core 500 part 5 pms level section 4 network computers computer networks mpanlao bjl ki tmsxoxoi bj k11 wc bj k fmi 012 write extended core msxoixo bjl ki1 mpcaolaol bjl k11 fixed point arithmetic logical operations using x ixi xj xk fm 35 xil txjl xkl ixi xj xk fm 37 xil txcj1 vkl rxi xk fm 47i xil csurnnodulo2xkl rxi xj fm 10 xil xjl bxi xj 2 xk fm 11 ixil txil xjl hxki 8 bxi xj xk fm 12 xcil txj v xkl rxi xj xk fm 13 ixil txji xkl bxi xk f fm 14 xci 7 xkl 8 rxi xk xj fm l5i xi txjl 7 xkl bxi yk xj fm 16i xi txj v xk bxi xk xj fm 17 xi txcj xk lxi jk fm 20 ixil txcil x zjk rotate axi jk fm 21 xi cxi 2jk xi bj xk fm 22 rj17 ixi txkl x ebcj1550 rotate rj17 xil cxck1 z7 bjllo axi bj xk fm 23 j17 ixicxk 2bj1loo bj17 ixi txk x z1 bj15 rotate mxi jk fm 43 xi5959jkl 2jk 1 jk n ixil 0 integer sum integer difference count number bits xk transmit logical product logical sm logical difference transmit complement logical product complement logical sun complement logical difference complement arithmetic right shift left shift nominally arithmetic right shift nominally form mask floating point arithmetic using x onlu least significant 70 part arithmetic stored floating dp operations fxi xj xk fm 30 xil txjl xkl sf fxi xj xk fm 31 xil txjl xkl sf nxi xj xk fm 32 xiil txjl xckl lsdf1 floating dp sum nxi xj yk fm 33 xil txjl xkl lsdf floating dp difference rxi xj xk fm 34 floating sum floating difference xcil c roundxcj1 roundxkl sf round floating difference rxi xj xk fm 35 xi c roundxj roundxkl sf fxi xj xk fm 40 x xj x xk sf rxi xj xk fm 41 round floating product floating product xi xj x xk sf next xil troundxci1 sf dxi xj xk fm 42 xi txjl x xk lsdfl floating dp product fxi xj xk fm 44 xi xj xkl sf rx xj xk f fm 45 xi roundxj xk sf round floating divide f bating divide normalize nxi rj xk fm 24 xi tnormalizexkl sf rj c normalizeexponentxkl sf chapter 39 1 parallel operation control data 6600 501 zxi bj xk fm 25 l round normazize xi c roundxk sf next x 1 c normal izex il sf b j normal izeexponent x 1 sf uxi bj xk fm 26 3 bj cxk5848 si unpack xi txk59470 si pxi bj xk fm 27 xk1584b bcjl si pack xk5947rd cxil si end instmctionusxecution 502 part 5 pms level section 4 network computers computer networks appendix 2 peripheral control processors pcp isp description cdc 6400 6500 6600 6416 appendix 2 cdc 6400 6500 6600 6416 peripheral control processorspcp isp description pc state a17 accmlator pl progrm address counter e5 state m040951110 4 index063111c mo6311d soecial arrau pe reserved index register ccentra1 state cpup17 e cpmo7777778159o main pc instruction address counter mp main c io registers ci pcpi coatao63ilo cactc 0 633 lflgo631 denotes full emptgl buffer k cfcn0631 data buffers peripheral ks bit denote ip 1 64 ks active function instruction register specific k instruction format ins 0 1 1 cb instruction 2 w instruction defined terms op codes see table page 50 longi nstruct shortinstruction 7 longinstruction 1 zl instruction k5d lns0116 function op code dc5d ins05o m110 insl address dart drkl70 dm ill lo inall 1 0 indirect bit dsignl 7d5 ood d5 l mdlio 0 tn 0 mdl effective address calculation process z f59 3 id f59 4 f5p 5 f rnd instruction inteqjretation process run lnsol cmlp1 p tp 1 next fetch iongoinstruction inscil mepi p tp next lnst ruct ionexecution execute chapter 39 parallel operation control data 6600 503 scn atam implementation io x 52 bits barrel io pc include ldn atd a09170 po9il temporary ffardware registers ispl qo3lll 0 ko 915 9 12 lmc 4 aadm accumulators instruction address counters psn null low order 6 bits instructim address data six bits hold operation code 3 bits specif trip count state instructions interpretation instruction execution f xsy8 8 00 psn 1 nu 7 7 shn aax2l igr x 8 00 io 20 30 40 50 60 70 06 pjn 7 a47 07 mjn a17 ljm pi md rjm mcmd tp pc mdl lmn aad lpn acaad sen acad lcn adni ad lpc ataadm psn exn cpypa adc aadm rpn acpp sed 1 a00 7 sbi 7 rai 401 sbm bcamz cwd cpm 1 md d5 adm crm mmm sxmdll cpmaa mldl11 acmz next z ejm 7 cflg c ijm pcm 7 cact fjm cvflg cwm cpm 3 mmm 5xmdil oam 4 7 cjlg 1 cydata 1 mmrnal ajm cdxtcdl ian cdatadl iam cflgd li cdatad 1 dan cudatadl c fan cfcnd acn f dcn cactd 1 end instructionqxecution 1 uord shortinstruction chapter 40 computernetwork examples entering era generalpurpose networks computers make technical economic sense requisite hardware software development operating systems multiprogramming capability still maturing thus unlike pms structures discussed book supply operational systems published descriptions upon draw consequently assembled several brief examples networks provide least illustrations sure important aspect computer systems near future interesting examples still planning stages exist currently still highly specialized spatially distributed intercommunicating networks digital devices existed long time many ones come easily mind computer networks example various airline reservation systems like american airlines sabre plugge perry 19611 spatially distributed termi nals ts single pc possibly mediated pios cios several pcs functionally integrated provide total capacity reliability needed military networks sage air defense system everett et al 19571 multiple computers sage actually large number transmit highly specialized data streams example aircraft positional information con trol national physics laboratory england made comprehensive proposal generalpurpose network davies et al 19671 although include chapter proposal stage lawrence radiation laboratory livermore doubt earliest impressive net work terms pms descriptions computer network n requires least two cs connected primary memory thus c pc mp communi cate cs messages duplex computers thus defined networks provided share mp networks links ls usually shown explicitly spatially distributed systems time delays flow rates links significant latter partly networks must make use telephone communication system exists inde pendently networks thus parameters correspond internal parameters individual computers may also limitations reliability cost accessing characteristics size information unit derive wholly links instance many computer net works would like buy transmissions telephone system short intervals milliseconds high data rates short switching time milliseconds le bursts switching time pricing policies within telephone system conspire make difficult thing thus networks links become important independent components one classification networks ns fixed variable interconnection structure fixed structure may mean links fixed permanently life network however fixed structure may mean connections made must held long periods time relative message flows example telephone switching system mentioned looks like variable switching structure level human conversations like fixed switching structure level computer conversations figures la ic show variable structure systems fig lb shows fixedstructure system former c talk directly c latter c talks directly cs thus communicate cs must transmit links must use another c l second classification ns nature delays suffered messages travel initiating c target c communication direct case delays switches links l two cs figs la lb alternatively communication involve storing messages intermediate nodes called storeand forward communication thus introducing additional memory delays communication decreasing demands coordination two cs although storeandforward systems built intermediate nodes ks buffer memories present context natural form system uses cs system intermediate nodes fig ic several kinds reasons justify existence particular network following list adapted roberts 1967 load sharing problem program data initiated one c temporarily overloaded sent another processing cost transshipment must clearly less costs 504 chapter 40 computernetwork examples 505 c fig la variablestructure direct switching network pms diagram delay getting problem processed load sharing implies highly similar facilities nodes network data sharing program run node access large specialized data base specialized automated library less costly bring program data bring data program program sharing data sent c specialized program might happen size program hence fundamentally reason data sharing might also happen knowledge ie initialization error rituals run program available one c another specialized facilities within network need exist one various rarely used facilities large randomaccess memories special display devices specialpurpose array processors cl kl fig lb fixednetwork pms diagram fig ic storeandforward network pms diagram using c switching message switching may communication task magnitude sophisticated switching control worth reliability components fail others used place thus permitting total system degrade gracefully present state art peripheral computers needed isolate periphery unreliability network vice versa peak computing power large parts total system devoted short periods single task important realtime constraints met depends able fractionate task independent subtasks communication multiplexing efficient use communication fa cilities obtained multiplexing number low datarate users example ttypewriter 150 bss may reason network per se may justify larger network provided reason one first place better communication community users eg scientific engineering community could mutually use pro grams data bases converse directly ie writing context mutual use might become much productive community less duplication work faster communication results etc better load distribution preprocessing tasks require highdatarate communication computer preprocessing smaller computer reduced information rate sent general system general view networks let us consider several examples 506 part 5 1 pms level msdisk lsmagnetic tape rﬁ mpl 5megabyte pie pcibm system360 model 40 50 tcard tl ne printer typewri ter section 4 network computers computer networks zbm asp attached support processor first example fig 2 simplest computer networks consisting two computers tied together functionally specialized addition required physically close function csupport job setup breakdown pre processing postprocessing ts network handled except txonsole cmain function cmain process data thus escalated version pcn pi0 organization pios made csupport thus take additional functions compared cdc 6600 organization cmain10 cio cios rather small cio4096 w 12 bw compared csupport asp organization 360 analog system consisting ibm 7090ibm 7040 emerged spontaneously early sixties several ibm installations order deal 7090 10 bottlenecks thus kind simple computer network us time detail advantages claimed asp reducing resource interferencel adapted ibm system360 attached support processor asp system description h2002230 c n fig 2 ibm system360 attached support processor systemasp pms diagram addition smaller modules mp form second processor processing application di vided main processor support proces sor performing functions best suited core requirements support processor small comparison main processor division responsibilities system expand capabilities minimum addition storage elimination concurrent use pc time main processor processing support functions printing clerical functions assigned support processor main processor longer shares pc time support functions application pro grams therefore application opportunity use resources main processor fiill capacity addition selector channels channel capacity system increased one additional selector channels attached support processor algorithm efficient management directaccess storage devices system inputoutput data sets algorithm designed specifically accommodate data demands data set characteristics available private devices inputoutput routines always know position access mechanism thereby ensuring mini mum seek time data transferred devices ibm cites reasons using asp system views differ usefulness ideally multipro grammed singleprocessor multiprocessor structure would easily provide advantages without overhead large mps two computers hold nearly operating system also note introduction systems60 page 584 supportcomputer functions handled main computer little loss large pc power 3 10 percent multiprocessor structure also cause less overhead passing data sets two cs alternatively asp could done common ms cs university texas network structure shown fig 3 similar asp cmain used job setup breakdown done several cs however several cs provide independent power small tasks setup time large system greater computation time also physically remote cmain thus serve make power central facility available local sites teletypes chapter 40 computernetwork examples 507 e etype telephone exchange cdc 6600 computation center ielephone exchange l ccdc 1700 linquistic research laboratory l ccdc 3100 college business administration l c8231 computer terminal card t1ine printer e lto cs campus fig 3 computation center university texas austin network pms diagram used enter jobs directly cmain run batch mode network fig 3 university texas derived internal planning memoranda similar systems existence construction universities mz proposed network figure 4 shows network proposed mit campus bhushan stotz ward 19671 moves complex switching system partly two cmains sdirect used nonstoreandforward mode c communicates directly another communication rate cs 40 230 kbs note higher data rates fairly large computer necessary handle storeand forward message switching information rates purpose network allow users small terminal cs get access c1bm 36067 cge645 two cs course communicate one another large number users connected ttypewriters via ste1ephone ex change lawrence radiation laboratory livermore network lrl network started 1964 appears earliest generalpurposecomputer network serves user population approximately 1000 several hundred simultaneous line users network consists five large computers three cdc 6600s two cdc 7600s switching computer dec pdp6 two pcs ant1 262 kword mp 10bit fixed head disk fastaccess files three terminal control com puters dec pdp8s large central file 1012bit ibm photostore controlled ibm 1800 computer hardwired 4 megabit per second links connect large computers switching computer terminal computers large file also connected switching computer main purpose network gain access central filing printing terminal facilities load sharing important consideration large computers operates nearly autonomously thus little change required system integrated network jobs enter net work three waysby batch input terminals large computer typewriter inputs large computer typewriter inputs terminal control computer turn connects central switch unlike uni versity computation centers provide service many users small jobs lrl network oriented users multiple large jobs storage crt display keyboard dataphone 12 il8 kbs 3 3 i5 chars dataphone 1 dataphone tdataphone dataphone c satel 1 te crt display 3 ste1ephone exchange swideband communications center 408 2304 kbs io 15 charsl2 48 kbs fig 4 m1tnetwork pms diagram proposed 508 part 5 pms level section 4 network computers computer networks dudlexed file cs sharing common secondary memory long term filing ______ ___ csf m5 c sf mstl r3 1 lzcrt console 1 ln csf ms u concentrators high speed message special systems store forwardsf ls fsx main processors secondary memory ms s50 180 bec s600 4800 bec 3s40 50 kbec s200 2000 kbsec fixed ixed telephone exchange direct csw 3 l 200 2000 kbs l40 50 kbs 600 4800 b5 __ l50 180 b5 icsf msfl console ttcard lines analoq plot message concen trators speciall systems store forwardsf lcard line plot teletype 3 u network periphery fig 5 typical computer network pms diagram typical local network summarize fig 5 direction last three networks moving presenting hypothetical local network may mature many large university campuses large industrial establishments network conceived single computing facility serve clientele many heterogeneous partially overlapping computing needs essential feature environment network collection com puting resources connects planned keep growing changing imperfectly controlled ways arises quasiindependent nature subparts large uni versities engineering establishments event network mixture functionally independent functionally special ized cs one probable feature duplexed cfiles handle ms functions cs except c1ibrary librarys computer though strongly coupled network would files specialized terminals including hard copy devices oriented library needs cfile increases requirements scentra1 provides much economic ms well easing ability connect new cs system since immediately access organized ms reader note four switches ss either fixed links variable switches eg telephone exchange computer used direct switch storeandforward switch interesting aspect network general hierarchical structure like hierarchical organi zations levels organization based data rates example lowlevel computer deals basic communication typewriters 150 bs chapter 40 computernetwork examples 509 c switch concentrates several typewriters timemultiplexed 2400bs link several 2400bs links turn con centrated prior transmitting via 50kbs link thus general organizing principle like large organizations handle problems lowest cheapest possible level another organization principle hierarchy relevant infor mation passed levels example encoding would used fraction bits flowing periphery would enter highestlevel computers levels assume specialized timeshared computers employed handle simpler tasks editing simple calculations etc network periphery number terminal computers le ctermina1 crt card lines analog plot key board although computers behave terminals dec 338 chap 25 typical terminal class part periphery connects networks part connects specialized processes eg process control experimental apparatus dedicated basis peripheral computers able local tasks independently larger unreliable computers combat logistics networkcomlognet comlognet developed us air force early 1960s purpose sending messages information among ts segal guerber 19611 built transmit low ncomlognet lt5ubscriber stationss tte1etype compoun81 magnetic tape terminal4 see fiqure 6 3t1compound rlr5i 50 3 rs fcard readerj 300600 bs mbuffer tcard punch tel etype l 12002400 kmsmagnetic tape 4t maqnetic tape 1 termi na 1 4800 bs ms buffer c ncomlognet 1 distribution adu ii fig 6b combat logistics networkcomlognet component relationships n comlognet isc 1 sc ss2 comlognet inswitchin9 centersc see figure 6d zttsubscriber stationss see figure 6a fig 6a combat logistics networkkomlognet pms diagram fig 6c scomlognet pms diagram 510 part 5 pms level section 4 network computers computer networks 10 chars medium 1200 4800 bs speed shown fig 6a regard network simply message switch three terminal types employs cs switching elements fundamentally storeandforward system security reliability response time considerations would possible construct equivalent system using standard lease wire switches telephone exchanges fig c communications data processorcdp p reader 3 7tconsole ccdp tpaper tape reader msl 3 drum ms148 magnetic tape ltoc external tline printer sys tem consol e 3 ctape search unit mpcore 15 pw 8192 w 56 bw ctape search unittsu kstprinter mp data store pc 1 mp procedure 596 bw function code trans za 3c accumulation r ionadu k iz5 low k boo bs speed 0 601 l4 bs high speed 601 pon j 4link communications lines fig 6d comlognet n3witching centersc pms diagram 6b tree used present relationship constituent members comlognet see first level comlognet switch links terminals shown fig 64 networks switch employs five specialized nautomatic electronic switching centersscs communicate among fig 6c terminals connect individual nscs mes sages routed two ts either storeandforward process within nsc among two nscs individual nscs located five specific locations consist fixed computer configurations five seven cs structure nsc fig 64 formed basically duplex c structure handles processing attached two ccommunications data processorcdp two four cac cumulation distribution unitadu handle communi cationlink processing ctape search unit used line process data msmagnetic tape structures ccdp ctape search unit arid cadu defined within fig 6d arpa network1 experimental computer network fig 7a operational connects 19 computer facilities associated contractors information technology branch advanced research projects agency arpa contractors engaged advanced research computer science technology form community attempt generalpurpose network since several nodes network eg mit see fig 4 constructing networks sites system faced good many design problems associated network unlike many networks discussed chapter arpa network consists sites physi cally remote developing total systems independent management agreedupon func tional specialization visivis furthermore uses node make nodes fairly general ones cited beginning chapter generated general scientific community since many institutions tied major academic institutions diversity guaranteed motivation behind experiment reveal begin solve technical problems general net works also discovering several advantages using networks listed earlier others unmentioned emerge important specific links sites etc change time thus actual structures present nature experiment almost guaranteed error chapter 40 computernetwork examples 511 cdartmouth colleqe nu illinois santa barbara fig 7a advanced research projects agency arpa network pms diagram tentative c local c host c interface messaqe processorlmp 1 l408 kbs tonarpa fig 76 advanced research projects agency arpa localcomputer pms diagram technically goals network 1 make user site behave though another site 2 let c site use c another site load program data sharing site added special c1nterface message processorimp cimp designed creators network provides communality permit network function one constraint network design make small perturbations larger host computers c1mp responsible network messages among nodes ie c1mps interface network c n local site local computer chostc1mp interface shown figs 7h 7c nloca1 fig 7c advanced research projects agency arpa localcomputer network pms diagram tentative lodi cal forn ia li tt leton massachusetts smojave california xl 312 smanual50 kbs telephone switching centers 2xclocallnlocai n c may communicate directly one another using ls communicate via ss fig 7d advanced research projects agency arpa fixed switching centers pms diagrams tentative 512 part 5 pms level local computer local network cases respectively c1mp choneywell516 16 bw 12 16 kw 1 pw capability connect four six links 5okbs data rate arpa network leases set fixed links l50 kbs emanate four sfixed shown fig 7d thus fixed links various sites shown fig 7a composed links fig 7d example lcarnegie mellon university bolt beranak newman goes carnegie mellon university pittsburgh pa williamstown ky littleton mass one two links bolt beranak newman boston mass llitt1eton williamstown part luniversity michigan lincoln laboratory fixedlink system network must operate storeandforward fashion c1mps site carrying function thus c1mp required site since uniformity section 4 network computers computer networks cs site control operation conclusions feel network important computer structure book understanding able organize computing power structure achieve reliability issues switches links vital understanding computer structures improve references bhusa67 david67 everr57 plugw61 robel67 segar61 ibm systern360 attached support processor asp system description h2002230